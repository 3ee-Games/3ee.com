import{S as kv,i as Ev,s as bv,l as bf,g as f,E as W7,d as t,v as FA,e as a,t as o,c as l,a as r,h as n,b as i,G as e,j as ce,k as c,m as u,F as ee,H as Re,N as hA,Y as VA,J as Ut,f as Mt,Z as YA,_ as KA,$ as XA,q as Bt,o as Wt,O as ZA,w as lr,x as rr,y as ir,B as or,C as j7,z as QA,A as gA,a1 as mA}from"../../chunks/index-2a82a4a8.js";import{P as JA}from"../../chunks/_post-913f18eb.js";import{g as M7}from"../../chunks/config-201c2df4.js";import{a as U7}from"../../chunks/accountStore-3492c591.js";/* empty css                                                                   */import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function $A(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A;function S(L,H){return typeof L[2].title!="undefined"?sL:tL}let O=S(_),z=O(_);function Q(L,H){return typeof L[2].description!="undefined"?lL:aL}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&vA(_),C=typeof _[2].footer_description!="undefined"&&_A(_);return{c(){p=a("hr"),m=c(),g=a("div"),z.c(),h=c(),v=a("p"),k=a("ion-icon"),b=o("SpaceLab Content"),w=c(),F.c(),T=c(),B&&B.c(),x=c(),C&&C.c(),E=c(),y=a("button"),I=a("ion-icon"),P=c(),N=a("span"),G=o("SpaceLab"),this.h()},l(L){p=l(L,"HR",{}),m=u(L),g=l(L,"DIV",{class:!0});var H=r(g);z.l(H),h=u(H),v=l(H,"P",{class:!0});var Z=r(v);k=l(Z,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),b=n(Z,"SpaceLab Content"),Z.forEach(t),w=u(H),F.l(H),T=u(H),B&&B.l(H),x=u(H),C&&C.l(H),E=u(H),y=l(H,"BUTTON",{class:!0});var q=r(y);I=l(q,"ION-ICON",{class:!0,name:!0}),r(I).forEach(t),P=u(q),N=l(q,"SPAN",{});var R=r(N);G=n(R,"SpaceLab"),R.forEach(t),q.forEach(t),H.forEach(t),this.h()},h(){ee(k,"class","icon svelte-s12rf8"),ee(k,"name","lock-closed"),i(v,"class","highlight large svelte-s12rf8"),ee(I,"class","icon svelte-s12rf8"),ee(I,"name","planet"),i(y,"class","button subscribe svelte-s12rf8"),i(g,"class","subscribe svelte-s12rf8")},m(L,H){f(L,p,H),f(L,m,H),f(L,g,H),z.m(g,null),e(g,h),e(g,v),e(v,k),e(v,b),e(g,w),F.m(g,null),e(g,T),B&&B.m(g,null),e(g,x),C&&C.m(g,null),e(g,E),e(g,y),e(y,I),e(y,P),e(y,N),e(N,G),D||(A=Re(y,"click",_[15]),D=!0)},p(L,H){O===(O=S(L))&&z?z.p(L,H):(z.d(1),z=O(L),z&&(z.c(),z.m(g,h))),j===(j=Q(L))&&F?F.p(L,H):(F.d(1),F=j(L),F&&(F.c(),F.m(g,T))),typeof L[2].list_description!="undefined"?B?B.p(L,H):(B=vA(L),B.c(),B.m(g,x)):B&&(B.d(1),B=null),typeof L[2].footer_description!="undefined"?C?C.p(L,H):(C=_A(L),C.c(),C.m(g,E)):C&&(C.d(1),C=null)},d(L){L&&t(p),L&&t(m),L&&t(g),z.d(),F.d(),B&&B.d(),C&&C.d(),D=!1,A()}}}function eL(_){let p,m,g,h=_[2].title+"",v,k,b,w,T,x,E,y=_[2].description+"",I,P,N,G,D,A,S,O,z,Q,j,F,B,C=typeof _[2].list_description!="undefined"&&kA(_),L=typeof _[2].footer_description!="undefined"&&EA(_);function H(R,M){if(R[2].github_private_repo&&R[2].github_state==="LOG_EXISTS")return oL;if(R[2].github_private_repo&&R[2].github_state==="NO_LOGS")return iL;if(R[2].github_private_repo&&R[2].github_state==="NO_GITHUB_USERNAME")return rL}let Z=H(_),q=Z&&Z(_);return{c(){p=a("hr"),m=c(),g=a("h2"),v=o(h),k=c(),b=a("p"),w=a("ion-icon"),T=o("SpaceLab Content"),x=c(),E=a("p"),I=o(y),P=c(),C&&C.c(),N=c(),L&&L.c(),G=c(),D=a("button"),A=a("ion-icon"),S=c(),O=a("span"),z=o("Download"),Q=c(),q&&q.c(),j=bf(),this.h()},l(R){p=l(R,"HR",{}),m=u(R),g=l(R,"H2",{class:!0});var M=r(g);v=n(M,h),M.forEach(t),k=u(R),b=l(R,"P",{class:!0});var jt=r(b);w=l(jt,"ION-ICON",{class:!0,name:!0}),r(w).forEach(t),T=n(jt,"SpaceLab Content"),jt.forEach(t),x=u(R),E=l(R,"P",{class:!0});var Se=r(E);I=n(Se,y),Se.forEach(t),P=u(R),C&&C.l(R),N=u(R),L&&L.l(R),G=u(R),D=l(R,"BUTTON",{class:!0});var fe=r(D);A=l(fe,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),S=u(fe),O=l(fe,"SPAN",{});var xf=r(O);z=n(xf,"Download"),xf.forEach(t),fe.forEach(t),Q=u(R),q&&q.l(R),j=bf(),this.h()},h(){i(g,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","planet-sharp"),i(b,"class","highlight large svelte-s12rf8"),i(E,"class","svelte-s12rf8"),ee(A,"class","icon svelte-s12rf8"),ee(A,"name","cloud-download"),i(D,"class","button svelte-s12rf8")},m(R,M){f(R,p,M),f(R,m,M),f(R,g,M),e(g,v),f(R,k,M),f(R,b,M),e(b,w),e(b,T),f(R,x,M),f(R,E,M),e(E,I),f(R,P,M),C&&C.m(R,M),f(R,N,M),L&&L.m(R,M),f(R,G,M),f(R,D,M),e(D,A),e(D,S),e(D,O),e(O,z),f(R,Q,M),q&&q.m(R,M),f(R,j,M),F||(B=Re(D,"click",_[10]),F=!0)},p(R,M){M&4&&h!==(h=R[2].title+"")&&ce(v,h),M&4&&y!==(y=R[2].description+"")&&ce(I,y),typeof R[2].list_description!="undefined"?C?C.p(R,M):(C=kA(R),C.c(),C.m(N.parentNode,N)):C&&(C.d(1),C=null),typeof R[2].footer_description!="undefined"?L?L.p(R,M):(L=EA(R),L.c(),L.m(G.parentNode,G)):L&&(L.d(1),L=null),Z===(Z=H(R))&&q?q.p(R,M):(q&&q.d(1),q=Z&&Z(R),q&&(q.c(),q.m(j.parentNode,j)))},d(R){R&&t(p),R&&t(m),R&&t(g),R&&t(k),R&&t(b),R&&t(x),R&&t(E),R&&t(P),C&&C.d(R),R&&t(N),L&&L.d(R),R&&t(G),R&&t(D),R&&t(Q),q&&q.d(R),R&&t(j),F=!1,B()}}}function tL(_){let p,m;return{c(){p=a("h2"),m=o(_[0]),this.h()},l(g){p=l(g,"H2",{class:!0});var h=r(p);m=n(h,_[0]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&1&&ce(m,g[0])},d(g){g&&t(p)}}}function sL(_){let p,m=_[2].title+"",g;return{c(){p=a("h2"),g=o(m),this.h()},l(h){p=l(h,"H2",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].title+"")&&ce(g,m)},d(h){h&&t(p)}}}function aL(_){let p,m;return{c(){p=a("p"),m=o(_[1]),this.h()},l(g){p=l(g,"P",{class:!0});var h=r(p);m=n(h,_[1]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&2&&ce(m,g[1])},d(g){g&&t(p)}}}function lL(_){let p,m=_[2].description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].description+"")&&ce(g,m)},d(h){h&&t(p)}}}function vA(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function _A(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function kA(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function EA(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function rL(_){let p,m,g,h,v,k;function b(x,E){return x[5]?cL:nL}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{class:!0});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[8]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function iL(_){let p,m,g,h,v,k;function b(x,E){return x[5]?fL:uL}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[7]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function oL(_){var A;let p,m,g,h,v,k,b=((A=_[6].profile)==null?void 0:A.githubUsername)+"",w,T,x,E,y,I,P,N,G,D;return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("p"),v=o("Your GitHub account "),k=a("span"),w=o(b),T=o(` is
			linked to this content.`),x=c(),E=a("button"),y=a("ion-icon"),I=c(),P=a("span"),N=o("Open Repository"),this.h()},l(S){p=l(S,"H2",{class:!0});var O=r(p);m=n(O,"Private GitHub Access"),O.forEach(t),g=u(S),h=l(S,"P",{class:!0});var z=r(h);v=n(z,"Your GitHub account "),k=l(z,"SPAN",{class:!0});var Q=r(k);w=n(Q,b),Q.forEach(t),T=n(z,` is
			linked to this content.`),z.forEach(t),x=u(S),E=l(S,"BUTTON",{class:!0});var j=r(E);y=l(j,"ION-ICON",{class:!0,name:!0}),r(y).forEach(t),I=u(j),P=l(j,"SPAN",{});var F=r(P);N=n(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(k,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(y,"class","icon svelte-s12rf8"),ee(y,"name","rocket-sharp"),i(E,"class","svelte-s12rf8")},m(S,O){f(S,p,O),e(p,m),f(S,g,O),f(S,h,O),e(h,v),e(h,k),e(k,w),e(h,T),f(S,x,O),f(S,E,O),e(E,y),e(E,I),e(E,P),e(P,N),G||(D=Re(E,"click",_[11]),G=!0)},p(S,O){var z;O&64&&b!==(b=((z=S[6].profile)==null?void 0:z.githubUsername)+"")&&ce(w,b)},d(S){S&&t(p),S&&t(g),S&&t(h),S&&t(x),S&&t(E),G=!1,D()}}}function nL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G;return{c(){p=a("p"),m=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),g=c(),h=a("label"),v=o("Github username:"),k=c(),b=a("input"),T=c(),x=a("button"),E=a("ion-icon"),y=c(),I=a("span"),P=o("Request Permission"),this.h()},l(D){p=l(D,"P",{class:!0});var A=r(p);m=n(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),g=u(D),h=l(D,"LABEL",{for:!0});var S=r(h);v=n(S,"Github username:"),S.forEach(t),k=u(D),b=l(D,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),T=u(D),x=l(D,"BUTTON",{class:!0});var O=r(x);E=l(O,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=u(O),I=l(O,"SPAN",{});var z=r(I);P=n(z,"Request Permission"),z.forEach(t),O.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"for","username"),i(b,"name","username"),i(b,"id","username"),i(b,"placeholder","enter a username"),i(b,"type","text"),b.required="true",i(b,"class",w=_[4]?"validation-error":""),ee(E,"class","icon svelte-s12rf8"),ee(E,"name","rocket-sharp"),i(x,"class","svelte-s12rf8")},m(D,A){f(D,p,A),e(p,m),f(D,g,A),f(D,h,A),e(h,v),f(D,k,A),f(D,b,A),hA(b,_[3]),f(D,T,A),f(D,x,A),e(x,E),e(x,y),e(x,I),e(I,P),N||(G=Re(b,"input",_[14]),N=!0)},p(D,A){A&16&&w!==(w=D[4]?"validation-error":"")&&i(b,"class",w),A&8&&b.value!==D[3]&&hA(b,D[3])},d(D){D&&t(p),D&&t(g),D&&t(h),D&&t(k),D&&t(b),D&&t(T),D&&t(x),N=!1,G()}}}function cL(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[13]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function uL(_){var I;let p,m,g,h=((I=_[6].profile)==null?void 0:I.githubUsername)+"",v,k,b,w,T,x,E,y;return{c(){p=a("p"),m=o("This content can grant access to a private GitHub repository. Allow "),g=a("span"),v=o(h),k=o(" access to this repo?"),b=c(),w=a("button"),T=a("ion-icon"),x=c(),E=a("span"),y=o("Request Permission"),this.h()},l(P){p=l(P,"P",{class:!0});var N=r(p);m=n(N,"This content can grant access to a private GitHub repository. Allow "),g=l(N,"SPAN",{class:!0});var G=r(g);v=n(G,h),G.forEach(t),k=n(N," access to this repo?"),N.forEach(t),b=u(P),w=l(P,"BUTTON",{class:!0});var D=r(w);T=l(D,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),x=u(D),E=l(D,"SPAN",{});var A=r(E);y=n(A,"Request Permission"),A.forEach(t),D.forEach(t),this.h()},h(){i(g,"class","highlight svelte-s12rf8"),i(p,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","rocket-sharp"),i(w,"class","svelte-s12rf8")},m(P,N){f(P,p,N),e(p,m),e(p,g),e(g,v),e(p,k),f(P,b,N),f(P,w,N),e(w,T),e(w,x),e(w,E),e(E,y)},p(P,N){var G;N&64&&h!==(h=((G=P[6].profile)==null?void 0:G.githubUsername)+"")&&ce(v,h)},d(P){P&&t(p),P&&t(b),P&&t(w)}}}function fL(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[12]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function dL(_){let p;function m(v,k){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?eL:$A}let g=m(_),h=g(_);return{c(){h.c(),p=bf()},l(v){h.l(v),p=bf()},m(v,k){h.m(v,k),f(v,p,k)},p(v,[k]){g===(g=m(v))&&h?h.p(v,k):(h.d(1),h=g(v),h&&(h.c(),h.m(p.parentNode,p)))},i:W7,o:W7,d(v){h.d(v),v&&t(p)}}}function B7(_){window.open(_,"_blank")||window.location.replace(_)}function pL(_,p,m){let{id:g}=p,{spacelabDefaultTitle:h="Spacelab Content"}=p,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=p,k={},b="",w=!1,T="",x;U7.subscribe(S=>{m(6,x=S)}),FA(async()=>{if(typeof(x==null?void 0:x.token)!="undefined"){const S=await fetch(`${M7().serviceUrl}/education/spacelab/${g}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors"});if(S.status===401){U7.set({}),U7.deleteLocalStorage();return}let O=await S.json();m(2,k=O)}else m(2,k.success=!1,k)});async function E(S){S.preventDefault();const O={};try{const z=await fetch(`${M7().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}async function y(S){if(S.preventDefault(),!b.trim()){m(4,w=!0),m(5,T="Please enter a valid GitHub username.");return}m(4,w=!1);const O={github_username:b};try{const z=await fetch(`${M7().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}const I=()=>window.open(k.url,"_blank"),P=()=>B7(`https://github.com/${k.github_repo_name}`),N=()=>B7(`https://github.com/${k.github_repo_name}`),G=()=>B7(`https://github.com/${k.github_repo_name}`);function D(){b=this.value,m(3,b)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=S=>{"id"in S&&m(9,g=S.id),"spacelabDefaultTitle"in S&&m(0,h=S.spacelabDefaultTitle),"spacelabDefaultContent"in S&&m(1,v=S.spacelabDefaultContent)},[h,v,k,b,w,T,x,E,y,g,I,P,N,G,D,A]}class hL extends kv{constructor(p){super(),Ev(this,p,pL,dL,bv,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const gL=_=>({}),bA=_=>({});function mL(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function vL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P;const N=_[7]["slider-label"],G=VA(N,_,_[6],bA),D=G||mL();return{c(){p=a("div"),m=a("img"),h=c(),v=a("img"),b=c(),w=a("label"),T=a("span"),D&&D.c(),x=c(),E=a("input"),this.h()},l(A){p=l(A,"DIV",{class:!0,style:!0,"data-testid":!0});var S=r(p);m=l(S,"IMG",{src:!0,alt:!0,class:!0}),h=u(S),v=l(S,"IMG",{src:!0,alt:!0,class:!0}),b=u(S),w=l(S,"LABEL",{class:!0});var O=r(w);T=l(O,"SPAN",{class:!0});var z=r(T);D&&D.l(z),z.forEach(t),x=u(O),E=l(O,"INPUT",{type:!0,min:!0,max:!0,class:!0}),O.forEach(t),S.forEach(t),this.h()},h(){Ut(m.src,g=_[0])||i(m,"src",g),i(m,"alt",_[1]),i(m,"class","left-img svelte-1po6qlg"),Ut(v.src,k=_[2])||i(v,"src",k),i(v,"alt",_[3]),i(v,"class","right-img svelte-1po6qlg"),i(T,"class","visually-hidden svelte-1po6qlg"),i(E,"type","range"),i(E,"min","0"),i(E,"max","100"),E.value=_[4],i(E,"class","svelte-1po6qlg"),i(w,"class","svelte-1po6qlg"),i(p,"class","svelte-compare-image-container svelte-1po6qlg"),Mt(p,"--slider-position",_[4]+"%"),i(p,"data-testid","svelte-compare-image")},m(A,S){f(A,p,S),e(p,m),e(p,h),e(p,v),e(p,b),e(p,w),e(w,T),D&&D.m(T,null),e(w,x),e(w,E),y=!0,I||(P=[Re(E,"input",_[5]),Re(E,"change",_[5]),Re(E,"click",_L)],I=!0)},p(A,[S]){(!y||S&1&&!Ut(m.src,g=A[0]))&&i(m,"src",g),(!y||S&2)&&i(m,"alt",A[1]),(!y||S&4&&!Ut(v.src,k=A[2]))&&i(v,"src",k),(!y||S&8)&&i(v,"alt",A[3]),G&&G.p&&(!y||S&64)&&YA(G,N,A,A[6],y?XA(N,A[6],S,gL):KA(A[6]),bA),(!y||S&16)&&(E.value=A[4]),(!y||S&16)&&Mt(p,"--slider-position",A[4]+"%")},i(A){y||(Bt(D,A),y=!0)},o(A){Wt(D,A),y=!1},d(A){A&&t(p),D&&D.d(A),I=!1,ZA(P)}}}function _L(_){_.target.focus()}function kL(_,p,m){let{$$slots:g={},$$scope:h}=p,{imageLeftSrc:v=""}=p,{imageLeftAlt:k=""}=p,{imageRightSrc:b=""}=p,{imageRightAlt:w=""}=p,T=50,x=null;function E(y){x&&cancelAnimationFrame(x),x=requestAnimationFrame(()=>{m(4,T=y.target.valueAsNumber)})}return _.$$set=y=>{"imageLeftSrc"in y&&m(0,v=y.imageLeftSrc),"imageLeftAlt"in y&&m(1,k=y.imageLeftAlt),"imageRightSrc"in y&&m(2,b=y.imageRightSrc),"imageRightAlt"in y&&m(3,w=y.imageRightAlt),"$$scope"in y&&m(6,h=y.$$scope)},[v,k,b,w,T,E,h,g]}class EL extends kv{constructor(p){super(),Ev(this,p,kL,vL,bv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function bL(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function xL(_){let p,m,g,h;return m=new EL({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[bL]},$$scope:{ctx:_}}}),{c(){p=a("div"),g=a("div"),lr(m.$$.fragment),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);g=l(k,"DIV",{style:!0});var b=r(g);rr(m.$$.fragment,b),k.forEach(t),this.h()},h(){Mt(g,"display","contents"),Mt(g,"--handle-size","2.5rem"),Mt(g,"--handle-background-color","rgba(0, 0, 0, 0.6)"),Mt(g,"--handle-background-image",_[4]),Mt(g,"--handle-border-width","0.125rem"),Mt(g,"--slider-color","#ffffff"),Mt(g,"--slider-width","0.125rem"),i(p,"class","image-compare-container svelte-s79nww")},m(v,k){f(v,p,k),e(p,g),ir(m,g,null),h=!0},p(v,[k]){const b={};k&1&&(b.imageLeftSrc=v[0]),k&2&&(b.imageLeftAlt=v[1]),k&4&&(b.imageRightSrc=v[2]),k&8&&(b.imageRightAlt=v[3]),k&32&&(b.$$scope={dirty:k,ctx:v}),m.$set(b)},i(v){h||(Bt(m.$$.fragment,v),h=!0)},o(v){Wt(m.$$.fragment,v),h=!1},d(v){v&&t(p),or(m)}}}function yL(_,p,m){const g=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=p,{imageLeftAlt:v="left"}=p,{imageRightSrc:k="https://via.placeholder.com/512x512/00aaff/ffffff/"}=p,{imageRightAlt:b="right"}=p;return _.$$set=w=>{"imageLeftSrc"in w&&m(0,h=w.imageLeftSrc),"imageLeftAlt"in w&&m(1,v=w.imageLeftAlt),"imageRightSrc"in w&&m(2,k=w.imageRightSrc),"imageRightAlt"in w&&m(3,b=w.imageRightAlt)},[h,v,k,b,g]}class _v extends kv{constructor(p){super(),Ev(this,p,yL,xL,bv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function wL(_){let p,m;return p=new hL({props:{id:SL,spacelabDefaultTitle:DL,spacelabDefaultContent:AL}}),{c(){lr(p.$$.fragment)},l(g){rr(p.$$.fragment,g)},m(g,h){ir(p,g,h),m=!0},p:W7,i(g){m||(Bt(p.$$.fragment,g),m=!0)},o(g){Wt(p.$$.fragment,g),m=!1},d(g){or(p,g)}}}function TL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A,S,O,z,Q,j,F,B,C,L,H,Z,q,R,M,jt,Se,fe,xf,Cp,nr,xv,Gp,Ft,Vt,yf,yv,Hp,cr,wv,qp,qa,ur,Tv,Mp,Ma,Up,fr,Rv,Bp,dr,Sv,Wp,pr,Dv,jp,At,hr,De,gr,Av,Lv,mr,Iv,Pv,vr,Ov,zv,Ae,Le,_r,wf,Nv,Cv,kr,Gv,Hv,Er,qv,Mv,Ie,br,Tf,Uv,Bv,xr,Wv,jv,yr,Fv,Vv,Pe,wr,Rf,Yv,Kv,Tr,Xv,Zv,Rr,Qv,Fp,Sr,Jv,Vp,Dr,$v,Yp,Ua,Ar,e2,Kp,Yt,Kt,Sf,t2,Xp,Ba,Df,s2,a2,Zp,Wa,Af,l2,r2,Qp,ja,Lf,i2,o2,Jp,Xt,Zt,If,n2,$p,Fa,Pf,c2,u2,eh,Va,Of,f2,d2,th,Ya,zf,p2,h2,sh,Qt,Jt,Nf,g2,ah,Ka,Cf,m2,v2,lh,Oe,_2,Gf,k2,E2,Hf,b2,x2,rh,ze,Lr,qf,y2,w2,T2,Ir,Mf,R2,S2,D2,$t,Uf,A2,L2,Pr,I2,P2,ih,Xa,Or,O2,oh,es,ts,Bf,Wf,z2,nh,zr,N2,ch,Ne,Nr,jf,C2,G2,H2,Cr,Ff,q2,M2,U2,Gr,Vf,B2,W2,uh,ss,as,Yf,Kf,j2,fh,Lt,Hr,Ce,qr,Xf,F2,V2,Mr,Zf,Y2,K2,Ur,Qf,X2,Z2,de,Ge,Br,Jf,Q2,J2,Wr,$2,e_,jr,t_,s_,He,Fr,$f,a_,l_,Vr,r_,i_,Yr,o_,n_,qe,Kr,ed,c_,u_,Xr,f_,d_,Zr,p_,h_,Me,Qr,td,g_,m_,Jr,v_,__,$r,k_,dh,ls,rs,sd,E_,ph,It,ei,is,ti,b_,x_,si,y_,w_,pe,os,ai,ad,T_,R_,li,S_,D_,ns,ri,ld,A_,L_,ii,I_,P_,cs,oi,rd,O_,z_,ni,N_,C_,us,ci,id,G_,H_,ui,q_,hh,fi,M_,gh,fs,ds,od,U_,mh,Za,yA=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,vh,Qa,wA=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,_h,ps,hs,nd,B_,kh,Pt,di,Ue,pi,W_,j_,hi,F_,V_,gi,Y_,K_,he,Be,mi,X_,Z_,vi,Q_,J_,_i,$_,e1,We,ki,t1,s1,Ei,a1,l1,bi,r1,i1,je,xi,o1,n1,yi,c1,u1,wi,f1,d1,Fe,Ti,p1,h1,Ri,g1,m1,Si,v1,Eh,bh,xh,gs,ms,cd,_1,yh,vs,k1,Ja,E1,b1,wh,_s,ks,ud,x1,Th,Es,y1,$a,w1,T1,Rh,el,TA=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,Sh,bs,xs,fd,R1,Dh,Ve,dd,S1,D1,pd,A1,L1,hd,I1,Ah,ys,ws,gd,P1,Lh,Ye,md,O1,z1,vd,N1,C1,_d,G1,Ih,Ts,Rs,kd,H1,Ph,tl,Ed,q1,M1,Oh,sl,RA=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,zh,Ss,Ds,bd,U1,Nh,Ke,xd,B1,W1,yd,j1,F1,wd,V1,Ch,al,Di,Y1,Gh,As,Ls,Td,K1,Hh,ll,Rd,X1,Z1,qh,Ai,Q1,Mh,Xe,rl,J1,Li,$1,ek,tk,Sd,sk,ak,Dd,lk,Uh,il,Ii,rk,Bh,Is,Ps,Ad,ik,Wh,ol,Ld,ok,nk,jh,nl,SA=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Fh,Pi,ck,Vh,Ze,Id,uk,fk,Pd,dk,pk,Od,hk,Yh,cl,Oi,gk,Kh,Os,zs,zd,mk,Xh,Ns,vk,Nd,_k,kk,Zh,ul,DA=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,Qh,fl,AA=`<code class="language-python"><span class="token comment"># Cosine Annealing Example</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>
    optimizer<span class="token punctuation">,</span>
    T_max<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># Number of iterations per cycle</span>
    eta_min<span class="token operator">=</span><span class="token number">1e-7</span>  <span class="token comment"># Minimum learning rate</span>
<span class="token punctuation">)</span></code>`,Jh,dl,Cd,Ek,bk,$h,Qe,Gd,xk,yk,Hd,wk,Tk,qd,Rk,eg,Ot,zi,ge,Ni,Sk,Dk,Ci,Ak,Lk,Gi,Ik,Pk,Hi,Ok,zk,le,me,qi,Nk,Ck,Mi,Gk,Hk,Ui,qk,Mk,Bi,Uk,Bk,ve,Wi,Wk,jk,ji,Fk,Vk,Fi,Yk,Kk,Vi,Xk,Zk,_e,Yi,Qk,Jk,Ki,$k,eE,Cs,tE,Md,sE,aE,lE,Je,rE,Xi,iE,oE,Zi,nE,cE,uE,ke,Qi,fE,dE,Ji,pE,hE,$i,gE,mE,eo,vE,_E,Ee,to,kE,EE,so,bE,xE,ao,yE,wE,lo,TE,tg,sg,ag,Gs,Hs,Ud,RE,lg,qs,SE,ro,DE,AE,rg,ue,LE,io,IE,PE,oo,OE,zE,no,NE,CE,co,GE,ig,uo,HE,og,Ms,Us,Bd,qE,ng,$e,Wd,pl,jd,ME,UE,BE,WE,Fd,hl,Vd,jE,FE,VE,YE,Yd,gl,Kd,KE,XE,ZE,cg,ml,ug,Bs,Ws,Xd,QE,fg,js,JE,vl,$E,eb,dg,et,tb,fo,sb,ab,po,lb,rb,pg,J,Zd,ho,ib,go,ob,nb,Qd,_l,cb,mo,ub,fb,db,Jd,Y,pb,vo,hb,gb,_o,mb,vb,ko,_b,kb,Eo,Eb,bb,bo,xb,yb,xo,wb,Tb,yo,Rb,Sb,wo,Db,Ab,$d,$,Lb,To,Ib,Pb,Ro,Ob,zb,So,Nb,Cb,Do,Gb,Hb,Ao,qb,Mb,Lo,Ub,Bb,Io,Wb,jb,ep,K,Fb,Po,Vb,Yb,Oo,Kb,Xb,zo,Zb,Qb,No,Jb,$b,Co,ex,tx,Go,sx,ax,Ho,lx,rx,qo,ix,ox,tp,Mo,nx,Uo,cx,ux,sp,Fs,fx,Bo,dx,px,Wo,hx,hg,tt,gx,jo,mx,vx,Fo,_x,kx,gg,kl,mg,Vs,Ys,ap,Ex,vg,Vo,bx,_g,be,Yo,El,xx,yx,wx,Ko,bl,Tx,Rx,Sx,Xo,xl,Dx,Ax,Lx,Zo,yl,Ix,Px,kg,Ks,Xs,lp,Ox,Eg,Qo,zx,bg,Jo,Nx,xg,st,Zs,rp,Cx,Gx,$o,Hx,qx,Mx,at,ip,Ux,Bx,en,Wx,jx,tn,Fx,Vx,Yx,sn,op,Kx,Xx,yg,wl,LA=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,wg,Qs,Tl,Zx,an,Qx,Jx,$x,Rl,ey,ln,ty,sy,Tg,Js,rn,ay,on,ly,ry,Sl,iy,nn,oy,ny,Rg,$s,ea,np,cy,Sg,ta,uy,Dl,fy,dy,Dg,Al,sa,py,Ll,hy,gy,Ag,aa,la,cp,my,Lg,ra,vy,cn,_y,ky,Ig,Il,IA=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Pg,un,Ey,Og,Pl,PA='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',zg,lt,by,fn,xy,yy,dn,wy,Ty,Ng,rt,Ry,pn,Sy,Dy,hn,Ay,Ly,Cg,gn,Iy,Gg,ia,mn,Py,up,fp,Oy,zy,vn,Ny,dp,pp,Cy,Hg,_n,Gy,qg,Ol,zl,V7,Mg,oa,na,hp,Hy,Ug,zt,qy,kn,My,Uy,En,By,Bg,Nt,bn,re,xn,Wy,jy,yn,Fy,Vy,wn,Yy,Ky,Tn,Xy,Zy,Rn,Qy,Jy,Sn,ie,Dn,$y,e3,An,t3,s3,Ln,a3,l3,In,r3,i3,Pn,o3,Wg,On,n3,jg,Nl,OA=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Fg,U,zn,Cl,c3,Nn,u3,f3,d3,p3,Cn,Gl,h3,Gn,g3,m3,v3,_3,Hn,Hl,k3,qn,E3,b3,x3,y3,Mn,ql,w3,Un,T3,R3,S3,D3,Bn,Ml,A3,Wn,L3,I3,P3,O3,jn,Ul,z3,Fn,N3,C3,G3,H3,Vn,Bl,q3,Yn,M3,U3,B3,W3,Kn,Wl,j3,Xn,F3,V3,Y3,K3,Zn,jl,X3,Qn,Z3,Q3,J3,$3,Jn,Fl,e4,$n,t4,s4,a4,l4,ec,Vl,r4,tc,i4,o4,n4,Vg,ca,ua,gp,c4,Yg,sc,u4,Kg,Yl,Xg,fa,da,mp,f4,Zg,pa,d4,Kl,p4,h4,Qg,ha,g4,ac,m4,v4,Jg,oe,lc,_4,$g,k4,vp,E4,b4,it,x4,rc,y4,w4,ic,T4,R4,oc,S4,D4,nc,A4,cc,L4,I4,ga,P4,uc,O4,z4,fc,N4,em,ot,C4,dc,G4,H4,pc,q4,M4,tm,xe,ma,U4,hc,B4,W4,gc,j4,F4,Xl,V4,mc,Y4,K4,X4,_p,Z4,Q4,kp,J4,sm,va,_a,Ep,$4,am,ye,vc,bp,e0,t0,s0,_c,xp,a0,l0,r0,kc,yp,i0,o0,n0,Ec,wp,c0,u0,lm,bc,f0,rm,Zl,Ql,Y7,im,ka,Ea,Tp,d0,om,xc,p0,nm,nt,Jl,h0,yc,g0,m0,v0,$l,_0,wc,k0,E0,b0,Rp,x0,cm,Ct,Tc,ct,Rc,y0,w0,Sc,T0,R0,Dc,S0,D0,we,ut,Ac,A0,L0,Lc,I0,P0,Ic,O0,z0,ft,Pc,N0,C0,Oc,G0,H0,zc,q0,M0,dt,Nc,U0,B0,Cc,W0,j0,Gc,F0,V0,pt,Hc,Y0,K0,qc,X0,Z0,Mc,Q0,um,ba,xa,Sp,J0,fm,Uc,$0,dm,Gt,Bc,ht,Wc,e5,t5,jc,s5,a5,Fc,l5,r5,W,gt,Vc,i5,o5,Yc,n5,c5,Kc,u5,f5,mt,Xc,d5,p5,Zc,h5,g5,Qc,m5,v5,vt,Jc,_5,k5,$c,E5,b5,eu,x5,y5,_t,tu,w5,T5,su,R5,S5,au,D5,A5,kt,lu,L5,I5,ru,P5,O5,iu,z5,N5,Et,ou,C5,G5,nu,H5,q5,cu,M5,U5,bt,uu,B5,W5,fu,j5,F5,du,V5,Y5,xt,pu,K5,X5,hu,Z5,Q5,gu,J5,$5,yt,mu,ew,tw,vu,sw,aw,_u,lw,rw,wt,ku,iw,ow,Eu,nw,cw,bu,uw,pm,ya,wa,Dp,fw,hm,xu,dw,gm,yu,pw,mm,er,tr,K7,vm,wu,hw,_m,Ht,Ta,Ap,gw,km,Em,bm;Ma=new _v({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),ml=new _v({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),kl=new _v({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Yl=new _v({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let Te=xA&&wL();return{c(){p=a("p"),m=o("Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),g=c(),h=a("p"),v=o("I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),k=c(),b=a("h4"),w=a("a"),T=a("span"),x=o("Experiment 1: Anime-Inspired Heroism"),E=c(),y=a("p"),I=a("img"),N=c(),G=a("p"),D=o("I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),A=c(),S=a("ul"),O=a("li"),z=o("My action figure photos (for costume accuracy)."),Q=c(),j=a("li"),F=o("Stylized anime references (for anatomy and texture)."),B=c(),C=a("p"),L=o("The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),H=c(),Z=a("h4"),q=a("a"),R=a("span"),M=o("Experiment 2: Retro Cartoon Resurrection"),jt=c(),Se=a("p"),fe=a("img"),Cp=c(),nr=a("p"),xv=o("Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),Gp=c(),Ft=a("h2"),Vt=a("a"),yf=a("span"),yv=o("What are Regularization Images?"),Hp=c(),cr=a("p"),wv=o("Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),qp=c(),qa=a("blockquote"),ur=a("p"),Tv=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),Mp=c(),lr(Ma.$$.fragment),Up=c(),fr=a("p"),Rv=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Bp=c(),dr=a("p"),Sv=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),Wp=c(),pr=a("p"),Dv=o("Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),jp=c(),At=a("table"),hr=a("thead"),De=a("tr"),gr=a("th"),Av=o("Aspect"),Lv=c(),mr=a("th"),Iv=o("Regularization"),Pv=c(),vr=a("th"),Ov=o("No Regularization"),zv=c(),Ae=a("tbody"),Le=a("tr"),_r=a("td"),wf=a("strong"),Nv=o("Class Definition"),Cv=c(),kr=a("td"),Gv=o("Explicit class anchoring"),Hv=c(),Er=a("td"),qv=o("Implicit class learning"),Mv=c(),Ie=a("tr"),br=a("td"),Tf=a("strong"),Uv=o("Failure Modes"),Bv=c(),xr=a("td"),Wv=o("Underfitting if overdone"),jv=c(),yr=a("td"),Fv=o("Overfitting/drift"),Vv=c(),Pe=a("tr"),wr=a("td"),Rf=a("strong"),Yv=o("Data Efficiency"),Kv=c(),Tr=a("td"),Xv=o("Better generalization"),Zv=c(),Rr=a("td"),Qv=o("Requires more data"),Fp=c(),Sr=a("p"),Jv=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Vp=c(),Dr=a("p"),$v=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Yp=c(),Ua=a("blockquote"),Ar=a("p"),e2=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Kp=c(),Yt=a("h4"),Kt=a("a"),Sf=a("span"),t2=o("Scenario 1: Limited Training Data"),Xp=c(),Ba=a("p"),Df=a("strong"),s2=o("Situation"),a2=o(": You only have a few images of your cat and no other cat images."),Zp=c(),Wa=a("p"),Af=a("strong"),l2=o("Problem"),r2=o(": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),Qp=c(),ja=a("p"),Lf=a("strong"),i2=o("Solution"),o2=o(": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Jp=c(),Xt=a("h4"),Zt=a("a"),If=a("span"),n2=o("Scenario 2: Imbalanced Training Data"),$p=c(),Fa=a("p"),Pf=a("strong"),c2=o("Situation"),u2=o(": You have many images of other cats but only a few of your cat."),eh=c(),Va=a("p"),Of=a("strong"),f2=o("Problem"),d2=o(": The model may focus too much on the other cats, failing to learn the unique features of your cat."),th=c(),Ya=a("p"),zf=a("strong"),p2=o("Solution"),h2=o(": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),sh=c(),Qt=a("h2"),Jt=a("a"),Nf=a("span"),g2=o("Divergence"),ah=c(),Ka=a("p"),Cf=a("strong"),m2=o("Divergence"),v2=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),lh=c(),Oe=a("p"),_2=o("Preventing divergence starts with "),Gf=a("strong"),k2=o("careful dataset curation"),E2=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Hf=a("strong"),b2=o("regularization techniques"),x2=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),rh=c(),ze=a("ul"),Lr=a("li"),qf=a("strong"),y2=o("Chaotic outputs"),w2=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),T2=c(),Ir=a("li"),Mf=a("strong"),R2=o("Exploding gradients"),S2=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),D2=c(),$t=a("li"),Uf=a("strong"),A2=o("Loss value instability (NaN/infinity values)"),L2=o(" The training loss fluctuates wildly, sometimes becoming "),Pr=a("code"),I2=o("NaN"),P2=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),ih=c(),Xa=a("blockquote"),Or=a("p"),O2=o("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),oh=c(),es=a("h2"),ts=a("a"),Bf=a("span"),Wf=a("strong"),z2=o("Overfitting"),nh=c(),zr=a("p"),N2=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),ch=c(),Ne=a("ul"),Nr=a("li"),jf=a("strong"),C2=o("Perfectly replicates training samples"),G2=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),H2=c(),Cr=a("li"),Ff=a("strong"),q2=o("Fails to generalize to new inputs"),M2=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),U2=c(),Gr=a("li"),Vf=a("strong"),B2=o("Shows excellent training loss but poor validation loss"),W2=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),uh=c(),ss=a("h3"),as=a("a"),Yf=a("span"),Kf=a("strong"),j2=o("Key Differences"),fh=c(),Lt=a("table"),Hr=a("thead"),Ce=a("tr"),qr=a("th"),Xf=a("strong"),F2=o("Aspect"),V2=c(),Mr=a("th"),Zf=a("strong"),Y2=o("Divergence"),K2=c(),Ur=a("th"),Qf=a("strong"),X2=o("Overfitting"),Z2=c(),de=a("tbody"),Ge=a("tr"),Br=a("td"),Jf=a("strong"),Q2=o("Cause"),J2=c(),Wr=a("td"),$2=o("Excessive learning rate"),e_=c(),jr=a("td"),t_=o("Insufficient regularization"),s_=c(),He=a("tr"),Fr=a("td"),$f=a("strong"),a_=o("Loss Behavior"),l_=c(),Vr=a("td"),r_=o("Sudden spikes/NaN values"),i_=c(),Yr=a("td"),o_=o("Steady decrease then rise"),n_=c(),qe=a("tr"),Kr=a("td"),ed=a("strong"),c_=o("Output Quality"),u_=c(),Xr=a("td"),f_=o("Random noise/artifacts"),d_=c(),Zr=a("td"),p_=o("Overly detailed replicas"),h_=c(),Me=a("tr"),Qr=a("td"),td=a("strong"),g_=o("Recovery"),m_=c(),Jr=a("td"),v_=o("Requires restart"),__=c(),$r=a("td"),k_=o("Early stopping works"),dh=c(),ls=a("h3"),rs=a("a"),sd=a("span"),E_=o("Preventing Divergence"),ph=c(),It=a("table"),ei=a("thead"),is=a("tr"),ti=a("th"),b_=o("Situation"),x_=c(),si=a("th"),y_=o("Outcome"),w_=c(),pe=a("tbody"),os=a("tr"),ai=a("td"),ad=a("strong"),T_=o("Excessive or inconsistent data"),R_=c(),li=a("td"),S_=o("Model struggles to learn and produces unreliable predictions."),D_=c(),ns=a("tr"),ri=a("td"),ld=a("strong"),A_=o("Lack of unique and consistent features"),L_=c(),ii=a("td"),I_=o("Poor generalization, leading to inaccurate or meaningless outputs."),P_=c(),cs=a("tr"),oi=a("td"),rd=a("strong"),O_=o("Carefully curated datasets"),z_=c(),ni=a("td"),N_=o("Improved learning by ensuring the model sees only relevant, high-quality data."),C_=c(),us=a("tr"),ci=a("td"),id=a("strong"),G_=o("Effective use of regularization techniques"),H_=c(),ui=a("td"),q_=o("Helps maintain focus on essential features and prevents instability."),hh=c(),fi=a("p"),M_=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),gh=c(),fs=a("h3"),ds=a("a"),od=a("span"),U_=o("Implementing these Strategies"),mh=c(),Za=a("pre"),vh=c(),Qa=a("pre"),_h=c(),ps=a("h3"),hs=a("a"),nd=a("span"),B_=o("Data Considerations"),kh=c(),Pt=a("table"),di=a("thead"),Ue=a("tr"),pi=a("th"),W_=o("Situation"),j_=c(),hi=a("th"),F_=o("Actual Risk"),V_=c(),gi=a("th"),Y_=o("Solution"),K_=c(),he=a("tbody"),Be=a("tr"),mi=a("td"),X_=o("High LR + small batch size"),Z_=c(),vi=a("td"),Q_=o("Divergence"),J_=c(),_i=a("td"),$_=o("Lower LR, increase batch size"),e1=c(),We=a("tr"),ki=a("td"),t1=o("Inconsistent features"),s1=c(),Ei=a("td"),a1=o("Overfitting"),l1=c(),bi=a("td"),r1=o("Improve dataset consistency"),i1=c(),je=a("tr"),xi=a("td"),o1=o("Insufficient reg images"),n1=c(),yi=a("td"),c1=o("Class leakage"),u1=c(),wi=a("td"),f1=o("Add 100-300 class images"),d1=c(),Fe=a("tr"),Ti=a("td"),p1=o("High variance in training data"),h1=c(),Ri=a("td"),g1=o("Mode collapse"),m1=c(),Si=a("td"),v1=o("Curate focused dataset"),Eh=c(),bh=a("hr"),xh=c(),gs=a("h2"),ms=a("a"),cd=a("span"),_1=o("Monitoring Tips"),yh=c(),vs=a("p"),k1=o("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ja=a("a"),E1=o("kohya-ss/sd-scripts"),b1=o(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),wh=c(),_s=a("h3"),ks=a("a"),ud=a("span"),x1=o("Track loss curves"),Th=c(),Es=a("p"),y1=o("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),$a=a("a"),w1=o("TensorBoard"),T1=o(" to create these graphs."),Rh=c(),el=a("pre"),Sh=c(),bs=a("h4"),xs=a("a"),fd=a("span"),R1=o("What to Monitor:"),Dh=c(),Ve=a("ul"),dd=a("li"),S1=o("Training Loss: Should decrease steadily but not too quickly."),D1=c(),pd=a("li"),A1=o("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),L1=c(),hd=a("li"),I1=o("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),Ah=c(),ys=a("h4"),ws=a("a"),gd=a("span"),P1=o("Warning Signs:"),Lh=c(),Ye=a("ul"),md=a("li"),O1=o("Sudden spikes in loss \u2192 Likely divergence."),z1=c(),vd=a("li"),N1=o("Loss plateauing too early \u2192 Learning rate may be too low."),C1=c(),_d=a("li"),G1=o("Validation loss increasing while training loss decreases \u2192 Overfitting."),Ih=c(),Ts=a("h3"),Rs=a("a"),kd=a("span"),H1=o("Generate validation images every 100 steps"),Ph=c(),tl=a("p"),Ed=a("strong"),q1=o("Why It Matters"),M1=o(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),Oh=c(),sl=a("pre"),zh=c(),Ss=a("h4"),Ds=a("a"),bd=a("span"),U1=o("What to Look For:"),Nh=c(),Ke=a("ul"),xd=a("li"),B1=o("Consistency: Outputs should align with the training data style."),W1=c(),yd=a("li"),j1=o("Artifacts: Check for distortions, noise, or unnatural features."),F1=c(),wd=a("li"),V1=o("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),Ch=c(),al=a("blockquote"),Di=a("p"),Y1=o("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),Gh=c(),As=a("h4"),Ls=a("a"),Td=a("span"),K1=o("Use Gradient Clipping"),Hh=c(),ll=a("p"),Rd=a("strong"),X1=o("Why It Matters"),Z1=o(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),qh=c(),Ai=a("p"),Q1=o("Key Insights:"),Mh=c(),Xe=a("ul"),rl=a("li"),J1=o("Gradient Norm "),Li=a("code"),$1=o("<"),ek=o(" than 0.1: Training may stall due to tiny updates."),tk=c(),Sd=a("li"),sk=o("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),ak=c(),Dd=a("li"),lk=o("Ideal Range: 0.1 to 2.0 for stable training."),Uh=c(),il=a("blockquote"),Ii=a("p"),rk=o("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Bh=c(),Is=a("h4"),Ps=a("a"),Ad=a("span"),ik=o("Enable Mixed Precision Training"),Wh=c(),ol=a("p"),Ld=a("strong"),ok=o("Why It Matters"),nk=o(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),jh=c(),nl=a("pre"),Fh=c(),Pi=a("p"),ck=o("Benefits:"),Vh=c(),Ze=a("ul"),Id=a("li"),uk=o("2-3x Faster Training: Leverages GPU tensor cores."),fk=c(),Pd=a("li"),dk=o("50% Less VRAM Usage: Allows larger batch sizes or models."),pk=c(),Od=a("li"),hk=o("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),Yh=c(),cl=a("blockquote"),Oi=a("p"),gk=o("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),Kh=c(),Os=a("h4"),zs=a("a"),zd=a("span"),mk=o("Start with Conservative Learning Rates"),Xh=c(),Ns=a("p"),vk=o("Start off with 1e-5 to 1e-6.  "),Nd=a("strong"),_k=o("Why It Matters"),kk=o(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Zh=c(),ul=a("pre"),Qh=c(),fl=a("pre"),Jh=c(),dl=a("p"),Cd=a("strong"),Ek=o("Warning Signs"),bk=o(":"),$h=c(),Qe=a("ul"),Gd=a("li"),xk=o("Loss Spikes: Learning rate is too high."),yk=c(),Hd=a("li"),wk=o("Slow Convergence: Learning rate is too low."),Tk=c(),qd=a("li"),Rk=o("Oscillating Loss: Poor scheduling or unstable gradients."),eg=c(),Ot=a("table"),zi=a("thead"),ge=a("tr"),Ni=a("th"),Sk=o("Practice"),Dk=c(),Ci=a("th"),Ak=o("Key Benefit"),Lk=c(),Gi=a("th"),Ik=o("Tool/Setting"),Pk=c(),Hi=a("th"),Ok=o("Warning Signs"),zk=c(),le=a("tbody"),me=a("tr"),qi=a("td"),Nk=o("Track Loss Curves"),Ck=c(),Mi=a("td"),Gk=o("Detect overfitting/divergence early"),Hk=c(),Ui=a("td"),qk=o("TensorBoard, Weights & Biases"),Mk=c(),Bi=a("td"),Uk=o("Spikes, plateaus, growing gaps"),Bk=c(),ve=a("tr"),Wi=a("td"),Wk=o("Generate Validation Images"),jk=c(),ji=a("td"),Fk=o("Visualize model progress"),Vk=c(),Fi=a("td"),Yk=o("Fixed prompts/seeds"),Kk=c(),Vi=a("td"),Xk=o("Artifacts, mode collapse"),Zk=c(),_e=a("tr"),Yi=a("td"),Qk=o("Gradient Clipping"),Jk=c(),Ki=a("td"),$k=o("Prevent exploding gradients"),eE=c(),Cs=a("td"),tE=o("clip"),Md=a("em"),sE=o("grad_norm"),aE=o(" (1.0-2.0)"),lE=c(),Je=a("td"),rE=o("Norm "),Xi=a("code"),iE=o(">"),oE=o(" 10.0 or "),Zi=a("code"),nE=o("<"),cE=o(" 0.1"),uE=c(),ke=a("tr"),Qi=a("td"),fE=o("Mixed Precision Training"),dE=c(),Ji=a("td"),pE=o("Faster training, lower VRAM usage"),hE=c(),$i=a("td"),gE=o("PyTorch AMP (torch.cuda.amp)"),mE=c(),eo=a("td"),vE=o("NaN values (disable if unstable)"),_E=c(),Ee=a("tr"),to=a("td"),kE=o("Conservative Learning Rates"),EE=c(),so=a("td"),bE=o("Stable training, avoid divergence"),xE=c(),ao=a("td"),yE=o("Start at 1e-5 to 1e-6, use scheduler"),wE=c(),lo=a("td"),TE=o("Spikes, slow convergence"),tg=c(),sg=a("hr"),ag=c(),Gs=a("h2"),Hs=a("a"),Ud=a("span"),RE=o("Generating Regularization images"),lg=c(),qs=a("p"),SE=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),ro=a("code"),DE=o("1boy"),AE=o(")."),rg=c(),ue=a("p"),LE=o("According to the Dreambooth technique, "),io=a("code"),IE=o("200"),PE=o(" regularization images per training image.  For example, if you have "),oo=a("code"),OE=o("16"),zE=o(" images: "),no=a("code"),NE=o("200 * 16 = 3200"),CE=o(" total regularization images.  When training, the math involved for calculating total steps is: "),co=a("code"),GE=o("repeats * training images >= repeats * regularization images"),ig=c(),uo=a("p"),HE=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),og=c(),Ms=a("h4"),Us=a("a"),Bd=a("span"),qE=o("Important considerations"),ng=c(),$e=a("ol"),Wd=a("li"),pl=a("p"),jd=a("strong"),ME=o("Use the same base model for regularization images and training"),UE=a("br"),BE=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),WE=c(),Fd=a("li"),hl=a("p"),Vd=a("strong"),jE=o("Maintain consistent class representation"),FE=a("br"),VE=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),YE=c(),Yd=a("li"),gl=a("p"),Kd=a("strong"),KE=o("Match output resolution to training data"),XE=a("br"),ZE=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),cg=c(),lr(ml.$$.fragment),ug=c(),Bs=a("h4"),Ws=a("a"),Xd=a("span"),QE=o("Generate using Stable Diffusion web UI"),fg=c(),js=a("p"),JE=o("We\u2019re going to use "),vl=a("a"),$E=o("Stable Diffusion web UI"),eb=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),dg=c(),et=a("p"),tb=o("We\u2019re going to use the "),fo=a("code"),sb=o("X/Y/Z plot"),ab=o(" script to use "),po=a("code"),lb=o("Prompt Search & Replace"),rb=o(" to dynamically build a prompt that will generate hundreds of regularization images."),pg=c(),J=a("ol"),Zd=a("li"),ho=a("p"),ib=o("Select the text 2 image tab.  Enter a generic prompt "),go=a("code"),ob=o("princeadam, portrait, looking_at_viewer, forest"),nb=c(),Qd=a("li"),_l=a("p"),cb=o("In generation parameters and select the "),mo=a("code"),ub=o("X/Y/Z plot"),fb=o(" script."),db=c(),Jd=a("li"),Y=a("p"),pb=o("Select the "),vo=a("code"),hb=o("X"),gb=o(" parameter and "),_o=a("code"),mb=o("Prompt SR"),vb=o(" for Prompt Replace.  We\u2019re going to replace "),ko=a("code"),_b=o("portrait"),kb=o(" with different camera angle tags: "),Eo=a("code"),Eb=o("close-up"),bb=o(", "),bo=a("code"),xb=o("upper_body"),yb=o(", "),xo=a("code"),wb=o("from_below"),Tb=o(", "),yo=a("code"),Rb=o("from_above"),Sb=o(", "),wo=a("code"),Db=o("dutch_angle"),Ab=c(),$d=a("li"),$=a("p"),Lb=o("Select the "),To=a("code"),Ib=o("Y"),Pb=o(" parameter and "),Ro=a("code"),Ob=o("Prompt SR"),zb=o(" for Prompt Replace.  Replace "),So=a("code"),Nb=o("looking_at_viewer"),Cb=o(": "),Do=a("code"),Gb=o("looking_away"),Hb=o(", "),Ao=a("code"),qb=o("looking_to_the_side"),Mb=o(", "),Lo=a("code"),Ub=o("looking_ahead"),Bb=o(", "),Io=a("code"),Wb=o("looking_down"),jb=c(),ep=a("li"),K=a("p"),Fb=o("Select the "),Po=a("code"),Vb=o("Z"),Yb=o(" parameter and "),Oo=a("code"),Kb=o("Prompt SR"),Xb=o(" for Prompt Replace. Replace "),zo=a("code"),Zb=o("forest"),Qb=o(" with a vareity of locatinos: "),No=a("code"),Jb=o("castle"),$b=o(", "),Co=a("code"),ex=o("mountain"),tx=o(", "),Go=a("code"),sx=o("cave"),ax=o(", "),Ho=a("code"),lx=o("farm"),rx=o(", "),qo=a("code"),ix=o("ocean"),ox=c(),tp=a("li"),Mo=a("p"),nx=o("Select a fast sampler like "),Uo=a("code"),cx=o("DPM2 KARRAS"),ux=c(),sp=a("li"),Fs=a("p"),fx=o("CFG Scale set to "),Bo=a("code"),dx=o("7"),px=o(" and Steps to "),Wo=a("code"),hx=o("20"),hg=c(),tt=a("p"),gx=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),jo=a("code"),mx=o("150"),vx=o(" - "),Fo=a("code"),_x=o("200"),kx=o(" and keep in mind we can add and remove as we try different training settings with different output."),gg=c(),lr(kl.$$.fragment),mg=c(),Vs=a("h4"),Ys=a("a"),ap=a("span"),Ex=o("Download images"),vg=c(),Vo=a("p"),bx=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),_g=c(),be=a("ul"),Yo=a("li"),El=a("a"),xx=o("3ee Games regularization images"),yx=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),wx=c(),Ko=a("li"),bl=a("a"),Tx=o("Pre-Rendered Regularization Images"),Rx=o(": Includes 1500 regularization images."),Sx=c(),Xo=a("li"),xl=a("a"),Dx=o("Stable Diffusion 1.5 Regularization Images"),Ax=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),Lx=c(),Zo=a("li"),yl=a("a"),Ix=o("Aitrepreneur SDXL image set"),Px=o(": a large image set generated with Stable Diffusion SDXL."),kg=c(),Ks=a("h4"),Xs=a("a"),lp=a("span"),Ox=o("Captioning Regularization images"),Eg=c(),Qo=a("p"),zx=o("While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),bg=c(),Jo=a("p"),Nx=o("Here\u2019s the workflow I used:"),xg=c(),st=a("ul"),Zs=a("li"),rp=a("strong"),Cx=o("Structured Filenames"),Gx=o(": Stable Diffusion Web UI automatically embeds prompts in filenames (e.g., "),$o=a("code"),Hx=o("princeadam_1boy_closeup.png"),qx=o(")."),Mx=c(),at=a("li"),ip=a("strong"),Ux=o("Automated Extraction"),Bx=o(": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),en=a("code"),Wx=o("1boy"),jx=o(" or "),tn=a("code"),Fx=o("purple_vest"),Vx=o("."),Yx=c(),sn=a("li"),op=a("strong"),Kx=o("Manual Verification"),Xx=o(": Spot-checked captions to ensure accuracy."),yg=c(),wl=a("pre"),wg=c(),Qs=a("ol"),Tl=a("li"),Zx=o("Save this file as "),an=a("code"),Qx=o("filename2txt.bat"),Jx=o(" and place it into the regularization images directory"),$x=c(),Rl=a("li"),ey=o("Run: "),ln=a("code"),ty=o(".\\filename2txt.bat"),sy=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Tg=c(),Js=a("ul"),rn=a("li"),ay=o("Example filename: "),on=a("code"),ly=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),ry=c(),Sl=a("li"),iy=o("Output: "),nn=a("code"),oy=o("aburbres,princeadam,1boy,close-up,purple_vest"),ny=o(" saved in a text file with the same name as image."),Rg=c(),$s=a("h2"),ea=a("a"),np=a("span"),cy=o("Training a LoRA"),Sg=c(),ta=a("p"),uy=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),Dl=a("a"),fy=o("kohya-ss/sd-scripts"),dy=o("."),Dg=c(),Al=a("blockquote"),sa=a("p"),py=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Ll=a("a"),hy=o("Kohya SD script documentation"),gy=o("."),Ag=c(),aa=a("h3"),la=a("a"),cp=a("span"),my=o("Directory setup"),Lg=c(),ra=a("p"),vy=o("In your configuration json, use "),cn=a("code"),_y=o("reg_data_dir"),ky=o(" to point to the directory with your regularization images:"),Ig=c(),Il=a("pre"),Pg=c(),un=a("p"),Ey=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Og=c(),Pl=a("pre"),zg=c(),lt=a("p"),by=o("Set the "),fn=a("code"),xy=o("number of iterations"),yy=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),dn=a("code"),wy=o("training images \xD7 iterations"),Ty=o(". If there are more regularization images than this, the extras won\u2019t be used."),Ng=c(),rt=a("p"),Ry=o("Create folders in the training image folder with the format "),pn=a("code"),Sy=o("<repetition count>_<class>"),Dy=o(" multiple times, and similarly create folders in the regularization image folder with the format "),hn=a("code"),Ay=o("<repetition count>_<class>"),Ly=o("."),Cg=c(),gn=a("p"),Iy=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Gg=c(),ia=a("ul"),mn=a("li"),Py=o("train_data_dir"),up=a("ul"),fp=a("li"),Oy=o("10_princeadam"),zy=c(),vn=a("li"),Ny=o("reg_dir"),dp=a("ul"),pp=a("li"),Cy=o("1_1boy"),Hg=c(),_n=a("p"),Gy=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),qg=c(),Ol=a("p"),zl=a("img"),Mg=c(),oa=a("h3"),na=a("a"),hp=a("span"),Hy=o("Training Settings"),Ug=c(),zt=a("p"),qy=o("The training setup we\u2019re going to use is:  "),kn=a("code"),My=o("Number of images * repeats * epoch / batch size = total steps"),Uy=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),En=a("code"),By=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Bg=c(),Nt=a("table"),bn=a("thead"),re=a("tr"),xn=a("th"),Wy=o("Number of Images"),jy=c(),yn=a("th"),Fy=o("Repeats"),Vy=c(),wn=a("th"),Yy=o("Epochs"),Ky=c(),Tn=a("th"),Xy=o("Batch Size"),Zy=c(),Rn=a("th"),Qy=o("Total Steps"),Jy=c(),Sn=a("tbody"),ie=a("tr"),Dn=a("td"),$y=o("45"),e3=c(),An=a("td"),t3=o("10"),s3=c(),Ln=a("td"),a3=o("20"),l3=c(),In=a("td"),r3=o("2"),i3=c(),Pn=a("td"),o3=o("4500"),Wg=c(),On=a("p"),n3=o("Now let\u2019s focus on these training settings:"),jg=c(),Nl=a("pre"),Fg=c(),U=a("ul"),zn=a("li"),Cl=a("strong"),c3=o("Learning Rate ("),Nn=a("code"),u3=o("learning_rate"),f3=o(")"),d3=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),p3=c(),Cn=a("li"),Gl=a("strong"),h3=o("Text Encoder Learning Rate ("),Gn=a("code"),g3=o("text_encoder_lr"),m3=o(")"),v3=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),_3=c(),Hn=a("li"),Hl=a("strong"),k3=o("UNet Learning Rate ("),qn=a("code"),E3=o("unet_lr"),b3=o(")"),x3=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),y3=c(),Mn=a("li"),ql=a("strong"),w3=o("Learning Rate Scheduler ("),Un=a("code"),T3=o("lr_scheduler"),R3=o(")"),S3=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),D3=c(),Bn=a("li"),Ml=a("strong"),A3=o("Number of Cycles in Learning Rate Scheduler ("),Wn=a("code"),L3=o("lr_scheduler_num_cycles"),I3=o(")"),P3=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),O3=c(),jn=a("li"),Ul=a("strong"),z3=o("Network Dimension ("),Fn=a("code"),N3=o("network_dim"),C3=o(")"),G3=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),H3=c(),Vn=a("li"),Bl=a("strong"),q3=o("Network Alpha ("),Yn=a("code"),M3=o("network_alpha"),U3=o(")"),B3=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),W3=c(),Kn=a("li"),Wl=a("strong"),j3=o("Clip Skip ("),Xn=a("code"),F3=o("clip_skip"),V3=o(")"),Y3=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),K3=c(),Zn=a("li"),jl=a("strong"),X3=o("Max Token Length ("),Qn=a("code"),Z3=o("max_token_length"),Q3=o(")"),J3=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),$3=c(),Jn=a("li"),Fl=a("strong"),e4=o("Noise Offset ("),$n=a("code"),t4=o("noise_offset"),s4=o(")"),a4=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),l4=c(),ec=a("li"),Vl=a("strong"),r4=o("Regularization Data Directory ("),tc=a("code"),i4=o("reg_data_dir"),o4=o(")"),n4=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Vg=c(),ca=a("h3"),ua=a("a"),gp=a("span"),c4=o("Fine Tuning"),Yg=c(),sc=a("p"),u4=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),Kg=c(),lr(Yl.$$.fragment),Xg=c(),fa=a("h4"),da=a("a"),mp=a("span"),f4=o("Workflow with Auto1111 WebUI"),Zg=c(),pa=a("p"),d4=o("We\u2019re going to use "),Kl=a("a"),p4=o("Stable Diffusion web UI"),h4=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Qg=c(),ha=a("p"),g4=o("We\u2019re going to use the "),ac=a("code"),m4=o("X/Y/Z plot"),v4=o(" script to compare different epochs."),Jg=c(),oe=a("ul"),lc=a("li"),_4=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),$g=a("princeadam0001:0.7"),k4=c(),vp=a("li"),E4=o("In generation parameters and select the X/Y/Z plot script."),b4=c(),it=a("li"),x4=o("Select "),rc=a("code"),y4=o("Prompt SR"),w4=o(" for Prompt Replace.  We\u2019re going to replace "),ic=a("code"),T4=o("<princeadam0001:0.7>"),R4=o(" with different epoch: "),oc=a("code"),S4=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),D4=c(),nc=a("li"),A4=o("Select a fast sampler like "),cc=a("code"),L4=o("DPM2 KARRAS"),I4=c(),ga=a("li"),P4=o("CFG Scale set to "),uc=a("code"),O4=o("7"),z4=o(" and Steps to "),fc=a("code"),N4=o("20"),em=c(),ot=a("p"),C4=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),dc=a("code"),G4=o("network_dim"),H4=o(" and "),pc=a("code"),q4=o("network_alpha"),M4=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),tm=c(),xe=a("ul"),ma=a("li"),U4=o("Select "),hc=a("code"),B4=o("Prompt SR"),W4=o(" for Prompt Replace.  We\u2019re going to replace the weights "),gc=a("code"),j4=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),F4=c(),Xl=a("li"),V4=o("Use Prompt SR to generate a variety of angles: Select "),mc=a("code"),Y4=o("Prompt SR"),K4=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),X4=c(),_p=a("li"),Z4=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),Q4=c(),kp=a("li"),J4=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),sm=c(),va=a("h4"),_a=a("a"),Ep=a("span"),$4=o("Issues to look for"),am=c(),ye=a("ul"),vc=a("li"),bp=a("strong"),e0=o("Undercooked:"),t0=o(" Lacks output, adjust unet learning rate or extend training duration."),s0=c(),_c=a("li"),xp=a("strong"),a0=o("Overcooked:"),l0=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),r0=c(),kc=a("li"),yp=a("strong"),i0=o("Overfit:"),o0=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),n0=c(),Ec=a("li"),wp=a("strong"),c0=o("Mismatched:"),u0=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),lm=c(),bc=a("p"),f0=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),rm=c(),Zl=a("p"),Ql=a("img"),im=c(),ka=a("h2"),Ea=a("a"),Tp=a("span"),d0=o("Troubleshooting"),om=c(),xc=a("p"),p0=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),nm=c(),nt=a("ul"),Jl=a("li"),h0=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),yc=a("code"),g0=o("200"),m0=o(" regularization images per training image."),v0=c(),$l=a("li"),_0=o("Repeats of regularization images, but may overfit more.  Increasing the "),wc=a("code"),k0=o("repetition_count"),E0=o(" will cycle through the images more but the results may have results that overfit the model."),b0=c(),Rp=a("li"),x0=o("Create more regularization images without increasing repeats will help with the overfitting."),cm=c(),Ct=a("table"),Tc=a("thead"),ct=a("tr"),Rc=a("th"),y0=o("Issue"),w0=c(),Sc=a("th"),T0=o("Situation"),R0=c(),Dc=a("th"),S0=o("Recommendation"),D0=c(),we=a("tbody"),ut=a("tr"),Ac=a("td"),A0=o("Varying quality"),L0=c(),Lc=a("td"),I0=o("Results differ from expectations"),P0=c(),Ic=a("td"),O0=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),z0=c(),ft=a("tr"),Pc=a("td"),N0=o("Inadequate regularization for input data"),C0=c(),Oc=a("td"),G0=o("Lower input images, less regularization needed"),H0=c(),zc=a("td"),q0=o("Reduce the number of input images or increasing the quantity of reg images."),M0=c(),dt=a("tr"),Nc=a("td"),U0=o("Overfitting due to repetition"),B0=c(),Cc=a("td"),W0=o("Repeats of reg images, risk of overfitting"),j0=c(),Gc=a("td"),F0=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),V0=c(),pt=a("tr"),Hc=a("td"),Y0=o("Mitigate overfitting while increasing diversity"),K0=c(),qc=a("td"),X0=o("Create more reg images without repeats"),Z0=c(),Mc=a("td"),Q0=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),um=c(),ba=a("h4"),xa=a("a"),Sp=a("span"),J0=o("More Solutions"),fm=c(),Uc=a("p"),$0=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),dm=c(),Gt=a("table"),Bc=a("thead"),ht=a("tr"),Wc=a("th"),e5=o("Symptom"),t5=c(),jc=a("th"),s5=o("Likely Cause"),a5=c(),Fc=a("th"),l5=o("Solution"),r5=c(),W=a("tbody"),gt=a("tr"),Vc=a("td"),i5=o("Plastic texture persists"),o5=c(),Yc=a("td"),n5=o("Insufficient human reg images"),c5=c(),Kc=a("td"),u5=o("Add real photos to reg set"),f5=c(),mt=a("tr"),Xc=a("td"),d5=o("Loss plateaus early"),p5=c(),Zc=a("td"),h5=o("Learning rate too low"),g5=c(),Qc=a("td"),m5=o("Increase LR by 10x"),v5=c(),vt=a("tr"),Jc=a("td"),_5=o("Features blurry"),k5=c(),$c=a("td"),E5=o("Network dimension too small"),b5=c(),eu=a("td"),x5=o("Increase network_dim to 64+"),y5=c(),_t=a("tr"),tu=a("td"),w5=o("Color distortion"),T5=c(),su=a("td"),R5=o("Noise offset conflict"),S5=c(),au=a("td"),D5=o("Try noise_offset 0.05-0.1"),A5=c(),kt=a("tr"),lu=a("td"),L5=o("Overly stylized outputs"),I5=c(),ru=a("td"),P5=o("Reg image style mismatch"),O5=c(),iu=a("td"),z5=o("Regenerate reg images with base model"),N5=c(),Et=a("tr"),ou=a("td"),C5=o("Training instability"),G5=c(),nu=a("td"),H5=o("Batch size too large"),q5=c(),cu=a("td"),M5=o("Reduce batch_size to 1-2"),U5=c(),bt=a("tr"),uu=a("td"),B5=o("Slow convergence"),W5=c(),fu=a("td"),j5=o("Network_alpha too high"),F5=c(),du=a("td"),V5=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),Y5=c(),xt=a("tr"),pu=a("td"),K5=o("Loss divergence"),X5=c(),hu=a("td"),Z5=o("Text encoder LR too high"),Q5=c(),gu=a("td"),J5=o("Reduce text_encoder_lr by 10x"),$5=c(),yt=a("tr"),mu=a("td"),ew=o("Poor prompt adherence"),tw=c(),vu=a("td"),sw=o("Clip skip too high"),aw=c(),_u=a("td"),lw=o("Reduce clip_skip to 1-2"),rw=c(),wt=a("tr"),ku=a("td"),iw=o("Memory errors"),ow=c(),Eu=a("td"),nw=o("Resolution too high"),cw=c(),bu=a("td"),uw=o("Reduce to 512-768px, enable gradient checkpointing"),pm=c(),ya=a("h2"),wa=a("a"),Dp=a("span"),fw=o("Results"),hm=c(),xu=a("p"),dw=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),gm=c(),yu=a("p"),pw=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),mm=c(),er=a("p"),tr=a("img"),vm=c(),wu=a("p"),hw=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),_m=c(),Ht=a("h2"),Ta=a("a"),Ap=a("span"),gw=o("spacelab"),km=c(),Te&&Te.c(),Em=bf(),this.h()},l(s){p=l(s,"P",{});var d=r(p);m=n(d,"Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),d.forEach(t),g=u(s),h=l(s,"P",{});var X7=r(h);v=n(X7,"I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),X7.forEach(t),k=u(s),b=l(s,"H4",{id:!0});var mw=r(b);w=l(mw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Z7=r(w);T=l(Z7,"SPAN",{class:!0}),r(T).forEach(t),Z7.forEach(t),x=n(mw,"Experiment 1: Anime-Inspired Heroism"),mw.forEach(t),E=u(s),y=l(s,"P",{class:!0});var Q7=r(y);I=l(Q7,"IMG",{src:!0,alt:!0,class:!0}),Q7.forEach(t),N=u(s),G=l(s,"P",{});var J7=r(G);D=n(J7,"I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),J7.forEach(t),A=u(s),S=l(s,"UL",{});var xm=r(S);O=l(xm,"LI",{});var $7=r(O);z=n($7,"My action figure photos (for costume accuracy)."),$7.forEach(t),Q=u(xm),j=l(xm,"LI",{});var e6=r(j);F=n(e6,"Stylized anime references (for anatomy and texture)."),e6.forEach(t),xm.forEach(t),B=u(s),C=l(s,"P",{});var t6=r(C);L=n(t6,"The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),t6.forEach(t),H=u(s),Z=l(s,"H4",{id:!0});var vw=r(Z);q=l(vw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var s6=r(q);R=l(s6,"SPAN",{class:!0}),r(R).forEach(t),s6.forEach(t),M=n(vw,"Experiment 2: Retro Cartoon Resurrection"),vw.forEach(t),jt=u(s),Se=l(s,"P",{class:!0});var a6=r(Se);fe=l(a6,"IMG",{src:!0,alt:!0,class:!0}),a6.forEach(t),Cp=u(s),nr=l(s,"P",{});var l6=r(nr);xv=n(l6,"Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),l6.forEach(t),Gp=u(s),Ft=l(s,"H2",{id:!0});var _w=r(Ft);Vt=l(_w,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r6=r(Vt);yf=l(r6,"SPAN",{class:!0}),r(yf).forEach(t),r6.forEach(t),yv=n(_w,"What are Regularization Images?"),_w.forEach(t),Hp=u(s),cr=l(s,"P",{});var i6=r(cr);wv=n(i6,"Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),i6.forEach(t),qp=u(s),qa=l(s,"BLOCKQUOTE",{class:!0});var o6=r(qa);ur=l(o6,"P",{class:!0});var n6=r(ur);Tv=n(n6,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),n6.forEach(t),o6.forEach(t),Mp=u(s),rr(Ma.$$.fragment,s),Up=u(s),fr=l(s,"P",{});var c6=r(fr);Rv=n(c6,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),c6.forEach(t),Bp=u(s),dr=l(s,"P",{});var u6=r(dr);Sv=n(u6,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),u6.forEach(t),Wp=u(s),pr=l(s,"P",{});var f6=r(pr);Dv=n(f6,"Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),f6.forEach(t),jp=u(s),At=l(s,"TABLE",{class:!0});var ym=r(At);hr=l(ym,"THEAD",{class:!0});var d6=r(hr);De=l(d6,"TR",{class:!0});var Tu=r(De);gr=l(Tu,"TH",{class:!0});var p6=r(gr);Av=n(p6,"Aspect"),p6.forEach(t),Lv=u(Tu),mr=l(Tu,"TH",{class:!0});var h6=r(mr);Iv=n(h6,"Regularization"),h6.forEach(t),Pv=u(Tu),vr=l(Tu,"TH",{class:!0});var g6=r(vr);Ov=n(g6,"No Regularization"),g6.forEach(t),Tu.forEach(t),d6.forEach(t),zv=u(ym),Ae=l(ym,"TBODY",{class:!0});var Ru=r(Ae);Le=l(Ru,"TR",{class:!0});var Su=r(Le);_r=l(Su,"TD",{class:!0});var m6=r(_r);wf=l(m6,"STRONG",{});var v6=r(wf);Nv=n(v6,"Class Definition"),v6.forEach(t),m6.forEach(t),Cv=u(Su),kr=l(Su,"TD",{class:!0});var _6=r(kr);Gv=n(_6,"Explicit class anchoring"),_6.forEach(t),Hv=u(Su),Er=l(Su,"TD",{class:!0});var k6=r(Er);qv=n(k6,"Implicit class learning"),k6.forEach(t),Su.forEach(t),Mv=u(Ru),Ie=l(Ru,"TR",{class:!0});var Du=r(Ie);br=l(Du,"TD",{class:!0});var E6=r(br);Tf=l(E6,"STRONG",{});var b6=r(Tf);Uv=n(b6,"Failure Modes"),b6.forEach(t),E6.forEach(t),Bv=u(Du),xr=l(Du,"TD",{class:!0});var x6=r(xr);Wv=n(x6,"Underfitting if overdone"),x6.forEach(t),jv=u(Du),yr=l(Du,"TD",{class:!0});var y6=r(yr);Fv=n(y6,"Overfitting/drift"),y6.forEach(t),Du.forEach(t),Vv=u(Ru),Pe=l(Ru,"TR",{class:!0});var Au=r(Pe);wr=l(Au,"TD",{class:!0});var w6=r(wr);Rf=l(w6,"STRONG",{});var T6=r(Rf);Yv=n(T6,"Data Efficiency"),T6.forEach(t),w6.forEach(t),Kv=u(Au),Tr=l(Au,"TD",{class:!0});var R6=r(Tr);Xv=n(R6,"Better generalization"),R6.forEach(t),Zv=u(Au),Rr=l(Au,"TD",{class:!0});var S6=r(Rr);Qv=n(S6,"Requires more data"),S6.forEach(t),Au.forEach(t),Ru.forEach(t),ym.forEach(t),Fp=u(s),Sr=l(s,"P",{});var D6=r(Sr);Jv=n(D6,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),D6.forEach(t),Vp=u(s),Dr=l(s,"P",{});var A6=r(Dr);$v=n(A6,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),A6.forEach(t),Yp=u(s),Ua=l(s,"BLOCKQUOTE",{class:!0});var L6=r(Ua);Ar=l(L6,"P",{class:!0});var I6=r(Ar);e2=n(I6,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),I6.forEach(t),L6.forEach(t),Kp=u(s),Yt=l(s,"H4",{id:!0});var kw=r(Yt);Kt=l(kw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var P6=r(Kt);Sf=l(P6,"SPAN",{class:!0}),r(Sf).forEach(t),P6.forEach(t),t2=n(kw,"Scenario 1: Limited Training Data"),kw.forEach(t),Xp=u(s),Ba=l(s,"P",{});var Ew=r(Ba);Df=l(Ew,"STRONG",{});var O6=r(Df);s2=n(O6,"Situation"),O6.forEach(t),a2=n(Ew,": You only have a few images of your cat and no other cat images."),Ew.forEach(t),Zp=u(s),Wa=l(s,"P",{});var bw=r(Wa);Af=l(bw,"STRONG",{});var z6=r(Af);l2=n(z6,"Problem"),z6.forEach(t),r2=n(bw,": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),bw.forEach(t),Qp=u(s),ja=l(s,"P",{});var xw=r(ja);Lf=l(xw,"STRONG",{});var N6=r(Lf);i2=n(N6,"Solution"),N6.forEach(t),o2=n(xw,": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),xw.forEach(t),Jp=u(s),Xt=l(s,"H4",{id:!0});var yw=r(Xt);Zt=l(yw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var C6=r(Zt);If=l(C6,"SPAN",{class:!0}),r(If).forEach(t),C6.forEach(t),n2=n(yw,"Scenario 2: Imbalanced Training Data"),yw.forEach(t),$p=u(s),Fa=l(s,"P",{});var ww=r(Fa);Pf=l(ww,"STRONG",{});var G6=r(Pf);c2=n(G6,"Situation"),G6.forEach(t),u2=n(ww,": You have many images of other cats but only a few of your cat."),ww.forEach(t),eh=u(s),Va=l(s,"P",{});var Tw=r(Va);Of=l(Tw,"STRONG",{});var H6=r(Of);f2=n(H6,"Problem"),H6.forEach(t),d2=n(Tw,": The model may focus too much on the other cats, failing to learn the unique features of your cat."),Tw.forEach(t),th=u(s),Ya=l(s,"P",{});var Rw=r(Ya);zf=l(Rw,"STRONG",{});var q6=r(zf);p2=n(q6,"Solution"),q6.forEach(t),h2=n(Rw,": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Rw.forEach(t),sh=u(s),Qt=l(s,"H2",{id:!0});var Sw=r(Qt);Jt=l(Sw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var M6=r(Jt);Nf=l(M6,"SPAN",{class:!0}),r(Nf).forEach(t),M6.forEach(t),g2=n(Sw,"Divergence"),Sw.forEach(t),ah=u(s),Ka=l(s,"P",{});var Dw=r(Ka);Cf=l(Dw,"STRONG",{});var U6=r(Cf);m2=n(U6,"Divergence"),U6.forEach(t),v2=n(Dw," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Dw.forEach(t),lh=u(s),Oe=l(s,"P",{});var Lu=r(Oe);_2=n(Lu,"Preventing divergence starts with "),Gf=l(Lu,"STRONG",{});var B6=r(Gf);k2=n(B6,"careful dataset curation"),B6.forEach(t),E2=n(Lu,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Hf=l(Lu,"STRONG",{});var W6=r(Hf);b2=n(W6,"regularization techniques"),W6.forEach(t),x2=n(Lu," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Lu.forEach(t),rh=u(s),ze=l(s,"UL",{});var Iu=r(ze);Lr=l(Iu,"LI",{});var Aw=r(Lr);qf=l(Aw,"STRONG",{});var j6=r(qf);y2=n(j6,"Chaotic outputs"),j6.forEach(t),w2=n(Aw," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),Aw.forEach(t),T2=u(Iu),Ir=l(Iu,"LI",{});var Lw=r(Ir);Mf=l(Lw,"STRONG",{});var F6=r(Mf);R2=n(F6,"Exploding gradients"),F6.forEach(t),S2=n(Lw," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),Lw.forEach(t),D2=u(Iu),$t=l(Iu,"LI",{});var Lp=r($t);Uf=l(Lp,"STRONG",{});var V6=r(Uf);A2=n(V6,"Loss value instability (NaN/infinity values)"),V6.forEach(t),L2=n(Lp," The training loss fluctuates wildly, sometimes becoming "),Pr=l(Lp,"CODE",{class:!0});var Y6=r(Pr);I2=n(Y6,"NaN"),Y6.forEach(t),P2=n(Lp," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Lp.forEach(t),Iu.forEach(t),ih=u(s),Xa=l(s,"BLOCKQUOTE",{class:!0});var K6=r(Xa);Or=l(K6,"P",{class:!0});var X6=r(Or);O2=n(X6,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),X6.forEach(t),K6.forEach(t),oh=u(s),es=l(s,"H2",{id:!0});var Iw=r(es);ts=l(Iw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Z6=r(ts);Bf=l(Z6,"SPAN",{class:!0}),r(Bf).forEach(t),Z6.forEach(t),Wf=l(Iw,"STRONG",{});var Q6=r(Wf);z2=n(Q6,"Overfitting"),Q6.forEach(t),Iw.forEach(t),nh=u(s),zr=l(s,"P",{});var J6=r(zr);N2=n(J6,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),J6.forEach(t),ch=u(s),Ne=l(s,"UL",{});var Pu=r(Ne);Nr=l(Pu,"LI",{});var Pw=r(Nr);jf=l(Pw,"STRONG",{});var $6=r(jf);C2=n($6,"Perfectly replicates training samples"),$6.forEach(t),G2=n(Pw," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),Pw.forEach(t),H2=u(Pu),Cr=l(Pu,"LI",{});var Ow=r(Cr);Ff=l(Ow,"STRONG",{});var eT=r(Ff);q2=n(eT,"Fails to generalize to new inputs"),eT.forEach(t),M2=n(Ow," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Ow.forEach(t),U2=u(Pu),Gr=l(Pu,"LI",{});var zw=r(Gr);Vf=l(zw,"STRONG",{});var tT=r(Vf);B2=n(tT,"Shows excellent training loss but poor validation loss"),tT.forEach(t),W2=n(zw," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),zw.forEach(t),Pu.forEach(t),uh=u(s),ss=l(s,"H3",{id:!0});var Nw=r(ss);as=l(Nw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var sT=r(as);Yf=l(sT,"SPAN",{class:!0}),r(Yf).forEach(t),sT.forEach(t),Kf=l(Nw,"STRONG",{});var aT=r(Kf);j2=n(aT,"Key Differences"),aT.forEach(t),Nw.forEach(t),fh=u(s),Lt=l(s,"TABLE",{class:!0});var wm=r(Lt);Hr=l(wm,"THEAD",{class:!0});var lT=r(Hr);Ce=l(lT,"TR",{class:!0});var Ou=r(Ce);qr=l(Ou,"TH",{class:!0});var rT=r(qr);Xf=l(rT,"STRONG",{});var iT=r(Xf);F2=n(iT,"Aspect"),iT.forEach(t),rT.forEach(t),V2=u(Ou),Mr=l(Ou,"TH",{class:!0});var oT=r(Mr);Zf=l(oT,"STRONG",{});var nT=r(Zf);Y2=n(nT,"Divergence"),nT.forEach(t),oT.forEach(t),K2=u(Ou),Ur=l(Ou,"TH",{class:!0});var cT=r(Ur);Qf=l(cT,"STRONG",{});var uT=r(Qf);X2=n(uT,"Overfitting"),uT.forEach(t),cT.forEach(t),Ou.forEach(t),lT.forEach(t),Z2=u(wm),de=l(wm,"TBODY",{class:!0});var Ra=r(de);Ge=l(Ra,"TR",{class:!0});var zu=r(Ge);Br=l(zu,"TD",{class:!0});var fT=r(Br);Jf=l(fT,"STRONG",{});var dT=r(Jf);Q2=n(dT,"Cause"),dT.forEach(t),fT.forEach(t),J2=u(zu),Wr=l(zu,"TD",{class:!0});var pT=r(Wr);$2=n(pT,"Excessive learning rate"),pT.forEach(t),e_=u(zu),jr=l(zu,"TD",{class:!0});var hT=r(jr);t_=n(hT,"Insufficient regularization"),hT.forEach(t),zu.forEach(t),s_=u(Ra),He=l(Ra,"TR",{class:!0});var Nu=r(He);Fr=l(Nu,"TD",{class:!0});var gT=r(Fr);$f=l(gT,"STRONG",{});var mT=r($f);a_=n(mT,"Loss Behavior"),mT.forEach(t),gT.forEach(t),l_=u(Nu),Vr=l(Nu,"TD",{class:!0});var vT=r(Vr);r_=n(vT,"Sudden spikes/NaN values"),vT.forEach(t),i_=u(Nu),Yr=l(Nu,"TD",{class:!0});var _T=r(Yr);o_=n(_T,"Steady decrease then rise"),_T.forEach(t),Nu.forEach(t),n_=u(Ra),qe=l(Ra,"TR",{class:!0});var Cu=r(qe);Kr=l(Cu,"TD",{class:!0});var kT=r(Kr);ed=l(kT,"STRONG",{});var ET=r(ed);c_=n(ET,"Output Quality"),ET.forEach(t),kT.forEach(t),u_=u(Cu),Xr=l(Cu,"TD",{class:!0});var bT=r(Xr);f_=n(bT,"Random noise/artifacts"),bT.forEach(t),d_=u(Cu),Zr=l(Cu,"TD",{class:!0});var xT=r(Zr);p_=n(xT,"Overly detailed replicas"),xT.forEach(t),Cu.forEach(t),h_=u(Ra),Me=l(Ra,"TR",{class:!0});var Gu=r(Me);Qr=l(Gu,"TD",{class:!0});var yT=r(Qr);td=l(yT,"STRONG",{});var wT=r(td);g_=n(wT,"Recovery"),wT.forEach(t),yT.forEach(t),m_=u(Gu),Jr=l(Gu,"TD",{class:!0});var TT=r(Jr);v_=n(TT,"Requires restart"),TT.forEach(t),__=u(Gu),$r=l(Gu,"TD",{class:!0});var RT=r($r);k_=n(RT,"Early stopping works"),RT.forEach(t),Gu.forEach(t),Ra.forEach(t),wm.forEach(t),dh=u(s),ls=l(s,"H3",{id:!0});var Cw=r(ls);rs=l(Cw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ST=r(rs);sd=l(ST,"SPAN",{class:!0}),r(sd).forEach(t),ST.forEach(t),E_=n(Cw,"Preventing Divergence"),Cw.forEach(t),ph=u(s),It=l(s,"TABLE",{class:!0});var Tm=r(It);ei=l(Tm,"THEAD",{class:!0});var DT=r(ei);is=l(DT,"TR",{class:!0});var Rm=r(is);ti=l(Rm,"TH",{class:!0});var AT=r(ti);b_=n(AT,"Situation"),AT.forEach(t),x_=u(Rm),si=l(Rm,"TH",{class:!0});var LT=r(si);y_=n(LT,"Outcome"),LT.forEach(t),Rm.forEach(t),DT.forEach(t),w_=u(Tm),pe=l(Tm,"TBODY",{class:!0});var Sa=r(pe);os=l(Sa,"TR",{class:!0});var Sm=r(os);ai=l(Sm,"TD",{class:!0});var IT=r(ai);ad=l(IT,"STRONG",{});var PT=r(ad);T_=n(PT,"Excessive or inconsistent data"),PT.forEach(t),IT.forEach(t),R_=u(Sm),li=l(Sm,"TD",{class:!0});var OT=r(li);S_=n(OT,"Model struggles to learn and produces unreliable predictions."),OT.forEach(t),Sm.forEach(t),D_=u(Sa),ns=l(Sa,"TR",{class:!0});var Dm=r(ns);ri=l(Dm,"TD",{class:!0});var zT=r(ri);ld=l(zT,"STRONG",{});var NT=r(ld);A_=n(NT,"Lack of unique and consistent features"),NT.forEach(t),zT.forEach(t),L_=u(Dm),ii=l(Dm,"TD",{class:!0});var CT=r(ii);I_=n(CT,"Poor generalization, leading to inaccurate or meaningless outputs."),CT.forEach(t),Dm.forEach(t),P_=u(Sa),cs=l(Sa,"TR",{class:!0});var Am=r(cs);oi=l(Am,"TD",{class:!0});var GT=r(oi);rd=l(GT,"STRONG",{});var HT=r(rd);O_=n(HT,"Carefully curated datasets"),HT.forEach(t),GT.forEach(t),z_=u(Am),ni=l(Am,"TD",{class:!0});var qT=r(ni);N_=n(qT,"Improved learning by ensuring the model sees only relevant, high-quality data."),qT.forEach(t),Am.forEach(t),C_=u(Sa),us=l(Sa,"TR",{class:!0});var Lm=r(us);ci=l(Lm,"TD",{class:!0});var MT=r(ci);id=l(MT,"STRONG",{});var UT=r(id);G_=n(UT,"Effective use of regularization techniques"),UT.forEach(t),MT.forEach(t),H_=u(Lm),ui=l(Lm,"TD",{class:!0});var BT=r(ui);q_=n(BT,"Helps maintain focus on essential features and prevents instability."),BT.forEach(t),Lm.forEach(t),Sa.forEach(t),Tm.forEach(t),hh=u(s),fi=l(s,"P",{});var WT=r(fi);M_=n(WT,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),WT.forEach(t),gh=u(s),fs=l(s,"H3",{id:!0});var Gw=r(fs);ds=l(Gw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jT=r(ds);od=l(jT,"SPAN",{class:!0}),r(od).forEach(t),jT.forEach(t),U_=n(Gw,"Implementing these Strategies"),Gw.forEach(t),mh=u(s),Za=l(s,"PRE",{class:!0});var zA=r(Za);zA.forEach(t),vh=u(s),Qa=l(s,"PRE",{class:!0});var NA=r(Qa);NA.forEach(t),_h=u(s),ps=l(s,"H3",{id:!0});var Hw=r(ps);hs=l(Hw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var FT=r(hs);nd=l(FT,"SPAN",{class:!0}),r(nd).forEach(t),FT.forEach(t),B_=n(Hw,"Data Considerations"),Hw.forEach(t),kh=u(s),Pt=l(s,"TABLE",{class:!0});var Im=r(Pt);di=l(Im,"THEAD",{class:!0});var VT=r(di);Ue=l(VT,"TR",{class:!0});var Hu=r(Ue);pi=l(Hu,"TH",{class:!0});var YT=r(pi);W_=n(YT,"Situation"),YT.forEach(t),j_=u(Hu),hi=l(Hu,"TH",{class:!0});var KT=r(hi);F_=n(KT,"Actual Risk"),KT.forEach(t),V_=u(Hu),gi=l(Hu,"TH",{class:!0});var XT=r(gi);Y_=n(XT,"Solution"),XT.forEach(t),Hu.forEach(t),VT.forEach(t),K_=u(Im),he=l(Im,"TBODY",{class:!0});var Da=r(he);Be=l(Da,"TR",{class:!0});var qu=r(Be);mi=l(qu,"TD",{class:!0});var ZT=r(mi);X_=n(ZT,"High LR + small batch size"),ZT.forEach(t),Z_=u(qu),vi=l(qu,"TD",{class:!0});var QT=r(vi);Q_=n(QT,"Divergence"),QT.forEach(t),J_=u(qu),_i=l(qu,"TD",{class:!0});var JT=r(_i);$_=n(JT,"Lower LR, increase batch size"),JT.forEach(t),qu.forEach(t),e1=u(Da),We=l(Da,"TR",{class:!0});var Mu=r(We);ki=l(Mu,"TD",{class:!0});var $T=r(ki);t1=n($T,"Inconsistent features"),$T.forEach(t),s1=u(Mu),Ei=l(Mu,"TD",{class:!0});var e8=r(Ei);a1=n(e8,"Overfitting"),e8.forEach(t),l1=u(Mu),bi=l(Mu,"TD",{class:!0});var t8=r(bi);r1=n(t8,"Improve dataset consistency"),t8.forEach(t),Mu.forEach(t),i1=u(Da),je=l(Da,"TR",{class:!0});var Uu=r(je);xi=l(Uu,"TD",{class:!0});var s8=r(xi);o1=n(s8,"Insufficient reg images"),s8.forEach(t),n1=u(Uu),yi=l(Uu,"TD",{class:!0});var a8=r(yi);c1=n(a8,"Class leakage"),a8.forEach(t),u1=u(Uu),wi=l(Uu,"TD",{class:!0});var l8=r(wi);f1=n(l8,"Add 100-300 class images"),l8.forEach(t),Uu.forEach(t),d1=u(Da),Fe=l(Da,"TR",{class:!0});var Bu=r(Fe);Ti=l(Bu,"TD",{class:!0});var r8=r(Ti);p1=n(r8,"High variance in training data"),r8.forEach(t),h1=u(Bu),Ri=l(Bu,"TD",{class:!0});var i8=r(Ri);g1=n(i8,"Mode collapse"),i8.forEach(t),m1=u(Bu),Si=l(Bu,"TD",{class:!0});var o8=r(Si);v1=n(o8,"Curate focused dataset"),o8.forEach(t),Bu.forEach(t),Da.forEach(t),Im.forEach(t),Eh=u(s),bh=l(s,"HR",{}),xh=u(s),gs=l(s,"H2",{id:!0});var qw=r(gs);ms=l(qw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var n8=r(ms);cd=l(n8,"SPAN",{class:!0}),r(cd).forEach(t),n8.forEach(t),_1=n(qw,"Monitoring Tips"),qw.forEach(t),yh=u(s),vs=l(s,"P",{});var Pm=r(vs);k1=n(Pm,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ja=l(Pm,"A",{href:!0,rel:!0});var c8=r(Ja);E1=n(c8,"kohya-ss/sd-scripts"),c8.forEach(t),b1=n(Pm,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),Pm.forEach(t),wh=u(s),_s=l(s,"H3",{id:!0});var Mw=r(_s);ks=l(Mw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var u8=r(ks);ud=l(u8,"SPAN",{class:!0}),r(ud).forEach(t),u8.forEach(t),x1=n(Mw,"Track loss curves"),Mw.forEach(t),Th=u(s),Es=l(s,"P",{});var Om=r(Es);y1=n(Om,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),$a=l(Om,"A",{href:!0,rel:!0});var f8=r($a);w1=n(f8,"TensorBoard"),f8.forEach(t),T1=n(Om," to create these graphs."),Om.forEach(t),Rh=u(s),el=l(s,"PRE",{class:!0});var CA=r(el);CA.forEach(t),Sh=u(s),bs=l(s,"H4",{id:!0});var Uw=r(bs);xs=l(Uw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var d8=r(xs);fd=l(d8,"SPAN",{class:!0}),r(fd).forEach(t),d8.forEach(t),R1=n(Uw,"What to Monitor:"),Uw.forEach(t),Dh=u(s),Ve=l(s,"UL",{});var Wu=r(Ve);dd=l(Wu,"LI",{});var p8=r(dd);S1=n(p8,"Training Loss: Should decrease steadily but not too quickly."),p8.forEach(t),D1=u(Wu),pd=l(Wu,"LI",{});var h8=r(pd);A1=n(h8,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),h8.forEach(t),L1=u(Wu),hd=l(Wu,"LI",{});var g8=r(hd);I1=n(g8,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),g8.forEach(t),Wu.forEach(t),Ah=u(s),ys=l(s,"H4",{id:!0});var Bw=r(ys);ws=l(Bw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var m8=r(ws);gd=l(m8,"SPAN",{class:!0}),r(gd).forEach(t),m8.forEach(t),P1=n(Bw,"Warning Signs:"),Bw.forEach(t),Lh=u(s),Ye=l(s,"UL",{});var ju=r(Ye);md=l(ju,"LI",{});var v8=r(md);O1=n(v8,"Sudden spikes in loss \u2192 Likely divergence."),v8.forEach(t),z1=u(ju),vd=l(ju,"LI",{});var _8=r(vd);N1=n(_8,"Loss plateauing too early \u2192 Learning rate may be too low."),_8.forEach(t),C1=u(ju),_d=l(ju,"LI",{});var k8=r(_d);G1=n(k8,"Validation loss increasing while training loss decreases \u2192 Overfitting."),k8.forEach(t),ju.forEach(t),Ih=u(s),Ts=l(s,"H3",{id:!0});var Ww=r(Ts);Rs=l(Ww,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var E8=r(Rs);kd=l(E8,"SPAN",{class:!0}),r(kd).forEach(t),E8.forEach(t),H1=n(Ww,"Generate validation images every 100 steps"),Ww.forEach(t),Ph=u(s),tl=l(s,"P",{});var jw=r(tl);Ed=l(jw,"STRONG",{});var b8=r(Ed);q1=n(b8,"Why It Matters"),b8.forEach(t),M1=n(jw," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),jw.forEach(t),Oh=u(s),sl=l(s,"PRE",{class:!0});var GA=r(sl);GA.forEach(t),zh=u(s),Ss=l(s,"H4",{id:!0});var Fw=r(Ss);Ds=l(Fw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var x8=r(Ds);bd=l(x8,"SPAN",{class:!0}),r(bd).forEach(t),x8.forEach(t),U1=n(Fw,"What to Look For:"),Fw.forEach(t),Nh=u(s),Ke=l(s,"UL",{});var Fu=r(Ke);xd=l(Fu,"LI",{});var y8=r(xd);B1=n(y8,"Consistency: Outputs should align with the training data style."),y8.forEach(t),W1=u(Fu),yd=l(Fu,"LI",{});var w8=r(yd);j1=n(w8,"Artifacts: Check for distortions, noise, or unnatural features."),w8.forEach(t),F1=u(Fu),wd=l(Fu,"LI",{});var T8=r(wd);V1=n(T8,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),T8.forEach(t),Fu.forEach(t),Ch=u(s),al=l(s,"BLOCKQUOTE",{class:!0});var R8=r(al);Di=l(R8,"P",{class:!0});var S8=r(Di);Y1=n(S8,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),S8.forEach(t),R8.forEach(t),Gh=u(s),As=l(s,"H4",{id:!0});var Vw=r(As);Ls=l(Vw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var D8=r(Ls);Td=l(D8,"SPAN",{class:!0}),r(Td).forEach(t),D8.forEach(t),K1=n(Vw,"Use Gradient Clipping"),Vw.forEach(t),Hh=u(s),ll=l(s,"P",{});var Yw=r(ll);Rd=l(Yw,"STRONG",{});var A8=r(Rd);X1=n(A8,"Why It Matters"),A8.forEach(t),Z1=n(Yw,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),Yw.forEach(t),qh=u(s),Ai=l(s,"P",{});var L8=r(Ai);Q1=n(L8,"Key Insights:"),L8.forEach(t),Mh=u(s),Xe=l(s,"UL",{});var Vu=r(Xe);rl=l(Vu,"LI",{});var zm=r(rl);J1=n(zm,"Gradient Norm "),Li=l(zm,"CODE",{class:!0});var I8=r(Li);$1=n(I8,"<"),I8.forEach(t),ek=n(zm," than 0.1: Training may stall due to tiny updates."),zm.forEach(t),tk=u(Vu),Sd=l(Vu,"LI",{});var P8=r(Sd);sk=n(P8,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),P8.forEach(t),ak=u(Vu),Dd=l(Vu,"LI",{});var O8=r(Dd);lk=n(O8,"Ideal Range: 0.1 to 2.0 for stable training."),O8.forEach(t),Vu.forEach(t),Uh=u(s),il=l(s,"BLOCKQUOTE",{class:!0});var z8=r(il);Ii=l(z8,"P",{class:!0});var N8=r(Ii);rk=n(N8,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),N8.forEach(t),z8.forEach(t),Bh=u(s),Is=l(s,"H4",{id:!0});var Kw=r(Is);Ps=l(Kw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var C8=r(Ps);Ad=l(C8,"SPAN",{class:!0}),r(Ad).forEach(t),C8.forEach(t),ik=n(Kw,"Enable Mixed Precision Training"),Kw.forEach(t),Wh=u(s),ol=l(s,"P",{});var Xw=r(ol);Ld=l(Xw,"STRONG",{});var G8=r(Ld);ok=n(G8,"Why It Matters"),G8.forEach(t),nk=n(Xw,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),Xw.forEach(t),jh=u(s),nl=l(s,"PRE",{class:!0});var HA=r(nl);HA.forEach(t),Fh=u(s),Pi=l(s,"P",{});var H8=r(Pi);ck=n(H8,"Benefits:"),H8.forEach(t),Vh=u(s),Ze=l(s,"UL",{});var Yu=r(Ze);Id=l(Yu,"LI",{});var q8=r(Id);uk=n(q8,"2-3x Faster Training: Leverages GPU tensor cores."),q8.forEach(t),fk=u(Yu),Pd=l(Yu,"LI",{});var M8=r(Pd);dk=n(M8,"50% Less VRAM Usage: Allows larger batch sizes or models."),M8.forEach(t),pk=u(Yu),Od=l(Yu,"LI",{});var U8=r(Od);hk=n(U8,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),U8.forEach(t),Yu.forEach(t),Yh=u(s),cl=l(s,"BLOCKQUOTE",{class:!0});var B8=r(cl);Oi=l(B8,"P",{class:!0});var W8=r(Oi);gk=n(W8,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),W8.forEach(t),B8.forEach(t),Kh=u(s),Os=l(s,"H4",{id:!0});var Zw=r(Os);zs=l(Zw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var j8=r(zs);zd=l(j8,"SPAN",{class:!0}),r(zd).forEach(t),j8.forEach(t),mk=n(Zw,"Start with Conservative Learning Rates"),Zw.forEach(t),Xh=u(s),Ns=l(s,"P",{});var Nm=r(Ns);vk=n(Nm,"Start off with 1e-5 to 1e-6.  "),Nd=l(Nm,"STRONG",{});var F8=r(Nd);_k=n(F8,"Why It Matters"),F8.forEach(t),kk=n(Nm,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Nm.forEach(t),Zh=u(s),ul=l(s,"PRE",{class:!0});var qA=r(ul);qA.forEach(t),Qh=u(s),fl=l(s,"PRE",{class:!0});var MA=r(fl);MA.forEach(t),Jh=u(s),dl=l(s,"P",{});var Qw=r(dl);Cd=l(Qw,"STRONG",{});var V8=r(Cd);Ek=n(V8,"Warning Signs"),V8.forEach(t),bk=n(Qw,":"),Qw.forEach(t),$h=u(s),Qe=l(s,"UL",{});var Ku=r(Qe);Gd=l(Ku,"LI",{});var Y8=r(Gd);xk=n(Y8,"Loss Spikes: Learning rate is too high."),Y8.forEach(t),yk=u(Ku),Hd=l(Ku,"LI",{});var K8=r(Hd);wk=n(K8,"Slow Convergence: Learning rate is too low."),K8.forEach(t),Tk=u(Ku),qd=l(Ku,"LI",{});var X8=r(qd);Rk=n(X8,"Oscillating Loss: Poor scheduling or unstable gradients."),X8.forEach(t),Ku.forEach(t),eg=u(s),Ot=l(s,"TABLE",{class:!0});var Cm=r(Ot);zi=l(Cm,"THEAD",{class:!0});var Z8=r(zi);ge=l(Z8,"TR",{class:!0});var Aa=r(ge);Ni=l(Aa,"TH",{class:!0});var Q8=r(Ni);Sk=n(Q8,"Practice"),Q8.forEach(t),Dk=u(Aa),Ci=l(Aa,"TH",{class:!0});var J8=r(Ci);Ak=n(J8,"Key Benefit"),J8.forEach(t),Lk=u(Aa),Gi=l(Aa,"TH",{class:!0});var $8=r(Gi);Ik=n($8,"Tool/Setting"),$8.forEach(t),Pk=u(Aa),Hi=l(Aa,"TH",{class:!0});var eR=r(Hi);Ok=n(eR,"Warning Signs"),eR.forEach(t),Aa.forEach(t),Z8.forEach(t),zk=u(Cm),le=l(Cm,"TBODY",{class:!0});var Tt=r(le);me=l(Tt,"TR",{class:!0});var La=r(me);qi=l(La,"TD",{class:!0});var tR=r(qi);Nk=n(tR,"Track Loss Curves"),tR.forEach(t),Ck=u(La),Mi=l(La,"TD",{class:!0});var sR=r(Mi);Gk=n(sR,"Detect overfitting/divergence early"),sR.forEach(t),Hk=u(La),Ui=l(La,"TD",{class:!0});var aR=r(Ui);qk=n(aR,"TensorBoard, Weights & Biases"),aR.forEach(t),Mk=u(La),Bi=l(La,"TD",{class:!0});var lR=r(Bi);Uk=n(lR,"Spikes, plateaus, growing gaps"),lR.forEach(t),La.forEach(t),Bk=u(Tt),ve=l(Tt,"TR",{class:!0});var Ia=r(ve);Wi=l(Ia,"TD",{class:!0});var rR=r(Wi);Wk=n(rR,"Generate Validation Images"),rR.forEach(t),jk=u(Ia),ji=l(Ia,"TD",{class:!0});var iR=r(ji);Fk=n(iR,"Visualize model progress"),iR.forEach(t),Vk=u(Ia),Fi=l(Ia,"TD",{class:!0});var oR=r(Fi);Yk=n(oR,"Fixed prompts/seeds"),oR.forEach(t),Kk=u(Ia),Vi=l(Ia,"TD",{class:!0});var nR=r(Vi);Xk=n(nR,"Artifacts, mode collapse"),nR.forEach(t),Ia.forEach(t),Zk=u(Tt),_e=l(Tt,"TR",{class:!0});var Pa=r(_e);Yi=l(Pa,"TD",{class:!0});var cR=r(Yi);Qk=n(cR,"Gradient Clipping"),cR.forEach(t),Jk=u(Pa),Ki=l(Pa,"TD",{class:!0});var uR=r(Ki);$k=n(uR,"Prevent exploding gradients"),uR.forEach(t),eE=u(Pa),Cs=l(Pa,"TD",{class:!0});var Gm=r(Cs);tE=n(Gm,"clip"),Md=l(Gm,"EM",{});var fR=r(Md);sE=n(fR,"grad_norm"),fR.forEach(t),aE=n(Gm," (1.0-2.0)"),Gm.forEach(t),lE=u(Pa),Je=l(Pa,"TD",{class:!0});var Xu=r(Je);rE=n(Xu,"Norm "),Xi=l(Xu,"CODE",{class:!0});var dR=r(Xi);iE=n(dR,">"),dR.forEach(t),oE=n(Xu," 10.0 or "),Zi=l(Xu,"CODE",{class:!0});var pR=r(Zi);nE=n(pR,"<"),pR.forEach(t),cE=n(Xu," 0.1"),Xu.forEach(t),Pa.forEach(t),uE=u(Tt),ke=l(Tt,"TR",{class:!0});var Oa=r(ke);Qi=l(Oa,"TD",{class:!0});var hR=r(Qi);fE=n(hR,"Mixed Precision Training"),hR.forEach(t),dE=u(Oa),Ji=l(Oa,"TD",{class:!0});var gR=r(Ji);pE=n(gR,"Faster training, lower VRAM usage"),gR.forEach(t),hE=u(Oa),$i=l(Oa,"TD",{class:!0});var mR=r($i);gE=n(mR,"PyTorch AMP (torch.cuda.amp)"),mR.forEach(t),mE=u(Oa),eo=l(Oa,"TD",{class:!0});var vR=r(eo);vE=n(vR,"NaN values (disable if unstable)"),vR.forEach(t),Oa.forEach(t),_E=u(Tt),Ee=l(Tt,"TR",{class:!0});var za=r(Ee);to=l(za,"TD",{class:!0});var _R=r(to);kE=n(_R,"Conservative Learning Rates"),_R.forEach(t),EE=u(za),so=l(za,"TD",{class:!0});var kR=r(so);bE=n(kR,"Stable training, avoid divergence"),kR.forEach(t),xE=u(za),ao=l(za,"TD",{class:!0});var ER=r(ao);yE=n(ER,"Start at 1e-5 to 1e-6, use scheduler"),ER.forEach(t),wE=u(za),lo=l(za,"TD",{class:!0});var bR=r(lo);TE=n(bR,"Spikes, slow convergence"),bR.forEach(t),za.forEach(t),Tt.forEach(t),Cm.forEach(t),tg=u(s),sg=l(s,"HR",{}),ag=u(s),Gs=l(s,"H2",{id:!0});var Jw=r(Gs);Hs=l(Jw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xR=r(Hs);Ud=l(xR,"SPAN",{class:!0}),r(Ud).forEach(t),xR.forEach(t),RE=n(Jw,"Generating Regularization images"),Jw.forEach(t),lg=u(s),qs=l(s,"P",{});var Hm=r(qs);SE=n(Hm,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),ro=l(Hm,"CODE",{class:!0});var yR=r(ro);DE=n(yR,"1boy"),yR.forEach(t),AE=n(Hm,")."),Hm.forEach(t),rg=u(s),ue=l(s,"P",{});var qt=r(ue);LE=n(qt,"According to the Dreambooth technique, "),io=l(qt,"CODE",{class:!0});var wR=r(io);IE=n(wR,"200"),wR.forEach(t),PE=n(qt," regularization images per training image.  For example, if you have "),oo=l(qt,"CODE",{class:!0});var TR=r(oo);OE=n(TR,"16"),TR.forEach(t),zE=n(qt," images: "),no=l(qt,"CODE",{class:!0});var RR=r(no);NE=n(RR,"200 * 16 = 3200"),RR.forEach(t),CE=n(qt," total regularization images.  When training, the math involved for calculating total steps is: "),co=l(qt,"CODE",{class:!0});var SR=r(co);GE=n(SR,"repeats * training images >= repeats * regularization images"),SR.forEach(t),qt.forEach(t),ig=u(s),uo=l(s,"P",{});var DR=r(uo);HE=n(DR,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),DR.forEach(t),og=u(s),Ms=l(s,"H4",{id:!0});var $w=r(Ms);Us=l($w,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var AR=r(Us);Bd=l(AR,"SPAN",{class:!0}),r(Bd).forEach(t),AR.forEach(t),qE=n($w,"Important considerations"),$w.forEach(t),ng=u(s),$e=l(s,"OL",{});var Zu=r($e);Wd=l(Zu,"LI",{});var LR=r(Wd);pl=l(LR,"P",{});var qm=r(pl);jd=l(qm,"STRONG",{});var IR=r(jd);ME=n(IR,"Use the same base model for regularization images and training"),IR.forEach(t),UE=l(qm,"BR",{}),BE=n(qm,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),qm.forEach(t),LR.forEach(t),WE=u(Zu),Fd=l(Zu,"LI",{});var PR=r(Fd);hl=l(PR,"P",{});var Mm=r(hl);Vd=l(Mm,"STRONG",{});var OR=r(Vd);jE=n(OR,"Maintain consistent class representation"),OR.forEach(t),FE=l(Mm,"BR",{}),VE=n(Mm,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Mm.forEach(t),PR.forEach(t),YE=u(Zu),Yd=l(Zu,"LI",{});var zR=r(Yd);gl=l(zR,"P",{});var Um=r(gl);Kd=l(Um,"STRONG",{});var NR=r(Kd);KE=n(NR,"Match output resolution to training data"),NR.forEach(t),XE=l(Um,"BR",{}),ZE=n(Um,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Um.forEach(t),zR.forEach(t),Zu.forEach(t),cg=u(s),rr(ml.$$.fragment,s),ug=u(s),Bs=l(s,"H4",{id:!0});var e7=r(Bs);Ws=l(e7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var CR=r(Ws);Xd=l(CR,"SPAN",{class:!0}),r(Xd).forEach(t),CR.forEach(t),QE=n(e7,"Generate using Stable Diffusion web UI"),e7.forEach(t),fg=u(s),js=l(s,"P",{});var Bm=r(js);JE=n(Bm,"We\u2019re going to use "),vl=l(Bm,"A",{href:!0,rel:!0});var GR=r(vl);$E=n(GR,"Stable Diffusion web UI"),GR.forEach(t),eb=n(Bm," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Bm.forEach(t),dg=u(s),et=l(s,"P",{});var Qu=r(et);tb=n(Qu,"We\u2019re going to use the "),fo=l(Qu,"CODE",{class:!0});var HR=r(fo);sb=n(HR,"X/Y/Z plot"),HR.forEach(t),ab=n(Qu," script to use "),po=l(Qu,"CODE",{class:!0});var qR=r(po);lb=n(qR,"Prompt Search & Replace"),qR.forEach(t),rb=n(Qu," to dynamically build a prompt that will generate hundreds of regularization images."),Qu.forEach(t),pg=u(s),J=l(s,"OL",{});var ne=r(J);Zd=l(ne,"LI",{});var MR=r(Zd);ho=l(MR,"P",{});var t7=r(ho);ib=n(t7,"Select the text 2 image tab.  Enter a generic prompt "),go=l(t7,"CODE",{class:!0});var UR=r(go);ob=n(UR,"princeadam, portrait, looking_at_viewer, forest"),UR.forEach(t),t7.forEach(t),MR.forEach(t),nb=u(ne),Qd=l(ne,"LI",{});var BR=r(Qd);_l=l(BR,"P",{});var Wm=r(_l);cb=n(Wm,"In generation parameters and select the "),mo=l(Wm,"CODE",{class:!0});var WR=r(mo);ub=n(WR,"X/Y/Z plot"),WR.forEach(t),fb=n(Wm," script."),Wm.forEach(t),BR.forEach(t),db=u(ne),Jd=l(ne,"LI",{});var jR=r(Jd);Y=l(jR,"P",{});var te=r(Y);pb=n(te,"Select the "),vo=l(te,"CODE",{class:!0});var FR=r(vo);hb=n(FR,"X"),FR.forEach(t),gb=n(te," parameter and "),_o=l(te,"CODE",{class:!0});var VR=r(_o);mb=n(VR,"Prompt SR"),VR.forEach(t),vb=n(te," for Prompt Replace.  We\u2019re going to replace "),ko=l(te,"CODE",{class:!0});var YR=r(ko);_b=n(YR,"portrait"),YR.forEach(t),kb=n(te," with different camera angle tags: "),Eo=l(te,"CODE",{class:!0});var KR=r(Eo);Eb=n(KR,"close-up"),KR.forEach(t),bb=n(te,", "),bo=l(te,"CODE",{class:!0});var XR=r(bo);xb=n(XR,"upper_body"),XR.forEach(t),yb=n(te,", "),xo=l(te,"CODE",{class:!0});var ZR=r(xo);wb=n(ZR,"from_below"),ZR.forEach(t),Tb=n(te,", "),yo=l(te,"CODE",{class:!0});var QR=r(yo);Rb=n(QR,"from_above"),QR.forEach(t),Sb=n(te,", "),wo=l(te,"CODE",{class:!0});var JR=r(wo);Db=n(JR,"dutch_angle"),JR.forEach(t),te.forEach(t),jR.forEach(t),Ab=u(ne),$d=l(ne,"LI",{});var $R=r($d);$=l($R,"P",{});var ae=r($);Lb=n(ae,"Select the "),To=l(ae,"CODE",{class:!0});var eS=r(To);Ib=n(eS,"Y"),eS.forEach(t),Pb=n(ae," parameter and "),Ro=l(ae,"CODE",{class:!0});var tS=r(Ro);Ob=n(tS,"Prompt SR"),tS.forEach(t),zb=n(ae," for Prompt Replace.  Replace "),So=l(ae,"CODE",{class:!0});var sS=r(So);Nb=n(sS,"looking_at_viewer"),sS.forEach(t),Cb=n(ae,": "),Do=l(ae,"CODE",{class:!0});var aS=r(Do);Gb=n(aS,"looking_away"),aS.forEach(t),Hb=n(ae,", "),Ao=l(ae,"CODE",{class:!0});var lS=r(Ao);qb=n(lS,"looking_to_the_side"),lS.forEach(t),Mb=n(ae,", "),Lo=l(ae,"CODE",{class:!0});var rS=r(Lo);Ub=n(rS,"looking_ahead"),rS.forEach(t),Bb=n(ae,", "),Io=l(ae,"CODE",{class:!0});var iS=r(Io);Wb=n(iS,"looking_down"),iS.forEach(t),ae.forEach(t),$R.forEach(t),jb=u(ne),ep=l(ne,"LI",{});var oS=r(ep);K=l(oS,"P",{});var se=r(K);Fb=n(se,"Select the "),Po=l(se,"CODE",{class:!0});var nS=r(Po);Vb=n(nS,"Z"),nS.forEach(t),Yb=n(se," parameter and "),Oo=l(se,"CODE",{class:!0});var cS=r(Oo);Kb=n(cS,"Prompt SR"),cS.forEach(t),Xb=n(se," for Prompt Replace. Replace "),zo=l(se,"CODE",{class:!0});var uS=r(zo);Zb=n(uS,"forest"),uS.forEach(t),Qb=n(se," with a vareity of locatinos: "),No=l(se,"CODE",{class:!0});var fS=r(No);Jb=n(fS,"castle"),fS.forEach(t),$b=n(se,", "),Co=l(se,"CODE",{class:!0});var dS=r(Co);ex=n(dS,"mountain"),dS.forEach(t),tx=n(se,", "),Go=l(se,"CODE",{class:!0});var pS=r(Go);sx=n(pS,"cave"),pS.forEach(t),ax=n(se,", "),Ho=l(se,"CODE",{class:!0});var hS=r(Ho);lx=n(hS,"farm"),hS.forEach(t),rx=n(se,", "),qo=l(se,"CODE",{class:!0});var gS=r(qo);ix=n(gS,"ocean"),gS.forEach(t),se.forEach(t),oS.forEach(t),ox=u(ne),tp=l(ne,"LI",{});var mS=r(tp);Mo=l(mS,"P",{});var s7=r(Mo);nx=n(s7,"Select a fast sampler like "),Uo=l(s7,"CODE",{class:!0});var vS=r(Uo);cx=n(vS,"DPM2 KARRAS"),vS.forEach(t),s7.forEach(t),mS.forEach(t),ux=u(ne),sp=l(ne,"LI",{});var _S=r(sp);Fs=l(_S,"P",{});var Ip=r(Fs);fx=n(Ip,"CFG Scale set to "),Bo=l(Ip,"CODE",{class:!0});var kS=r(Bo);dx=n(kS,"7"),kS.forEach(t),px=n(Ip," and Steps to "),Wo=l(Ip,"CODE",{class:!0});var ES=r(Wo);hx=n(ES,"20"),ES.forEach(t),Ip.forEach(t),_S.forEach(t),ne.forEach(t),hg=u(s),tt=l(s,"P",{});var Ju=r(tt);gx=n(Ju,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),jo=l(Ju,"CODE",{class:!0});var bS=r(jo);mx=n(bS,"150"),bS.forEach(t),vx=n(Ju," - "),Fo=l(Ju,"CODE",{class:!0});var xS=r(Fo);_x=n(xS,"200"),xS.forEach(t),kx=n(Ju," and keep in mind we can add and remove as we try different training settings with different output."),Ju.forEach(t),gg=u(s),rr(kl.$$.fragment,s),mg=u(s),Vs=l(s,"H4",{id:!0});var a7=r(Vs);Ys=l(a7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var yS=r(Ys);ap=l(yS,"SPAN",{class:!0}),r(ap).forEach(t),yS.forEach(t),Ex=n(a7,"Download images"),a7.forEach(t),vg=u(s),Vo=l(s,"P",{});var wS=r(Vo);bx=n(wS,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),wS.forEach(t),_g=u(s),be=l(s,"UL",{});var Na=r(be);Yo=l(Na,"LI",{});var l7=r(Yo);El=l(l7,"A",{href:!0,rel:!0});var TS=r(El);xx=n(TS,"3ee Games regularization images"),TS.forEach(t),yx=n(l7,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),l7.forEach(t),wx=u(Na),Ko=l(Na,"LI",{});var r7=r(Ko);bl=l(r7,"A",{href:!0,rel:!0});var RS=r(bl);Tx=n(RS,"Pre-Rendered Regularization Images"),RS.forEach(t),Rx=n(r7,": Includes 1500 regularization images."),r7.forEach(t),Sx=u(Na),Xo=l(Na,"LI",{});var i7=r(Xo);xl=l(i7,"A",{href:!0,rel:!0});var SS=r(xl);Dx=n(SS,"Stable Diffusion 1.5 Regularization Images"),SS.forEach(t),Ax=n(i7,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),i7.forEach(t),Lx=u(Na),Zo=l(Na,"LI",{});var o7=r(Zo);yl=l(o7,"A",{href:!0,rel:!0});var DS=r(yl);Ix=n(DS,"Aitrepreneur SDXL image set"),DS.forEach(t),Px=n(o7,": a large image set generated with Stable Diffusion SDXL."),o7.forEach(t),Na.forEach(t),kg=u(s),Ks=l(s,"H4",{id:!0});var n7=r(Ks);Xs=l(n7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var AS=r(Xs);lp=l(AS,"SPAN",{class:!0}),r(lp).forEach(t),AS.forEach(t),Ox=n(n7,"Captioning Regularization images"),n7.forEach(t),Eg=u(s),Qo=l(s,"P",{});var LS=r(Qo);zx=n(LS,"While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),LS.forEach(t),bg=u(s),Jo=l(s,"P",{});var IS=r(Jo);Nx=n(IS,"Here\u2019s the workflow I used:"),IS.forEach(t),xg=u(s),st=l(s,"UL",{});var $u=r(st);Zs=l($u,"LI",{});var Pp=r(Zs);rp=l(Pp,"STRONG",{});var PS=r(rp);Cx=n(PS,"Structured Filenames"),PS.forEach(t),Gx=n(Pp,": Stable Diffusion Web UI automatically embeds prompts in filenames (e.g., "),$o=l(Pp,"CODE",{class:!0});var OS=r($o);Hx=n(OS,"princeadam_1boy_closeup.png"),OS.forEach(t),qx=n(Pp,")."),Pp.forEach(t),Mx=u($u),at=l($u,"LI",{});var sr=r(at);ip=l(sr,"STRONG",{});var zS=r(ip);Ux=n(zS,"Automated Extraction"),zS.forEach(t),Bx=n(sr,": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),en=l(sr,"CODE",{class:!0});var NS=r(en);Wx=n(NS,"1boy"),NS.forEach(t),jx=n(sr," or "),tn=l(sr,"CODE",{class:!0});var CS=r(tn);Fx=n(CS,"purple_vest"),CS.forEach(t),Vx=n(sr,"."),sr.forEach(t),Yx=u($u),sn=l($u,"LI",{});var c7=r(sn);op=l(c7,"STRONG",{});var GS=r(op);Kx=n(GS,"Manual Verification"),GS.forEach(t),Xx=n(c7,": Spot-checked captions to ensure accuracy."),c7.forEach(t),$u.forEach(t),yg=u(s),wl=l(s,"PRE",{class:!0});var UA=r(wl);UA.forEach(t),wg=u(s),Qs=l(s,"OL",{});var jm=r(Qs);Tl=l(jm,"LI",{});var Fm=r(Tl);Zx=n(Fm,"Save this file as "),an=l(Fm,"CODE",{class:!0});var HS=r(an);Qx=n(HS,"filename2txt.bat"),HS.forEach(t),Jx=n(Fm," and place it into the regularization images directory"),Fm.forEach(t),$x=u(jm),Rl=l(jm,"LI",{});var Vm=r(Rl);ey=n(Vm,"Run: "),ln=l(Vm,"CODE",{class:!0});var qS=r(ln);ty=n(qS,".\\filename2txt.bat"),qS.forEach(t),sy=n(Vm,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Vm.forEach(t),jm.forEach(t),Tg=u(s),Js=l(s,"UL",{});var Ym=r(Js);rn=l(Ym,"LI",{});var u7=r(rn);ay=n(u7,"Example filename: "),on=l(u7,"CODE",{class:!0});var MS=r(on);ly=n(MS,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),MS.forEach(t),u7.forEach(t),ry=u(Ym),Sl=l(Ym,"LI",{});var Km=r(Sl);iy=n(Km,"Output: "),nn=l(Km,"CODE",{class:!0});var US=r(nn);oy=n(US,"aburbres,princeadam,1boy,close-up,purple_vest"),US.forEach(t),ny=n(Km," saved in a text file with the same name as image."),Km.forEach(t),Ym.forEach(t),Rg=u(s),$s=l(s,"H2",{id:!0});var f7=r($s);ea=l(f7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var BS=r(ea);np=l(BS,"SPAN",{class:!0}),r(np).forEach(t),BS.forEach(t),cy=n(f7,"Training a LoRA"),f7.forEach(t),Sg=u(s),ta=l(s,"P",{});var Xm=r(ta);uy=n(Xm,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),Dl=l(Xm,"A",{href:!0,rel:!0});var WS=r(Dl);fy=n(WS,"kohya-ss/sd-scripts"),WS.forEach(t),dy=n(Xm,"."),Xm.forEach(t),Dg=u(s),Al=l(s,"BLOCKQUOTE",{class:!0});var jS=r(Al);sa=l(jS,"P",{class:!0});var Zm=r(sa);py=n(Zm,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Ll=l(Zm,"A",{href:!0,rel:!0});var FS=r(Ll);hy=n(FS,"Kohya SD script documentation"),FS.forEach(t),gy=n(Zm,"."),Zm.forEach(t),jS.forEach(t),Ag=u(s),aa=l(s,"H3",{id:!0});var d7=r(aa);la=l(d7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var VS=r(la);cp=l(VS,"SPAN",{class:!0}),r(cp).forEach(t),VS.forEach(t),my=n(d7,"Directory setup"),d7.forEach(t),Lg=u(s),ra=l(s,"P",{});var Qm=r(ra);vy=n(Qm,"In your configuration json, use "),cn=l(Qm,"CODE",{class:!0});var YS=r(cn);_y=n(YS,"reg_data_dir"),YS.forEach(t),ky=n(Qm," to point to the directory with your regularization images:"),Qm.forEach(t),Ig=u(s),Il=l(s,"PRE",{class:!0});var BA=r(Il);BA.forEach(t),Pg=u(s),un=l(s,"P",{});var KS=r(un);Ey=n(KS,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),KS.forEach(t),Og=u(s),Pl=l(s,"PRE",{class:!0});var WA=r(Pl);WA.forEach(t),zg=u(s),lt=l(s,"P",{});var ef=r(lt);by=n(ef,"Set the "),fn=l(ef,"CODE",{class:!0});var XS=r(fn);xy=n(XS,"number of iterations"),XS.forEach(t),yy=n(ef," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),dn=l(ef,"CODE",{class:!0});var ZS=r(dn);wy=n(ZS,"training images \xD7 iterations"),ZS.forEach(t),Ty=n(ef,". If there are more regularization images than this, the extras won\u2019t be used."),ef.forEach(t),Ng=u(s),rt=l(s,"P",{});var tf=r(rt);Ry=n(tf,"Create folders in the training image folder with the format "),pn=l(tf,"CODE",{class:!0});var QS=r(pn);Sy=n(QS,"<repetition count>_<class>"),QS.forEach(t),Dy=n(tf," multiple times, and similarly create folders in the regularization image folder with the format "),hn=l(tf,"CODE",{class:!0});var JS=r(hn);Ay=n(JS,"<repetition count>_<class>"),JS.forEach(t),Ly=n(tf,"."),tf.forEach(t),Cg=u(s),gn=l(s,"P",{});var $S=r(gn);Iy=n($S,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),$S.forEach(t),Gg=u(s),ia=l(s,"UL",{});var Jm=r(ia);mn=l(Jm,"LI",{});var p7=r(mn);Py=n(p7,"train_data_dir"),up=l(p7,"UL",{});var eD=r(up);fp=l(eD,"LI",{});var tD=r(fp);Oy=n(tD,"10_princeadam"),tD.forEach(t),eD.forEach(t),p7.forEach(t),zy=u(Jm),vn=l(Jm,"LI",{});var h7=r(vn);Ny=n(h7,"reg_dir"),dp=l(h7,"UL",{});var sD=r(dp);pp=l(sD,"LI",{});var aD=r(pp);Cy=n(aD,"1_1boy"),aD.forEach(t),sD.forEach(t),h7.forEach(t),Jm.forEach(t),Hg=u(s),_n=l(s,"P",{});var lD=r(_n);Gy=n(lD,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),lD.forEach(t),qg=u(s),Ol=l(s,"P",{class:!0});var rD=r(Ol);zl=l(rD,"IMG",{src:!0,alt:!0,class:!0}),rD.forEach(t),Mg=u(s),oa=l(s,"H3",{id:!0});var g7=r(oa);na=l(g7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var iD=r(na);hp=l(iD,"SPAN",{class:!0}),r(hp).forEach(t),iD.forEach(t),Hy=n(g7,"Training Settings"),g7.forEach(t),Ug=u(s),zt=l(s,"P",{});var Op=r(zt);qy=n(Op,"The training setup we\u2019re going to use is:  "),kn=l(Op,"CODE",{class:!0});var oD=r(kn);My=n(oD,"Number of images * repeats * epoch / batch size = total steps"),oD.forEach(t),Uy=n(Op,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),En=l(Op,"CODE",{class:!0});var nD=r(En);By=n(nD,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),nD.forEach(t),Op.forEach(t),Bg=u(s),Nt=l(s,"TABLE",{class:!0});var $m=r(Nt);bn=l($m,"THEAD",{class:!0});var cD=r(bn);re=l(cD,"TR",{class:!0});var Rt=r(re);xn=l(Rt,"TH",{class:!0});var uD=r(xn);Wy=n(uD,"Number of Images"),uD.forEach(t),jy=u(Rt),yn=l(Rt,"TH",{class:!0});var fD=r(yn);Fy=n(fD,"Repeats"),fD.forEach(t),Vy=u(Rt),wn=l(Rt,"TH",{class:!0});var dD=r(wn);Yy=n(dD,"Epochs"),dD.forEach(t),Ky=u(Rt),Tn=l(Rt,"TH",{class:!0});var pD=r(Tn);Xy=n(pD,"Batch Size"),pD.forEach(t),Zy=u(Rt),Rn=l(Rt,"TH",{class:!0});var hD=r(Rn);Qy=n(hD,"Total Steps"),hD.forEach(t),Rt.forEach(t),cD.forEach(t),Jy=u($m),Sn=l($m,"TBODY",{class:!0});var gD=r(Sn);ie=l(gD,"TR",{class:!0});var St=r(ie);Dn=l(St,"TD",{class:!0});var mD=r(Dn);$y=n(mD,"45"),mD.forEach(t),e3=u(St),An=l(St,"TD",{class:!0});var vD=r(An);t3=n(vD,"10"),vD.forEach(t),s3=u(St),Ln=l(St,"TD",{class:!0});var _D=r(Ln);a3=n(_D,"20"),_D.forEach(t),l3=u(St),In=l(St,"TD",{class:!0});var kD=r(In);r3=n(kD,"2"),kD.forEach(t),i3=u(St),Pn=l(St,"TD",{class:!0});var ED=r(Pn);o3=n(ED,"4500"),ED.forEach(t),St.forEach(t),gD.forEach(t),$m.forEach(t),Wg=u(s),On=l(s,"P",{});var bD=r(On);n3=n(bD,"Now let\u2019s focus on these training settings:"),bD.forEach(t),jg=u(s),Nl=l(s,"PRE",{class:!0});var jA=r(Nl);jA.forEach(t),Fg=u(s),U=l(s,"UL",{});var V=r(U);zn=l(V,"LI",{});var m7=r(zn);Cl=l(m7,"STRONG",{});var ev=r(Cl);c3=n(ev,"Learning Rate ("),Nn=l(ev,"CODE",{class:!0});var xD=r(Nn);u3=n(xD,"learning_rate"),xD.forEach(t),f3=n(ev,")"),ev.forEach(t),d3=n(m7,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),m7.forEach(t),p3=u(V),Cn=l(V,"LI",{});var v7=r(Cn);Gl=l(v7,"STRONG",{});var tv=r(Gl);h3=n(tv,"Text Encoder Learning Rate ("),Gn=l(tv,"CODE",{class:!0});var yD=r(Gn);g3=n(yD,"text_encoder_lr"),yD.forEach(t),m3=n(tv,")"),tv.forEach(t),v3=n(v7,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),v7.forEach(t),_3=u(V),Hn=l(V,"LI",{});var _7=r(Hn);Hl=l(_7,"STRONG",{});var sv=r(Hl);k3=n(sv,"UNet Learning Rate ("),qn=l(sv,"CODE",{class:!0});var wD=r(qn);E3=n(wD,"unet_lr"),wD.forEach(t),b3=n(sv,")"),sv.forEach(t),x3=n(_7,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),_7.forEach(t),y3=u(V),Mn=l(V,"LI",{});var k7=r(Mn);ql=l(k7,"STRONG",{});var av=r(ql);w3=n(av,"Learning Rate Scheduler ("),Un=l(av,"CODE",{class:!0});var TD=r(Un);T3=n(TD,"lr_scheduler"),TD.forEach(t),R3=n(av,")"),av.forEach(t),S3=n(k7,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),k7.forEach(t),D3=u(V),Bn=l(V,"LI",{});var E7=r(Bn);Ml=l(E7,"STRONG",{});var lv=r(Ml);A3=n(lv,"Number of Cycles in Learning Rate Scheduler ("),Wn=l(lv,"CODE",{class:!0});var RD=r(Wn);L3=n(RD,"lr_scheduler_num_cycles"),RD.forEach(t),I3=n(lv,")"),lv.forEach(t),P3=n(E7,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),E7.forEach(t),O3=u(V),jn=l(V,"LI",{});var b7=r(jn);Ul=l(b7,"STRONG",{});var rv=r(Ul);z3=n(rv,"Network Dimension ("),Fn=l(rv,"CODE",{class:!0});var SD=r(Fn);N3=n(SD,"network_dim"),SD.forEach(t),C3=n(rv,")"),rv.forEach(t),G3=n(b7,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),b7.forEach(t),H3=u(V),Vn=l(V,"LI",{});var x7=r(Vn);Bl=l(x7,"STRONG",{});var iv=r(Bl);q3=n(iv,"Network Alpha ("),Yn=l(iv,"CODE",{class:!0});var DD=r(Yn);M3=n(DD,"network_alpha"),DD.forEach(t),U3=n(iv,")"),iv.forEach(t),B3=n(x7,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),x7.forEach(t),W3=u(V),Kn=l(V,"LI",{});var y7=r(Kn);Wl=l(y7,"STRONG",{});var ov=r(Wl);j3=n(ov,"Clip Skip ("),Xn=l(ov,"CODE",{class:!0});var AD=r(Xn);F3=n(AD,"clip_skip"),AD.forEach(t),V3=n(ov,")"),ov.forEach(t),Y3=n(y7,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),y7.forEach(t),K3=u(V),Zn=l(V,"LI",{});var w7=r(Zn);jl=l(w7,"STRONG",{});var nv=r(jl);X3=n(nv,"Max Token Length ("),Qn=l(nv,"CODE",{class:!0});var LD=r(Qn);Z3=n(LD,"max_token_length"),LD.forEach(t),Q3=n(nv,")"),nv.forEach(t),J3=n(w7,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),w7.forEach(t),$3=u(V),Jn=l(V,"LI",{});var T7=r(Jn);Fl=l(T7,"STRONG",{});var cv=r(Fl);e4=n(cv,"Noise Offset ("),$n=l(cv,"CODE",{class:!0});var ID=r($n);t4=n(ID,"noise_offset"),ID.forEach(t),s4=n(cv,")"),cv.forEach(t),a4=n(T7,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),T7.forEach(t),l4=u(V),ec=l(V,"LI",{});var R7=r(ec);Vl=l(R7,"STRONG",{});var uv=r(Vl);r4=n(uv,"Regularization Data Directory ("),tc=l(uv,"CODE",{class:!0});var PD=r(tc);i4=n(PD,"reg_data_dir"),PD.forEach(t),o4=n(uv,")"),uv.forEach(t),n4=n(R7,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),R7.forEach(t),V.forEach(t),Vg=u(s),ca=l(s,"H3",{id:!0});var S7=r(ca);ua=l(S7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var OD=r(ua);gp=l(OD,"SPAN",{class:!0}),r(gp).forEach(t),OD.forEach(t),c4=n(S7,"Fine Tuning"),S7.forEach(t),Yg=u(s),sc=l(s,"P",{});var zD=r(sc);u4=n(zD,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),zD.forEach(t),Kg=u(s),rr(Yl.$$.fragment,s),Xg=u(s),fa=l(s,"H4",{id:!0});var D7=r(fa);da=l(D7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ND=r(da);mp=l(ND,"SPAN",{class:!0}),r(mp).forEach(t),ND.forEach(t),f4=n(D7,"Workflow with Auto1111 WebUI"),D7.forEach(t),Zg=u(s),pa=l(s,"P",{});var fv=r(pa);d4=n(fv,"We\u2019re going to use "),Kl=l(fv,"A",{href:!0,rel:!0});var CD=r(Kl);p4=n(CD,"Stable Diffusion web UI"),CD.forEach(t),h4=n(fv," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),fv.forEach(t),Qg=u(s),ha=l(s,"P",{});var dv=r(ha);g4=n(dv,"We\u2019re going to use the "),ac=l(dv,"CODE",{class:!0});var GD=r(ac);m4=n(GD,"X/Y/Z plot"),GD.forEach(t),v4=n(dv," script to compare different epochs."),dv.forEach(t),Jg=u(s),oe=l(s,"UL",{});var Dt=r(oe);lc=l(Dt,"LI",{});var A7=r(lc);_4=n(A7,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),$g=l(A7,"PRINCEADAM0001:0.7",{}),r($g).forEach(t),A7.forEach(t),k4=u(Dt),vp=l(Dt,"LI",{});var HD=r(vp);E4=n(HD,"In generation parameters and select the X/Y/Z plot script."),HD.forEach(t),b4=u(Dt),it=l(Dt,"LI",{});var ar=r(it);x4=n(ar,"Select "),rc=l(ar,"CODE",{class:!0});var qD=r(rc);y4=n(qD,"Prompt SR"),qD.forEach(t),w4=n(ar," for Prompt Replace.  We\u2019re going to replace "),ic=l(ar,"CODE",{class:!0});var MD=r(ic);T4=n(MD,"<princeadam0001:0.7>"),MD.forEach(t),R4=n(ar," with different epoch: "),oc=l(ar,"CODE",{class:!0});var UD=r(oc);S4=n(UD,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),UD.forEach(t),ar.forEach(t),D4=u(Dt),nc=l(Dt,"LI",{});var L7=r(nc);A4=n(L7,"Select a fast sampler like "),cc=l(L7,"CODE",{class:!0});var BD=r(cc);L4=n(BD,"DPM2 KARRAS"),BD.forEach(t),L7.forEach(t),I4=u(Dt),ga=l(Dt,"LI",{});var zp=r(ga);P4=n(zp,"CFG Scale set to "),uc=l(zp,"CODE",{class:!0});var WD=r(uc);O4=n(WD,"7"),WD.forEach(t),z4=n(zp," and Steps to "),fc=l(zp,"CODE",{class:!0});var jD=r(fc);N4=n(jD,"20"),jD.forEach(t),zp.forEach(t),Dt.forEach(t),em=u(s),ot=l(s,"P",{});var sf=r(ot);C4=n(sf,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),dc=l(sf,"CODE",{class:!0});var FD=r(dc);G4=n(FD,"network_dim"),FD.forEach(t),H4=n(sf," and "),pc=l(sf,"CODE",{class:!0});var VD=r(pc);q4=n(VD,"network_alpha"),VD.forEach(t),M4=n(sf,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),sf.forEach(t),tm=u(s),xe=l(s,"UL",{});var Ca=r(xe);ma=l(Ca,"LI",{});var Np=r(ma);U4=n(Np,"Select "),hc=l(Np,"CODE",{class:!0});var YD=r(hc);B4=n(YD,"Prompt SR"),YD.forEach(t),W4=n(Np," for Prompt Replace.  We\u2019re going to replace the weights "),gc=l(Np,"CODE",{class:!0});var KD=r(gc);j4=n(KD,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),KD.forEach(t),Np.forEach(t),F4=u(Ca),Xl=l(Ca,"LI",{});var pv=r(Xl);V4=n(pv,"Use Prompt SR to generate a variety of angles: Select "),mc=l(pv,"CODE",{class:!0});var XD=r(mc);Y4=n(XD,"Prompt SR"),XD.forEach(t),K4=n(pv," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),pv.forEach(t),X4=u(Ca),_p=l(Ca,"LI",{});var ZD=r(_p);Z4=n(ZD,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),ZD.forEach(t),Q4=u(Ca),kp=l(Ca,"LI",{});var QD=r(kp);J4=n(QD,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),QD.forEach(t),Ca.forEach(t),sm=u(s),va=l(s,"H4",{id:!0});var I7=r(va);_a=l(I7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var JD=r(_a);Ep=l(JD,"SPAN",{class:!0}),r(Ep).forEach(t),JD.forEach(t),$4=n(I7,"Issues to look for"),I7.forEach(t),am=u(s),ye=l(s,"UL",{});var Ga=r(ye);vc=l(Ga,"LI",{});var P7=r(vc);bp=l(P7,"STRONG",{});var $D=r(bp);e0=n($D,"Undercooked:"),$D.forEach(t),t0=n(P7," Lacks output, adjust unet learning rate or extend training duration."),P7.forEach(t),s0=u(Ga),_c=l(Ga,"LI",{});var O7=r(_c);xp=l(O7,"STRONG",{});var e9=r(xp);a0=n(e9,"Overcooked:"),e9.forEach(t),l0=n(O7," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),O7.forEach(t),r0=u(Ga),kc=l(Ga,"LI",{});var z7=r(kc);yp=l(z7,"STRONG",{});var t9=r(yp);i0=n(t9,"Overfit:"),t9.forEach(t),o0=n(z7," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),z7.forEach(t),n0=u(Ga),Ec=l(Ga,"LI",{});var N7=r(Ec);wp=l(N7,"STRONG",{});var s9=r(wp);c0=n(s9,"Mismatched:"),s9.forEach(t),u0=n(N7," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),N7.forEach(t),Ga.forEach(t),lm=u(s),bc=l(s,"P",{});var a9=r(bc);f0=n(a9,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),a9.forEach(t),rm=u(s),Zl=l(s,"P",{class:!0});var l9=r(Zl);Ql=l(l9,"IMG",{src:!0,alt:!0,class:!0}),l9.forEach(t),im=u(s),ka=l(s,"H2",{id:!0});var C7=r(ka);Ea=l(C7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r9=r(Ea);Tp=l(r9,"SPAN",{class:!0}),r(Tp).forEach(t),r9.forEach(t),d0=n(C7,"Troubleshooting"),C7.forEach(t),om=u(s),xc=l(s,"P",{});var i9=r(xc);p0=n(i9,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),i9.forEach(t),nm=u(s),nt=l(s,"UL",{});var af=r(nt);Jl=l(af,"LI",{});var hv=r(Jl);h0=n(hv,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),yc=l(hv,"CODE",{class:!0});var o9=r(yc);g0=n(o9,"200"),o9.forEach(t),m0=n(hv," regularization images per training image."),hv.forEach(t),v0=u(af),$l=l(af,"LI",{});var gv=r($l);_0=n(gv,"Repeats of regularization images, but may overfit more.  Increasing the "),wc=l(gv,"CODE",{class:!0});var n9=r(wc);k0=n(n9,"repetition_count"),n9.forEach(t),E0=n(gv," will cycle through the images more but the results may have results that overfit the model."),gv.forEach(t),b0=u(af),Rp=l(af,"LI",{});var c9=r(Rp);x0=n(c9,"Create more regularization images without increasing repeats will help with the overfitting."),c9.forEach(t),af.forEach(t),cm=u(s),Ct=l(s,"TABLE",{class:!0});var mv=r(Ct);Tc=l(mv,"THEAD",{class:!0});var u9=r(Tc);ct=l(u9,"TR",{class:!0});var lf=r(ct);Rc=l(lf,"TH",{class:!0});var f9=r(Rc);y0=n(f9,"Issue"),f9.forEach(t),w0=u(lf),Sc=l(lf,"TH",{class:!0});var d9=r(Sc);T0=n(d9,"Situation"),d9.forEach(t),R0=u(lf),Dc=l(lf,"TH",{class:!0});var p9=r(Dc);S0=n(p9,"Recommendation"),p9.forEach(t),lf.forEach(t),u9.forEach(t),D0=u(mv),we=l(mv,"TBODY",{class:!0});var Ha=r(we);ut=l(Ha,"TR",{class:!0});var rf=r(ut);Ac=l(rf,"TD",{class:!0});var h9=r(Ac);A0=n(h9,"Varying quality"),h9.forEach(t),L0=u(rf),Lc=l(rf,"TD",{class:!0});var g9=r(Lc);I0=n(g9,"Results differ from expectations"),g9.forEach(t),P0=u(rf),Ic=l(rf,"TD",{class:!0});var m9=r(Ic);O0=n(m9,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),m9.forEach(t),rf.forEach(t),z0=u(Ha),ft=l(Ha,"TR",{class:!0});var of=r(ft);Pc=l(of,"TD",{class:!0});var v9=r(Pc);N0=n(v9,"Inadequate regularization for input data"),v9.forEach(t),C0=u(of),Oc=l(of,"TD",{class:!0});var _9=r(Oc);G0=n(_9,"Lower input images, less regularization needed"),_9.forEach(t),H0=u(of),zc=l(of,"TD",{class:!0});var k9=r(zc);q0=n(k9,"Reduce the number of input images or increasing the quantity of reg images."),k9.forEach(t),of.forEach(t),M0=u(Ha),dt=l(Ha,"TR",{class:!0});var nf=r(dt);Nc=l(nf,"TD",{class:!0});var E9=r(Nc);U0=n(E9,"Overfitting due to repetition"),E9.forEach(t),B0=u(nf),Cc=l(nf,"TD",{class:!0});var b9=r(Cc);W0=n(b9,"Repeats of reg images, risk of overfitting"),b9.forEach(t),j0=u(nf),Gc=l(nf,"TD",{class:!0});var x9=r(Gc);F0=n(x9,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),x9.forEach(t),nf.forEach(t),V0=u(Ha),pt=l(Ha,"TR",{class:!0});var cf=r(pt);Hc=l(cf,"TD",{class:!0});var y9=r(Hc);Y0=n(y9,"Mitigate overfitting while increasing diversity"),y9.forEach(t),K0=u(cf),qc=l(cf,"TD",{class:!0});var w9=r(qc);X0=n(w9,"Create more reg images without repeats"),w9.forEach(t),Z0=u(cf),Mc=l(cf,"TD",{class:!0});var T9=r(Mc);Q0=n(T9,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),T9.forEach(t),cf.forEach(t),Ha.forEach(t),mv.forEach(t),um=u(s),ba=l(s,"H4",{id:!0});var G7=r(ba);xa=l(G7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var R9=r(xa);Sp=l(R9,"SPAN",{class:!0}),r(Sp).forEach(t),R9.forEach(t),J0=n(G7,"More Solutions"),G7.forEach(t),fm=u(s),Uc=l(s,"P",{});var S9=r(Uc);$0=n(S9,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),S9.forEach(t),dm=u(s),Gt=l(s,"TABLE",{class:!0});var vv=r(Gt);Bc=l(vv,"THEAD",{class:!0});var D9=r(Bc);ht=l(D9,"TR",{class:!0});var uf=r(ht);Wc=l(uf,"TH",{class:!0});var A9=r(Wc);e5=n(A9,"Symptom"),A9.forEach(t),t5=u(uf),jc=l(uf,"TH",{class:!0});var L9=r(jc);s5=n(L9,"Likely Cause"),L9.forEach(t),a5=u(uf),Fc=l(uf,"TH",{class:!0});var I9=r(Fc);l5=n(I9,"Solution"),I9.forEach(t),uf.forEach(t),D9.forEach(t),r5=u(vv),W=l(vv,"TBODY",{class:!0});var X=r(W);gt=l(X,"TR",{class:!0});var ff=r(gt);Vc=l(ff,"TD",{class:!0});var P9=r(Vc);i5=n(P9,"Plastic texture persists"),P9.forEach(t),o5=u(ff),Yc=l(ff,"TD",{class:!0});var O9=r(Yc);n5=n(O9,"Insufficient human reg images"),O9.forEach(t),c5=u(ff),Kc=l(ff,"TD",{class:!0});var z9=r(Kc);u5=n(z9,"Add real photos to reg set"),z9.forEach(t),ff.forEach(t),f5=u(X),mt=l(X,"TR",{class:!0});var df=r(mt);Xc=l(df,"TD",{class:!0});var N9=r(Xc);d5=n(N9,"Loss plateaus early"),N9.forEach(t),p5=u(df),Zc=l(df,"TD",{class:!0});var C9=r(Zc);h5=n(C9,"Learning rate too low"),C9.forEach(t),g5=u(df),Qc=l(df,"TD",{class:!0});var G9=r(Qc);m5=n(G9,"Increase LR by 10x"),G9.forEach(t),df.forEach(t),v5=u(X),vt=l(X,"TR",{class:!0});var pf=r(vt);Jc=l(pf,"TD",{class:!0});var H9=r(Jc);_5=n(H9,"Features blurry"),H9.forEach(t),k5=u(pf),$c=l(pf,"TD",{class:!0});var q9=r($c);E5=n(q9,"Network dimension too small"),q9.forEach(t),b5=u(pf),eu=l(pf,"TD",{class:!0});var M9=r(eu);x5=n(M9,"Increase network_dim to 64+"),M9.forEach(t),pf.forEach(t),y5=u(X),_t=l(X,"TR",{class:!0});var hf=r(_t);tu=l(hf,"TD",{class:!0});var U9=r(tu);w5=n(U9,"Color distortion"),U9.forEach(t),T5=u(hf),su=l(hf,"TD",{class:!0});var B9=r(su);R5=n(B9,"Noise offset conflict"),B9.forEach(t),S5=u(hf),au=l(hf,"TD",{class:!0});var W9=r(au);D5=n(W9,"Try noise_offset 0.05-0.1"),W9.forEach(t),hf.forEach(t),A5=u(X),kt=l(X,"TR",{class:!0});var gf=r(kt);lu=l(gf,"TD",{class:!0});var j9=r(lu);L5=n(j9,"Overly stylized outputs"),j9.forEach(t),I5=u(gf),ru=l(gf,"TD",{class:!0});var F9=r(ru);P5=n(F9,"Reg image style mismatch"),F9.forEach(t),O5=u(gf),iu=l(gf,"TD",{class:!0});var V9=r(iu);z5=n(V9,"Regenerate reg images with base model"),V9.forEach(t),gf.forEach(t),N5=u(X),Et=l(X,"TR",{class:!0});var mf=r(Et);ou=l(mf,"TD",{class:!0});var Y9=r(ou);C5=n(Y9,"Training instability"),Y9.forEach(t),G5=u(mf),nu=l(mf,"TD",{class:!0});var K9=r(nu);H5=n(K9,"Batch size too large"),K9.forEach(t),q5=u(mf),cu=l(mf,"TD",{class:!0});var X9=r(cu);M5=n(X9,"Reduce batch_size to 1-2"),X9.forEach(t),mf.forEach(t),U5=u(X),bt=l(X,"TR",{class:!0});var vf=r(bt);uu=l(vf,"TD",{class:!0});var Z9=r(uu);B5=n(Z9,"Slow convergence"),Z9.forEach(t),W5=u(vf),fu=l(vf,"TD",{class:!0});var Q9=r(fu);j5=n(Q9,"Network_alpha too high"),Q9.forEach(t),F5=u(vf),du=l(vf,"TD",{class:!0});var J9=r(du);V5=n(J9,"Set alpha = dim/2 (e.g., 64/2 = 32)"),J9.forEach(t),vf.forEach(t),Y5=u(X),xt=l(X,"TR",{class:!0});var _f=r(xt);pu=l(_f,"TD",{class:!0});var $9=r(pu);K5=n($9,"Loss divergence"),$9.forEach(t),X5=u(_f),hu=l(_f,"TD",{class:!0});var eA=r(hu);Z5=n(eA,"Text encoder LR too high"),eA.forEach(t),Q5=u(_f),gu=l(_f,"TD",{class:!0});var tA=r(gu);J5=n(tA,"Reduce text_encoder_lr by 10x"),tA.forEach(t),_f.forEach(t),$5=u(X),yt=l(X,"TR",{class:!0});var kf=r(yt);mu=l(kf,"TD",{class:!0});var sA=r(mu);ew=n(sA,"Poor prompt adherence"),sA.forEach(t),tw=u(kf),vu=l(kf,"TD",{class:!0});var aA=r(vu);sw=n(aA,"Clip skip too high"),aA.forEach(t),aw=u(kf),_u=l(kf,"TD",{class:!0});var lA=r(_u);lw=n(lA,"Reduce clip_skip to 1-2"),lA.forEach(t),kf.forEach(t),rw=u(X),wt=l(X,"TR",{class:!0});var Ef=r(wt);ku=l(Ef,"TD",{class:!0});var rA=r(ku);iw=n(rA,"Memory errors"),rA.forEach(t),ow=u(Ef),Eu=l(Ef,"TD",{class:!0});var iA=r(Eu);nw=n(iA,"Resolution too high"),iA.forEach(t),cw=u(Ef),bu=l(Ef,"TD",{class:!0});var oA=r(bu);uw=n(oA,"Reduce to 512-768px, enable gradient checkpointing"),oA.forEach(t),Ef.forEach(t),X.forEach(t),vv.forEach(t),pm=u(s),ya=l(s,"H2",{id:!0});var H7=r(ya);wa=l(H7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var nA=r(wa);Dp=l(nA,"SPAN",{class:!0}),r(Dp).forEach(t),nA.forEach(t),fw=n(H7,"Results"),H7.forEach(t),hm=u(s),xu=l(s,"P",{});var cA=r(xu);dw=n(cA,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),cA.forEach(t),gm=u(s),yu=l(s,"P",{});var uA=r(yu);pw=n(uA,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),uA.forEach(t),mm=u(s),er=l(s,"P",{class:!0});var fA=r(er);tr=l(fA,"IMG",{src:!0,alt:!0,class:!0}),fA.forEach(t),vm=u(s),wu=l(s,"P",{});var dA=r(wu);hw=n(dA,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),dA.forEach(t),_m=u(s),Ht=l(s,"H2",{id:!0,class:!0});var q7=r(Ht);Ta=l(q7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var pA=r(Ta);Ap=l(pA,"SPAN",{class:!0}),r(Ap).forEach(t),pA.forEach(t),gw=n(q7,"spacelab"),q7.forEach(t),km=u(s),Te&&Te.l(s),Em=bf(),this.h()},h(){i(T,"class","icon icon-link"),i(w,"aria-hidden","true"),i(w,"tabindex","-1"),i(w,"href","#experiment-1-anime-inspired-heroism"),i(b,"id","experiment-1-anime-inspired-heroism"),Ut(I.src,P="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png")||i(I,"src",P),i(I,"alt","image"),i(I,"class","svelte-x2kgxs"),i(y,"class","svelte-x2kgxs"),i(R,"class","icon icon-link"),i(q,"aria-hidden","true"),i(q,"tabindex","-1"),i(q,"href","#experiment-2-retro-cartoon-resurrection"),i(Z,"id","experiment-2-retro-cartoon-resurrection"),Ut(fe.src,xf="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1738190889/blog/fiz3ariex9rpsoovdccl.png")||i(fe,"src",xf),i(fe,"alt","image"),i(fe,"class","svelte-x2kgxs"),i(Se,"class","svelte-x2kgxs"),i(yf,"class","icon icon-link"),i(Vt,"aria-hidden","true"),i(Vt,"tabindex","-1"),i(Vt,"href","#what-are-regularization-images"),i(Ft,"id","what-are-regularization-images"),i(ur,"class","svelte-x2kgxs"),i(qa,"class","svelte-x2kgxs"),i(gr,"class","svelte-x2kgxs"),i(mr,"class","svelte-x2kgxs"),i(vr,"class","svelte-x2kgxs"),i(De,"class","svelte-x2kgxs"),i(hr,"class","svelte-x2kgxs"),i(_r,"class","svelte-x2kgxs"),i(kr,"class","svelte-x2kgxs"),i(Er,"class","svelte-x2kgxs"),i(Le,"class","svelte-x2kgxs"),i(br,"class","svelte-x2kgxs"),i(xr,"class","svelte-x2kgxs"),i(yr,"class","svelte-x2kgxs"),i(Ie,"class","svelte-x2kgxs"),i(wr,"class","svelte-x2kgxs"),i(Tr,"class","svelte-x2kgxs"),i(Rr,"class","svelte-x2kgxs"),i(Pe,"class","svelte-x2kgxs"),i(Ae,"class","svelte-x2kgxs"),i(At,"class","svelte-x2kgxs"),i(Ar,"class","svelte-x2kgxs"),i(Ua,"class","svelte-x2kgxs"),i(Sf,"class","icon icon-link"),i(Kt,"aria-hidden","true"),i(Kt,"tabindex","-1"),i(Kt,"href","#scenario-1-limited-training-data"),i(Yt,"id","scenario-1-limited-training-data"),i(If,"class","icon icon-link"),i(Zt,"aria-hidden","true"),i(Zt,"tabindex","-1"),i(Zt,"href","#scenario-2-imbalanced-training-data"),i(Xt,"id","scenario-2-imbalanced-training-data"),i(Nf,"class","icon icon-link"),i(Jt,"aria-hidden","true"),i(Jt,"tabindex","-1"),i(Jt,"href","#divergence"),i(Qt,"id","divergence"),i(Pr,"class","svelte-x2kgxs"),i(Or,"class","svelte-x2kgxs"),i(Xa,"class","svelte-x2kgxs"),i(Bf,"class","icon icon-link"),i(ts,"aria-hidden","true"),i(ts,"tabindex","-1"),i(ts,"href","#overfitting"),i(es,"id","overfitting"),i(Yf,"class","icon icon-link"),i(as,"aria-hidden","true"),i(as,"tabindex","-1"),i(as,"href","#key-differences"),i(ss,"id","key-differences"),i(qr,"class","svelte-x2kgxs"),i(Mr,"class","svelte-x2kgxs"),i(Ur,"class","svelte-x2kgxs"),i(Ce,"class","svelte-x2kgxs"),i(Hr,"class","svelte-x2kgxs"),i(Br,"class","svelte-x2kgxs"),i(Wr,"class","svelte-x2kgxs"),i(jr,"class","svelte-x2kgxs"),i(Ge,"class","svelte-x2kgxs"),i(Fr,"class","svelte-x2kgxs"),i(Vr,"class","svelte-x2kgxs"),i(Yr,"class","svelte-x2kgxs"),i(He,"class","svelte-x2kgxs"),i(Kr,"class","svelte-x2kgxs"),i(Xr,"class","svelte-x2kgxs"),i(Zr,"class","svelte-x2kgxs"),i(qe,"class","svelte-x2kgxs"),i(Qr,"class","svelte-x2kgxs"),i(Jr,"class","svelte-x2kgxs"),i($r,"class","svelte-x2kgxs"),i(Me,"class","svelte-x2kgxs"),i(de,"class","svelte-x2kgxs"),i(Lt,"class","svelte-x2kgxs"),i(sd,"class","icon icon-link"),i(rs,"aria-hidden","true"),i(rs,"tabindex","-1"),i(rs,"href","#preventing-divergence"),i(ls,"id","preventing-divergence"),i(ti,"class","svelte-x2kgxs"),i(si,"class","svelte-x2kgxs"),i(is,"class","svelte-x2kgxs"),i(ei,"class","svelte-x2kgxs"),i(ai,"class","svelte-x2kgxs"),i(li,"class","svelte-x2kgxs"),i(os,"class","svelte-x2kgxs"),i(ri,"class","svelte-x2kgxs"),i(ii,"class","svelte-x2kgxs"),i(ns,"class","svelte-x2kgxs"),i(oi,"class","svelte-x2kgxs"),i(ni,"class","svelte-x2kgxs"),i(cs,"class","svelte-x2kgxs"),i(ci,"class","svelte-x2kgxs"),i(ui,"class","svelte-x2kgxs"),i(us,"class","svelte-x2kgxs"),i(pe,"class","svelte-x2kgxs"),i(It,"class","svelte-x2kgxs"),i(od,"class","icon icon-link"),i(ds,"aria-hidden","true"),i(ds,"tabindex","-1"),i(ds,"href","#implementing-these-strategies"),i(fs,"id","implementing-these-strategies"),i(Za,"class","language-python"),i(Qa,"class","language-python"),i(nd,"class","icon icon-link"),i(hs,"aria-hidden","true"),i(hs,"tabindex","-1"),i(hs,"href","#data-considerations"),i(ps,"id","data-considerations"),i(pi,"class","svelte-x2kgxs"),i(hi,"class","svelte-x2kgxs"),i(gi,"class","svelte-x2kgxs"),i(Ue,"class","svelte-x2kgxs"),i(di,"class","svelte-x2kgxs"),i(mi,"class","svelte-x2kgxs"),i(vi,"class","svelte-x2kgxs"),i(_i,"class","svelte-x2kgxs"),i(Be,"class","svelte-x2kgxs"),i(ki,"class","svelte-x2kgxs"),i(Ei,"class","svelte-x2kgxs"),i(bi,"class","svelte-x2kgxs"),i(We,"class","svelte-x2kgxs"),i(xi,"class","svelte-x2kgxs"),i(yi,"class","svelte-x2kgxs"),i(wi,"class","svelte-x2kgxs"),i(je,"class","svelte-x2kgxs"),i(Ti,"class","svelte-x2kgxs"),i(Ri,"class","svelte-x2kgxs"),i(Si,"class","svelte-x2kgxs"),i(Fe,"class","svelte-x2kgxs"),i(he,"class","svelte-x2kgxs"),i(Pt,"class","svelte-x2kgxs"),i(cd,"class","icon icon-link"),i(ms,"aria-hidden","true"),i(ms,"tabindex","-1"),i(ms,"href","#monitoring-tips"),i(gs,"id","monitoring-tips"),i(Ja,"href","https://github.com/kohya-ss/sd-scripts"),i(Ja,"rel","nofollow"),i(ud,"class","icon icon-link"),i(ks,"aria-hidden","true"),i(ks,"tabindex","-1"),i(ks,"href","#track-loss-curves"),i(_s,"id","track-loss-curves"),i($a,"href","https://www.tensorflow.org/tensorboard"),i($a,"rel","nofollow"),i(el,"class","language-bash"),i(fd,"class","icon icon-link"),i(xs,"aria-hidden","true"),i(xs,"tabindex","-1"),i(xs,"href","#what-to-monitor"),i(bs,"id","what-to-monitor"),i(gd,"class","icon icon-link"),i(ws,"aria-hidden","true"),i(ws,"tabindex","-1"),i(ws,"href","#warning-signs"),i(ys,"id","warning-signs"),i(kd,"class","icon icon-link"),i(Rs,"aria-hidden","true"),i(Rs,"tabindex","-1"),i(Rs,"href","#generate-validation-images-every-100-steps"),i(Ts,"id","generate-validation-images-every-100-steps"),i(sl,"class","language-json"),i(bd,"class","icon icon-link"),i(Ds,"aria-hidden","true"),i(Ds,"tabindex","-1"),i(Ds,"href","#what-to-look-for"),i(Ss,"id","what-to-look-for"),i(Di,"class","svelte-x2kgxs"),i(al,"class","svelte-x2kgxs"),i(Td,"class","icon icon-link"),i(Ls,"aria-hidden","true"),i(Ls,"tabindex","-1"),i(Ls,"href","#use-gradient-clipping"),i(As,"id","use-gradient-clipping"),i(Li,"class","svelte-x2kgxs"),i(Ii,"class","svelte-x2kgxs"),i(il,"class","svelte-x2kgxs"),i(Ad,"class","icon icon-link"),i(Ps,"aria-hidden","true"),i(Ps,"tabindex","-1"),i(Ps,"href","#enable-mixed-precision-training"),i(Is,"id","enable-mixed-precision-training"),i(nl,"class","language-python"),i(Oi,"class","svelte-x2kgxs"),i(cl,"class","svelte-x2kgxs"),i(zd,"class","icon icon-link"),i(zs,"aria-hidden","true"),i(zs,"tabindex","-1"),i(zs,"href","#start-with-conservative-learning-rates"),i(Os,"id","start-with-conservative-learning-rates"),i(ul,"class","language-yml"),i(fl,"class","language-python"),i(Ni,"class","svelte-x2kgxs"),i(Ci,"class","svelte-x2kgxs"),i(Gi,"class","svelte-x2kgxs"),i(Hi,"class","svelte-x2kgxs"),i(ge,"class","svelte-x2kgxs"),i(zi,"class","svelte-x2kgxs"),i(qi,"class","svelte-x2kgxs"),i(Mi,"class","svelte-x2kgxs"),i(Ui,"class","svelte-x2kgxs"),i(Bi,"class","svelte-x2kgxs"),i(me,"class","svelte-x2kgxs"),i(Wi,"class","svelte-x2kgxs"),i(ji,"class","svelte-x2kgxs"),i(Fi,"class","svelte-x2kgxs"),i(Vi,"class","svelte-x2kgxs"),i(ve,"class","svelte-x2kgxs"),i(Yi,"class","svelte-x2kgxs"),i(Ki,"class","svelte-x2kgxs"),i(Cs,"class","svelte-x2kgxs"),i(Xi,"class","svelte-x2kgxs"),i(Zi,"class","svelte-x2kgxs"),i(Je,"class","svelte-x2kgxs"),i(_e,"class","svelte-x2kgxs"),i(Qi,"class","svelte-x2kgxs"),i(Ji,"class","svelte-x2kgxs"),i($i,"class","svelte-x2kgxs"),i(eo,"class","svelte-x2kgxs"),i(ke,"class","svelte-x2kgxs"),i(to,"class","svelte-x2kgxs"),i(so,"class","svelte-x2kgxs"),i(ao,"class","svelte-x2kgxs"),i(lo,"class","svelte-x2kgxs"),i(Ee,"class","svelte-x2kgxs"),i(le,"class","svelte-x2kgxs"),i(Ot,"class","svelte-x2kgxs"),i(Ud,"class","icon icon-link"),i(Hs,"aria-hidden","true"),i(Hs,"tabindex","-1"),i(Hs,"href","#generating-regularization-images"),i(Gs,"id","generating-regularization-images"),i(ro,"class","svelte-x2kgxs"),i(io,"class","svelte-x2kgxs"),i(oo,"class","svelte-x2kgxs"),i(no,"class","svelte-x2kgxs"),i(co,"class","svelte-x2kgxs"),i(Bd,"class","icon icon-link"),i(Us,"aria-hidden","true"),i(Us,"tabindex","-1"),i(Us,"href","#important-considerations"),i(Ms,"id","important-considerations"),i(Xd,"class","icon icon-link"),i(Ws,"aria-hidden","true"),i(Ws,"tabindex","-1"),i(Ws,"href","#generate-using-stable-diffusion-web-ui"),i(Bs,"id","generate-using-stable-diffusion-web-ui"),i(vl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(vl,"rel","nofollow"),i(fo,"class","svelte-x2kgxs"),i(po,"class","svelte-x2kgxs"),i(go,"class","svelte-x2kgxs"),i(mo,"class","svelte-x2kgxs"),i(vo,"class","svelte-x2kgxs"),i(_o,"class","svelte-x2kgxs"),i(ko,"class","svelte-x2kgxs"),i(Eo,"class","svelte-x2kgxs"),i(bo,"class","svelte-x2kgxs"),i(xo,"class","svelte-x2kgxs"),i(yo,"class","svelte-x2kgxs"),i(wo,"class","svelte-x2kgxs"),i(To,"class","svelte-x2kgxs"),i(Ro,"class","svelte-x2kgxs"),i(So,"class","svelte-x2kgxs"),i(Do,"class","svelte-x2kgxs"),i(Ao,"class","svelte-x2kgxs"),i(Lo,"class","svelte-x2kgxs"),i(Io,"class","svelte-x2kgxs"),i(Po,"class","svelte-x2kgxs"),i(Oo,"class","svelte-x2kgxs"),i(zo,"class","svelte-x2kgxs"),i(No,"class","svelte-x2kgxs"),i(Co,"class","svelte-x2kgxs"),i(Go,"class","svelte-x2kgxs"),i(Ho,"class","svelte-x2kgxs"),i(qo,"class","svelte-x2kgxs"),i(Uo,"class","svelte-x2kgxs"),i(Bo,"class","svelte-x2kgxs"),i(Wo,"class","svelte-x2kgxs"),i(jo,"class","svelte-x2kgxs"),i(Fo,"class","svelte-x2kgxs"),i(ap,"class","icon icon-link"),i(Ys,"aria-hidden","true"),i(Ys,"tabindex","-1"),i(Ys,"href","#download-images"),i(Vs,"id","download-images"),i(El,"href","https://huggingface.co/3ee"),i(El,"rel","nofollow"),i(bl,"href","https://github.com/Luehrsen/sd_regularization_images"),i(bl,"rel","nofollow"),i(xl,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(xl,"rel","nofollow"),i(yl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(yl,"rel","nofollow"),i(lp,"class","icon icon-link"),i(Xs,"aria-hidden","true"),i(Xs,"tabindex","-1"),i(Xs,"href","#captioning-regularization-images"),i(Ks,"id","captioning-regularization-images"),i($o,"class","svelte-x2kgxs"),i(en,"class","svelte-x2kgxs"),i(tn,"class","svelte-x2kgxs"),i(wl,"class","language-shell"),i(an,"class","svelte-x2kgxs"),i(ln,"class","svelte-x2kgxs"),i(on,"class","svelte-x2kgxs"),i(nn,"class","svelte-x2kgxs"),i(np,"class","icon icon-link"),i(ea,"aria-hidden","true"),i(ea,"tabindex","-1"),i(ea,"href","#training-a-lora"),i($s,"id","training-a-lora"),i(Dl,"href","https://github.com/kohya-ss/sd-scripts"),i(Dl,"rel","nofollow"),i(Ll,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(Ll,"rel","nofollow"),i(sa,"class","svelte-x2kgxs"),i(Al,"class","svelte-x2kgxs"),i(cp,"class","icon icon-link"),i(la,"aria-hidden","true"),i(la,"tabindex","-1"),i(la,"href","#directory-setup"),i(aa,"id","directory-setup"),i(cn,"class","svelte-x2kgxs"),i(Il,"class","language-json"),i(Pl,"class","language-xml"),i(fn,"class","svelte-x2kgxs"),i(dn,"class","svelte-x2kgxs"),i(pn,"class","svelte-x2kgxs"),i(hn,"class","svelte-x2kgxs"),Ut(zl.src,V7="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(zl,"src",V7),i(zl,"alt","image"),i(zl,"class","svelte-x2kgxs"),i(Ol,"class","svelte-x2kgxs"),i(hp,"class","icon icon-link"),i(na,"aria-hidden","true"),i(na,"tabindex","-1"),i(na,"href","#training-settings"),i(oa,"id","training-settings"),i(kn,"class","svelte-x2kgxs"),i(En,"class","svelte-x2kgxs"),i(xn,"class","svelte-x2kgxs"),i(yn,"class","svelte-x2kgxs"),i(wn,"class","svelte-x2kgxs"),i(Tn,"class","svelte-x2kgxs"),i(Rn,"class","svelte-x2kgxs"),i(re,"class","svelte-x2kgxs"),i(bn,"class","svelte-x2kgxs"),i(Dn,"class","svelte-x2kgxs"),i(An,"class","svelte-x2kgxs"),i(Ln,"class","svelte-x2kgxs"),i(In,"class","svelte-x2kgxs"),i(Pn,"class","svelte-x2kgxs"),i(ie,"class","svelte-x2kgxs"),i(Sn,"class","svelte-x2kgxs"),i(Nt,"class","svelte-x2kgxs"),i(Nl,"class","language-json"),i(Nn,"class","svelte-x2kgxs"),i(Gn,"class","svelte-x2kgxs"),i(qn,"class","svelte-x2kgxs"),i(Un,"class","svelte-x2kgxs"),i(Wn,"class","svelte-x2kgxs"),i(Fn,"class","svelte-x2kgxs"),i(Yn,"class","svelte-x2kgxs"),i(Xn,"class","svelte-x2kgxs"),i(Qn,"class","svelte-x2kgxs"),i($n,"class","svelte-x2kgxs"),i(tc,"class","svelte-x2kgxs"),i(gp,"class","icon icon-link"),i(ua,"aria-hidden","true"),i(ua,"tabindex","-1"),i(ua,"href","#fine-tuning"),i(ca,"id","fine-tuning"),i(mp,"class","icon icon-link"),i(da,"aria-hidden","true"),i(da,"tabindex","-1"),i(da,"href","#workflow-with-auto1111-webui"),i(fa,"id","workflow-with-auto1111-webui"),i(Kl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(Kl,"rel","nofollow"),i(ac,"class","svelte-x2kgxs"),i(rc,"class","svelte-x2kgxs"),i(ic,"class","svelte-x2kgxs"),i(oc,"class","svelte-x2kgxs"),i(cc,"class","svelte-x2kgxs"),i(uc,"class","svelte-x2kgxs"),i(fc,"class","svelte-x2kgxs"),i(dc,"class","svelte-x2kgxs"),i(pc,"class","svelte-x2kgxs"),i(hc,"class","svelte-x2kgxs"),i(gc,"class","svelte-x2kgxs"),i(mc,"class","svelte-x2kgxs"),i(Ep,"class","icon icon-link"),i(_a,"aria-hidden","true"),i(_a,"tabindex","-1"),i(_a,"href","#issues-to-look-for"),i(va,"id","issues-to-look-for"),Ut(Ql.src,Y7="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(Ql,"src",Y7),i(Ql,"alt","image"),i(Ql,"class","svelte-x2kgxs"),i(Zl,"class","svelte-x2kgxs"),i(Tp,"class","icon icon-link"),i(Ea,"aria-hidden","true"),i(Ea,"tabindex","-1"),i(Ea,"href","#troubleshooting"),i(ka,"id","troubleshooting"),i(yc,"class","svelte-x2kgxs"),i(wc,"class","svelte-x2kgxs"),i(Rc,"class","svelte-x2kgxs"),i(Sc,"class","svelte-x2kgxs"),i(Dc,"class","svelte-x2kgxs"),i(ct,"class","svelte-x2kgxs"),i(Tc,"class","svelte-x2kgxs"),i(Ac,"class","svelte-x2kgxs"),i(Lc,"class","svelte-x2kgxs"),i(Ic,"class","svelte-x2kgxs"),i(ut,"class","svelte-x2kgxs"),i(Pc,"class","svelte-x2kgxs"),i(Oc,"class","svelte-x2kgxs"),i(zc,"class","svelte-x2kgxs"),i(ft,"class","svelte-x2kgxs"),i(Nc,"class","svelte-x2kgxs"),i(Cc,"class","svelte-x2kgxs"),i(Gc,"class","svelte-x2kgxs"),i(dt,"class","svelte-x2kgxs"),i(Hc,"class","svelte-x2kgxs"),i(qc,"class","svelte-x2kgxs"),i(Mc,"class","svelte-x2kgxs"),i(pt,"class","svelte-x2kgxs"),i(we,"class","svelte-x2kgxs"),i(Ct,"class","svelte-x2kgxs"),i(Sp,"class","icon icon-link"),i(xa,"aria-hidden","true"),i(xa,"tabindex","-1"),i(xa,"href","#more-solutions"),i(ba,"id","more-solutions"),i(Wc,"class","svelte-x2kgxs"),i(jc,"class","svelte-x2kgxs"),i(Fc,"class","svelte-x2kgxs"),i(ht,"class","svelte-x2kgxs"),i(Bc,"class","svelte-x2kgxs"),i(Vc,"class","svelte-x2kgxs"),i(Yc,"class","svelte-x2kgxs"),i(Kc,"class","svelte-x2kgxs"),i(gt,"class","svelte-x2kgxs"),i(Xc,"class","svelte-x2kgxs"),i(Zc,"class","svelte-x2kgxs"),i(Qc,"class","svelte-x2kgxs"),i(mt,"class","svelte-x2kgxs"),i(Jc,"class","svelte-x2kgxs"),i($c,"class","svelte-x2kgxs"),i(eu,"class","svelte-x2kgxs"),i(vt,"class","svelte-x2kgxs"),i(tu,"class","svelte-x2kgxs"),i(su,"class","svelte-x2kgxs"),i(au,"class","svelte-x2kgxs"),i(_t,"class","svelte-x2kgxs"),i(lu,"class","svelte-x2kgxs"),i(ru,"class","svelte-x2kgxs"),i(iu,"class","svelte-x2kgxs"),i(kt,"class","svelte-x2kgxs"),i(ou,"class","svelte-x2kgxs"),i(nu,"class","svelte-x2kgxs"),i(cu,"class","svelte-x2kgxs"),i(Et,"class","svelte-x2kgxs"),i(uu,"class","svelte-x2kgxs"),i(fu,"class","svelte-x2kgxs"),i(du,"class","svelte-x2kgxs"),i(bt,"class","svelte-x2kgxs"),i(pu,"class","svelte-x2kgxs"),i(hu,"class","svelte-x2kgxs"),i(gu,"class","svelte-x2kgxs"),i(xt,"class","svelte-x2kgxs"),i(mu,"class","svelte-x2kgxs"),i(vu,"class","svelte-x2kgxs"),i(_u,"class","svelte-x2kgxs"),i(yt,"class","svelte-x2kgxs"),i(ku,"class","svelte-x2kgxs"),i(Eu,"class","svelte-x2kgxs"),i(bu,"class","svelte-x2kgxs"),i(wt,"class","svelte-x2kgxs"),i(W,"class","svelte-x2kgxs"),i(Gt,"class","svelte-x2kgxs"),i(Dp,"class","icon icon-link"),i(wa,"aria-hidden","true"),i(wa,"tabindex","-1"),i(wa,"href","#results"),i(ya,"id","results"),Ut(tr.src,K7="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(tr,"src",K7),i(tr,"alt","image"),i(tr,"class","svelte-x2kgxs"),i(er,"class","svelte-x2kgxs"),i(Ap,"class","icon icon-link"),i(Ta,"aria-hidden","true"),i(Ta,"tabindex","-1"),i(Ta,"href","#spacelab"),i(Ht,"id","spacelab"),i(Ht,"class","svelte-x2kgxs")},m(s,d){f(s,p,d),e(p,m),f(s,g,d),f(s,h,d),e(h,v),f(s,k,d),f(s,b,d),e(b,w),e(w,T),e(b,x),f(s,E,d),f(s,y,d),e(y,I),f(s,N,d),f(s,G,d),e(G,D),f(s,A,d),f(s,S,d),e(S,O),e(O,z),e(S,Q),e(S,j),e(j,F),f(s,B,d),f(s,C,d),e(C,L),f(s,H,d),f(s,Z,d),e(Z,q),e(q,R),e(Z,M),f(s,jt,d),f(s,Se,d),e(Se,fe),f(s,Cp,d),f(s,nr,d),e(nr,xv),f(s,Gp,d),f(s,Ft,d),e(Ft,Vt),e(Vt,yf),e(Ft,yv),f(s,Hp,d),f(s,cr,d),e(cr,wv),f(s,qp,d),f(s,qa,d),e(qa,ur),e(ur,Tv),f(s,Mp,d),ir(Ma,s,d),f(s,Up,d),f(s,fr,d),e(fr,Rv),f(s,Bp,d),f(s,dr,d),e(dr,Sv),f(s,Wp,d),f(s,pr,d),e(pr,Dv),f(s,jp,d),f(s,At,d),e(At,hr),e(hr,De),e(De,gr),e(gr,Av),e(De,Lv),e(De,mr),e(mr,Iv),e(De,Pv),e(De,vr),e(vr,Ov),e(At,zv),e(At,Ae),e(Ae,Le),e(Le,_r),e(_r,wf),e(wf,Nv),e(Le,Cv),e(Le,kr),e(kr,Gv),e(Le,Hv),e(Le,Er),e(Er,qv),e(Ae,Mv),e(Ae,Ie),e(Ie,br),e(br,Tf),e(Tf,Uv),e(Ie,Bv),e(Ie,xr),e(xr,Wv),e(Ie,jv),e(Ie,yr),e(yr,Fv),e(Ae,Vv),e(Ae,Pe),e(Pe,wr),e(wr,Rf),e(Rf,Yv),e(Pe,Kv),e(Pe,Tr),e(Tr,Xv),e(Pe,Zv),e(Pe,Rr),e(Rr,Qv),f(s,Fp,d),f(s,Sr,d),e(Sr,Jv),f(s,Vp,d),f(s,Dr,d),e(Dr,$v),f(s,Yp,d),f(s,Ua,d),e(Ua,Ar),e(Ar,e2),f(s,Kp,d),f(s,Yt,d),e(Yt,Kt),e(Kt,Sf),e(Yt,t2),f(s,Xp,d),f(s,Ba,d),e(Ba,Df),e(Df,s2),e(Ba,a2),f(s,Zp,d),f(s,Wa,d),e(Wa,Af),e(Af,l2),e(Wa,r2),f(s,Qp,d),f(s,ja,d),e(ja,Lf),e(Lf,i2),e(ja,o2),f(s,Jp,d),f(s,Xt,d),e(Xt,Zt),e(Zt,If),e(Xt,n2),f(s,$p,d),f(s,Fa,d),e(Fa,Pf),e(Pf,c2),e(Fa,u2),f(s,eh,d),f(s,Va,d),e(Va,Of),e(Of,f2),e(Va,d2),f(s,th,d),f(s,Ya,d),e(Ya,zf),e(zf,p2),e(Ya,h2),f(s,sh,d),f(s,Qt,d),e(Qt,Jt),e(Jt,Nf),e(Qt,g2),f(s,ah,d),f(s,Ka,d),e(Ka,Cf),e(Cf,m2),e(Ka,v2),f(s,lh,d),f(s,Oe,d),e(Oe,_2),e(Oe,Gf),e(Gf,k2),e(Oe,E2),e(Oe,Hf),e(Hf,b2),e(Oe,x2),f(s,rh,d),f(s,ze,d),e(ze,Lr),e(Lr,qf),e(qf,y2),e(Lr,w2),e(ze,T2),e(ze,Ir),e(Ir,Mf),e(Mf,R2),e(Ir,S2),e(ze,D2),e(ze,$t),e($t,Uf),e(Uf,A2),e($t,L2),e($t,Pr),e(Pr,I2),e($t,P2),f(s,ih,d),f(s,Xa,d),e(Xa,Or),e(Or,O2),f(s,oh,d),f(s,es,d),e(es,ts),e(ts,Bf),e(es,Wf),e(Wf,z2),f(s,nh,d),f(s,zr,d),e(zr,N2),f(s,ch,d),f(s,Ne,d),e(Ne,Nr),e(Nr,jf),e(jf,C2),e(Nr,G2),e(Ne,H2),e(Ne,Cr),e(Cr,Ff),e(Ff,q2),e(Cr,M2),e(Ne,U2),e(Ne,Gr),e(Gr,Vf),e(Vf,B2),e(Gr,W2),f(s,uh,d),f(s,ss,d),e(ss,as),e(as,Yf),e(ss,Kf),e(Kf,j2),f(s,fh,d),f(s,Lt,d),e(Lt,Hr),e(Hr,Ce),e(Ce,qr),e(qr,Xf),e(Xf,F2),e(Ce,V2),e(Ce,Mr),e(Mr,Zf),e(Zf,Y2),e(Ce,K2),e(Ce,Ur),e(Ur,Qf),e(Qf,X2),e(Lt,Z2),e(Lt,de),e(de,Ge),e(Ge,Br),e(Br,Jf),e(Jf,Q2),e(Ge,J2),e(Ge,Wr),e(Wr,$2),e(Ge,e_),e(Ge,jr),e(jr,t_),e(de,s_),e(de,He),e(He,Fr),e(Fr,$f),e($f,a_),e(He,l_),e(He,Vr),e(Vr,r_),e(He,i_),e(He,Yr),e(Yr,o_),e(de,n_),e(de,qe),e(qe,Kr),e(Kr,ed),e(ed,c_),e(qe,u_),e(qe,Xr),e(Xr,f_),e(qe,d_),e(qe,Zr),e(Zr,p_),e(de,h_),e(de,Me),e(Me,Qr),e(Qr,td),e(td,g_),e(Me,m_),e(Me,Jr),e(Jr,v_),e(Me,__),e(Me,$r),e($r,k_),f(s,dh,d),f(s,ls,d),e(ls,rs),e(rs,sd),e(ls,E_),f(s,ph,d),f(s,It,d),e(It,ei),e(ei,is),e(is,ti),e(ti,b_),e(is,x_),e(is,si),e(si,y_),e(It,w_),e(It,pe),e(pe,os),e(os,ai),e(ai,ad),e(ad,T_),e(os,R_),e(os,li),e(li,S_),e(pe,D_),e(pe,ns),e(ns,ri),e(ri,ld),e(ld,A_),e(ns,L_),e(ns,ii),e(ii,I_),e(pe,P_),e(pe,cs),e(cs,oi),e(oi,rd),e(rd,O_),e(cs,z_),e(cs,ni),e(ni,N_),e(pe,C_),e(pe,us),e(us,ci),e(ci,id),e(id,G_),e(us,H_),e(us,ui),e(ui,q_),f(s,hh,d),f(s,fi,d),e(fi,M_),f(s,gh,d),f(s,fs,d),e(fs,ds),e(ds,od),e(fs,U_),f(s,mh,d),f(s,Za,d),Za.innerHTML=yA,f(s,vh,d),f(s,Qa,d),Qa.innerHTML=wA,f(s,_h,d),f(s,ps,d),e(ps,hs),e(hs,nd),e(ps,B_),f(s,kh,d),f(s,Pt,d),e(Pt,di),e(di,Ue),e(Ue,pi),e(pi,W_),e(Ue,j_),e(Ue,hi),e(hi,F_),e(Ue,V_),e(Ue,gi),e(gi,Y_),e(Pt,K_),e(Pt,he),e(he,Be),e(Be,mi),e(mi,X_),e(Be,Z_),e(Be,vi),e(vi,Q_),e(Be,J_),e(Be,_i),e(_i,$_),e(he,e1),e(he,We),e(We,ki),e(ki,t1),e(We,s1),e(We,Ei),e(Ei,a1),e(We,l1),e(We,bi),e(bi,r1),e(he,i1),e(he,je),e(je,xi),e(xi,o1),e(je,n1),e(je,yi),e(yi,c1),e(je,u1),e(je,wi),e(wi,f1),e(he,d1),e(he,Fe),e(Fe,Ti),e(Ti,p1),e(Fe,h1),e(Fe,Ri),e(Ri,g1),e(Fe,m1),e(Fe,Si),e(Si,v1),f(s,Eh,d),f(s,bh,d),f(s,xh,d),f(s,gs,d),e(gs,ms),e(ms,cd),e(gs,_1),f(s,yh,d),f(s,vs,d),e(vs,k1),e(vs,Ja),e(Ja,E1),e(vs,b1),f(s,wh,d),f(s,_s,d),e(_s,ks),e(ks,ud),e(_s,x1),f(s,Th,d),f(s,Es,d),e(Es,y1),e(Es,$a),e($a,w1),e(Es,T1),f(s,Rh,d),f(s,el,d),el.innerHTML=TA,f(s,Sh,d),f(s,bs,d),e(bs,xs),e(xs,fd),e(bs,R1),f(s,Dh,d),f(s,Ve,d),e(Ve,dd),e(dd,S1),e(Ve,D1),e(Ve,pd),e(pd,A1),e(Ve,L1),e(Ve,hd),e(hd,I1),f(s,Ah,d),f(s,ys,d),e(ys,ws),e(ws,gd),e(ys,P1),f(s,Lh,d),f(s,Ye,d),e(Ye,md),e(md,O1),e(Ye,z1),e(Ye,vd),e(vd,N1),e(Ye,C1),e(Ye,_d),e(_d,G1),f(s,Ih,d),f(s,Ts,d),e(Ts,Rs),e(Rs,kd),e(Ts,H1),f(s,Ph,d),f(s,tl,d),e(tl,Ed),e(Ed,q1),e(tl,M1),f(s,Oh,d),f(s,sl,d),sl.innerHTML=RA,f(s,zh,d),f(s,Ss,d),e(Ss,Ds),e(Ds,bd),e(Ss,U1),f(s,Nh,d),f(s,Ke,d),e(Ke,xd),e(xd,B1),e(Ke,W1),e(Ke,yd),e(yd,j1),e(Ke,F1),e(Ke,wd),e(wd,V1),f(s,Ch,d),f(s,al,d),e(al,Di),e(Di,Y1),f(s,Gh,d),f(s,As,d),e(As,Ls),e(Ls,Td),e(As,K1),f(s,Hh,d),f(s,ll,d),e(ll,Rd),e(Rd,X1),e(ll,Z1),f(s,qh,d),f(s,Ai,d),e(Ai,Q1),f(s,Mh,d),f(s,Xe,d),e(Xe,rl),e(rl,J1),e(rl,Li),e(Li,$1),e(rl,ek),e(Xe,tk),e(Xe,Sd),e(Sd,sk),e(Xe,ak),e(Xe,Dd),e(Dd,lk),f(s,Uh,d),f(s,il,d),e(il,Ii),e(Ii,rk),f(s,Bh,d),f(s,Is,d),e(Is,Ps),e(Ps,Ad),e(Is,ik),f(s,Wh,d),f(s,ol,d),e(ol,Ld),e(Ld,ok),e(ol,nk),f(s,jh,d),f(s,nl,d),nl.innerHTML=SA,f(s,Fh,d),f(s,Pi,d),e(Pi,ck),f(s,Vh,d),f(s,Ze,d),e(Ze,Id),e(Id,uk),e(Ze,fk),e(Ze,Pd),e(Pd,dk),e(Ze,pk),e(Ze,Od),e(Od,hk),f(s,Yh,d),f(s,cl,d),e(cl,Oi),e(Oi,gk),f(s,Kh,d),f(s,Os,d),e(Os,zs),e(zs,zd),e(Os,mk),f(s,Xh,d),f(s,Ns,d),e(Ns,vk),e(Ns,Nd),e(Nd,_k),e(Ns,kk),f(s,Zh,d),f(s,ul,d),ul.innerHTML=DA,f(s,Qh,d),f(s,fl,d),fl.innerHTML=AA,f(s,Jh,d),f(s,dl,d),e(dl,Cd),e(Cd,Ek),e(dl,bk),f(s,$h,d),f(s,Qe,d),e(Qe,Gd),e(Gd,xk),e(Qe,yk),e(Qe,Hd),e(Hd,wk),e(Qe,Tk),e(Qe,qd),e(qd,Rk),f(s,eg,d),f(s,Ot,d),e(Ot,zi),e(zi,ge),e(ge,Ni),e(Ni,Sk),e(ge,Dk),e(ge,Ci),e(Ci,Ak),e(ge,Lk),e(ge,Gi),e(Gi,Ik),e(ge,Pk),e(ge,Hi),e(Hi,Ok),e(Ot,zk),e(Ot,le),e(le,me),e(me,qi),e(qi,Nk),e(me,Ck),e(me,Mi),e(Mi,Gk),e(me,Hk),e(me,Ui),e(Ui,qk),e(me,Mk),e(me,Bi),e(Bi,Uk),e(le,Bk),e(le,ve),e(ve,Wi),e(Wi,Wk),e(ve,jk),e(ve,ji),e(ji,Fk),e(ve,Vk),e(ve,Fi),e(Fi,Yk),e(ve,Kk),e(ve,Vi),e(Vi,Xk),e(le,Zk),e(le,_e),e(_e,Yi),e(Yi,Qk),e(_e,Jk),e(_e,Ki),e(Ki,$k),e(_e,eE),e(_e,Cs),e(Cs,tE),e(Cs,Md),e(Md,sE),e(Cs,aE),e(_e,lE),e(_e,Je),e(Je,rE),e(Je,Xi),e(Xi,iE),e(Je,oE),e(Je,Zi),e(Zi,nE),e(Je,cE),e(le,uE),e(le,ke),e(ke,Qi),e(Qi,fE),e(ke,dE),e(ke,Ji),e(Ji,pE),e(ke,hE),e(ke,$i),e($i,gE),e(ke,mE),e(ke,eo),e(eo,vE),e(le,_E),e(le,Ee),e(Ee,to),e(to,kE),e(Ee,EE),e(Ee,so),e(so,bE),e(Ee,xE),e(Ee,ao),e(ao,yE),e(Ee,wE),e(Ee,lo),e(lo,TE),f(s,tg,d),f(s,sg,d),f(s,ag,d),f(s,Gs,d),e(Gs,Hs),e(Hs,Ud),e(Gs,RE),f(s,lg,d),f(s,qs,d),e(qs,SE),e(qs,ro),e(ro,DE),e(qs,AE),f(s,rg,d),f(s,ue,d),e(ue,LE),e(ue,io),e(io,IE),e(ue,PE),e(ue,oo),e(oo,OE),e(ue,zE),e(ue,no),e(no,NE),e(ue,CE),e(ue,co),e(co,GE),f(s,ig,d),f(s,uo,d),e(uo,HE),f(s,og,d),f(s,Ms,d),e(Ms,Us),e(Us,Bd),e(Ms,qE),f(s,ng,d),f(s,$e,d),e($e,Wd),e(Wd,pl),e(pl,jd),e(jd,ME),e(pl,UE),e(pl,BE),e($e,WE),e($e,Fd),e(Fd,hl),e(hl,Vd),e(Vd,jE),e(hl,FE),e(hl,VE),e($e,YE),e($e,Yd),e(Yd,gl),e(gl,Kd),e(Kd,KE),e(gl,XE),e(gl,ZE),f(s,cg,d),ir(ml,s,d),f(s,ug,d),f(s,Bs,d),e(Bs,Ws),e(Ws,Xd),e(Bs,QE),f(s,fg,d),f(s,js,d),e(js,JE),e(js,vl),e(vl,$E),e(js,eb),f(s,dg,d),f(s,et,d),e(et,tb),e(et,fo),e(fo,sb),e(et,ab),e(et,po),e(po,lb),e(et,rb),f(s,pg,d),f(s,J,d),e(J,Zd),e(Zd,ho),e(ho,ib),e(ho,go),e(go,ob),e(J,nb),e(J,Qd),e(Qd,_l),e(_l,cb),e(_l,mo),e(mo,ub),e(_l,fb),e(J,db),e(J,Jd),e(Jd,Y),e(Y,pb),e(Y,vo),e(vo,hb),e(Y,gb),e(Y,_o),e(_o,mb),e(Y,vb),e(Y,ko),e(ko,_b),e(Y,kb),e(Y,Eo),e(Eo,Eb),e(Y,bb),e(Y,bo),e(bo,xb),e(Y,yb),e(Y,xo),e(xo,wb),e(Y,Tb),e(Y,yo),e(yo,Rb),e(Y,Sb),e(Y,wo),e(wo,Db),e(J,Ab),e(J,$d),e($d,$),e($,Lb),e($,To),e(To,Ib),e($,Pb),e($,Ro),e(Ro,Ob),e($,zb),e($,So),e(So,Nb),e($,Cb),e($,Do),e(Do,Gb),e($,Hb),e($,Ao),e(Ao,qb),e($,Mb),e($,Lo),e(Lo,Ub),e($,Bb),e($,Io),e(Io,Wb),e(J,jb),e(J,ep),e(ep,K),e(K,Fb),e(K,Po),e(Po,Vb),e(K,Yb),e(K,Oo),e(Oo,Kb),e(K,Xb),e(K,zo),e(zo,Zb),e(K,Qb),e(K,No),e(No,Jb),e(K,$b),e(K,Co),e(Co,ex),e(K,tx),e(K,Go),e(Go,sx),e(K,ax),e(K,Ho),e(Ho,lx),e(K,rx),e(K,qo),e(qo,ix),e(J,ox),e(J,tp),e(tp,Mo),e(Mo,nx),e(Mo,Uo),e(Uo,cx),e(J,ux),e(J,sp),e(sp,Fs),e(Fs,fx),e(Fs,Bo),e(Bo,dx),e(Fs,px),e(Fs,Wo),e(Wo,hx),f(s,hg,d),f(s,tt,d),e(tt,gx),e(tt,jo),e(jo,mx),e(tt,vx),e(tt,Fo),e(Fo,_x),e(tt,kx),f(s,gg,d),ir(kl,s,d),f(s,mg,d),f(s,Vs,d),e(Vs,Ys),e(Ys,ap),e(Vs,Ex),f(s,vg,d),f(s,Vo,d),e(Vo,bx),f(s,_g,d),f(s,be,d),e(be,Yo),e(Yo,El),e(El,xx),e(Yo,yx),e(be,wx),e(be,Ko),e(Ko,bl),e(bl,Tx),e(Ko,Rx),e(be,Sx),e(be,Xo),e(Xo,xl),e(xl,Dx),e(Xo,Ax),e(be,Lx),e(be,Zo),e(Zo,yl),e(yl,Ix),e(Zo,Px),f(s,kg,d),f(s,Ks,d),e(Ks,Xs),e(Xs,lp),e(Ks,Ox),f(s,Eg,d),f(s,Qo,d),e(Qo,zx),f(s,bg,d),f(s,Jo,d),e(Jo,Nx),f(s,xg,d),f(s,st,d),e(st,Zs),e(Zs,rp),e(rp,Cx),e(Zs,Gx),e(Zs,$o),e($o,Hx),e(Zs,qx),e(st,Mx),e(st,at),e(at,ip),e(ip,Ux),e(at,Bx),e(at,en),e(en,Wx),e(at,jx),e(at,tn),e(tn,Fx),e(at,Vx),e(st,Yx),e(st,sn),e(sn,op),e(op,Kx),e(sn,Xx),f(s,yg,d),f(s,wl,d),wl.innerHTML=LA,f(s,wg,d),f(s,Qs,d),e(Qs,Tl),e(Tl,Zx),e(Tl,an),e(an,Qx),e(Tl,Jx),e(Qs,$x),e(Qs,Rl),e(Rl,ey),e(Rl,ln),e(ln,ty),e(Rl,sy),f(s,Tg,d),f(s,Js,d),e(Js,rn),e(rn,ay),e(rn,on),e(on,ly),e(Js,ry),e(Js,Sl),e(Sl,iy),e(Sl,nn),e(nn,oy),e(Sl,ny),f(s,Rg,d),f(s,$s,d),e($s,ea),e(ea,np),e($s,cy),f(s,Sg,d),f(s,ta,d),e(ta,uy),e(ta,Dl),e(Dl,fy),e(ta,dy),f(s,Dg,d),f(s,Al,d),e(Al,sa),e(sa,py),e(sa,Ll),e(Ll,hy),e(sa,gy),f(s,Ag,d),f(s,aa,d),e(aa,la),e(la,cp),e(aa,my),f(s,Lg,d),f(s,ra,d),e(ra,vy),e(ra,cn),e(cn,_y),e(ra,ky),f(s,Ig,d),f(s,Il,d),Il.innerHTML=IA,f(s,Pg,d),f(s,un,d),e(un,Ey),f(s,Og,d),f(s,Pl,d),Pl.innerHTML=PA,f(s,zg,d),f(s,lt,d),e(lt,by),e(lt,fn),e(fn,xy),e(lt,yy),e(lt,dn),e(dn,wy),e(lt,Ty),f(s,Ng,d),f(s,rt,d),e(rt,Ry),e(rt,pn),e(pn,Sy),e(rt,Dy),e(rt,hn),e(hn,Ay),e(rt,Ly),f(s,Cg,d),f(s,gn,d),e(gn,Iy),f(s,Gg,d),f(s,ia,d),e(ia,mn),e(mn,Py),e(mn,up),e(up,fp),e(fp,Oy),e(ia,zy),e(ia,vn),e(vn,Ny),e(vn,dp),e(dp,pp),e(pp,Cy),f(s,Hg,d),f(s,_n,d),e(_n,Gy),f(s,qg,d),f(s,Ol,d),e(Ol,zl),f(s,Mg,d),f(s,oa,d),e(oa,na),e(na,hp),e(oa,Hy),f(s,Ug,d),f(s,zt,d),e(zt,qy),e(zt,kn),e(kn,My),e(zt,Uy),e(zt,En),e(En,By),f(s,Bg,d),f(s,Nt,d),e(Nt,bn),e(bn,re),e(re,xn),e(xn,Wy),e(re,jy),e(re,yn),e(yn,Fy),e(re,Vy),e(re,wn),e(wn,Yy),e(re,Ky),e(re,Tn),e(Tn,Xy),e(re,Zy),e(re,Rn),e(Rn,Qy),e(Nt,Jy),e(Nt,Sn),e(Sn,ie),e(ie,Dn),e(Dn,$y),e(ie,e3),e(ie,An),e(An,t3),e(ie,s3),e(ie,Ln),e(Ln,a3),e(ie,l3),e(ie,In),e(In,r3),e(ie,i3),e(ie,Pn),e(Pn,o3),f(s,Wg,d),f(s,On,d),e(On,n3),f(s,jg,d),f(s,Nl,d),Nl.innerHTML=OA,f(s,Fg,d),f(s,U,d),e(U,zn),e(zn,Cl),e(Cl,c3),e(Cl,Nn),e(Nn,u3),e(Cl,f3),e(zn,d3),e(U,p3),e(U,Cn),e(Cn,Gl),e(Gl,h3),e(Gl,Gn),e(Gn,g3),e(Gl,m3),e(Cn,v3),e(U,_3),e(U,Hn),e(Hn,Hl),e(Hl,k3),e(Hl,qn),e(qn,E3),e(Hl,b3),e(Hn,x3),e(U,y3),e(U,Mn),e(Mn,ql),e(ql,w3),e(ql,Un),e(Un,T3),e(ql,R3),e(Mn,S3),e(U,D3),e(U,Bn),e(Bn,Ml),e(Ml,A3),e(Ml,Wn),e(Wn,L3),e(Ml,I3),e(Bn,P3),e(U,O3),e(U,jn),e(jn,Ul),e(Ul,z3),e(Ul,Fn),e(Fn,N3),e(Ul,C3),e(jn,G3),e(U,H3),e(U,Vn),e(Vn,Bl),e(Bl,q3),e(Bl,Yn),e(Yn,M3),e(Bl,U3),e(Vn,B3),e(U,W3),e(U,Kn),e(Kn,Wl),e(Wl,j3),e(Wl,Xn),e(Xn,F3),e(Wl,V3),e(Kn,Y3),e(U,K3),e(U,Zn),e(Zn,jl),e(jl,X3),e(jl,Qn),e(Qn,Z3),e(jl,Q3),e(Zn,J3),e(U,$3),e(U,Jn),e(Jn,Fl),e(Fl,e4),e(Fl,$n),e($n,t4),e(Fl,s4),e(Jn,a4),e(U,l4),e(U,ec),e(ec,Vl),e(Vl,r4),e(Vl,tc),e(tc,i4),e(Vl,o4),e(ec,n4),f(s,Vg,d),f(s,ca,d),e(ca,ua),e(ua,gp),e(ca,c4),f(s,Yg,d),f(s,sc,d),e(sc,u4),f(s,Kg,d),ir(Yl,s,d),f(s,Xg,d),f(s,fa,d),e(fa,da),e(da,mp),e(fa,f4),f(s,Zg,d),f(s,pa,d),e(pa,d4),e(pa,Kl),e(Kl,p4),e(pa,h4),f(s,Qg,d),f(s,ha,d),e(ha,g4),e(ha,ac),e(ac,m4),e(ha,v4),f(s,Jg,d),f(s,oe,d),e(oe,lc),e(lc,_4),e(lc,$g),e(oe,k4),e(oe,vp),e(vp,E4),e(oe,b4),e(oe,it),e(it,x4),e(it,rc),e(rc,y4),e(it,w4),e(it,ic),e(ic,T4),e(it,R4),e(it,oc),e(oc,S4),e(oe,D4),e(oe,nc),e(nc,A4),e(nc,cc),e(cc,L4),e(oe,I4),e(oe,ga),e(ga,P4),e(ga,uc),e(uc,O4),e(ga,z4),e(ga,fc),e(fc,N4),f(s,em,d),f(s,ot,d),e(ot,C4),e(ot,dc),e(dc,G4),e(ot,H4),e(ot,pc),e(pc,q4),e(ot,M4),f(s,tm,d),f(s,xe,d),e(xe,ma),e(ma,U4),e(ma,hc),e(hc,B4),e(ma,W4),e(ma,gc),e(gc,j4),e(xe,F4),e(xe,Xl),e(Xl,V4),e(Xl,mc),e(mc,Y4),e(Xl,K4),e(xe,X4),e(xe,_p),e(_p,Z4),e(xe,Q4),e(xe,kp),e(kp,J4),f(s,sm,d),f(s,va,d),e(va,_a),e(_a,Ep),e(va,$4),f(s,am,d),f(s,ye,d),e(ye,vc),e(vc,bp),e(bp,e0),e(vc,t0),e(ye,s0),e(ye,_c),e(_c,xp),e(xp,a0),e(_c,l0),e(ye,r0),e(ye,kc),e(kc,yp),e(yp,i0),e(kc,o0),e(ye,n0),e(ye,Ec),e(Ec,wp),e(wp,c0),e(Ec,u0),f(s,lm,d),f(s,bc,d),e(bc,f0),f(s,rm,d),f(s,Zl,d),e(Zl,Ql),f(s,im,d),f(s,ka,d),e(ka,Ea),e(Ea,Tp),e(ka,d0),f(s,om,d),f(s,xc,d),e(xc,p0),f(s,nm,d),f(s,nt,d),e(nt,Jl),e(Jl,h0),e(Jl,yc),e(yc,g0),e(Jl,m0),e(nt,v0),e(nt,$l),e($l,_0),e($l,wc),e(wc,k0),e($l,E0),e(nt,b0),e(nt,Rp),e(Rp,x0),f(s,cm,d),f(s,Ct,d),e(Ct,Tc),e(Tc,ct),e(ct,Rc),e(Rc,y0),e(ct,w0),e(ct,Sc),e(Sc,T0),e(ct,R0),e(ct,Dc),e(Dc,S0),e(Ct,D0),e(Ct,we),e(we,ut),e(ut,Ac),e(Ac,A0),e(ut,L0),e(ut,Lc),e(Lc,I0),e(ut,P0),e(ut,Ic),e(Ic,O0),e(we,z0),e(we,ft),e(ft,Pc),e(Pc,N0),e(ft,C0),e(ft,Oc),e(Oc,G0),e(ft,H0),e(ft,zc),e(zc,q0),e(we,M0),e(we,dt),e(dt,Nc),e(Nc,U0),e(dt,B0),e(dt,Cc),e(Cc,W0),e(dt,j0),e(dt,Gc),e(Gc,F0),e(we,V0),e(we,pt),e(pt,Hc),e(Hc,Y0),e(pt,K0),e(pt,qc),e(qc,X0),e(pt,Z0),e(pt,Mc),e(Mc,Q0),f(s,um,d),f(s,ba,d),e(ba,xa),e(xa,Sp),e(ba,J0),f(s,fm,d),f(s,Uc,d),e(Uc,$0),f(s,dm,d),f(s,Gt,d),e(Gt,Bc),e(Bc,ht),e(ht,Wc),e(Wc,e5),e(ht,t5),e(ht,jc),e(jc,s5),e(ht,a5),e(ht,Fc),e(Fc,l5),e(Gt,r5),e(Gt,W),e(W,gt),e(gt,Vc),e(Vc,i5),e(gt,o5),e(gt,Yc),e(Yc,n5),e(gt,c5),e(gt,Kc),e(Kc,u5),e(W,f5),e(W,mt),e(mt,Xc),e(Xc,d5),e(mt,p5),e(mt,Zc),e(Zc,h5),e(mt,g5),e(mt,Qc),e(Qc,m5),e(W,v5),e(W,vt),e(vt,Jc),e(Jc,_5),e(vt,k5),e(vt,$c),e($c,E5),e(vt,b5),e(vt,eu),e(eu,x5),e(W,y5),e(W,_t),e(_t,tu),e(tu,w5),e(_t,T5),e(_t,su),e(su,R5),e(_t,S5),e(_t,au),e(au,D5),e(W,A5),e(W,kt),e(kt,lu),e(lu,L5),e(kt,I5),e(kt,ru),e(ru,P5),e(kt,O5),e(kt,iu),e(iu,z5),e(W,N5),e(W,Et),e(Et,ou),e(ou,C5),e(Et,G5),e(Et,nu),e(nu,H5),e(Et,q5),e(Et,cu),e(cu,M5),e(W,U5),e(W,bt),e(bt,uu),e(uu,B5),e(bt,W5),e(bt,fu),e(fu,j5),e(bt,F5),e(bt,du),e(du,V5),e(W,Y5),e(W,xt),e(xt,pu),e(pu,K5),e(xt,X5),e(xt,hu),e(hu,Z5),e(xt,Q5),e(xt,gu),e(gu,J5),e(W,$5),e(W,yt),e(yt,mu),e(mu,ew),e(yt,tw),e(yt,vu),e(vu,sw),e(yt,aw),e(yt,_u),e(_u,lw),e(W,rw),e(W,wt),e(wt,ku),e(ku,iw),e(wt,ow),e(wt,Eu),e(Eu,nw),e(wt,cw),e(wt,bu),e(bu,uw),f(s,pm,d),f(s,ya,d),e(ya,wa),e(wa,Dp),e(ya,fw),f(s,hm,d),f(s,xu,d),e(xu,dw),f(s,gm,d),f(s,yu,d),e(yu,pw),f(s,mm,d),f(s,er,d),e(er,tr),f(s,vm,d),f(s,wu,d),e(wu,hw),f(s,_m,d),f(s,Ht,d),e(Ht,Ta),e(Ta,Ap),e(Ht,gw),f(s,km,d),Te&&Te.m(s,d),f(s,Em,d),bm=!0},p(s,d){xA&&Te.p(s,d)},i(s){bm||(Bt(Ma.$$.fragment,s),Bt(ml.$$.fragment,s),Bt(kl.$$.fragment,s),Bt(Yl.$$.fragment,s),Bt(Te),bm=!0)},o(s){Wt(Ma.$$.fragment,s),Wt(ml.$$.fragment,s),Wt(kl.$$.fragment,s),Wt(Yl.$$.fragment,s),Wt(Te),bm=!1},d(s){s&&t(p),s&&t(g),s&&t(h),s&&t(k),s&&t(b),s&&t(E),s&&t(y),s&&t(N),s&&t(G),s&&t(A),s&&t(S),s&&t(B),s&&t(C),s&&t(H),s&&t(Z),s&&t(jt),s&&t(Se),s&&t(Cp),s&&t(nr),s&&t(Gp),s&&t(Ft),s&&t(Hp),s&&t(cr),s&&t(qp),s&&t(qa),s&&t(Mp),or(Ma,s),s&&t(Up),s&&t(fr),s&&t(Bp),s&&t(dr),s&&t(Wp),s&&t(pr),s&&t(jp),s&&t(At),s&&t(Fp),s&&t(Sr),s&&t(Vp),s&&t(Dr),s&&t(Yp),s&&t(Ua),s&&t(Kp),s&&t(Yt),s&&t(Xp),s&&t(Ba),s&&t(Zp),s&&t(Wa),s&&t(Qp),s&&t(ja),s&&t(Jp),s&&t(Xt),s&&t($p),s&&t(Fa),s&&t(eh),s&&t(Va),s&&t(th),s&&t(Ya),s&&t(sh),s&&t(Qt),s&&t(ah),s&&t(Ka),s&&t(lh),s&&t(Oe),s&&t(rh),s&&t(ze),s&&t(ih),s&&t(Xa),s&&t(oh),s&&t(es),s&&t(nh),s&&t(zr),s&&t(ch),s&&t(Ne),s&&t(uh),s&&t(ss),s&&t(fh),s&&t(Lt),s&&t(dh),s&&t(ls),s&&t(ph),s&&t(It),s&&t(hh),s&&t(fi),s&&t(gh),s&&t(fs),s&&t(mh),s&&t(Za),s&&t(vh),s&&t(Qa),s&&t(_h),s&&t(ps),s&&t(kh),s&&t(Pt),s&&t(Eh),s&&t(bh),s&&t(xh),s&&t(gs),s&&t(yh),s&&t(vs),s&&t(wh),s&&t(_s),s&&t(Th),s&&t(Es),s&&t(Rh),s&&t(el),s&&t(Sh),s&&t(bs),s&&t(Dh),s&&t(Ve),s&&t(Ah),s&&t(ys),s&&t(Lh),s&&t(Ye),s&&t(Ih),s&&t(Ts),s&&t(Ph),s&&t(tl),s&&t(Oh),s&&t(sl),s&&t(zh),s&&t(Ss),s&&t(Nh),s&&t(Ke),s&&t(Ch),s&&t(al),s&&t(Gh),s&&t(As),s&&t(Hh),s&&t(ll),s&&t(qh),s&&t(Ai),s&&t(Mh),s&&t(Xe),s&&t(Uh),s&&t(il),s&&t(Bh),s&&t(Is),s&&t(Wh),s&&t(ol),s&&t(jh),s&&t(nl),s&&t(Fh),s&&t(Pi),s&&t(Vh),s&&t(Ze),s&&t(Yh),s&&t(cl),s&&t(Kh),s&&t(Os),s&&t(Xh),s&&t(Ns),s&&t(Zh),s&&t(ul),s&&t(Qh),s&&t(fl),s&&t(Jh),s&&t(dl),s&&t($h),s&&t(Qe),s&&t(eg),s&&t(Ot),s&&t(tg),s&&t(sg),s&&t(ag),s&&t(Gs),s&&t(lg),s&&t(qs),s&&t(rg),s&&t(ue),s&&t(ig),s&&t(uo),s&&t(og),s&&t(Ms),s&&t(ng),s&&t($e),s&&t(cg),or(ml,s),s&&t(ug),s&&t(Bs),s&&t(fg),s&&t(js),s&&t(dg),s&&t(et),s&&t(pg),s&&t(J),s&&t(hg),s&&t(tt),s&&t(gg),or(kl,s),s&&t(mg),s&&t(Vs),s&&t(vg),s&&t(Vo),s&&t(_g),s&&t(be),s&&t(kg),s&&t(Ks),s&&t(Eg),s&&t(Qo),s&&t(bg),s&&t(Jo),s&&t(xg),s&&t(st),s&&t(yg),s&&t(wl),s&&t(wg),s&&t(Qs),s&&t(Tg),s&&t(Js),s&&t(Rg),s&&t($s),s&&t(Sg),s&&t(ta),s&&t(Dg),s&&t(Al),s&&t(Ag),s&&t(aa),s&&t(Lg),s&&t(ra),s&&t(Ig),s&&t(Il),s&&t(Pg),s&&t(un),s&&t(Og),s&&t(Pl),s&&t(zg),s&&t(lt),s&&t(Ng),s&&t(rt),s&&t(Cg),s&&t(gn),s&&t(Gg),s&&t(ia),s&&t(Hg),s&&t(_n),s&&t(qg),s&&t(Ol),s&&t(Mg),s&&t(oa),s&&t(Ug),s&&t(zt),s&&t(Bg),s&&t(Nt),s&&t(Wg),s&&t(On),s&&t(jg),s&&t(Nl),s&&t(Fg),s&&t(U),s&&t(Vg),s&&t(ca),s&&t(Yg),s&&t(sc),s&&t(Kg),or(Yl,s),s&&t(Xg),s&&t(fa),s&&t(Zg),s&&t(pa),s&&t(Qg),s&&t(ha),s&&t(Jg),s&&t(oe),s&&t(em),s&&t(ot),s&&t(tm),s&&t(xe),s&&t(sm),s&&t(va),s&&t(am),s&&t(ye),s&&t(lm),s&&t(bc),s&&t(rm),s&&t(Zl),s&&t(im),s&&t(ka),s&&t(om),s&&t(xc),s&&t(nm),s&&t(nt),s&&t(cm),s&&t(Ct),s&&t(um),s&&t(ba),s&&t(fm),s&&t(Uc),s&&t(dm),s&&t(Gt),s&&t(pm),s&&t(ya),s&&t(hm),s&&t(xu),s&&t(gm),s&&t(yu),s&&t(mm),s&&t(er),s&&t(vm),s&&t(wu),s&&t(_m),s&&t(Ht),s&&t(km),Te&&Te.d(s),s&&t(Em)}}}function RL(_){let p,m;const g=[_[0],F7];let h={$$slots:{default:[TL]},$$scope:{ctx:_}};for(let v=0;v<g.length;v+=1)h=j7(h,g[v]);return p=new JA({props:h}),{c(){lr(p.$$.fragment)},l(v){rr(p.$$.fragment,v)},m(v,k){ir(p,v,k),m=!0},p(v,[k]){const b=k&1?QA(g,[k&1&&gA(v[0]),k&0&&gA(F7)]):{};k&2&&(b.$$scope={dirty:k,ctx:v}),p.$set(b)},i(v){m||(Bt(p.$$.fragment,v),m=!0)},o(v){Wt(p.$$.fragment,v),m=!1},d(v){or(p,v)}}}const F7={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:qL,date:ML,modifiedDate:UL,categories:BL,svg:WL,seoImage:jL,shortDescription:FL,author:VL,spacelab:xA,id:SL,spacelabDefaultTitle:DL,spacelabDefaultContent:AL,menu:YL,keywords:KL}=F7;function LL(_,p,m){return _.$$set=g=>{m(0,p=j7(j7({},p),mA(g)))},p=mA(p),[p]}class XL extends kv{constructor(p){super(),Ev(this,p,LL,RL,bv,{})}}export{XL as default,F7 as metadata};
