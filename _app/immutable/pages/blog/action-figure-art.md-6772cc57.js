import{S as Sc,i as Oc,s as Ac,l as Io,g as c,E as u_,d as t,v as ME,e as i,t as l,c as o,a as r,h as s,b as f,G as e,j as ce,k as u,m as d,F as $,H as ke,N as TE,Y as BE,J as Ha,f as Ze,Z as FE,_ as YE,$ as XE,q as Ce,o as Ne,O as ZE,w as jt,x as Wt,y as Mt,B as Bt,C as d_,z as KE,A as SE,a1 as OE}from"../../chunks/index-2a82a4a8.js";import{P as VE}from"../../chunks/_post-913f18eb.js";import{g as n_}from"../../chunks/config-201c2df4.js";import{a as c_}from"../../chunks/accountStore-3492c591.js";import{R as QE}from"../../chunks/ResponsivePicture-526d3695.js";import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function JE(_){let n,g,m,h,v,b,y,R,T,w,E,k,I,z,P,x,S,A;function O(L,H){return typeof L[2].title!="undefined"?ty:ey}let C=O(_),N=C(_);function V(L,H){return typeof L[2].description!="undefined"?iy:ay}let M=V(_),B=M(_),W=typeof _[2].list_description!="undefined"&&AE(_),q=typeof _[2].footer_description!="undefined"&&zE(_);return{c(){n=i("hr"),g=u(),m=i("div"),N.c(),h=u(),v=i("p"),b=i("ion-icon"),y=l("SpaceLab Content"),R=u(),B.c(),T=u(),W&&W.c(),w=u(),q&&q.c(),E=u(),k=i("button"),I=i("ion-icon"),z=u(),P=i("span"),x=l("SpaceLab"),this.h()},l(L){n=o(L,"HR",{}),g=d(L),m=o(L,"DIV",{class:!0});var H=r(m);N.l(H),h=d(H),v=o(H,"P",{class:!0});var Y=r(v);b=o(Y,"ION-ICON",{class:!0,name:!0}),r(b).forEach(t),y=s(Y,"SpaceLab Content"),Y.forEach(t),R=d(H),B.l(H),T=d(H),W&&W.l(H),w=d(H),q&&q.l(H),E=d(H),k=o(H,"BUTTON",{class:!0});var U=r(k);I=o(U,"ION-ICON",{class:!0,name:!0}),r(I).forEach(t),z=d(U),P=o(U,"SPAN",{});var D=r(P);x=s(D,"SpaceLab"),D.forEach(t),U.forEach(t),H.forEach(t),this.h()},h(){$(b,"class","icon svelte-s12rf8"),$(b,"name","lock-closed"),f(v,"class","highlight large svelte-s12rf8"),$(I,"class","icon svelte-s12rf8"),$(I,"name","planet"),f(k,"class","button subscribe svelte-s12rf8"),f(m,"class","subscribe svelte-s12rf8")},m(L,H){c(L,n,H),c(L,g,H),c(L,m,H),N.m(m,null),e(m,h),e(m,v),e(v,b),e(v,y),e(m,R),B.m(m,null),e(m,T),W&&W.m(m,null),e(m,w),q&&q.m(m,null),e(m,E),e(m,k),e(k,I),e(k,z),e(k,P),e(P,x),S||(A=ke(k,"click",_[15]),S=!0)},p(L,H){C===(C=O(L))&&N?N.p(L,H):(N.d(1),N=C(L),N&&(N.c(),N.m(m,h))),M===(M=V(L))&&B?B.p(L,H):(B.d(1),B=M(L),B&&(B.c(),B.m(m,T))),typeof L[2].list_description!="undefined"?W?W.p(L,H):(W=AE(L),W.c(),W.m(m,w)):W&&(W.d(1),W=null),typeof L[2].footer_description!="undefined"?q?q.p(L,H):(q=zE(L),q.c(),q.m(m,E)):q&&(q.d(1),q=null)},d(L){L&&t(n),L&&t(g),L&&t(m),N.d(),B.d(),W&&W.d(),q&&q.d(),S=!1,A()}}}function $E(_){let n,g,m,h=_[2].title+"",v,b,y,R,T,w,E,k=_[2].description+"",I,z,P,x,S,A,O,C,N,V,M,B,W,q=typeof _[2].list_description!="undefined"&&LE(_),L=typeof _[2].footer_description!="undefined"&&IE(_);function H(D,G){if(D[2].github_private_repo&&D[2].github_state==="LOG_EXISTS")return ly;if(D[2].github_private_repo&&D[2].github_state==="NO_LOGS")return ry;if(D[2].github_private_repo&&D[2].github_state==="NO_GITHUB_USERNAME")return oy}let Y=H(_),U=Y&&Y(_);return{c(){n=i("hr"),g=u(),m=i("h2"),v=l(h),b=u(),y=i("p"),R=i("ion-icon"),T=l("SpaceLab Content"),w=u(),E=i("p"),I=l(k),z=u(),q&&q.c(),P=u(),L&&L.c(),x=u(),S=i("button"),A=i("ion-icon"),O=u(),C=i("span"),N=l("Download"),V=u(),U&&U.c(),M=Io(),this.h()},l(D){n=o(D,"HR",{}),g=d(D),m=o(D,"H2",{class:!0});var G=r(m);v=s(G,h),G.forEach(t),b=d(D),y=o(D,"P",{class:!0});var Ft=r(y);R=o(Ft,"ION-ICON",{class:!0,name:!0}),r(R).forEach(t),T=s(Ft,"SpaceLab Content"),Ft.forEach(t),w=d(D),E=o(D,"P",{class:!0});var Ua=r(E);I=s(Ua,k),Ua.forEach(t),z=d(D),q&&q.l(D),P=d(D),L&&L.l(D),x=d(D),S=o(D,"BUTTON",{class:!0});var De=r(S);A=o(De,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),O=d(De),C=o(De,"SPAN",{});var ja=r(C);N=s(ja,"Download"),ja.forEach(t),De.forEach(t),V=d(D),U&&U.l(D),M=Io(),this.h()},h(){f(m,"class","svelte-s12rf8"),$(R,"class","icon svelte-s12rf8"),$(R,"name","planet-sharp"),f(y,"class","highlight large svelte-s12rf8"),f(E,"class","svelte-s12rf8"),$(A,"class","icon svelte-s12rf8"),$(A,"name","cloud-download"),f(S,"class","button svelte-s12rf8")},m(D,G){c(D,n,G),c(D,g,G),c(D,m,G),e(m,v),c(D,b,G),c(D,y,G),e(y,R),e(y,T),c(D,w,G),c(D,E,G),e(E,I),c(D,z,G),q&&q.m(D,G),c(D,P,G),L&&L.m(D,G),c(D,x,G),c(D,S,G),e(S,A),e(S,O),e(S,C),e(C,N),c(D,V,G),U&&U.m(D,G),c(D,M,G),B||(W=ke(S,"click",_[10]),B=!0)},p(D,G){G&4&&h!==(h=D[2].title+"")&&ce(v,h),G&4&&k!==(k=D[2].description+"")&&ce(I,k),typeof D[2].list_description!="undefined"?q?q.p(D,G):(q=LE(D),q.c(),q.m(P.parentNode,P)):q&&(q.d(1),q=null),typeof D[2].footer_description!="undefined"?L?L.p(D,G):(L=IE(D),L.c(),L.m(x.parentNode,x)):L&&(L.d(1),L=null),Y===(Y=H(D))&&U?U.p(D,G):(U&&U.d(1),U=Y&&Y(D),U&&(U.c(),U.m(M.parentNode,M)))},d(D){D&&t(n),D&&t(g),D&&t(m),D&&t(b),D&&t(y),D&&t(w),D&&t(E),D&&t(z),q&&q.d(D),D&&t(P),L&&L.d(D),D&&t(x),D&&t(S),D&&t(V),U&&U.d(D),D&&t(M),B=!1,W()}}}function ey(_){let n,g;return{c(){n=i("h2"),g=l(_[0]),this.h()},l(m){n=o(m,"H2",{class:!0});var h=r(n);g=s(h,_[0]),h.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(m,h){c(m,n,h),e(n,g)},p(m,h){h&1&&ce(g,m[0])},d(m){m&&t(n)}}}function ty(_){let n,g=_[2].title+"",m;return{c(){n=i("h2"),m=l(g),this.h()},l(h){n=o(h,"H2",{class:!0});var v=r(n);m=s(v,g),v.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(h,v){c(h,n,v),e(n,m)},p(h,v){v&4&&g!==(g=h[2].title+"")&&ce(m,g)},d(h){h&&t(n)}}}function ay(_){let n,g;return{c(){n=i("p"),g=l(_[1]),this.h()},l(m){n=o(m,"P",{class:!0});var h=r(n);g=s(h,_[1]),h.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(m,h){c(m,n,h),e(n,g)},p(m,h){h&2&&ce(g,m[1])},d(m){m&&t(n)}}}function iy(_){let n,g=_[2].description+"",m;return{c(){n=i("p"),m=l(g),this.h()},l(h){n=o(h,"P",{class:!0});var v=r(n);m=s(v,g),v.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(h,v){c(h,n,v),e(n,m)},p(h,v){v&4&&g!==(g=h[2].description+"")&&ce(m,g)},d(h){h&&t(n)}}}function AE(_){let n,g,m=_[2].list_description+"",h;return{c(){n=i("div"),g=i("p"),h=l(m),this.h()},l(v){n=o(v,"DIV",{class:!0});var b=r(n);g=o(b,"P",{class:!0});var y=r(g);h=s(y,m),y.forEach(t),b.forEach(t),this.h()},h(){f(g,"class","svelte-s12rf8"),f(n,"class","list-description svelte-s12rf8")},m(v,b){c(v,n,b),e(n,g),e(g,h)},p(v,b){b&4&&m!==(m=v[2].list_description+"")&&ce(h,m)},d(v){v&&t(n)}}}function zE(_){let n,g=_[2].footer_description+"",m;return{c(){n=i("p"),m=l(g),this.h()},l(h){n=o(h,"P",{class:!0});var v=r(n);m=s(v,g),v.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(h,v){c(h,n,v),e(n,m)},p(h,v){v&4&&g!==(g=h[2].footer_description+"")&&ce(m,g)},d(h){h&&t(n)}}}function LE(_){let n,g,m=_[2].list_description+"",h;return{c(){n=i("div"),g=i("p"),h=l(m),this.h()},l(v){n=o(v,"DIV",{class:!0});var b=r(n);g=o(b,"P",{class:!0});var y=r(g);h=s(y,m),y.forEach(t),b.forEach(t),this.h()},h(){f(g,"class","svelte-s12rf8"),f(n,"class","list-description svelte-s12rf8")},m(v,b){c(v,n,b),e(n,g),e(g,h)},p(v,b){b&4&&m!==(m=v[2].list_description+"")&&ce(h,m)},d(v){v&&t(n)}}}function IE(_){let n,g=_[2].footer_description+"",m;return{c(){n=i("p"),m=l(g),this.h()},l(h){n=o(h,"P",{class:!0});var v=r(n);m=s(v,g),v.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(h,v){c(h,n,v),e(n,m)},p(h,v){v&4&&g!==(g=h[2].footer_description+"")&&ce(m,g)},d(h){h&&t(n)}}}function oy(_){let n,g,m,h,v,b;function y(w,E){return w[5]?ny:sy}let R=y(_),T=R(_);return{c(){n=i("h2"),g=l("Private GitHub Access"),m=u(),h=i("form"),T.c(),this.h()},l(w){n=o(w,"H2",{class:!0});var E=r(n);g=s(E,"Private GitHub Access"),E.forEach(t),m=d(w),h=o(w,"FORM",{class:!0});var k=r(h);T.l(k),k.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8"),f(h,"class","request-permission svelte-s12rf8")},m(w,E){c(w,n,E),e(n,g),c(w,m,E),c(w,h,E),T.m(h,null),v||(b=ke(h,"submit",_[8]),v=!0)},p(w,E){R===(R=y(w))&&T?T.p(w,E):(T.d(1),T=R(w),T&&(T.c(),T.m(h,null)))},d(w){w&&t(n),w&&t(m),w&&t(h),T.d(),v=!1,b()}}}function ry(_){let n,g,m,h,v,b;function y(w,E){return w[5]?fy:cy}let R=y(_),T=R(_);return{c(){n=i("h2"),g=l("Private GitHub Access"),m=u(),h=i("form"),T.c(),this.h()},l(w){n=o(w,"H2",{class:!0});var E=r(n);g=s(E,"Private GitHub Access"),E.forEach(t),m=d(w),h=o(w,"FORM",{});var k=r(h);T.l(k),k.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8")},m(w,E){c(w,n,E),e(n,g),c(w,m,E),c(w,h,E),T.m(h,null),v||(b=ke(h,"submit",_[7]),v=!0)},p(w,E){R===(R=y(w))&&T?T.p(w,E):(T.d(1),T=R(w),T&&(T.c(),T.m(h,null)))},d(w){w&&t(n),w&&t(m),w&&t(h),T.d(),v=!1,b()}}}function ly(_){var A;let n,g,m,h,v,b,y=((A=_[6].profile)==null?void 0:A.githubUsername)+"",R,T,w,E,k,I,z,P,x,S;return{c(){n=i("h2"),g=l("Private GitHub Access"),m=u(),h=i("p"),v=l("Your GitHub account "),b=i("span"),R=l(y),T=l(` is
			linked to this content.`),w=u(),E=i("button"),k=i("ion-icon"),I=u(),z=i("span"),P=l("Open Repository"),this.h()},l(O){n=o(O,"H2",{class:!0});var C=r(n);g=s(C,"Private GitHub Access"),C.forEach(t),m=d(O),h=o(O,"P",{class:!0});var N=r(h);v=s(N,"Your GitHub account "),b=o(N,"SPAN",{class:!0});var V=r(b);R=s(V,y),V.forEach(t),T=s(N,` is
			linked to this content.`),N.forEach(t),w=d(O),E=o(O,"BUTTON",{class:!0});var M=r(E);k=o(M,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),I=d(M),z=o(M,"SPAN",{});var B=r(z);P=s(B,"Open Repository"),B.forEach(t),M.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8"),f(b,"class","highlight svelte-s12rf8"),f(h,"class","svelte-s12rf8"),$(k,"class","icon svelte-s12rf8"),$(k,"name","rocket-sharp"),f(E,"class","svelte-s12rf8")},m(O,C){c(O,n,C),e(n,g),c(O,m,C),c(O,h,C),e(h,v),e(h,b),e(b,R),e(h,T),c(O,w,C),c(O,E,C),e(E,k),e(E,I),e(E,z),e(z,P),x||(S=ke(E,"click",_[11]),x=!0)},p(O,C){var N;C&64&&y!==(y=((N=O[6].profile)==null?void 0:N.githubUsername)+"")&&ce(R,y)},d(O){O&&t(n),O&&t(m),O&&t(h),O&&t(w),O&&t(E),x=!1,S()}}}function sy(_){let n,g,m,h,v,b,y,R,T,w,E,k,I,z,P,x;return{c(){n=i("p"),g=l(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),m=u(),h=i("label"),v=l("Github username:"),b=u(),y=i("input"),T=u(),w=i("button"),E=i("ion-icon"),k=u(),I=i("span"),z=l("Request Permission"),this.h()},l(S){n=o(S,"P",{class:!0});var A=r(n);g=s(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),m=d(S),h=o(S,"LABEL",{for:!0});var O=r(h);v=s(O,"Github username:"),O.forEach(t),b=d(S),y=o(S,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),T=d(S),w=o(S,"BUTTON",{class:!0});var C=r(w);E=o(C,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),k=d(C),I=o(C,"SPAN",{});var N=r(I);z=s(N,"Request Permission"),N.forEach(t),C.forEach(t),this.h()},h(){f(n,"class","svelte-s12rf8"),f(h,"for","username"),f(y,"name","username"),f(y,"id","username"),f(y,"placeholder","enter a username"),f(y,"type","text"),y.required="true",f(y,"class",R=_[4]?"validation-error":""),$(E,"class","icon svelte-s12rf8"),$(E,"name","rocket-sharp"),f(w,"class","svelte-s12rf8")},m(S,A){c(S,n,A),e(n,g),c(S,m,A),c(S,h,A),e(h,v),c(S,b,A),c(S,y,A),TE(y,_[3]),c(S,T,A),c(S,w,A),e(w,E),e(w,k),e(w,I),e(I,z),P||(x=ke(y,"input",_[14]),P=!0)},p(S,A){A&16&&R!==(R=S[4]?"validation-error":"")&&f(y,"class",R),A&8&&y.value!==S[3]&&TE(y,S[3])},d(S){S&&t(n),S&&t(m),S&&t(h),S&&t(b),S&&t(y),S&&t(T),S&&t(w),P=!1,x()}}}function ny(_){let n,g,m,h,v,b,y,R,T,w;return{c(){n=i("p"),g=l(_[5]),m=u(),h=i("button"),v=i("ion-icon"),b=u(),y=i("span"),R=l("Open Repository"),this.h()},l(E){n=o(E,"P",{class:!0});var k=r(n);g=s(k,_[5]),k.forEach(t),m=d(E),h=o(E,"BUTTON",{class:!0});var I=r(h);v=o(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),b=d(I),y=o(I,"SPAN",{});var z=r(y);R=s(z,"Open Repository"),z.forEach(t),I.forEach(t),this.h()},h(){f(n,"class","feedback svelte-s12rf8"),$(v,"class","icon svelte-s12rf8"),$(v,"name","rocket-sharp"),f(h,"class","svelte-s12rf8")},m(E,k){c(E,n,k),e(n,g),c(E,m,k),c(E,h,k),e(h,v),e(h,b),e(h,y),e(y,R),T||(w=ke(h,"click",_[13]),T=!0)},p(E,k){k&32&&ce(g,E[5])},d(E){E&&t(n),E&&t(m),E&&t(h),T=!1,w()}}}function cy(_){var I;let n,g,m,h=((I=_[6].profile)==null?void 0:I.githubUsername)+"",v,b,y,R,T,w,E,k;return{c(){n=i("p"),g=l("This content can grant access to a private GitHub repository. Allow "),m=i("span"),v=l(h),b=l(" access to this repo?"),y=u(),R=i("button"),T=i("ion-icon"),w=u(),E=i("span"),k=l("Request Permission"),this.h()},l(z){n=o(z,"P",{class:!0});var P=r(n);g=s(P,"This content can grant access to a private GitHub repository. Allow "),m=o(P,"SPAN",{class:!0});var x=r(m);v=s(x,h),x.forEach(t),b=s(P," access to this repo?"),P.forEach(t),y=d(z),R=o(z,"BUTTON",{class:!0});var S=r(R);T=o(S,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),w=d(S),E=o(S,"SPAN",{});var A=r(E);k=s(A,"Request Permission"),A.forEach(t),S.forEach(t),this.h()},h(){f(m,"class","highlight svelte-s12rf8"),f(n,"class","svelte-s12rf8"),$(T,"class","icon svelte-s12rf8"),$(T,"name","rocket-sharp"),f(R,"class","svelte-s12rf8")},m(z,P){c(z,n,P),e(n,g),e(n,m),e(m,v),e(n,b),c(z,y,P),c(z,R,P),e(R,T),e(R,w),e(R,E),e(E,k)},p(z,P){var x;P&64&&h!==(h=((x=z[6].profile)==null?void 0:x.githubUsername)+"")&&ce(v,h)},d(z){z&&t(n),z&&t(y),z&&t(R)}}}function fy(_){let n,g,m,h,v,b,y,R,T,w;return{c(){n=i("p"),g=l(_[5]),m=u(),h=i("button"),v=i("ion-icon"),b=u(),y=i("span"),R=l("Open Repository"),this.h()},l(E){n=o(E,"P",{class:!0});var k=r(n);g=s(k,_[5]),k.forEach(t),m=d(E),h=o(E,"BUTTON",{class:!0});var I=r(h);v=o(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),b=d(I),y=o(I,"SPAN",{});var z=r(y);R=s(z,"Open Repository"),z.forEach(t),I.forEach(t),this.h()},h(){f(n,"class","feedback svelte-s12rf8"),$(v,"class","icon svelte-s12rf8"),$(v,"name","rocket-sharp"),f(h,"class","svelte-s12rf8")},m(E,k){c(E,n,k),e(n,g),c(E,m,k),c(E,h,k),e(h,v),e(h,b),e(h,y),e(y,R),T||(w=ke(h,"click",_[12]),T=!0)},p(E,k){k&32&&ce(g,E[5])},d(E){E&&t(n),E&&t(m),E&&t(h),T=!1,w()}}}function uy(_){let n;function g(v,b){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?$E:JE}let m=g(_),h=m(_);return{c(){h.c(),n=Io()},l(v){h.l(v),n=Io()},m(v,b){h.m(v,b),c(v,n,b)},p(v,[b]){m===(m=g(v))&&h?h.p(v,b):(h.d(1),h=m(v),h&&(h.c(),h.m(n.parentNode,n)))},i:u_,o:u_,d(v){h.d(v),v&&t(n)}}}function f_(_){window.open(_,"_blank")||window.location.replace(_)}function dy(_,n,g){let{id:m}=n,{spacelabDefaultTitle:h="Spacelab Content"}=n,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=n,b={},y="",R=!1,T="",w;c_.subscribe(O=>{g(6,w=O)}),ME(async()=>{if(typeof(w==null?void 0:w.token)!="undefined"){const O=await fetch(`${n_().serviceUrl}/education/spacelab/${m}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+w.token},mode:"cors"});if(O.status===401){c_.set({}),c_.deleteLocalStorage();return}let C=await O.json();g(2,b=C)}else g(2,b.success=!1,b)});async function E(O){O.preventDefault();const C={};try{const N=await fetch(`${n_().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+w.token},mode:"cors",body:JSON.stringify(C)});if(N.ok)g(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const V=await N.json();g(5,T=V.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),g(5,T="An unexpected error occurred. Please try again later.")}}async function k(O){if(O.preventDefault(),!y.trim()){g(4,R=!0),g(5,T="Please enter a valid GitHub username.");return}g(4,R=!1);const C={github_username:y};try{const N=await fetch(`${n_().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+w.token},mode:"cors",body:JSON.stringify(C)});if(N.ok)g(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const V=await N.json();g(5,T=V.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),g(5,T="An unexpected error occurred. Please try again later.")}}const I=()=>window.open(b.url,"_blank"),z=()=>f_(`https://github.com/${b.github_repo_name}`),P=()=>f_(`https://github.com/${b.github_repo_name}`),x=()=>f_(`https://github.com/${b.github_repo_name}`);function S(){y=this.value,g(3,y)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=O=>{"id"in O&&g(9,m=O.id),"spacelabDefaultTitle"in O&&g(0,h=O.spacelabDefaultTitle),"spacelabDefaultContent"in O&&g(1,v=O.spacelabDefaultContent)},[h,v,b,y,R,T,w,E,k,m,I,z,P,x,S,A]}class py extends Sc{constructor(n){super(),Oc(this,n,dy,uy,Ac,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const hy=_=>({}),PE=_=>({});function my(_){let n;return{c(){n=l(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(g){n=s(g,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(g,m){c(g,n,m)},d(g){g&&t(n)}}}function gy(_){let n,g,m,h,v,b,y,R,T,w,E,k,I,z;const P=_[7]["slider-label"],x=BE(P,_,_[6],PE),S=x||my();return{c(){n=i("div"),g=i("img"),h=u(),v=i("img"),y=u(),R=i("label"),T=i("span"),S&&S.c(),w=u(),E=i("input"),this.h()},l(A){n=o(A,"DIV",{class:!0,style:!0,"data-testid":!0});var O=r(n);g=o(O,"IMG",{src:!0,alt:!0,class:!0}),h=d(O),v=o(O,"IMG",{src:!0,alt:!0,class:!0}),y=d(O),R=o(O,"LABEL",{class:!0});var C=r(R);T=o(C,"SPAN",{class:!0});var N=r(T);S&&S.l(N),N.forEach(t),w=d(C),E=o(C,"INPUT",{type:!0,min:!0,max:!0,class:!0}),C.forEach(t),O.forEach(t),this.h()},h(){Ha(g.src,m=_[0])||f(g,"src",m),f(g,"alt",_[1]),f(g,"class","left-img svelte-1po6qlg"),Ha(v.src,b=_[2])||f(v,"src",b),f(v,"alt",_[3]),f(v,"class","right-img svelte-1po6qlg"),f(T,"class","visually-hidden svelte-1po6qlg"),f(E,"type","range"),f(E,"min","0"),f(E,"max","100"),E.value=_[4],f(E,"class","svelte-1po6qlg"),f(R,"class","svelte-1po6qlg"),f(n,"class","svelte-compare-image-container svelte-1po6qlg"),Ze(n,"--slider-position",_[4]+"%"),f(n,"data-testid","svelte-compare-image")},m(A,O){c(A,n,O),e(n,g),e(n,h),e(n,v),e(n,y),e(n,R),e(R,T),S&&S.m(T,null),e(R,w),e(R,E),k=!0,I||(z=[ke(E,"input",_[5]),ke(E,"change",_[5]),ke(E,"click",vy)],I=!0)},p(A,[O]){(!k||O&1&&!Ha(g.src,m=A[0]))&&f(g,"src",m),(!k||O&2)&&f(g,"alt",A[1]),(!k||O&4&&!Ha(v.src,b=A[2]))&&f(v,"src",b),(!k||O&8)&&f(v,"alt",A[3]),x&&x.p&&(!k||O&64)&&FE(x,P,A,A[6],k?XE(P,A[6],O,hy):YE(A[6]),PE),(!k||O&16)&&(E.value=A[4]),(!k||O&16)&&Ze(n,"--slider-position",A[4]+"%")},i(A){k||(Ce(S,A),k=!0)},o(A){Ne(S,A),k=!1},d(A){A&&t(n),S&&S.d(A),I=!1,ZE(z)}}}function vy(_){_.target.focus()}function _y(_,n,g){let{$$slots:m={},$$scope:h}=n,{imageLeftSrc:v=""}=n,{imageLeftAlt:b=""}=n,{imageRightSrc:y=""}=n,{imageRightAlt:R=""}=n,T=50,w=null;function E(k){w&&cancelAnimationFrame(w),w=requestAnimationFrame(()=>{g(4,T=k.target.valueAsNumber)})}return _.$$set=k=>{"imageLeftSrc"in k&&g(0,v=k.imageLeftSrc),"imageLeftAlt"in k&&g(1,b=k.imageLeftAlt),"imageRightSrc"in k&&g(2,y=k.imageRightSrc),"imageRightAlt"in k&&g(3,R=k.imageRightAlt),"$$scope"in k&&g(6,h=k.$$scope)},[v,b,y,R,T,E,h,m]}class by extends Sc{constructor(n){super(),Oc(this,n,_y,gy,Ac,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function Ey(_){let n;return{c(){n=l(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(g){n=s(g,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(g,m){c(g,n,m)},d(g){g&&t(n)}}}function yy(_){let n,g,m,h;return g=new by({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[Ey]},$$scope:{ctx:_}}}),{c(){n=i("div"),m=i("div"),jt(g.$$.fragment),this.h()},l(v){n=o(v,"DIV",{class:!0});var b=r(n);m=o(b,"DIV",{style:!0});var y=r(m);Wt(g.$$.fragment,y),b.forEach(t),this.h()},h(){Ze(m,"display","contents"),Ze(m,"--handle-size","2.5rem"),Ze(m,"--handle-background-color","rgba(0, 0, 0, 0.6)"),Ze(m,"--handle-background-image",_[4]),Ze(m,"--handle-border-width","0.125rem"),Ze(m,"--slider-color","#ffffff"),Ze(m,"--slider-width","0.125rem"),f(n,"class","image-compare-container svelte-s79nww")},m(v,b){c(v,n,b),e(n,m),Mt(g,m,null),h=!0},p(v,[b]){const y={};b&1&&(y.imageLeftSrc=v[0]),b&2&&(y.imageLeftAlt=v[1]),b&4&&(y.imageRightSrc=v[2]),b&8&&(y.imageRightAlt=v[3]),b&32&&(y.$$scope={dirty:b,ctx:v}),g.$set(y)},i(v){h||(Ce(g.$$.fragment,v),h=!0)},o(v){Ne(g.$$.fragment,v),h=!1},d(v){v&&t(n),Bt(g)}}}function wy(_,n,g){const m=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=n,{imageLeftAlt:v="left"}=n,{imageRightSrc:b="https://via.placeholder.com/512x512/00aaff/ffffff/"}=n,{imageRightAlt:y="right"}=n;return _.$$set=R=>{"imageLeftSrc"in R&&g(0,h=R.imageLeftSrc),"imageLeftAlt"in R&&g(1,v=R.imageLeftAlt),"imageRightSrc"in R&&g(2,b=R.imageRightSrc),"imageRightAlt"in R&&g(3,y=R.imageRightAlt)},[h,v,b,y,m]}class Tc extends Sc{constructor(n){super(),Oc(this,n,wy,yy,Ac,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function ky(_){let n,g;return n=new py({props:{id:Ty,spacelabDefaultTitle:Sy,spacelabDefaultContent:Oy}}),{c(){jt(n.$$.fragment)},l(m){Wt(n.$$.fragment,m)},m(m,h){Mt(n,m,h),g=!0},p:u_,i(m){g||(Ce(n.$$.fragment,m),g=!0)},o(m){Ne(n.$$.fragment,m),g=!1},d(m){Bt(n,m)}}}function Dy(_){let n,g,m,h,v,b,y,R,T,w,E,k,I,z,P,x,S,A,O,C,N,V,M,B,W,q,L,H,Y,U,D,G,Ft,Ua,De,ja,zc,Po,Lc,Ic,_e,qe,Wa,Co,Pc,Cc,Ma,Nc,qc,Ba,xc,Gc,xe,Fa,No,Hc,Uc,Ya,jc,Wc,Xa,Mc,Bc,Ge,Za,qo,Fc,Yc,Ka,Xc,Zc,Va,Kc,Vc,He,Qa,xo,Qc,Jc,Ja,$c,ef,$a,tf,Es,ei,af,ys,ti,of,ws,Yt,ai,rf,ks,Xt,Go,lf,sf,Ds,Zt,Ho,nf,cf,Rs,Kt,Uo,ff,uf,Ts,Vt,jo,df,pf,Ss,Ke,Ve,Wo,hf,Os,Qe,mf,Mo,gf,vf,As,ii,_f,zs,oi,bf,Ls,Ue,Bo,Qt,Fo,Ef,yf,Yo,wf,kf,be,Jt,ri,Df,Rf,li,Tf,Sf,$t,si,Of,Af,ni,zf,Lf,ea,ci,If,Pf,fi,Cf,Nf,ta,ui,qf,xf,di,Gf,Is,Je,$e,Xo,Hf,Ps,et,Uf,Zo,jf,Wf,Cs,pe,Mf,Ko,Bf,Ff,Vo,Yf,Xf,Qo,Zf,Kf,Ns,aa,pi,Jo,Vf,qs,hi,Qf,xs,ia,Gs,tt,at,$o,Jf,Hs,it,$f,oa,eu,tu,Us,Re,au,er,iu,ou,tr,ru,lu,js,Q,ar,mi,su,ir,nu,cu,or,ra,fu,rr,uu,du,pu,lr,X,hu,sr,mu,gu,nr,vu,_u,cr,bu,Eu,fr,yu,wu,ur,ku,Du,dr,Ru,Tu,pr,Su,Ou,hr,Au,zu,mr,J,Lu,gr,Iu,Pu,vr,Cu,Nu,_r,qu,xu,br,Gu,Hu,Er,Uu,ju,yr,Wu,Mu,wr,Bu,Fu,kr,Z,Yu,Dr,Xu,Zu,Rr,Ku,Vu,Tr,Qu,Ju,Sr,$u,ed,Or,td,ad,Ar,id,od,zr,rd,ld,Lr,sd,nd,Ir,gi,cd,Pr,fd,ud,Cr,ot,dd,Nr,pd,hd,qr,md,Ws,Te,gd,xr,vd,_d,Gr,bd,Ed,Ms,la,Bs,rt,lt,Hr,yd,Fs,vi,wd,Ys,he,_i,sa,kd,Dd,Rd,bi,na,Td,Sd,Od,Ei,ca,Ad,zd,Ld,yi,fa,Id,Pd,Xs,st,nt,Ur,Cd,Zs,ct,Nd,jr,qd,xd,Ks,ua,NE=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"filename=%%i"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption_filename=%%~ni.txt"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption=%%~ni"</span>

    rem Extracting the part from the first character to the first comma <span class="token keyword">in</span> the filename
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1,* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!caption!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>

    <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span> <span class="token operator">></span> <span class="token string">"!caption_filename!"</span>
<span class="token punctuation">)</span></code>`,Vs,Se,Gd,Wr,Hd,Ud,Mr,jd,Wd,Qs,da,Md,Br,Bd,Js,ft,Fd,Fr,Yd,Xd,$s,ut,dt,Yr,Zd,en,wi,Kd,tn,pa,ki,Vd,an,pt,ht,Xr,Qd,on,mt,Jd,Zr,$d,ep,rn,ha,qE=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,ln,Di,tp,sn,ma,xE='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',nn,ie,ap,Kr,ip,op,Vr,rp,lp,Qr,sp,np,Jr,cp,fp,$r,up,dp,cn,Oe,pp,el,hp,mp,tl,gp,vp,fn,Ri,_p,un,gt,Ti,bp,al,il,Ep,yp,Si,wp,ol,rl,kp,dn,Oi,Dp,pn,ga,va,h_,hn,vt,_t,ll,Rp,mn,bt,Tp,sl,Sp,Op,gn,je,nl,fe,cl,Ap,zp,fl,Lp,Ip,ul,Pp,Cp,dl,Np,qp,pl,xp,Gp,hl,ue,Ai,Hp,Up,zi,jp,Wp,Li,Mp,Bp,Ii,Fp,Yp,Pi,Xp,vn,Ci,Zp,_n,_a,GE=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"5e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,bn,j,Ni,ba,Kp,ml,Vp,Qp,Jp,$p,qi,Ea,eh,gl,th,ah,ih,oh,xi,ya,rh,vl,lh,sh,nh,ch,Gi,wa,fh,_l,uh,dh,ph,hh,Hi,ka,mh,bl,gh,vh,_h,bh,Ui,Da,Eh,El,yh,wh,kh,Dh,ji,Ra,Rh,yl,Th,Sh,Oh,Ah,Wi,Ta,zh,wl,Lh,Ih,Ph,Ch,Mi,Sa,Nh,kl,qh,xh,Gh,Hh,Bi,Oa,Uh,Dl,jh,Wh,Mh,Bh,Fi,Aa,Fh,Rl,Yh,Xh,Zh,En,Et,yt,Tl,Kh,yn,Yi,Vh,wn,za,kn,wt,kt,Sl,Qh,Dn,Dt,Jh,La,$h,em,Rn,Rt,tm,Ol,am,im,Tn,le,Xi,om,Al,rm,lm,Ia,sm,zl,nm,cm,fm,se,um,Ll,dm,pm,Il,hm,mm,Pl,gm,vm,Cl,_m,bm,Nl,Em,ym,Zi,wm,ql,km,Dm,Tt,Rm,xl,Tm,Sm,Gl,Om,Sn,Ae,Am,Hl,zm,Lm,Ul,Im,Pm,On,me,K,Cm,jl,Nm,qm,Wl,xm,Gm,Ml,Hm,Um,Bl,jm,Wm,Fl,Mm,Bm,Yl,Fm,Ym,Xl,Xm,Zm,Zl,Km,Vm,oe,Qm,Kl,Jm,$m,Vl,eg,tg,Ql,ag,ig,Jl,og,rg,$l,lg,sg,es,ng,cg,ts,fg,ug,as,dg,An,St,Ot,is,pg,zn,ge,Ki,os,hg,mg,gg,Vi,rs,vg,_g,bg,Qi,ls,Eg,yg,wg,Ji,ss,kg,Dg,Ln,$i,Rg,In,Pa,Ca,m_,Pn,At,zt,ns,Tg,Cn,eo,Sg,Nn,ze,Na,Og,cs,Ag,zg,Lg,qa,Ig,fs,Pg,Cg,Ng,us,qg,qn,We,ds,Me,ps,xg,Gg,hs,Hg,Ug,ms,jg,Wg,Ee,Be,to,Mg,Bg,ao,Fg,Yg,io,Xg,Zg,Fe,oo,Kg,Vg,ro,Qg,Jg,lo,$g,ev,Ye,so,tv,av,no,iv,ov,Lt,rv,gs,lv,sv,nv,Xe,co,cv,fv,fo,uv,dv,uo,pv,xn,It,Pt,vs,hv,Gn,po,mv,Hn,ho,gv,Un,xa,Ga,g_,jn,mo,vv,Wn,Mn,Bn;h=new QE({props:{smallImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png",largeImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png",alt:"Action Figure with reg images",largeWidth:"968",largeHeight:"512",smallWidth:"484",smallHeight:"256"}}),A=new Tc({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),ia=new Tc({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),la=new Tc({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),za=new Tc({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let ye=CE&&ky();return{c(){n=i("p"),g=l("I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),m=u(),jt(h.$$.fragment),v=u(),b=i("h2"),y=i("a"),R=i("span"),T=l("What are Regularization Images?"),w=u(),E=i("p"),k=l("Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model.  To further illustrate: regularization images are extra pictures that are used to help Stable Diffusion learn better."),I=u(),z=i("blockquote"),P=i("p"),x=l("Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),S=u(),jt(A.$$.fragment),O=u(),C=i("p"),N=l("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),V=u(),M=i("p"),B=l("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),W=u(),q=i("p"),L=l("In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),H=u(),Y=i("table"),U=i("thead"),D=i("tr"),G=i("th"),Ft=l("Aspect"),Ua=u(),De=i("th"),ja=l("Regularization"),zc=u(),Po=i("th"),Lc=l("No Regularization"),Ic=u(),_e=i("tbody"),qe=i("tr"),Wa=i("td"),Co=i("strong"),Pc=l("Definition"),Cc=u(),Ma=i("td"),Nc=l("Defines skateboard class"),qc=u(),Ba=i("td"),xc=l("No specific class"),Gc=u(),xe=i("tr"),Fa=i("td"),No=i("strong"),Hc=l("Example"),Uc=u(),Ya=i("td"),jc=l("Uses skateboard images"),Wc=u(),Xa=i("td"),Mc=l("No specific images"),Bc=u(),Ge=i("tr"),Za=i("td"),qo=i("strong"),Fc=l("Purpose"),Yc=u(),Ka=i("td"),Xc=l("Prevents drift, focuses on skateboard class"),Zc=u(),Va=i("td"),Kc=l("May drift to unrelated classes"),Vc=u(),He=i("tr"),Qa=i("td"),xo=i("strong"),Qc=l("Overfitting"),Jc=u(),Ja=i("td"),$c=l("Guards against overfitting"),ef=u(),$a=i("td"),tf=l("Higher risk of overfitting"),Es=u(),ei=i("p"),af=l("Regularization helps us make sure our models can correctly classify new data points they were not trained on. We call this ability to work well with new data \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),ys=u(),ti=i("p"),of=l("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well even with the training data. This happens when we limit our model\u2019s ability too much."),ws=u(),Yt=i("blockquote"),ai=i("p"),rf=l("Imagine a graph of points. We want to find a function that fits those points well. We could choose a simple function, which might not fit the points very well. Or we could choose a very complex function that fits the points perfectly, but it might not work well with new points we haven\u2019t seen before. The key is to find the right balance between simplicity and complexity to achieve the best performance."),ks=u(),Xt=i("p"),Go=i("strong"),lf=l("Scenario 1"),sf=l(": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),Ds=u(),Zt=i("p"),Ho=i("strong"),nf=l("Solution"),cf=l(": consider using regularization images to help the model learn more about cat features."),Rs=u(),Kt=i("p"),Uo=i("strong"),ff=l("Scenario 2"),uf=l(": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),Ts=u(),Vt=i("p"),jo=i("strong"),df=l("Solution"),pf=l(": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),Ss=u(),Ke=i("h2"),Ve=i("a"),Wo=i("span"),hf=l("Divergence"),Os=u(),Qe=i("p"),mf=l("Providing too much data leads to "),Mo=i("strong"),gf=l("divergence"),vf=l(". Divergence happens when the model produces random outputs that do not accurately represent the subject\u2019s likeness. This can occur because the model is trying to learn from too many images with inconsistent features, causing it to become confused and produce poor results."),As=u(),ii=i("p"),_f=l("To avoid divergence, we need to ensure the model is focusing on the features that are unique and consistent with your subject.  This starts from carefully curating the dataset by selecting high-quality images that accurately represent the object."),zs=u(),oi=i("p"),bf=l("Training a model to recognize specific objects requires careful consideration of the dataset and the use of regularization techniques to ensure the model is focused on the right features and is not prone to divergence."),Ls=u(),Ue=i("table"),Bo=i("thead"),Qt=i("tr"),Fo=i("th"),Ef=l("Situation"),yf=u(),Yo=i("th"),wf=l("Outcome"),kf=u(),be=i("tbody"),Jt=i("tr"),ri=i("td"),Df=l("Too many regularization images or inconsistent features"),Rf=u(),li=i("td"),Tf=l("Model performance suffers, leading to inaccurate predictions."),Sf=u(),$t=i("tr"),si=i("td"),Of=l("Lack of focus on unique and consistent features"),Af=u(),ni=i("td"),zf=l("Difficulty learning meaningful patterns, impacting prediction accuracy."),Lf=u(),ea=i("tr"),ci=i("td"),If=l("Need for careful dataset curation"),Pf=u(),fi=i("td"),Cf=l("High-quality image selection to avoid confusion and divergence."),Nf=u(),ta=i("tr"),ui=i("td"),qf=l("Importance of regularization techniques"),xf=u(),di=i("td"),Gf=l("Proper use ensures model focuses on relevant features for accurate predictions."),Is=u(),Je=i("h2"),$e=i("a"),Xo=i("span"),Hf=l("Generating Regularization images"),Ps=u(),et=i("p"),Uf=l("Regularization images are generated using model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Zo=i("code"),jf=l("1boy"),Wf=l(")."),Cs=u(),pe=i("p"),Mf=l("According to the Dreambooth technique, "),Ko=i("code"),Bf=l("200"),Ff=l(" regularization images per training image.  For example, if you have "),Vo=i("code"),Yf=l("16"),Xf=l(" images: "),Qo=i("code"),Zf=l("200 * 16 = 3200"),Kf=l(" total regularization images.  When training, the math involved for calculating total steps is:"),Ns=u(),aa=i("blockquote"),pi=i("p"),Jo=i("code"),Vf=l("repeats * training images >= repeats * regularization images"),qs=u(),hi=i("p"),Qf=l("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),xs=u(),jt(ia.$$.fragment),Gs=u(),tt=i("h4"),at=i("a"),$o=i("span"),Jf=l("Generate using Stable Diffusion web UI"),Hs=u(),it=i("p"),$f=l("We\u2019re going to use "),oa=i("a"),eu=l("Stable Diffusion web UI"),tu=l(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Us=u(),Re=i("p"),au=l("We\u2019re going to use the "),er=i("code"),iu=l("X/Y/Z plot"),ou=l(" script to use "),tr=i("code"),ru=l("Prompt Search & Replace"),lu=l(" to dynamically build a prompt that will generate hundreds of regularization images."),js=u(),Q=i("ol"),ar=i("li"),mi=i("p"),su=l("Select the text 2 image tab.  Enter a generic prompt "),ir=i("code"),nu=l("princeadam, portrait, looking_at_viewer, forest"),cu=u(),or=i("li"),ra=i("p"),fu=l("In generation parameters and select the "),rr=i("code"),uu=l("X/Y/Z plot"),du=l(" script."),pu=u(),lr=i("li"),X=i("p"),hu=l("Select the "),sr=i("code"),mu=l("X"),gu=l(" parameter and "),nr=i("code"),vu=l("Prompt SR"),_u=l(" for Prompt Replace.  We\u2019re going to replace "),cr=i("code"),bu=l("portrait"),Eu=l(" with different camera angle tags: "),fr=i("code"),yu=l("close-up"),wu=l(", "),ur=i("code"),ku=l("upper_body"),Du=l(", "),dr=i("code"),Ru=l("from_below"),Tu=l(", "),pr=i("code"),Su=l("from_above"),Ou=l(", "),hr=i("code"),Au=l("dutch_angle"),zu=u(),mr=i("li"),J=i("p"),Lu=l("Select the "),gr=i("code"),Iu=l("Y"),Pu=l(" parameter and "),vr=i("code"),Cu=l("Prompt SR"),Nu=l(" for Prompt Replace.  Replace "),_r=i("code"),qu=l("looking_at_viewer"),xu=l(": "),br=i("code"),Gu=l("looking_away"),Hu=l(", "),Er=i("code"),Uu=l("looking_to_the_side"),ju=l(", "),yr=i("code"),Wu=l("looking_ahead"),Mu=l(", "),wr=i("code"),Bu=l("looking_down"),Fu=u(),kr=i("li"),Z=i("p"),Yu=l("Select the "),Dr=i("code"),Xu=l("Z"),Zu=l(" parameter and "),Rr=i("code"),Ku=l("Prompt SR"),Vu=l(" for Prompt Replace. Replace "),Tr=i("code"),Qu=l("forest"),Ju=l(" with a vareity of locatinos: "),Sr=i("code"),$u=l("castle"),ed=l(", "),Or=i("code"),td=l("mountain"),ad=l(", "),Ar=i("code"),id=l("cave"),od=l(", "),zr=i("code"),rd=l("farm"),ld=l(", "),Lr=i("code"),sd=l("ocean"),nd=u(),Ir=i("li"),gi=i("p"),cd=l("Select a fast sampler like "),Pr=i("code"),fd=l("DPM2 KARRAS"),ud=u(),Cr=i("li"),ot=i("p"),dd=l("CFG Scale set to "),Nr=i("code"),pd=l("7"),hd=l(" and Steps to "),qr=i("code"),md=l("20"),Ws=u(),Te=i("p"),gd=l("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),xr=i("code"),vd=l("150"),_d=l(" - "),Gr=i("code"),bd=l("200"),Ed=l(" and keep in mind we can add and remove as we try different training settings with different output."),Ms=u(),jt(la.$$.fragment),Bs=u(),rt=i("h4"),lt=i("a"),Hr=i("span"),yd=l("Download images"),Fs=u(),vi=i("p"),wd=l("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Ys=u(),he=i("ul"),_i=i("li"),sa=i("a"),kd=l("3ee Games regularization images"),Dd=l(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),Rd=u(),bi=i("li"),na=i("a"),Td=l("Pre-Rendered Regularization Images"),Sd=l(": Includes 1500 regularization images."),Od=u(),Ei=i("li"),ca=i("a"),Ad=l("Stable Diffusion 1.5 Regularization Images"),zd=l(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),Ld=u(),yi=i("li"),fa=i("a"),Id=l("Aitrepreneur SDXL image set"),Pd=l(": a large image set generated with Stable Diffusion SDXL."),Xs=u(),st=i("h4"),nt=i("a"),Ur=i("span"),Cd=l("Captioning Regularization images"),Zs=u(),ct=i("p"),Nd=l("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),jr=i("code"),qd=l("txt"),xd=l(" files with a shell script:"),Ks=u(),ua=i("pre"),Vs=u(),Se=i("p"),Gd=l("Save this file as "),Wr=i("code"),Hd=l("filename2txt.bat"),Ud=l(" and place it into the regularization images directory and run: "),Mr=i("code"),jd=l(".\\filename2txt.bat"),Wd=l(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Qs=u(),da=i("p"),Md=l("Example filename: "),Br=i("code"),Bd=l("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),Js=u(),ft=i("p"),Fd=l("Output: "),Fr=i("code"),Yd=l("aburbres,princeadam,1boy,close-up,purple_vest"),Xd=l(" saved in a text file with the same name as image."),$s=u(),ut=i("h2"),dt=i("a"),Yr=i("span"),Zd=l("Training a LoRA"),en=u(),wi=i("p"),Kd=l("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images."),tn=u(),pa=i("blockquote"),ki=i("p"),Vd=l("Learning how to train a LoRA is a completely different subject all on its own.  Learn more about LoRA training: LINK HERE."),an=u(),pt=i("h3"),ht=i("a"),Xr=i("span"),Qd=l("Directory setup"),on=u(),mt=i("p"),Jd=l("In your configuration json, use "),Zr=i("code"),$d=l("reg_data_dir"),ep=l(" to point to the directory with your regularization images:"),rn=u(),ha=i("pre"),ln=u(),Di=i("p"),tp=l("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),sn=u(),ma=i("pre"),nn=u(),ie=i("p"),ap=l("Specify the "),Kr=i("code"),ip=l("number of iterations"),op=l(" so that the number of iterations of training images "),Vr=i("code"),rp=l("x"),lp=l(" =  the number of training images "),Qr=i("code"),sp=l("\u2265"),np=l(" the number of iterations of regularization images "),Jr=i("code"),cp=l("x"),fp=l(` the number of regularization images .
(The number of data in one epoch is \u201Cnumber of repetitions of training images `),$r=i("code"),up=l("x"),dp=l(" number of training images\u201D. If the number of regularization images is more than that, the remaining regularization images will not be used.)"),cn=u(),Oe=i("p"),pp=l("Create folders in the training image folder with the format "),el=i("code"),hp=l("<repetition count>_<class>"),mp=l(" multiple times, and similarly create folders in the regularization image folder with the format "),tl=i("code"),gp=l("<repetition count>_<class>"),vp=l("."),fn=u(),Ri=i("p"),_p=l("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),un=u(),gt=i("ul"),Ti=i("li"),bp=l("train_data_dir"),al=i("ul"),il=i("li"),Ep=l("10_princeadam"),yp=u(),Si=i("li"),wp=l("reg_dir"),ol=i("ul"),rl=i("li"),kp=l("1_1boy"),dn=u(),Oi=i("p"),Dp=l("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),pn=u(),ga=i("p"),va=i("img"),hn=u(),vt=i("h3"),_t=i("a"),ll=i("span"),Rp=l("Training Settings"),mn=u(),bt=i("p"),Tp=l("The training setup we\u2019re going to use is:  "),sl=i("code"),Sp=l("Number of images * repeats * epoch / batch size = total steps"),Op=l(".  Based on our training data, we have 45 images and going for 4500 steps:"),gn=u(),je=i("table"),nl=i("thead"),fe=i("tr"),cl=i("th"),Ap=l("Number of Images"),zp=u(),fl=i("th"),Lp=l("Repeats"),Ip=u(),ul=i("th"),Pp=l("Epochs"),Cp=u(),dl=i("th"),Np=l("Batch Size"),qp=u(),pl=i("th"),xp=l("Total Steps"),Gp=u(),hl=i("tbody"),ue=i("tr"),Ai=i("td"),Hp=l("45"),Up=u(),zi=i("td"),jp=l("10"),Wp=u(),Li=i("td"),Mp=l("20"),Bp=u(),Ii=i("td"),Fp=l("2"),Yp=u(),Pi=i("td"),Xp=l("4500"),vn=u(),Ci=i("p"),Zp=l("Now let\u2019s focus on these training settings:"),_n=u(),_a=i("pre"),bn=u(),j=i("ul"),Ni=i("li"),ba=i("strong"),Kp=l("Learning Rate ("),ml=i("code"),Vp=l("learning_rate"),Qp=l(")"),Jp=l(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),$p=u(),qi=i("li"),Ea=i("strong"),eh=l("Text Encoder Learning Rate ("),gl=i("code"),th=l("text_encoder_lr"),ah=l(")"),ih=l(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),oh=u(),xi=i("li"),ya=i("strong"),rh=l("UNet Learning Rate ("),vl=i("code"),lh=l("unet_lr"),sh=l(")"),nh=l(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),ch=u(),Gi=i("li"),wa=i("strong"),fh=l("Learning Rate Scheduler ("),_l=i("code"),uh=l("lr_scheduler"),dh=l(")"),ph=l(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),hh=u(),Hi=i("li"),ka=i("strong"),mh=l("Number of Cycles in Learning Rate Scheduler ("),bl=i("code"),gh=l("lr_scheduler_num_cycles"),vh=l(")"),_h=l(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),bh=u(),Ui=i("li"),Da=i("strong"),Eh=l("Network Dimension ("),El=i("code"),yh=l("network_dim"),wh=l(")"),kh=l(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Dh=u(),ji=i("li"),Ra=i("strong"),Rh=l("Network Alpha ("),yl=i("code"),Th=l("network_alpha"),Sh=l(")"),Oh=l(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Ah=u(),Wi=i("li"),Ta=i("strong"),zh=l("Clip Skip ("),wl=i("code"),Lh=l("clip_skip"),Ih=l(")"),Ph=l(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Ch=u(),Mi=i("li"),Sa=i("strong"),Nh=l("Max Token Length ("),kl=i("code"),qh=l("max_token_length"),xh=l(")"),Gh=l(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Hh=u(),Bi=i("li"),Oa=i("strong"),Uh=l("Noise Offset ("),Dl=i("code"),jh=l("noise_offset"),Wh=l(")"),Mh=l(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Bh=u(),Fi=i("li"),Aa=i("strong"),Fh=l("Regularization Data Directory ("),Rl=i("code"),Yh=l("reg_data_dir"),Xh=l(")"),Zh=l(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),En=u(),Et=i("h3"),yt=i("a"),Tl=i("span"),Kh=l("Fine Tuning"),yn=u(),Yi=i("p"),Vh=l("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),wn=u(),jt(za.$$.fragment),kn=u(),wt=i("h4"),kt=i("a"),Sl=i("span"),Qh=l("Workflow with Auto1111 WebUI"),Dn=u(),Dt=i("p"),Jh=l("We\u2019re going to use "),La=i("a"),$h=l("Stable Diffusion web UI"),em=l(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Rn=u(),Rt=i("p"),tm=l("We\u2019re going to use the "),Ol=i("code"),am=l("X/Y/Z plot"),im=l(" script to compare different epochs."),Tn=u(),le=i("ul"),Xi=i("li"),om=l("Select the text 2 image tab.  Enter a generic prompt "),Al=i("code"),rm=l("princeadam, portrait, <princeadam0001:0.7>"),lm=u(),Ia=i("li"),sm=l("In generation parameters and select the "),zl=i("code"),nm=l("X/Y/Z plot"),cm=l(" script."),fm=u(),se=i("li"),um=l("Select "),Ll=i("code"),dm=l("Prompt SR"),pm=l(" for Prompt Replace.  We\u2019re going to replace "),Il=i("code"),hm=l("<princeadam0001:0.7>"),mm=l(" with different epoch: "),Pl=i("code"),gm=l("<princeadam0001:0.7>"),vm=l(", "),Cl=i("code"),_m=l("<princeadam0003:0.7>"),bm=l(", "),Nl=i("code"),Em=l("<princeadam0023:0.7>"),ym=u(),Zi=i("li"),wm=l("Select a fast sampler like "),ql=i("code"),km=l("DPM2 KARRAS"),Dm=u(),Tt=i("li"),Rm=l("CFG Scale set to "),xl=i("code"),Tm=l("7"),Sm=l(" and Steps to "),Gl=i("code"),Om=l("20"),Sn=u(),Ae=i("p"),Am=l("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Hl=i("code"),zm=l("network_dim"),Lm=l(" and "),Ul=i("code"),Im=l("network_alpha"),Pm=l("?  Those are the settings that directly control the output strength mentioned earlier."),On=u(),me=i("ul"),K=i("li"),Cm=l("Select "),jl=i("code"),Nm=l("Prompt SR"),qm=l(" for Prompt Replace.  We\u2019re going to replace the weights "),Wl=i("code"),xm=l("<princeadam12:0.4>"),Gm=l(","),Ml=i("code"),Hm=l("<princeadam12:0.5>"),Um=l(", "),Bl=i("code"),jm=l("<princeadam12:0.6>"),Wm=l(", "),Fl=i("code"),Mm=l("<princeadam12:0.7>"),Bm=l(", "),Yl=i("code"),Fm=l("<princeadam12:0.8>"),Ym=l(", "),Xl=i("code"),Xm=l("<princeadam12:0.9>"),Zm=l(", "),Zl=i("code"),Km=l("<princeadam12:1.0>"),Vm=u(),oe=i("li"),Qm=l("Use another "),Kl=i("code"),Jm=l("Prompt SR"),$m=l(" to generate a variety of different angles: Select "),Vl=i("code"),eg=l("Prompt SR"),tg=l(" for Prompt Replace.  Replace "),Ql=i("code"),ag=l("upper_body"),ig=l(" with different camera angles: "),Jl=i("code"),og=l("from_below"),rg=l(", "),$l=i("code"),lg=l("from_above"),sg=l(", "),es=i("code"),ng=l("close_up"),cg=u(),ts=i("li"),fg=l("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),ug=u(),as=i("li"),dg=l("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),An=u(),St=i("h4"),Ot=i("a"),is=i("span"),pg=l("Issues to look for"),zn=u(),ge=i("ul"),Ki=i("li"),os=i("strong"),hg=l("Undercooked:"),mg=l(" Lacks output, adjust unet learning rate or extend training duration."),gg=u(),Vi=i("li"),rs=i("strong"),vg=l("Overcooked:"),_g=l(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),bg=u(),Qi=i("li"),ls=i("strong"),Eg=l("Overfit:"),yg=l(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),wg=u(),Ji=i("li"),ss=i("strong"),kg=l("Mismatched:"),Dg=l(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Ln=u(),$i=i("p"),Rg=l("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),In=u(),Pa=i("p"),Ca=i("img"),Pn=u(),At=i("h4"),zt=i("a"),ns=i("span"),Tg=l("Troubleshooting"),Cn=u(),eo=i("p"),Sg=l("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),Nn=u(),ze=i("ul"),Na=i("li"),Og=l("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),cs=i("code"),Ag=l("200"),zg=l(" regularization images per training image."),Lg=u(),qa=i("li"),Ig=l("Repeats of regularization images, but may overfit more.  Increasing the "),fs=i("code"),Pg=l("repetition_count"),Cg=l(" will cycle through the images more but the results may have results that overfit the model."),Ng=u(),us=i("li"),qg=l("Create more regularization images without increasing repeats will help with the overfitting."),qn=u(),We=i("table"),ds=i("thead"),Me=i("tr"),ps=i("th"),xg=l("Issue"),Gg=u(),hs=i("th"),Hg=l("Situation"),Ug=u(),ms=i("th"),jg=l("Recommendation"),Wg=u(),Ee=i("tbody"),Be=i("tr"),to=i("td"),Mg=l("Varying quality"),Bg=u(),ao=i("td"),Fg=l("Results differ from expectations"),Yg=u(),io=i("td"),Xg=l("Evaluate the quality and quantity of regularization images. Adjust the number and selection and check for better results."),Zg=u(),Fe=i("tr"),oo=i("td"),Kg=l("Inadequate regularization for input data"),Vg=u(),ro=i("td"),Qg=l("Lower input images, less regularization needed"),Jg=u(),lo=i("td"),$g=l("Consider reducing the number of input images or increasing the quantity and diversity of regularization images."),ev=u(),Ye=i("tr"),so=i("td"),tv=l("Overfitting due to repetition"),av=u(),no=i("td"),iv=l("Repeats of regularization images, risk of overfitting"),ov=u(),Lt=i("td"),rv=l("Adjust the "),gs=i("code"),lv=l("repetition_count"),sv=l(" to balance cycling through images without overfitting. Monitor results for improvements."),nv=u(),Xe=i("tr"),co=i("td"),cv=l("Mitigate overfitting while increasing diversity"),fv=u(),fo=i("td"),uv=l("Create more regularization images without repeats"),dv=u(),uo=i("td"),pv=l("Generate additional regularization images without increasing repetitions. Enhance model adaptability without overfitting."),xn=u(),It=i("h3"),Pt=i("a"),vs=i("span"),hv=l("Results"),Gn=u(),po=i("p"),mv=l("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),Hn=u(),ho=i("p"),gv=l("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),Un=u(),xa=i("p"),Ga=i("img"),jn=u(),mo=i("p"),vv=l("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),Wn=u(),ye&&ye.c(),Mn=Io(),this.h()},l(a){n=o(a,"P",{});var p=r(n);g=s(p,"I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),p.forEach(t),m=d(a),Wt(h.$$.fragment,a),v=d(a),b=o(a,"H2",{id:!0});var _v=r(b);y=o(_v,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var v_=r(y);R=o(v_,"SPAN",{class:!0}),r(R).forEach(t),v_.forEach(t),T=s(_v,"What are Regularization Images?"),_v.forEach(t),w=d(a),E=o(a,"P",{});var __=r(E);k=s(__,"Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model.  To further illustrate: regularization images are extra pictures that are used to help Stable Diffusion learn better."),__.forEach(t),I=d(a),z=o(a,"BLOCKQUOTE",{class:!0});var b_=r(z);P=o(b_,"P",{class:!0});var E_=r(P);x=s(E_,"Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),E_.forEach(t),b_.forEach(t),S=d(a),Wt(A.$$.fragment,a),O=d(a),C=o(a,"P",{});var y_=r(C);N=s(y_,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),y_.forEach(t),V=d(a),M=o(a,"P",{});var w_=r(M);B=s(w_,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),w_.forEach(t),W=d(a),q=o(a,"P",{});var k_=r(q);L=s(k_,"In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),k_.forEach(t),H=d(a),Y=o(a,"TABLE",{class:!0});var Fn=r(Y);U=o(Fn,"THEAD",{});var D_=r(U);D=o(D_,"TR",{});var go=r(D);G=o(go,"TH",{});var R_=r(G);Ft=s(R_,"Aspect"),R_.forEach(t),Ua=d(go),De=o(go,"TH",{});var T_=r(De);ja=s(T_,"Regularization"),T_.forEach(t),zc=d(go),Po=o(go,"TH",{});var S_=r(Po);Lc=s(S_,"No Regularization"),S_.forEach(t),go.forEach(t),D_.forEach(t),Ic=d(Fn),_e=o(Fn,"TBODY",{});var Ct=r(_e);qe=o(Ct,"TR",{});var vo=r(qe);Wa=o(vo,"TD",{class:!0});var O_=r(Wa);Co=o(O_,"STRONG",{});var A_=r(Co);Pc=s(A_,"Definition"),A_.forEach(t),O_.forEach(t),Cc=d(vo),Ma=o(vo,"TD",{class:!0});var z_=r(Ma);Nc=s(z_,"Defines skateboard class"),z_.forEach(t),qc=d(vo),Ba=o(vo,"TD",{class:!0});var L_=r(Ba);xc=s(L_,"No specific class"),L_.forEach(t),vo.forEach(t),Gc=d(Ct),xe=o(Ct,"TR",{});var _o=r(xe);Fa=o(_o,"TD",{class:!0});var I_=r(Fa);No=o(I_,"STRONG",{});var P_=r(No);Hc=s(P_,"Example"),P_.forEach(t),I_.forEach(t),Uc=d(_o),Ya=o(_o,"TD",{class:!0});var C_=r(Ya);jc=s(C_,"Uses skateboard images"),C_.forEach(t),Wc=d(_o),Xa=o(_o,"TD",{class:!0});var N_=r(Xa);Mc=s(N_,"No specific images"),N_.forEach(t),_o.forEach(t),Bc=d(Ct),Ge=o(Ct,"TR",{});var bo=r(Ge);Za=o(bo,"TD",{class:!0});var q_=r(Za);qo=o(q_,"STRONG",{});var x_=r(qo);Fc=s(x_,"Purpose"),x_.forEach(t),q_.forEach(t),Yc=d(bo),Ka=o(bo,"TD",{class:!0});var G_=r(Ka);Xc=s(G_,"Prevents drift, focuses on skateboard class"),G_.forEach(t),Zc=d(bo),Va=o(bo,"TD",{class:!0});var H_=r(Va);Kc=s(H_,"May drift to unrelated classes"),H_.forEach(t),bo.forEach(t),Vc=d(Ct),He=o(Ct,"TR",{});var Eo=r(He);Qa=o(Eo,"TD",{class:!0});var U_=r(Qa);xo=o(U_,"STRONG",{});var j_=r(xo);Qc=s(j_,"Overfitting"),j_.forEach(t),U_.forEach(t),Jc=d(Eo),Ja=o(Eo,"TD",{class:!0});var W_=r(Ja);$c=s(W_,"Guards against overfitting"),W_.forEach(t),ef=d(Eo),$a=o(Eo,"TD",{class:!0});var M_=r($a);tf=s(M_,"Higher risk of overfitting"),M_.forEach(t),Eo.forEach(t),Ct.forEach(t),Fn.forEach(t),Es=d(a),ei=o(a,"P",{});var B_=r(ei);af=s(B_,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. We call this ability to work well with new data \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),B_.forEach(t),ys=d(a),ti=o(a,"P",{});var F_=r(ti);of=s(F_,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well even with the training data. This happens when we limit our model\u2019s ability too much."),F_.forEach(t),ws=d(a),Yt=o(a,"BLOCKQUOTE",{class:!0});var Y_=r(Yt);ai=o(Y_,"P",{class:!0});var X_=r(ai);rf=s(X_,"Imagine a graph of points. We want to find a function that fits those points well. We could choose a simple function, which might not fit the points very well. Or we could choose a very complex function that fits the points perfectly, but it might not work well with new points we haven\u2019t seen before. The key is to find the right balance between simplicity and complexity to achieve the best performance."),X_.forEach(t),Y_.forEach(t),ks=d(a),Xt=o(a,"P",{});var bv=r(Xt);Go=o(bv,"STRONG",{});var Z_=r(Go);lf=s(Z_,"Scenario 1"),Z_.forEach(t),sf=s(bv,": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),bv.forEach(t),Ds=d(a),Zt=o(a,"P",{});var Ev=r(Zt);Ho=o(Ev,"STRONG",{});var K_=r(Ho);nf=s(K_,"Solution"),K_.forEach(t),cf=s(Ev,": consider using regularization images to help the model learn more about cat features."),Ev.forEach(t),Rs=d(a),Kt=o(a,"P",{});var yv=r(Kt);Uo=o(yv,"STRONG",{});var V_=r(Uo);ff=s(V_,"Scenario 2"),V_.forEach(t),uf=s(yv,": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),yv.forEach(t),Ts=d(a),Vt=o(a,"P",{});var wv=r(Vt);jo=o(wv,"STRONG",{});var Q_=r(jo);df=s(Q_,"Solution"),Q_.forEach(t),pf=s(wv,": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),wv.forEach(t),Ss=d(a),Ke=o(a,"H2",{id:!0});var kv=r(Ke);Ve=o(kv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var J_=r(Ve);Wo=o(J_,"SPAN",{class:!0}),r(Wo).forEach(t),J_.forEach(t),hf=s(kv,"Divergence"),kv.forEach(t),Os=d(a),Qe=o(a,"P",{});var Yn=r(Qe);mf=s(Yn,"Providing too much data leads to "),Mo=o(Yn,"STRONG",{});var $_=r(Mo);gf=s($_,"divergence"),$_.forEach(t),vf=s(Yn,". Divergence happens when the model produces random outputs that do not accurately represent the subject\u2019s likeness. This can occur because the model is trying to learn from too many images with inconsistent features, causing it to become confused and produce poor results."),Yn.forEach(t),As=d(a),ii=o(a,"P",{});var e1=r(ii);_f=s(e1,"To avoid divergence, we need to ensure the model is focusing on the features that are unique and consistent with your subject.  This starts from carefully curating the dataset by selecting high-quality images that accurately represent the object."),e1.forEach(t),zs=d(a),oi=o(a,"P",{});var t1=r(oi);bf=s(t1,"Training a model to recognize specific objects requires careful consideration of the dataset and the use of regularization techniques to ensure the model is focused on the right features and is not prone to divergence."),t1.forEach(t),Ls=d(a),Ue=o(a,"TABLE",{class:!0});var Xn=r(Ue);Bo=o(Xn,"THEAD",{});var a1=r(Bo);Qt=o(a1,"TR",{});var Zn=r(Qt);Fo=o(Zn,"TH",{});var i1=r(Fo);Ef=s(i1,"Situation"),i1.forEach(t),yf=d(Zn),Yo=o(Zn,"TH",{});var o1=r(Yo);wf=s(o1,"Outcome"),o1.forEach(t),Zn.forEach(t),a1.forEach(t),kf=d(Xn),be=o(Xn,"TBODY",{});var Nt=r(be);Jt=o(Nt,"TR",{});var Kn=r(Jt);ri=o(Kn,"TD",{class:!0});var r1=r(ri);Df=s(r1,"Too many regularization images or inconsistent features"),r1.forEach(t),Rf=d(Kn),li=o(Kn,"TD",{class:!0});var l1=r(li);Tf=s(l1,"Model performance suffers, leading to inaccurate predictions."),l1.forEach(t),Kn.forEach(t),Sf=d(Nt),$t=o(Nt,"TR",{});var Vn=r($t);si=o(Vn,"TD",{class:!0});var s1=r(si);Of=s(s1,"Lack of focus on unique and consistent features"),s1.forEach(t),Af=d(Vn),ni=o(Vn,"TD",{class:!0});var n1=r(ni);zf=s(n1,"Difficulty learning meaningful patterns, impacting prediction accuracy."),n1.forEach(t),Vn.forEach(t),Lf=d(Nt),ea=o(Nt,"TR",{});var Qn=r(ea);ci=o(Qn,"TD",{class:!0});var c1=r(ci);If=s(c1,"Need for careful dataset curation"),c1.forEach(t),Pf=d(Qn),fi=o(Qn,"TD",{class:!0});var f1=r(fi);Cf=s(f1,"High-quality image selection to avoid confusion and divergence."),f1.forEach(t),Qn.forEach(t),Nf=d(Nt),ta=o(Nt,"TR",{});var Jn=r(ta);ui=o(Jn,"TD",{class:!0});var u1=r(ui);qf=s(u1,"Importance of regularization techniques"),u1.forEach(t),xf=d(Jn),di=o(Jn,"TD",{class:!0});var d1=r(di);Gf=s(d1,"Proper use ensures model focuses on relevant features for accurate predictions."),d1.forEach(t),Jn.forEach(t),Nt.forEach(t),Xn.forEach(t),Is=d(a),Je=o(a,"H2",{id:!0});var Dv=r(Je);$e=o(Dv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var p1=r($e);Xo=o(p1,"SPAN",{class:!0}),r(Xo).forEach(t),p1.forEach(t),Hf=s(Dv,"Generating Regularization images"),Dv.forEach(t),Ps=d(a),et=o(a,"P",{});var $n=r(et);Uf=s($n,"Regularization images are generated using model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Zo=o($n,"CODE",{});var h1=r(Zo);jf=s(h1,"1boy"),h1.forEach(t),Wf=s($n,")."),$n.forEach(t),Cs=d(a),pe=o(a,"P",{});var qt=r(pe);Mf=s(qt,"According to the Dreambooth technique, "),Ko=o(qt,"CODE",{});var m1=r(Ko);Bf=s(m1,"200"),m1.forEach(t),Ff=s(qt," regularization images per training image.  For example, if you have "),Vo=o(qt,"CODE",{});var g1=r(Vo);Yf=s(g1,"16"),g1.forEach(t),Xf=s(qt," images: "),Qo=o(qt,"CODE",{});var v1=r(Qo);Zf=s(v1,"200 * 16 = 3200"),v1.forEach(t),Kf=s(qt," total regularization images.  When training, the math involved for calculating total steps is:"),qt.forEach(t),Ns=d(a),aa=o(a,"BLOCKQUOTE",{class:!0});var _1=r(aa);pi=o(_1,"P",{class:!0});var b1=r(pi);Jo=o(b1,"CODE",{});var E1=r(Jo);Vf=s(E1,"repeats * training images >= repeats * regularization images"),E1.forEach(t),b1.forEach(t),_1.forEach(t),qs=d(a),hi=o(a,"P",{});var y1=r(hi);Qf=s(y1,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),y1.forEach(t),xs=d(a),Wt(ia.$$.fragment,a),Gs=d(a),tt=o(a,"H4",{id:!0});var Rv=r(tt);at=o(Rv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w1=r(at);$o=o(w1,"SPAN",{class:!0}),r($o).forEach(t),w1.forEach(t),Jf=s(Rv,"Generate using Stable Diffusion web UI"),Rv.forEach(t),Hs=d(a),it=o(a,"P",{});var ec=r(it);$f=s(ec,"We\u2019re going to use "),oa=o(ec,"A",{href:!0,rel:!0});var k1=r(oa);eu=s(k1,"Stable Diffusion web UI"),k1.forEach(t),tu=s(ec," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),ec.forEach(t),Us=d(a),Re=o(a,"P",{});var yo=r(Re);au=s(yo,"We\u2019re going to use the "),er=o(yo,"CODE",{});var D1=r(er);iu=s(D1,"X/Y/Z plot"),D1.forEach(t),ou=s(yo," script to use "),tr=o(yo,"CODE",{});var R1=r(tr);ru=s(R1,"Prompt Search & Replace"),R1.forEach(t),lu=s(yo," to dynamically build a prompt that will generate hundreds of regularization images."),yo.forEach(t),js=d(a),Q=o(a,"OL",{});var ne=r(Q);ar=o(ne,"LI",{});var T1=r(ar);mi=o(T1,"P",{});var Tv=r(mi);su=s(Tv,"Select the text 2 image tab.  Enter a generic prompt "),ir=o(Tv,"CODE",{});var S1=r(ir);nu=s(S1,"princeadam, portrait, looking_at_viewer, forest"),S1.forEach(t),Tv.forEach(t),T1.forEach(t),cu=d(ne),or=o(ne,"LI",{});var O1=r(or);ra=o(O1,"P",{});var tc=r(ra);fu=s(tc,"In generation parameters and select the "),rr=o(tc,"CODE",{});var A1=r(rr);uu=s(A1,"X/Y/Z plot"),A1.forEach(t),du=s(tc," script."),tc.forEach(t),O1.forEach(t),pu=d(ne),lr=o(ne,"LI",{});var z1=r(lr);X=o(z1,"P",{});var ee=r(X);hu=s(ee,"Select the "),sr=o(ee,"CODE",{});var L1=r(sr);mu=s(L1,"X"),L1.forEach(t),gu=s(ee," parameter and "),nr=o(ee,"CODE",{});var I1=r(nr);vu=s(I1,"Prompt SR"),I1.forEach(t),_u=s(ee," for Prompt Replace.  We\u2019re going to replace "),cr=o(ee,"CODE",{});var P1=r(cr);bu=s(P1,"portrait"),P1.forEach(t),Eu=s(ee," with different camera angle tags: "),fr=o(ee,"CODE",{});var C1=r(fr);yu=s(C1,"close-up"),C1.forEach(t),wu=s(ee,", "),ur=o(ee,"CODE",{});var N1=r(ur);ku=s(N1,"upper_body"),N1.forEach(t),Du=s(ee,", "),dr=o(ee,"CODE",{});var q1=r(dr);Ru=s(q1,"from_below"),q1.forEach(t),Tu=s(ee,", "),pr=o(ee,"CODE",{});var x1=r(pr);Su=s(x1,"from_above"),x1.forEach(t),Ou=s(ee,", "),hr=o(ee,"CODE",{});var G1=r(hr);Au=s(G1,"dutch_angle"),G1.forEach(t),ee.forEach(t),z1.forEach(t),zu=d(ne),mr=o(ne,"LI",{});var H1=r(mr);J=o(H1,"P",{});var re=r(J);Lu=s(re,"Select the "),gr=o(re,"CODE",{});var U1=r(gr);Iu=s(U1,"Y"),U1.forEach(t),Pu=s(re," parameter and "),vr=o(re,"CODE",{});var j1=r(vr);Cu=s(j1,"Prompt SR"),j1.forEach(t),Nu=s(re," for Prompt Replace.  Replace "),_r=o(re,"CODE",{});var W1=r(_r);qu=s(W1,"looking_at_viewer"),W1.forEach(t),xu=s(re,": "),br=o(re,"CODE",{});var M1=r(br);Gu=s(M1,"looking_away"),M1.forEach(t),Hu=s(re,", "),Er=o(re,"CODE",{});var B1=r(Er);Uu=s(B1,"looking_to_the_side"),B1.forEach(t),ju=s(re,", "),yr=o(re,"CODE",{});var F1=r(yr);Wu=s(F1,"looking_ahead"),F1.forEach(t),Mu=s(re,", "),wr=o(re,"CODE",{});var Y1=r(wr);Bu=s(Y1,"looking_down"),Y1.forEach(t),re.forEach(t),H1.forEach(t),Fu=d(ne),kr=o(ne,"LI",{});var X1=r(kr);Z=o(X1,"P",{});var te=r(Z);Yu=s(te,"Select the "),Dr=o(te,"CODE",{});var Z1=r(Dr);Xu=s(Z1,"Z"),Z1.forEach(t),Zu=s(te," parameter and "),Rr=o(te,"CODE",{});var K1=r(Rr);Ku=s(K1,"Prompt SR"),K1.forEach(t),Vu=s(te," for Prompt Replace. Replace "),Tr=o(te,"CODE",{});var V1=r(Tr);Qu=s(V1,"forest"),V1.forEach(t),Ju=s(te," with a vareity of locatinos: "),Sr=o(te,"CODE",{});var Q1=r(Sr);$u=s(Q1,"castle"),Q1.forEach(t),ed=s(te,", "),Or=o(te,"CODE",{});var J1=r(Or);td=s(J1,"mountain"),J1.forEach(t),ad=s(te,", "),Ar=o(te,"CODE",{});var $1=r(Ar);id=s($1,"cave"),$1.forEach(t),od=s(te,", "),zr=o(te,"CODE",{});var e2=r(zr);rd=s(e2,"farm"),e2.forEach(t),ld=s(te,", "),Lr=o(te,"CODE",{});var t2=r(Lr);sd=s(t2,"ocean"),t2.forEach(t),te.forEach(t),X1.forEach(t),nd=d(ne),Ir=o(ne,"LI",{});var a2=r(Ir);gi=o(a2,"P",{});var Sv=r(gi);cd=s(Sv,"Select a fast sampler like "),Pr=o(Sv,"CODE",{});var i2=r(Pr);fd=s(i2,"DPM2 KARRAS"),i2.forEach(t),Sv.forEach(t),a2.forEach(t),ud=d(ne),Cr=o(ne,"LI",{});var o2=r(Cr);ot=o(o2,"P",{});var _s=r(ot);dd=s(_s,"CFG Scale set to "),Nr=o(_s,"CODE",{});var r2=r(Nr);pd=s(r2,"7"),r2.forEach(t),hd=s(_s," and Steps to "),qr=o(_s,"CODE",{});var l2=r(qr);md=s(l2,"20"),l2.forEach(t),_s.forEach(t),o2.forEach(t),ne.forEach(t),Ws=d(a),Te=o(a,"P",{});var wo=r(Te);gd=s(wo,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),xr=o(wo,"CODE",{});var s2=r(xr);vd=s(s2,"150"),s2.forEach(t),_d=s(wo," - "),Gr=o(wo,"CODE",{});var n2=r(Gr);bd=s(n2,"200"),n2.forEach(t),Ed=s(wo," and keep in mind we can add and remove as we try different training settings with different output."),wo.forEach(t),Ms=d(a),Wt(la.$$.fragment,a),Bs=d(a),rt=o(a,"H4",{id:!0});var Ov=r(rt);lt=o(Ov,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var c2=r(lt);Hr=o(c2,"SPAN",{class:!0}),r(Hr).forEach(t),c2.forEach(t),yd=s(Ov,"Download images"),Ov.forEach(t),Fs=d(a),vi=o(a,"P",{});var f2=r(vi);wd=s(f2,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),f2.forEach(t),Ys=d(a),he=o(a,"UL",{});var xt=r(he);_i=o(xt,"LI",{});var Av=r(_i);sa=o(Av,"A",{href:!0,rel:!0});var u2=r(sa);kd=s(u2,"3ee Games regularization images"),u2.forEach(t),Dd=s(Av,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),Av.forEach(t),Rd=d(xt),bi=o(xt,"LI",{});var zv=r(bi);na=o(zv,"A",{href:!0,rel:!0});var d2=r(na);Td=s(d2,"Pre-Rendered Regularization Images"),d2.forEach(t),Sd=s(zv,": Includes 1500 regularization images."),zv.forEach(t),Od=d(xt),Ei=o(xt,"LI",{});var Lv=r(Ei);ca=o(Lv,"A",{href:!0,rel:!0});var p2=r(ca);Ad=s(p2,"Stable Diffusion 1.5 Regularization Images"),p2.forEach(t),zd=s(Lv,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),Lv.forEach(t),Ld=d(xt),yi=o(xt,"LI",{});var Iv=r(yi);fa=o(Iv,"A",{href:!0,rel:!0});var h2=r(fa);Id=s(h2,"Aitrepreneur SDXL image set"),h2.forEach(t),Pd=s(Iv,": a large image set generated with Stable Diffusion SDXL."),Iv.forEach(t),xt.forEach(t),Xs=d(a),st=o(a,"H4",{id:!0});var Pv=r(st);nt=o(Pv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var m2=r(nt);Ur=o(m2,"SPAN",{class:!0}),r(Ur).forEach(t),m2.forEach(t),Cd=s(Pv,"Captioning Regularization images"),Pv.forEach(t),Zs=d(a),ct=o(a,"P",{});var ac=r(ct);Nd=s(ac,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),jr=o(ac,"CODE",{});var g2=r(jr);qd=s(g2,"txt"),g2.forEach(t),xd=s(ac," files with a shell script:"),ac.forEach(t),Ks=d(a),ua=o(a,"PRE",{class:!0});var HE=r(ua);HE.forEach(t),Vs=d(a),Se=o(a,"P",{});var ko=r(Se);Gd=s(ko,"Save this file as "),Wr=o(ko,"CODE",{});var v2=r(Wr);Hd=s(v2,"filename2txt.bat"),v2.forEach(t),Ud=s(ko," and place it into the regularization images directory and run: "),Mr=o(ko,"CODE",{});var _2=r(Mr);jd=s(_2,".\\filename2txt.bat"),_2.forEach(t),Wd=s(ko,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),ko.forEach(t),Qs=d(a),da=o(a,"P",{});var Cv=r(da);Md=s(Cv,"Example filename: "),Br=o(Cv,"CODE",{});var b2=r(Br);Bd=s(b2,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),b2.forEach(t),Cv.forEach(t),Js=d(a),ft=o(a,"P",{});var ic=r(ft);Fd=s(ic,"Output: "),Fr=o(ic,"CODE",{});var E2=r(Fr);Yd=s(E2,"aburbres,princeadam,1boy,close-up,purple_vest"),E2.forEach(t),Xd=s(ic," saved in a text file with the same name as image."),ic.forEach(t),$s=d(a),ut=o(a,"H2",{id:!0});var Nv=r(ut);dt=o(Nv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var y2=r(dt);Yr=o(y2,"SPAN",{class:!0}),r(Yr).forEach(t),y2.forEach(t),Zd=s(Nv,"Training a LoRA"),Nv.forEach(t),en=d(a),wi=o(a,"P",{});var w2=r(wi);Kd=s(w2,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images."),w2.forEach(t),tn=d(a),pa=o(a,"BLOCKQUOTE",{class:!0});var k2=r(pa);ki=o(k2,"P",{class:!0});var D2=r(ki);Vd=s(D2,"Learning how to train a LoRA is a completely different subject all on its own.  Learn more about LoRA training: LINK HERE."),D2.forEach(t),k2.forEach(t),an=d(a),pt=o(a,"H3",{id:!0});var qv=r(pt);ht=o(qv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var R2=r(ht);Xr=o(R2,"SPAN",{class:!0}),r(Xr).forEach(t),R2.forEach(t),Qd=s(qv,"Directory setup"),qv.forEach(t),on=d(a),mt=o(a,"P",{});var oc=r(mt);Jd=s(oc,"In your configuration json, use "),Zr=o(oc,"CODE",{});var T2=r(Zr);$d=s(T2,"reg_data_dir"),T2.forEach(t),ep=s(oc," to point to the directory with your regularization images:"),oc.forEach(t),rn=d(a),ha=o(a,"PRE",{class:!0});var UE=r(ha);UE.forEach(t),ln=d(a),Di=o(a,"P",{});var S2=r(Di);tp=s(S2,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),S2.forEach(t),sn=d(a),ma=o(a,"PRE",{class:!0});var jE=r(ma);jE.forEach(t),nn=d(a),ie=o(a,"P",{});var ve=r(ie);ap=s(ve,"Specify the "),Kr=o(ve,"CODE",{});var O2=r(Kr);ip=s(O2,"number of iterations"),O2.forEach(t),op=s(ve," so that the number of iterations of training images "),Vr=o(ve,"CODE",{});var A2=r(Vr);rp=s(A2,"x"),A2.forEach(t),lp=s(ve," =  the number of training images "),Qr=o(ve,"CODE",{});var z2=r(Qr);sp=s(z2,"\u2265"),z2.forEach(t),np=s(ve," the number of iterations of regularization images "),Jr=o(ve,"CODE",{});var L2=r(Jr);cp=s(L2,"x"),L2.forEach(t),fp=s(ve,` the number of regularization images .
(The number of data in one epoch is \u201Cnumber of repetitions of training images `),$r=o(ve,"CODE",{});var I2=r($r);up=s(I2,"x"),I2.forEach(t),dp=s(ve," number of training images\u201D. If the number of regularization images is more than that, the remaining regularization images will not be used.)"),ve.forEach(t),cn=d(a),Oe=o(a,"P",{});var Do=r(Oe);pp=s(Do,"Create folders in the training image folder with the format "),el=o(Do,"CODE",{});var P2=r(el);hp=s(P2,"<repetition count>_<class>"),P2.forEach(t),mp=s(Do," multiple times, and similarly create folders in the regularization image folder with the format "),tl=o(Do,"CODE",{});var C2=r(tl);gp=s(C2,"<repetition count>_<class>"),C2.forEach(t),vp=s(Do,"."),Do.forEach(t),fn=d(a),Ri=o(a,"P",{});var N2=r(Ri);_p=s(N2,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),N2.forEach(t),un=d(a),gt=o(a,"UL",{});var rc=r(gt);Ti=o(rc,"LI",{});var xv=r(Ti);bp=s(xv,"train_data_dir"),al=o(xv,"UL",{});var q2=r(al);il=o(q2,"LI",{});var x2=r(il);Ep=s(x2,"10_princeadam"),x2.forEach(t),q2.forEach(t),xv.forEach(t),yp=d(rc),Si=o(rc,"LI",{});var Gv=r(Si);wp=s(Gv,"reg_dir"),ol=o(Gv,"UL",{});var G2=r(ol);rl=o(G2,"LI",{});var H2=r(rl);kp=s(H2,"1_1boy"),H2.forEach(t),G2.forEach(t),Gv.forEach(t),rc.forEach(t),dn=d(a),Oi=o(a,"P",{});var U2=r(Oi);Dp=s(U2,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),U2.forEach(t),pn=d(a),ga=o(a,"P",{class:!0});var j2=r(ga);va=o(j2,"IMG",{src:!0,alt:!0,class:!0}),j2.forEach(t),hn=d(a),vt=o(a,"H3",{id:!0});var Hv=r(vt);_t=o(Hv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var W2=r(_t);ll=o(W2,"SPAN",{class:!0}),r(ll).forEach(t),W2.forEach(t),Rp=s(Hv,"Training Settings"),Hv.forEach(t),mn=d(a),bt=o(a,"P",{});var lc=r(bt);Tp=s(lc,"The training setup we\u2019re going to use is:  "),sl=o(lc,"CODE",{});var M2=r(sl);Sp=s(M2,"Number of images * repeats * epoch / batch size = total steps"),M2.forEach(t),Op=s(lc,".  Based on our training data, we have 45 images and going for 4500 steps:"),lc.forEach(t),gn=d(a),je=o(a,"TABLE",{class:!0});var sc=r(je);nl=o(sc,"THEAD",{});var B2=r(nl);fe=o(B2,"TR",{});var Le=r(fe);cl=o(Le,"TH",{});var F2=r(cl);Ap=s(F2,"Number of Images"),F2.forEach(t),zp=d(Le),fl=o(Le,"TH",{});var Y2=r(fl);Lp=s(Y2,"Repeats"),Y2.forEach(t),Ip=d(Le),ul=o(Le,"TH",{});var X2=r(ul);Pp=s(X2,"Epochs"),X2.forEach(t),Cp=d(Le),dl=o(Le,"TH",{});var Z2=r(dl);Np=s(Z2,"Batch Size"),Z2.forEach(t),qp=d(Le),pl=o(Le,"TH",{});var K2=r(pl);xp=s(K2,"Total Steps"),K2.forEach(t),Le.forEach(t),B2.forEach(t),Gp=d(sc),hl=o(sc,"TBODY",{});var V2=r(hl);ue=o(V2,"TR",{});var Ie=r(ue);Ai=o(Ie,"TD",{class:!0});var Q2=r(Ai);Hp=s(Q2,"45"),Q2.forEach(t),Up=d(Ie),zi=o(Ie,"TD",{class:!0});var J2=r(zi);jp=s(J2,"10"),J2.forEach(t),Wp=d(Ie),Li=o(Ie,"TD",{class:!0});var $2=r(Li);Mp=s($2,"20"),$2.forEach(t),Bp=d(Ie),Ii=o(Ie,"TD",{class:!0});var eb=r(Ii);Fp=s(eb,"2"),eb.forEach(t),Yp=d(Ie),Pi=o(Ie,"TD",{class:!0});var tb=r(Pi);Xp=s(tb,"4500"),tb.forEach(t),Ie.forEach(t),V2.forEach(t),sc.forEach(t),vn=d(a),Ci=o(a,"P",{});var ab=r(Ci);Zp=s(ab,"Now let\u2019s focus on these training settings:"),ab.forEach(t),_n=d(a),_a=o(a,"PRE",{class:!0});var WE=r(_a);WE.forEach(t),bn=d(a),j=o(a,"UL",{});var F=r(j);Ni=o(F,"LI",{});var Uv=r(Ni);ba=o(Uv,"STRONG",{});var nc=r(ba);Kp=s(nc,"Learning Rate ("),ml=o(nc,"CODE",{});var ib=r(ml);Vp=s(ib,"learning_rate"),ib.forEach(t),Qp=s(nc,")"),nc.forEach(t),Jp=s(Uv,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Uv.forEach(t),$p=d(F),qi=o(F,"LI",{});var jv=r(qi);Ea=o(jv,"STRONG",{});var cc=r(Ea);eh=s(cc,"Text Encoder Learning Rate ("),gl=o(cc,"CODE",{});var ob=r(gl);th=s(ob,"text_encoder_lr"),ob.forEach(t),ah=s(cc,")"),cc.forEach(t),ih=s(jv,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),jv.forEach(t),oh=d(F),xi=o(F,"LI",{});var Wv=r(xi);ya=o(Wv,"STRONG",{});var fc=r(ya);rh=s(fc,"UNet Learning Rate ("),vl=o(fc,"CODE",{});var rb=r(vl);lh=s(rb,"unet_lr"),rb.forEach(t),sh=s(fc,")"),fc.forEach(t),nh=s(Wv,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Wv.forEach(t),ch=d(F),Gi=o(F,"LI",{});var Mv=r(Gi);wa=o(Mv,"STRONG",{});var uc=r(wa);fh=s(uc,"Learning Rate Scheduler ("),_l=o(uc,"CODE",{});var lb=r(_l);uh=s(lb,"lr_scheduler"),lb.forEach(t),dh=s(uc,")"),uc.forEach(t),ph=s(Mv,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Mv.forEach(t),hh=d(F),Hi=o(F,"LI",{});var Bv=r(Hi);ka=o(Bv,"STRONG",{});var dc=r(ka);mh=s(dc,"Number of Cycles in Learning Rate Scheduler ("),bl=o(dc,"CODE",{});var sb=r(bl);gh=s(sb,"lr_scheduler_num_cycles"),sb.forEach(t),vh=s(dc,")"),dc.forEach(t),_h=s(Bv,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Bv.forEach(t),bh=d(F),Ui=o(F,"LI",{});var Fv=r(Ui);Da=o(Fv,"STRONG",{});var pc=r(Da);Eh=s(pc,"Network Dimension ("),El=o(pc,"CODE",{});var nb=r(El);yh=s(nb,"network_dim"),nb.forEach(t),wh=s(pc,")"),pc.forEach(t),kh=s(Fv,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Fv.forEach(t),Dh=d(F),ji=o(F,"LI",{});var Yv=r(ji);Ra=o(Yv,"STRONG",{});var hc=r(Ra);Rh=s(hc,"Network Alpha ("),yl=o(hc,"CODE",{});var cb=r(yl);Th=s(cb,"network_alpha"),cb.forEach(t),Sh=s(hc,")"),hc.forEach(t),Oh=s(Yv,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Yv.forEach(t),Ah=d(F),Wi=o(F,"LI",{});var Xv=r(Wi);Ta=o(Xv,"STRONG",{});var mc=r(Ta);zh=s(mc,"Clip Skip ("),wl=o(mc,"CODE",{});var fb=r(wl);Lh=s(fb,"clip_skip"),fb.forEach(t),Ih=s(mc,")"),mc.forEach(t),Ph=s(Xv,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Xv.forEach(t),Ch=d(F),Mi=o(F,"LI",{});var Zv=r(Mi);Sa=o(Zv,"STRONG",{});var gc=r(Sa);Nh=s(gc,"Max Token Length ("),kl=o(gc,"CODE",{});var ub=r(kl);qh=s(ub,"max_token_length"),ub.forEach(t),xh=s(gc,")"),gc.forEach(t),Gh=s(Zv,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Zv.forEach(t),Hh=d(F),Bi=o(F,"LI",{});var Kv=r(Bi);Oa=o(Kv,"STRONG",{});var vc=r(Oa);Uh=s(vc,"Noise Offset ("),Dl=o(vc,"CODE",{});var db=r(Dl);jh=s(db,"noise_offset"),db.forEach(t),Wh=s(vc,")"),vc.forEach(t),Mh=s(Kv,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Kv.forEach(t),Bh=d(F),Fi=o(F,"LI",{});var Vv=r(Fi);Aa=o(Vv,"STRONG",{});var _c=r(Aa);Fh=s(_c,"Regularization Data Directory ("),Rl=o(_c,"CODE",{});var pb=r(Rl);Yh=s(pb,"reg_data_dir"),pb.forEach(t),Xh=s(_c,")"),_c.forEach(t),Zh=s(Vv,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Vv.forEach(t),F.forEach(t),En=d(a),Et=o(a,"H3",{id:!0});var Qv=r(Et);yt=o(Qv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var hb=r(yt);Tl=o(hb,"SPAN",{class:!0}),r(Tl).forEach(t),hb.forEach(t),Kh=s(Qv,"Fine Tuning"),Qv.forEach(t),yn=d(a),Yi=o(a,"P",{});var mb=r(Yi);Vh=s(mb,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),mb.forEach(t),wn=d(a),Wt(za.$$.fragment,a),kn=d(a),wt=o(a,"H4",{id:!0});var Jv=r(wt);kt=o(Jv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var gb=r(kt);Sl=o(gb,"SPAN",{class:!0}),r(Sl).forEach(t),gb.forEach(t),Qh=s(Jv,"Workflow with Auto1111 WebUI"),Jv.forEach(t),Dn=d(a),Dt=o(a,"P",{});var bc=r(Dt);Jh=s(bc,"We\u2019re going to use "),La=o(bc,"A",{href:!0,rel:!0});var vb=r(La);$h=s(vb,"Stable Diffusion web UI"),vb.forEach(t),em=s(bc," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),bc.forEach(t),Rn=d(a),Rt=o(a,"P",{});var Ec=r(Rt);tm=s(Ec,"We\u2019re going to use the "),Ol=o(Ec,"CODE",{});var _b=r(Ol);am=s(_b,"X/Y/Z plot"),_b.forEach(t),im=s(Ec," script to compare different epochs."),Ec.forEach(t),Tn=d(a),le=o(a,"UL",{});var Pe=r(le);Xi=o(Pe,"LI",{});var $v=r(Xi);om=s($v,"Select the text 2 image tab.  Enter a generic prompt "),Al=o($v,"CODE",{});var bb=r(Al);rm=s(bb,"princeadam, portrait, <princeadam0001:0.7>"),bb.forEach(t),$v.forEach(t),lm=d(Pe),Ia=o(Pe,"LI",{});var yc=r(Ia);sm=s(yc,"In generation parameters and select the "),zl=o(yc,"CODE",{});var Eb=r(zl);nm=s(Eb,"X/Y/Z plot"),Eb.forEach(t),cm=s(yc," script."),yc.forEach(t),fm=d(Pe),se=o(Pe,"LI",{});var we=r(se);um=s(we,"Select "),Ll=o(we,"CODE",{});var yb=r(Ll);dm=s(yb,"Prompt SR"),yb.forEach(t),pm=s(we," for Prompt Replace.  We\u2019re going to replace "),Il=o(we,"CODE",{});var wb=r(Il);hm=s(wb,"<princeadam0001:0.7>"),wb.forEach(t),mm=s(we," with different epoch: "),Pl=o(we,"CODE",{});var kb=r(Pl);gm=s(kb,"<princeadam0001:0.7>"),kb.forEach(t),vm=s(we,", "),Cl=o(we,"CODE",{});var Db=r(Cl);_m=s(Db,"<princeadam0003:0.7>"),Db.forEach(t),bm=s(we,", "),Nl=o(we,"CODE",{});var Rb=r(Nl);Em=s(Rb,"<princeadam0023:0.7>"),Rb.forEach(t),we.forEach(t),ym=d(Pe),Zi=o(Pe,"LI",{});var e_=r(Zi);wm=s(e_,"Select a fast sampler like "),ql=o(e_,"CODE",{});var Tb=r(ql);km=s(Tb,"DPM2 KARRAS"),Tb.forEach(t),e_.forEach(t),Dm=d(Pe),Tt=o(Pe,"LI",{});var bs=r(Tt);Rm=s(bs,"CFG Scale set to "),xl=o(bs,"CODE",{});var Sb=r(xl);Tm=s(Sb,"7"),Sb.forEach(t),Sm=s(bs," and Steps to "),Gl=o(bs,"CODE",{});var Ob=r(Gl);Om=s(Ob,"20"),Ob.forEach(t),bs.forEach(t),Pe.forEach(t),Sn=d(a),Ae=o(a,"P",{});var Ro=r(Ae);Am=s(Ro,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Hl=o(Ro,"CODE",{});var Ab=r(Hl);zm=s(Ab,"network_dim"),Ab.forEach(t),Lm=s(Ro," and "),Ul=o(Ro,"CODE",{});var zb=r(Ul);Im=s(zb,"network_alpha"),zb.forEach(t),Pm=s(Ro,"?  Those are the settings that directly control the output strength mentioned earlier."),Ro.forEach(t),On=d(a),me=o(a,"UL",{});var Gt=r(me);K=o(Gt,"LI",{});var ae=r(K);Cm=s(ae,"Select "),jl=o(ae,"CODE",{});var Lb=r(jl);Nm=s(Lb,"Prompt SR"),Lb.forEach(t),qm=s(ae," for Prompt Replace.  We\u2019re going to replace the weights "),Wl=o(ae,"CODE",{});var Ib=r(Wl);xm=s(Ib,"<princeadam12:0.4>"),Ib.forEach(t),Gm=s(ae,","),Ml=o(ae,"CODE",{});var Pb=r(Ml);Hm=s(Pb,"<princeadam12:0.5>"),Pb.forEach(t),Um=s(ae,", "),Bl=o(ae,"CODE",{});var Cb=r(Bl);jm=s(Cb,"<princeadam12:0.6>"),Cb.forEach(t),Wm=s(ae,", "),Fl=o(ae,"CODE",{});var Nb=r(Fl);Mm=s(Nb,"<princeadam12:0.7>"),Nb.forEach(t),Bm=s(ae,", "),Yl=o(ae,"CODE",{});var qb=r(Yl);Fm=s(qb,"<princeadam12:0.8>"),qb.forEach(t),Ym=s(ae,", "),Xl=o(ae,"CODE",{});var xb=r(Xl);Xm=s(xb,"<princeadam12:0.9>"),xb.forEach(t),Zm=s(ae,", "),Zl=o(ae,"CODE",{});var Gb=r(Zl);Km=s(Gb,"<princeadam12:1.0>"),Gb.forEach(t),ae.forEach(t),Vm=d(Gt),oe=o(Gt,"LI",{});var de=r(oe);Qm=s(de,"Use another "),Kl=o(de,"CODE",{});var Hb=r(Kl);Jm=s(Hb,"Prompt SR"),Hb.forEach(t),$m=s(de," to generate a variety of different angles: Select "),Vl=o(de,"CODE",{});var Ub=r(Vl);eg=s(Ub,"Prompt SR"),Ub.forEach(t),tg=s(de," for Prompt Replace.  Replace "),Ql=o(de,"CODE",{});var jb=r(Ql);ag=s(jb,"upper_body"),jb.forEach(t),ig=s(de," with different camera angles: "),Jl=o(de,"CODE",{});var Wb=r(Jl);og=s(Wb,"from_below"),Wb.forEach(t),rg=s(de,", "),$l=o(de,"CODE",{});var Mb=r($l);lg=s(Mb,"from_above"),Mb.forEach(t),sg=s(de,", "),es=o(de,"CODE",{});var Bb=r(es);ng=s(Bb,"close_up"),Bb.forEach(t),de.forEach(t),cg=d(Gt),ts=o(Gt,"LI",{});var Fb=r(ts);fg=s(Fb,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),Fb.forEach(t),ug=d(Gt),as=o(Gt,"LI",{});var Yb=r(as);dg=s(Yb,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),Yb.forEach(t),Gt.forEach(t),An=d(a),St=o(a,"H4",{id:!0});var t_=r(St);Ot=o(t_,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Xb=r(Ot);is=o(Xb,"SPAN",{class:!0}),r(is).forEach(t),Xb.forEach(t),pg=s(t_,"Issues to look for"),t_.forEach(t),zn=d(a),ge=o(a,"UL",{});var Ht=r(ge);Ki=o(Ht,"LI",{});var a_=r(Ki);os=o(a_,"STRONG",{});var Zb=r(os);hg=s(Zb,"Undercooked:"),Zb.forEach(t),mg=s(a_," Lacks output, adjust unet learning rate or extend training duration."),a_.forEach(t),gg=d(Ht),Vi=o(Ht,"LI",{});var i_=r(Vi);rs=o(i_,"STRONG",{});var Kb=r(rs);vg=s(Kb,"Overcooked:"),Kb.forEach(t),_g=s(i_," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),i_.forEach(t),bg=d(Ht),Qi=o(Ht,"LI",{});var o_=r(Qi);ls=o(o_,"STRONG",{});var Vb=r(ls);Eg=s(Vb,"Overfit:"),Vb.forEach(t),yg=s(o_," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),o_.forEach(t),wg=d(Ht),Ji=o(Ht,"LI",{});var r_=r(Ji);ss=o(r_,"STRONG",{});var Qb=r(ss);kg=s(Qb,"Mismatched:"),Qb.forEach(t),Dg=s(r_," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),r_.forEach(t),Ht.forEach(t),Ln=d(a),$i=o(a,"P",{});var Jb=r($i);Rg=s(Jb,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),Jb.forEach(t),In=d(a),Pa=o(a,"P",{class:!0});var $b=r(Pa);Ca=o($b,"IMG",{src:!0,alt:!0,class:!0}),$b.forEach(t),Pn=d(a),At=o(a,"H4",{id:!0});var l_=r(At);zt=o(l_,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var eE=r(zt);ns=o(eE,"SPAN",{class:!0}),r(ns).forEach(t),eE.forEach(t),Tg=s(l_,"Troubleshooting"),l_.forEach(t),Cn=d(a),eo=o(a,"P",{});var tE=r(eo);Sg=s(tE,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),tE.forEach(t),Nn=d(a),ze=o(a,"UL",{});var To=r(ze);Na=o(To,"LI",{});var wc=r(Na);Og=s(wc,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),cs=o(wc,"CODE",{});var aE=r(cs);Ag=s(aE,"200"),aE.forEach(t),zg=s(wc," regularization images per training image."),wc.forEach(t),Lg=d(To),qa=o(To,"LI",{});var kc=r(qa);Ig=s(kc,"Repeats of regularization images, but may overfit more.  Increasing the "),fs=o(kc,"CODE",{});var iE=r(fs);Pg=s(iE,"repetition_count"),iE.forEach(t),Cg=s(kc," will cycle through the images more but the results may have results that overfit the model."),kc.forEach(t),Ng=d(To),us=o(To,"LI",{});var oE=r(us);qg=s(oE,"Create more regularization images without increasing repeats will help with the overfitting."),oE.forEach(t),To.forEach(t),qn=d(a),We=o(a,"TABLE",{class:!0});var Dc=r(We);ds=o(Dc,"THEAD",{});var rE=r(ds);Me=o(rE,"TR",{});var So=r(Me);ps=o(So,"TH",{});var lE=r(ps);xg=s(lE,"Issue"),lE.forEach(t),Gg=d(So),hs=o(So,"TH",{});var sE=r(hs);Hg=s(sE,"Situation"),sE.forEach(t),Ug=d(So),ms=o(So,"TH",{});var nE=r(ms);jg=s(nE,"Recommendation"),nE.forEach(t),So.forEach(t),rE.forEach(t),Wg=d(Dc),Ee=o(Dc,"TBODY",{});var Ut=r(Ee);Be=o(Ut,"TR",{});var Oo=r(Be);to=o(Oo,"TD",{class:!0});var cE=r(to);Mg=s(cE,"Varying quality"),cE.forEach(t),Bg=d(Oo),ao=o(Oo,"TD",{class:!0});var fE=r(ao);Fg=s(fE,"Results differ from expectations"),fE.forEach(t),Yg=d(Oo),io=o(Oo,"TD",{class:!0});var uE=r(io);Xg=s(uE,"Evaluate the quality and quantity of regularization images. Adjust the number and selection and check for better results."),uE.forEach(t),Oo.forEach(t),Zg=d(Ut),Fe=o(Ut,"TR",{});var Ao=r(Fe);oo=o(Ao,"TD",{class:!0});var dE=r(oo);Kg=s(dE,"Inadequate regularization for input data"),dE.forEach(t),Vg=d(Ao),ro=o(Ao,"TD",{class:!0});var pE=r(ro);Qg=s(pE,"Lower input images, less regularization needed"),pE.forEach(t),Jg=d(Ao),lo=o(Ao,"TD",{class:!0});var hE=r(lo);$g=s(hE,"Consider reducing the number of input images or increasing the quantity and diversity of regularization images."),hE.forEach(t),Ao.forEach(t),ev=d(Ut),Ye=o(Ut,"TR",{});var zo=r(Ye);so=o(zo,"TD",{class:!0});var mE=r(so);tv=s(mE,"Overfitting due to repetition"),mE.forEach(t),av=d(zo),no=o(zo,"TD",{class:!0});var gE=r(no);iv=s(gE,"Repeats of regularization images, risk of overfitting"),gE.forEach(t),ov=d(zo),Lt=o(zo,"TD",{class:!0});var Rc=r(Lt);rv=s(Rc,"Adjust the "),gs=o(Rc,"CODE",{});var vE=r(gs);lv=s(vE,"repetition_count"),vE.forEach(t),sv=s(Rc," to balance cycling through images without overfitting. Monitor results for improvements."),Rc.forEach(t),zo.forEach(t),nv=d(Ut),Xe=o(Ut,"TR",{});var Lo=r(Xe);co=o(Lo,"TD",{class:!0});var _E=r(co);cv=s(_E,"Mitigate overfitting while increasing diversity"),_E.forEach(t),fv=d(Lo),fo=o(Lo,"TD",{class:!0});var bE=r(fo);uv=s(bE,"Create more regularization images without repeats"),bE.forEach(t),dv=d(Lo),uo=o(Lo,"TD",{class:!0});var EE=r(uo);pv=s(EE,"Generate additional regularization images without increasing repetitions. Enhance model adaptability without overfitting."),EE.forEach(t),Lo.forEach(t),Ut.forEach(t),Dc.forEach(t),xn=d(a),It=o(a,"H3",{id:!0});var s_=r(It);Pt=o(s_,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var yE=r(Pt);vs=o(yE,"SPAN",{class:!0}),r(vs).forEach(t),yE.forEach(t),hv=s(s_,"Results"),s_.forEach(t),Gn=d(a),po=o(a,"P",{});var wE=r(po);mv=s(wE,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),wE.forEach(t),Hn=d(a),ho=o(a,"P",{});var kE=r(ho);gv=s(kE,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),kE.forEach(t),Un=d(a),xa=o(a,"P",{class:!0});var DE=r(xa);Ga=o(DE,"IMG",{src:!0,alt:!0,class:!0}),DE.forEach(t),jn=d(a),mo=o(a,"P",{});var RE=r(mo);vv=s(RE,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),RE.forEach(t),Wn=d(a),ye&&ye.l(a),Mn=Io(),this.h()},h(){f(R,"class","icon icon-link"),f(y,"aria-hidden","true"),f(y,"tabindex","-1"),f(y,"href","#what-are-regularization-images"),f(b,"id","what-are-regularization-images"),f(P,"class","svelte-1lvyfvh"),f(z,"class","svelte-1lvyfvh"),f(Wa,"class","svelte-1lvyfvh"),f(Ma,"class","svelte-1lvyfvh"),f(Ba,"class","svelte-1lvyfvh"),f(Fa,"class","svelte-1lvyfvh"),f(Ya,"class","svelte-1lvyfvh"),f(Xa,"class","svelte-1lvyfvh"),f(Za,"class","svelte-1lvyfvh"),f(Ka,"class","svelte-1lvyfvh"),f(Va,"class","svelte-1lvyfvh"),f(Qa,"class","svelte-1lvyfvh"),f(Ja,"class","svelte-1lvyfvh"),f($a,"class","svelte-1lvyfvh"),f(Y,"class","svelte-1lvyfvh"),f(ai,"class","svelte-1lvyfvh"),f(Yt,"class","svelte-1lvyfvh"),f(Wo,"class","icon icon-link"),f(Ve,"aria-hidden","true"),f(Ve,"tabindex","-1"),f(Ve,"href","#divergence"),f(Ke,"id","divergence"),f(ri,"class","svelte-1lvyfvh"),f(li,"class","svelte-1lvyfvh"),f(si,"class","svelte-1lvyfvh"),f(ni,"class","svelte-1lvyfvh"),f(ci,"class","svelte-1lvyfvh"),f(fi,"class","svelte-1lvyfvh"),f(ui,"class","svelte-1lvyfvh"),f(di,"class","svelte-1lvyfvh"),f(Ue,"class","svelte-1lvyfvh"),f(Xo,"class","icon icon-link"),f($e,"aria-hidden","true"),f($e,"tabindex","-1"),f($e,"href","#generating-regularization-images"),f(Je,"id","generating-regularization-images"),f(pi,"class","svelte-1lvyfvh"),f(aa,"class","svelte-1lvyfvh"),f($o,"class","icon icon-link"),f(at,"aria-hidden","true"),f(at,"tabindex","-1"),f(at,"href","#generate-using-stable-diffusion-web-ui"),f(tt,"id","generate-using-stable-diffusion-web-ui"),f(oa,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),f(oa,"rel","nofollow"),f(Hr,"class","icon icon-link"),f(lt,"aria-hidden","true"),f(lt,"tabindex","-1"),f(lt,"href","#download-images"),f(rt,"id","download-images"),f(sa,"href","https://huggingface.co/3ee"),f(sa,"rel","nofollow"),f(na,"href","https://github.com/Luehrsen/sd_regularization_images"),f(na,"rel","nofollow"),f(ca,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),f(ca,"rel","nofollow"),f(fa,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),f(fa,"rel","nofollow"),f(Ur,"class","icon icon-link"),f(nt,"aria-hidden","true"),f(nt,"tabindex","-1"),f(nt,"href","#captioning-regularization-images"),f(st,"id","captioning-regularization-images"),f(ua,"class","language-shell"),f(Yr,"class","icon icon-link"),f(dt,"aria-hidden","true"),f(dt,"tabindex","-1"),f(dt,"href","#training-a-lora"),f(ut,"id","training-a-lora"),f(ki,"class","svelte-1lvyfvh"),f(pa,"class","svelte-1lvyfvh"),f(Xr,"class","icon icon-link"),f(ht,"aria-hidden","true"),f(ht,"tabindex","-1"),f(ht,"href","#directory-setup"),f(pt,"id","directory-setup"),f(ha,"class","language-json"),f(ma,"class","language-xml"),Ha(va.src,h_="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||f(va,"src",h_),f(va,"alt","image"),f(va,"class","svelte-1lvyfvh"),f(ga,"class","svelte-1lvyfvh"),f(ll,"class","icon icon-link"),f(_t,"aria-hidden","true"),f(_t,"tabindex","-1"),f(_t,"href","#training-settings"),f(vt,"id","training-settings"),f(Ai,"class","svelte-1lvyfvh"),f(zi,"class","svelte-1lvyfvh"),f(Li,"class","svelte-1lvyfvh"),f(Ii,"class","svelte-1lvyfvh"),f(Pi,"class","svelte-1lvyfvh"),f(je,"class","svelte-1lvyfvh"),f(_a,"class","language-json"),f(Tl,"class","icon icon-link"),f(yt,"aria-hidden","true"),f(yt,"tabindex","-1"),f(yt,"href","#fine-tuning"),f(Et,"id","fine-tuning"),f(Sl,"class","icon icon-link"),f(kt,"aria-hidden","true"),f(kt,"tabindex","-1"),f(kt,"href","#workflow-with-auto1111-webui"),f(wt,"id","workflow-with-auto1111-webui"),f(La,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),f(La,"rel","nofollow"),f(is,"class","icon icon-link"),f(Ot,"aria-hidden","true"),f(Ot,"tabindex","-1"),f(Ot,"href","#issues-to-look-for"),f(St,"id","issues-to-look-for"),Ha(Ca.src,m_="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||f(Ca,"src",m_),f(Ca,"alt","image"),f(Ca,"class","svelte-1lvyfvh"),f(Pa,"class","svelte-1lvyfvh"),f(ns,"class","icon icon-link"),f(zt,"aria-hidden","true"),f(zt,"tabindex","-1"),f(zt,"href","#troubleshooting"),f(At,"id","troubleshooting"),f(to,"class","svelte-1lvyfvh"),f(ao,"class","svelte-1lvyfvh"),f(io,"class","svelte-1lvyfvh"),f(oo,"class","svelte-1lvyfvh"),f(ro,"class","svelte-1lvyfvh"),f(lo,"class","svelte-1lvyfvh"),f(so,"class","svelte-1lvyfvh"),f(no,"class","svelte-1lvyfvh"),f(Lt,"class","svelte-1lvyfvh"),f(co,"class","svelte-1lvyfvh"),f(fo,"class","svelte-1lvyfvh"),f(uo,"class","svelte-1lvyfvh"),f(We,"class","svelte-1lvyfvh"),f(vs,"class","icon icon-link"),f(Pt,"aria-hidden","true"),f(Pt,"tabindex","-1"),f(Pt,"href","#results"),f(It,"id","results"),Ha(Ga.src,g_="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||f(Ga,"src",g_),f(Ga,"alt","image"),f(Ga,"class","svelte-1lvyfvh"),f(xa,"class","svelte-1lvyfvh")},m(a,p){c(a,n,p),e(n,g),c(a,m,p),Mt(h,a,p),c(a,v,p),c(a,b,p),e(b,y),e(y,R),e(b,T),c(a,w,p),c(a,E,p),e(E,k),c(a,I,p),c(a,z,p),e(z,P),e(P,x),c(a,S,p),Mt(A,a,p),c(a,O,p),c(a,C,p),e(C,N),c(a,V,p),c(a,M,p),e(M,B),c(a,W,p),c(a,q,p),e(q,L),c(a,H,p),c(a,Y,p),e(Y,U),e(U,D),e(D,G),e(G,Ft),e(D,Ua),e(D,De),e(De,ja),e(D,zc),e(D,Po),e(Po,Lc),e(Y,Ic),e(Y,_e),e(_e,qe),e(qe,Wa),e(Wa,Co),e(Co,Pc),e(qe,Cc),e(qe,Ma),e(Ma,Nc),e(qe,qc),e(qe,Ba),e(Ba,xc),e(_e,Gc),e(_e,xe),e(xe,Fa),e(Fa,No),e(No,Hc),e(xe,Uc),e(xe,Ya),e(Ya,jc),e(xe,Wc),e(xe,Xa),e(Xa,Mc),e(_e,Bc),e(_e,Ge),e(Ge,Za),e(Za,qo),e(qo,Fc),e(Ge,Yc),e(Ge,Ka),e(Ka,Xc),e(Ge,Zc),e(Ge,Va),e(Va,Kc),e(_e,Vc),e(_e,He),e(He,Qa),e(Qa,xo),e(xo,Qc),e(He,Jc),e(He,Ja),e(Ja,$c),e(He,ef),e(He,$a),e($a,tf),c(a,Es,p),c(a,ei,p),e(ei,af),c(a,ys,p),c(a,ti,p),e(ti,of),c(a,ws,p),c(a,Yt,p),e(Yt,ai),e(ai,rf),c(a,ks,p),c(a,Xt,p),e(Xt,Go),e(Go,lf),e(Xt,sf),c(a,Ds,p),c(a,Zt,p),e(Zt,Ho),e(Ho,nf),e(Zt,cf),c(a,Rs,p),c(a,Kt,p),e(Kt,Uo),e(Uo,ff),e(Kt,uf),c(a,Ts,p),c(a,Vt,p),e(Vt,jo),e(jo,df),e(Vt,pf),c(a,Ss,p),c(a,Ke,p),e(Ke,Ve),e(Ve,Wo),e(Ke,hf),c(a,Os,p),c(a,Qe,p),e(Qe,mf),e(Qe,Mo),e(Mo,gf),e(Qe,vf),c(a,As,p),c(a,ii,p),e(ii,_f),c(a,zs,p),c(a,oi,p),e(oi,bf),c(a,Ls,p),c(a,Ue,p),e(Ue,Bo),e(Bo,Qt),e(Qt,Fo),e(Fo,Ef),e(Qt,yf),e(Qt,Yo),e(Yo,wf),e(Ue,kf),e(Ue,be),e(be,Jt),e(Jt,ri),e(ri,Df),e(Jt,Rf),e(Jt,li),e(li,Tf),e(be,Sf),e(be,$t),e($t,si),e(si,Of),e($t,Af),e($t,ni),e(ni,zf),e(be,Lf),e(be,ea),e(ea,ci),e(ci,If),e(ea,Pf),e(ea,fi),e(fi,Cf),e(be,Nf),e(be,ta),e(ta,ui),e(ui,qf),e(ta,xf),e(ta,di),e(di,Gf),c(a,Is,p),c(a,Je,p),e(Je,$e),e($e,Xo),e(Je,Hf),c(a,Ps,p),c(a,et,p),e(et,Uf),e(et,Zo),e(Zo,jf),e(et,Wf),c(a,Cs,p),c(a,pe,p),e(pe,Mf),e(pe,Ko),e(Ko,Bf),e(pe,Ff),e(pe,Vo),e(Vo,Yf),e(pe,Xf),e(pe,Qo),e(Qo,Zf),e(pe,Kf),c(a,Ns,p),c(a,aa,p),e(aa,pi),e(pi,Jo),e(Jo,Vf),c(a,qs,p),c(a,hi,p),e(hi,Qf),c(a,xs,p),Mt(ia,a,p),c(a,Gs,p),c(a,tt,p),e(tt,at),e(at,$o),e(tt,Jf),c(a,Hs,p),c(a,it,p),e(it,$f),e(it,oa),e(oa,eu),e(it,tu),c(a,Us,p),c(a,Re,p),e(Re,au),e(Re,er),e(er,iu),e(Re,ou),e(Re,tr),e(tr,ru),e(Re,lu),c(a,js,p),c(a,Q,p),e(Q,ar),e(ar,mi),e(mi,su),e(mi,ir),e(ir,nu),e(Q,cu),e(Q,or),e(or,ra),e(ra,fu),e(ra,rr),e(rr,uu),e(ra,du),e(Q,pu),e(Q,lr),e(lr,X),e(X,hu),e(X,sr),e(sr,mu),e(X,gu),e(X,nr),e(nr,vu),e(X,_u),e(X,cr),e(cr,bu),e(X,Eu),e(X,fr),e(fr,yu),e(X,wu),e(X,ur),e(ur,ku),e(X,Du),e(X,dr),e(dr,Ru),e(X,Tu),e(X,pr),e(pr,Su),e(X,Ou),e(X,hr),e(hr,Au),e(Q,zu),e(Q,mr),e(mr,J),e(J,Lu),e(J,gr),e(gr,Iu),e(J,Pu),e(J,vr),e(vr,Cu),e(J,Nu),e(J,_r),e(_r,qu),e(J,xu),e(J,br),e(br,Gu),e(J,Hu),e(J,Er),e(Er,Uu),e(J,ju),e(J,yr),e(yr,Wu),e(J,Mu),e(J,wr),e(wr,Bu),e(Q,Fu),e(Q,kr),e(kr,Z),e(Z,Yu),e(Z,Dr),e(Dr,Xu),e(Z,Zu),e(Z,Rr),e(Rr,Ku),e(Z,Vu),e(Z,Tr),e(Tr,Qu),e(Z,Ju),e(Z,Sr),e(Sr,$u),e(Z,ed),e(Z,Or),e(Or,td),e(Z,ad),e(Z,Ar),e(Ar,id),e(Z,od),e(Z,zr),e(zr,rd),e(Z,ld),e(Z,Lr),e(Lr,sd),e(Q,nd),e(Q,Ir),e(Ir,gi),e(gi,cd),e(gi,Pr),e(Pr,fd),e(Q,ud),e(Q,Cr),e(Cr,ot),e(ot,dd),e(ot,Nr),e(Nr,pd),e(ot,hd),e(ot,qr),e(qr,md),c(a,Ws,p),c(a,Te,p),e(Te,gd),e(Te,xr),e(xr,vd),e(Te,_d),e(Te,Gr),e(Gr,bd),e(Te,Ed),c(a,Ms,p),Mt(la,a,p),c(a,Bs,p),c(a,rt,p),e(rt,lt),e(lt,Hr),e(rt,yd),c(a,Fs,p),c(a,vi,p),e(vi,wd),c(a,Ys,p),c(a,he,p),e(he,_i),e(_i,sa),e(sa,kd),e(_i,Dd),e(he,Rd),e(he,bi),e(bi,na),e(na,Td),e(bi,Sd),e(he,Od),e(he,Ei),e(Ei,ca),e(ca,Ad),e(Ei,zd),e(he,Ld),e(he,yi),e(yi,fa),e(fa,Id),e(yi,Pd),c(a,Xs,p),c(a,st,p),e(st,nt),e(nt,Ur),e(st,Cd),c(a,Zs,p),c(a,ct,p),e(ct,Nd),e(ct,jr),e(jr,qd),e(ct,xd),c(a,Ks,p),c(a,ua,p),ua.innerHTML=NE,c(a,Vs,p),c(a,Se,p),e(Se,Gd),e(Se,Wr),e(Wr,Hd),e(Se,Ud),e(Se,Mr),e(Mr,jd),e(Se,Wd),c(a,Qs,p),c(a,da,p),e(da,Md),e(da,Br),e(Br,Bd),c(a,Js,p),c(a,ft,p),e(ft,Fd),e(ft,Fr),e(Fr,Yd),e(ft,Xd),c(a,$s,p),c(a,ut,p),e(ut,dt),e(dt,Yr),e(ut,Zd),c(a,en,p),c(a,wi,p),e(wi,Kd),c(a,tn,p),c(a,pa,p),e(pa,ki),e(ki,Vd),c(a,an,p),c(a,pt,p),e(pt,ht),e(ht,Xr),e(pt,Qd),c(a,on,p),c(a,mt,p),e(mt,Jd),e(mt,Zr),e(Zr,$d),e(mt,ep),c(a,rn,p),c(a,ha,p),ha.innerHTML=qE,c(a,ln,p),c(a,Di,p),e(Di,tp),c(a,sn,p),c(a,ma,p),ma.innerHTML=xE,c(a,nn,p),c(a,ie,p),e(ie,ap),e(ie,Kr),e(Kr,ip),e(ie,op),e(ie,Vr),e(Vr,rp),e(ie,lp),e(ie,Qr),e(Qr,sp),e(ie,np),e(ie,Jr),e(Jr,cp),e(ie,fp),e(ie,$r),e($r,up),e(ie,dp),c(a,cn,p),c(a,Oe,p),e(Oe,pp),e(Oe,el),e(el,hp),e(Oe,mp),e(Oe,tl),e(tl,gp),e(Oe,vp),c(a,fn,p),c(a,Ri,p),e(Ri,_p),c(a,un,p),c(a,gt,p),e(gt,Ti),e(Ti,bp),e(Ti,al),e(al,il),e(il,Ep),e(gt,yp),e(gt,Si),e(Si,wp),e(Si,ol),e(ol,rl),e(rl,kp),c(a,dn,p),c(a,Oi,p),e(Oi,Dp),c(a,pn,p),c(a,ga,p),e(ga,va),c(a,hn,p),c(a,vt,p),e(vt,_t),e(_t,ll),e(vt,Rp),c(a,mn,p),c(a,bt,p),e(bt,Tp),e(bt,sl),e(sl,Sp),e(bt,Op),c(a,gn,p),c(a,je,p),e(je,nl),e(nl,fe),e(fe,cl),e(cl,Ap),e(fe,zp),e(fe,fl),e(fl,Lp),e(fe,Ip),e(fe,ul),e(ul,Pp),e(fe,Cp),e(fe,dl),e(dl,Np),e(fe,qp),e(fe,pl),e(pl,xp),e(je,Gp),e(je,hl),e(hl,ue),e(ue,Ai),e(Ai,Hp),e(ue,Up),e(ue,zi),e(zi,jp),e(ue,Wp),e(ue,Li),e(Li,Mp),e(ue,Bp),e(ue,Ii),e(Ii,Fp),e(ue,Yp),e(ue,Pi),e(Pi,Xp),c(a,vn,p),c(a,Ci,p),e(Ci,Zp),c(a,_n,p),c(a,_a,p),_a.innerHTML=GE,c(a,bn,p),c(a,j,p),e(j,Ni),e(Ni,ba),e(ba,Kp),e(ba,ml),e(ml,Vp),e(ba,Qp),e(Ni,Jp),e(j,$p),e(j,qi),e(qi,Ea),e(Ea,eh),e(Ea,gl),e(gl,th),e(Ea,ah),e(qi,ih),e(j,oh),e(j,xi),e(xi,ya),e(ya,rh),e(ya,vl),e(vl,lh),e(ya,sh),e(xi,nh),e(j,ch),e(j,Gi),e(Gi,wa),e(wa,fh),e(wa,_l),e(_l,uh),e(wa,dh),e(Gi,ph),e(j,hh),e(j,Hi),e(Hi,ka),e(ka,mh),e(ka,bl),e(bl,gh),e(ka,vh),e(Hi,_h),e(j,bh),e(j,Ui),e(Ui,Da),e(Da,Eh),e(Da,El),e(El,yh),e(Da,wh),e(Ui,kh),e(j,Dh),e(j,ji),e(ji,Ra),e(Ra,Rh),e(Ra,yl),e(yl,Th),e(Ra,Sh),e(ji,Oh),e(j,Ah),e(j,Wi),e(Wi,Ta),e(Ta,zh),e(Ta,wl),e(wl,Lh),e(Ta,Ih),e(Wi,Ph),e(j,Ch),e(j,Mi),e(Mi,Sa),e(Sa,Nh),e(Sa,kl),e(kl,qh),e(Sa,xh),e(Mi,Gh),e(j,Hh),e(j,Bi),e(Bi,Oa),e(Oa,Uh),e(Oa,Dl),e(Dl,jh),e(Oa,Wh),e(Bi,Mh),e(j,Bh),e(j,Fi),e(Fi,Aa),e(Aa,Fh),e(Aa,Rl),e(Rl,Yh),e(Aa,Xh),e(Fi,Zh),c(a,En,p),c(a,Et,p),e(Et,yt),e(yt,Tl),e(Et,Kh),c(a,yn,p),c(a,Yi,p),e(Yi,Vh),c(a,wn,p),Mt(za,a,p),c(a,kn,p),c(a,wt,p),e(wt,kt),e(kt,Sl),e(wt,Qh),c(a,Dn,p),c(a,Dt,p),e(Dt,Jh),e(Dt,La),e(La,$h),e(Dt,em),c(a,Rn,p),c(a,Rt,p),e(Rt,tm),e(Rt,Ol),e(Ol,am),e(Rt,im),c(a,Tn,p),c(a,le,p),e(le,Xi),e(Xi,om),e(Xi,Al),e(Al,rm),e(le,lm),e(le,Ia),e(Ia,sm),e(Ia,zl),e(zl,nm),e(Ia,cm),e(le,fm),e(le,se),e(se,um),e(se,Ll),e(Ll,dm),e(se,pm),e(se,Il),e(Il,hm),e(se,mm),e(se,Pl),e(Pl,gm),e(se,vm),e(se,Cl),e(Cl,_m),e(se,bm),e(se,Nl),e(Nl,Em),e(le,ym),e(le,Zi),e(Zi,wm),e(Zi,ql),e(ql,km),e(le,Dm),e(le,Tt),e(Tt,Rm),e(Tt,xl),e(xl,Tm),e(Tt,Sm),e(Tt,Gl),e(Gl,Om),c(a,Sn,p),c(a,Ae,p),e(Ae,Am),e(Ae,Hl),e(Hl,zm),e(Ae,Lm),e(Ae,Ul),e(Ul,Im),e(Ae,Pm),c(a,On,p),c(a,me,p),e(me,K),e(K,Cm),e(K,jl),e(jl,Nm),e(K,qm),e(K,Wl),e(Wl,xm),e(K,Gm),e(K,Ml),e(Ml,Hm),e(K,Um),e(K,Bl),e(Bl,jm),e(K,Wm),e(K,Fl),e(Fl,Mm),e(K,Bm),e(K,Yl),e(Yl,Fm),e(K,Ym),e(K,Xl),e(Xl,Xm),e(K,Zm),e(K,Zl),e(Zl,Km),e(me,Vm),e(me,oe),e(oe,Qm),e(oe,Kl),e(Kl,Jm),e(oe,$m),e(oe,Vl),e(Vl,eg),e(oe,tg),e(oe,Ql),e(Ql,ag),e(oe,ig),e(oe,Jl),e(Jl,og),e(oe,rg),e(oe,$l),e($l,lg),e(oe,sg),e(oe,es),e(es,ng),e(me,cg),e(me,ts),e(ts,fg),e(me,ug),e(me,as),e(as,dg),c(a,An,p),c(a,St,p),e(St,Ot),e(Ot,is),e(St,pg),c(a,zn,p),c(a,ge,p),e(ge,Ki),e(Ki,os),e(os,hg),e(Ki,mg),e(ge,gg),e(ge,Vi),e(Vi,rs),e(rs,vg),e(Vi,_g),e(ge,bg),e(ge,Qi),e(Qi,ls),e(ls,Eg),e(Qi,yg),e(ge,wg),e(ge,Ji),e(Ji,ss),e(ss,kg),e(Ji,Dg),c(a,Ln,p),c(a,$i,p),e($i,Rg),c(a,In,p),c(a,Pa,p),e(Pa,Ca),c(a,Pn,p),c(a,At,p),e(At,zt),e(zt,ns),e(At,Tg),c(a,Cn,p),c(a,eo,p),e(eo,Sg),c(a,Nn,p),c(a,ze,p),e(ze,Na),e(Na,Og),e(Na,cs),e(cs,Ag),e(Na,zg),e(ze,Lg),e(ze,qa),e(qa,Ig),e(qa,fs),e(fs,Pg),e(qa,Cg),e(ze,Ng),e(ze,us),e(us,qg),c(a,qn,p),c(a,We,p),e(We,ds),e(ds,Me),e(Me,ps),e(ps,xg),e(Me,Gg),e(Me,hs),e(hs,Hg),e(Me,Ug),e(Me,ms),e(ms,jg),e(We,Wg),e(We,Ee),e(Ee,Be),e(Be,to),e(to,Mg),e(Be,Bg),e(Be,ao),e(ao,Fg),e(Be,Yg),e(Be,io),e(io,Xg),e(Ee,Zg),e(Ee,Fe),e(Fe,oo),e(oo,Kg),e(Fe,Vg),e(Fe,ro),e(ro,Qg),e(Fe,Jg),e(Fe,lo),e(lo,$g),e(Ee,ev),e(Ee,Ye),e(Ye,so),e(so,tv),e(Ye,av),e(Ye,no),e(no,iv),e(Ye,ov),e(Ye,Lt),e(Lt,rv),e(Lt,gs),e(gs,lv),e(Lt,sv),e(Ee,nv),e(Ee,Xe),e(Xe,co),e(co,cv),e(Xe,fv),e(Xe,fo),e(fo,uv),e(Xe,dv),e(Xe,uo),e(uo,pv),c(a,xn,p),c(a,It,p),e(It,Pt),e(Pt,vs),e(It,hv),c(a,Gn,p),c(a,po,p),e(po,mv),c(a,Hn,p),c(a,ho,p),e(ho,gv),c(a,Un,p),c(a,xa,p),e(xa,Ga),c(a,jn,p),c(a,mo,p),e(mo,vv),c(a,Wn,p),ye&&ye.m(a,p),c(a,Mn,p),Bn=!0},p(a,p){CE&&ye.p(a,p)},i(a){Bn||(Ce(h.$$.fragment,a),Ce(A.$$.fragment,a),Ce(ia.$$.fragment,a),Ce(la.$$.fragment,a),Ce(za.$$.fragment,a),Ce(ye),Bn=!0)},o(a){Ne(h.$$.fragment,a),Ne(A.$$.fragment,a),Ne(ia.$$.fragment,a),Ne(la.$$.fragment,a),Ne(za.$$.fragment,a),Ne(ye),Bn=!1},d(a){a&&t(n),a&&t(m),Bt(h,a),a&&t(v),a&&t(b),a&&t(w),a&&t(E),a&&t(I),a&&t(z),a&&t(S),Bt(A,a),a&&t(O),a&&t(C),a&&t(V),a&&t(M),a&&t(W),a&&t(q),a&&t(H),a&&t(Y),a&&t(Es),a&&t(ei),a&&t(ys),a&&t(ti),a&&t(ws),a&&t(Yt),a&&t(ks),a&&t(Xt),a&&t(Ds),a&&t(Zt),a&&t(Rs),a&&t(Kt),a&&t(Ts),a&&t(Vt),a&&t(Ss),a&&t(Ke),a&&t(Os),a&&t(Qe),a&&t(As),a&&t(ii),a&&t(zs),a&&t(oi),a&&t(Ls),a&&t(Ue),a&&t(Is),a&&t(Je),a&&t(Ps),a&&t(et),a&&t(Cs),a&&t(pe),a&&t(Ns),a&&t(aa),a&&t(qs),a&&t(hi),a&&t(xs),Bt(ia,a),a&&t(Gs),a&&t(tt),a&&t(Hs),a&&t(it),a&&t(Us),a&&t(Re),a&&t(js),a&&t(Q),a&&t(Ws),a&&t(Te),a&&t(Ms),Bt(la,a),a&&t(Bs),a&&t(rt),a&&t(Fs),a&&t(vi),a&&t(Ys),a&&t(he),a&&t(Xs),a&&t(st),a&&t(Zs),a&&t(ct),a&&t(Ks),a&&t(ua),a&&t(Vs),a&&t(Se),a&&t(Qs),a&&t(da),a&&t(Js),a&&t(ft),a&&t($s),a&&t(ut),a&&t(en),a&&t(wi),a&&t(tn),a&&t(pa),a&&t(an),a&&t(pt),a&&t(on),a&&t(mt),a&&t(rn),a&&t(ha),a&&t(ln),a&&t(Di),a&&t(sn),a&&t(ma),a&&t(nn),a&&t(ie),a&&t(cn),a&&t(Oe),a&&t(fn),a&&t(Ri),a&&t(un),a&&t(gt),a&&t(dn),a&&t(Oi),a&&t(pn),a&&t(ga),a&&t(hn),a&&t(vt),a&&t(mn),a&&t(bt),a&&t(gn),a&&t(je),a&&t(vn),a&&t(Ci),a&&t(_n),a&&t(_a),a&&t(bn),a&&t(j),a&&t(En),a&&t(Et),a&&t(yn),a&&t(Yi),a&&t(wn),Bt(za,a),a&&t(kn),a&&t(wt),a&&t(Dn),a&&t(Dt),a&&t(Rn),a&&t(Rt),a&&t(Tn),a&&t(le),a&&t(Sn),a&&t(Ae),a&&t(On),a&&t(me),a&&t(An),a&&t(St),a&&t(zn),a&&t(ge),a&&t(Ln),a&&t($i),a&&t(In),a&&t(Pa),a&&t(Pn),a&&t(At),a&&t(Cn),a&&t(eo),a&&t(Nn),a&&t(ze),a&&t(qn),a&&t(We),a&&t(xn),a&&t(It),a&&t(Gn),a&&t(po),a&&t(Hn),a&&t(ho),a&&t(Un),a&&t(xa),a&&t(jn),a&&t(mo),a&&t(Wn),ye&&ye.d(a),a&&t(Mn)}}}function Ry(_){let n,g;const m=[_[0],p_];let h={$$slots:{default:[Dy]},$$scope:{ctx:_}};for(let v=0;v<m.length;v+=1)h=d_(h,m[v]);return n=new VE({props:h}),{c(){jt(n.$$.fragment)},l(v){Wt(n.$$.fragment,v)},m(v,b){Mt(n,v,b),g=!0},p(v,[b]){const y=b&1?KE(m,[b&1&&SE(v[0]),b&0&&SE(p_)]):{};b&2&&(y.$$scope={dirty:b,ctx:v}),n.$set(y)},i(v){g||(Ce(n.$$.fragment,v),g=!0)},o(v){Ne(n.$$.fragment,v),g=!1},d(v){Bt(n,v)}}}const p_={title:"Action Figure Art",date:"2025-01-28",modifiedDate:"2025-01-28",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription."},{title:Gy,date:Hy,modifiedDate:Uy,categories:jy,svg:Wy,seoImage:My,shortDescription:By,author:Fy,spacelab:CE,id:Ty,spacelabDefaultTitle:Sy,spacelabDefaultContent:Oy}=p_;function Ay(_,n,g){return _.$$set=m=>{g(0,n=d_(d_({},n),OE(m)))},n=OE(n),[n]}class Yy extends Sc{constructor(n){super(),Oc(this,n,Ay,Ry,Ac,{})}}export{Yy as default,p_ as metadata};
