import{S as Tv,i as Rv,s as Sv,l as wf,g as f,E as J7,d as t,v as aL,e as a,t as o,c as l,a as r,h as n,b as i,G as e,j as ce,k as c,m as u,F as ee,H as Re,N as RA,Y as lL,J as Ut,f as Mt,Z as rL,_ as iL,$ as oL,q as Bt,o as Wt,O as nL,w as lr,x as rr,y as ir,B as or,C as $7,z as cL,A as SA,a1 as DA}from"../../chunks/index-2a82a4a8.js";import{P as uL}from"../../chunks/_post-913f18eb.js";import{g as X7}from"../../chunks/config-201c2df4.js";import{a as Z7}from"../../chunks/accountStore-3492c591.js";/* empty css                                                                   */import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function fL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A;function S(L,H){return typeof L[2].title!="undefined"?hL:pL}let O=S(_),z=O(_);function Q(L,H){return typeof L[2].description!="undefined"?mL:gL}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&AA(_),C=typeof _[2].footer_description!="undefined"&&LA(_);return{c(){p=a("hr"),m=c(),g=a("div"),z.c(),h=c(),v=a("p"),k=a("ion-icon"),b=o("SpaceLab Content"),w=c(),F.c(),T=c(),B&&B.c(),x=c(),C&&C.c(),E=c(),y=a("button"),I=a("ion-icon"),P=c(),N=a("span"),G=o("SpaceLab"),this.h()},l(L){p=l(L,"HR",{}),m=u(L),g=l(L,"DIV",{class:!0});var H=r(g);z.l(H),h=u(H),v=l(H,"P",{class:!0});var Z=r(v);k=l(Z,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),b=n(Z,"SpaceLab Content"),Z.forEach(t),w=u(H),F.l(H),T=u(H),B&&B.l(H),x=u(H),C&&C.l(H),E=u(H),y=l(H,"BUTTON",{class:!0});var q=r(y);I=l(q,"ION-ICON",{class:!0,name:!0}),r(I).forEach(t),P=u(q),N=l(q,"SPAN",{});var R=r(N);G=n(R,"SpaceLab"),R.forEach(t),q.forEach(t),H.forEach(t),this.h()},h(){ee(k,"class","icon svelte-s12rf8"),ee(k,"name","lock-closed"),i(v,"class","highlight large svelte-s12rf8"),ee(I,"class","icon svelte-s12rf8"),ee(I,"name","planet"),i(y,"class","button subscribe svelte-s12rf8"),i(g,"class","subscribe svelte-s12rf8")},m(L,H){f(L,p,H),f(L,m,H),f(L,g,H),z.m(g,null),e(g,h),e(g,v),e(v,k),e(v,b),e(g,w),F.m(g,null),e(g,T),B&&B.m(g,null),e(g,x),C&&C.m(g,null),e(g,E),e(g,y),e(y,I),e(y,P),e(y,N),e(N,G),D||(A=Re(y,"click",_[15]),D=!0)},p(L,H){O===(O=S(L))&&z?z.p(L,H):(z.d(1),z=O(L),z&&(z.c(),z.m(g,h))),j===(j=Q(L))&&F?F.p(L,H):(F.d(1),F=j(L),F&&(F.c(),F.m(g,T))),typeof L[2].list_description!="undefined"?B?B.p(L,H):(B=AA(L),B.c(),B.m(g,x)):B&&(B.d(1),B=null),typeof L[2].footer_description!="undefined"?C?C.p(L,H):(C=LA(L),C.c(),C.m(g,E)):C&&(C.d(1),C=null)},d(L){L&&t(p),L&&t(m),L&&t(g),z.d(),F.d(),B&&B.d(),C&&C.d(),D=!1,A()}}}function dL(_){let p,m,g,h=_[2].title+"",v,k,b,w,T,x,E,y=_[2].description+"",I,P,N,G,D,A,S,O,z,Q,j,F,B,C=typeof _[2].list_description!="undefined"&&IA(_),L=typeof _[2].footer_description!="undefined"&&PA(_);function H(R,M){if(R[2].github_private_repo&&R[2].github_state==="LOG_EXISTS")return kL;if(R[2].github_private_repo&&R[2].github_state==="NO_LOGS")return _L;if(R[2].github_private_repo&&R[2].github_state==="NO_GITHUB_USERNAME")return vL}let Z=H(_),q=Z&&Z(_);return{c(){p=a("hr"),m=c(),g=a("h2"),v=o(h),k=c(),b=a("p"),w=a("ion-icon"),T=o("SpaceLab Content"),x=c(),E=a("p"),I=o(y),P=c(),C&&C.c(),N=c(),L&&L.c(),G=c(),D=a("button"),A=a("ion-icon"),S=c(),O=a("span"),z=o("Download"),Q=c(),q&&q.c(),j=wf(),this.h()},l(R){p=l(R,"HR",{}),m=u(R),g=l(R,"H2",{class:!0});var M=r(g);v=n(M,h),M.forEach(t),k=u(R),b=l(R,"P",{class:!0});var jt=r(b);w=l(jt,"ION-ICON",{class:!0,name:!0}),r(w).forEach(t),T=n(jt,"SpaceLab Content"),jt.forEach(t),x=u(R),E=l(R,"P",{class:!0});var Se=r(E);I=n(Se,y),Se.forEach(t),P=u(R),C&&C.l(R),N=u(R),L&&L.l(R),G=u(R),D=l(R,"BUTTON",{class:!0});var fe=r(D);A=l(fe,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),S=u(fe),O=l(fe,"SPAN",{});var Tf=r(O);z=n(Tf,"Download"),Tf.forEach(t),fe.forEach(t),Q=u(R),q&&q.l(R),j=wf(),this.h()},h(){i(g,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","planet-sharp"),i(b,"class","highlight large svelte-s12rf8"),i(E,"class","svelte-s12rf8"),ee(A,"class","icon svelte-s12rf8"),ee(A,"name","cloud-download"),i(D,"class","button svelte-s12rf8")},m(R,M){f(R,p,M),f(R,m,M),f(R,g,M),e(g,v),f(R,k,M),f(R,b,M),e(b,w),e(b,T),f(R,x,M),f(R,E,M),e(E,I),f(R,P,M),C&&C.m(R,M),f(R,N,M),L&&L.m(R,M),f(R,G,M),f(R,D,M),e(D,A),e(D,S),e(D,O),e(O,z),f(R,Q,M),q&&q.m(R,M),f(R,j,M),F||(B=Re(D,"click",_[10]),F=!0)},p(R,M){M&4&&h!==(h=R[2].title+"")&&ce(v,h),M&4&&y!==(y=R[2].description+"")&&ce(I,y),typeof R[2].list_description!="undefined"?C?C.p(R,M):(C=IA(R),C.c(),C.m(N.parentNode,N)):C&&(C.d(1),C=null),typeof R[2].footer_description!="undefined"?L?L.p(R,M):(L=PA(R),L.c(),L.m(G.parentNode,G)):L&&(L.d(1),L=null),Z===(Z=H(R))&&q?q.p(R,M):(q&&q.d(1),q=Z&&Z(R),q&&(q.c(),q.m(j.parentNode,j)))},d(R){R&&t(p),R&&t(m),R&&t(g),R&&t(k),R&&t(b),R&&t(x),R&&t(E),R&&t(P),C&&C.d(R),R&&t(N),L&&L.d(R),R&&t(G),R&&t(D),R&&t(Q),q&&q.d(R),R&&t(j),F=!1,B()}}}function pL(_){let p,m;return{c(){p=a("h2"),m=o(_[0]),this.h()},l(g){p=l(g,"H2",{class:!0});var h=r(p);m=n(h,_[0]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&1&&ce(m,g[0])},d(g){g&&t(p)}}}function hL(_){let p,m=_[2].title+"",g;return{c(){p=a("h2"),g=o(m),this.h()},l(h){p=l(h,"H2",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].title+"")&&ce(g,m)},d(h){h&&t(p)}}}function gL(_){let p,m;return{c(){p=a("p"),m=o(_[1]),this.h()},l(g){p=l(g,"P",{class:!0});var h=r(p);m=n(h,_[1]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&2&&ce(m,g[1])},d(g){g&&t(p)}}}function mL(_){let p,m=_[2].description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].description+"")&&ce(g,m)},d(h){h&&t(p)}}}function AA(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function LA(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function IA(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function PA(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function vL(_){let p,m,g,h,v,k;function b(x,E){return x[5]?bL:EL}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{class:!0});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[8]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function _L(_){let p,m,g,h,v,k;function b(x,E){return x[5]?yL:xL}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[7]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function kL(_){var A;let p,m,g,h,v,k,b=((A=_[6].profile)==null?void 0:A.githubUsername)+"",w,T,x,E,y,I,P,N,G,D;return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("p"),v=o("Your GitHub account "),k=a("span"),w=o(b),T=o(` is
			linked to this content.`),x=c(),E=a("button"),y=a("ion-icon"),I=c(),P=a("span"),N=o("Open Repository"),this.h()},l(S){p=l(S,"H2",{class:!0});var O=r(p);m=n(O,"Private GitHub Access"),O.forEach(t),g=u(S),h=l(S,"P",{class:!0});var z=r(h);v=n(z,"Your GitHub account "),k=l(z,"SPAN",{class:!0});var Q=r(k);w=n(Q,b),Q.forEach(t),T=n(z,` is
			linked to this content.`),z.forEach(t),x=u(S),E=l(S,"BUTTON",{class:!0});var j=r(E);y=l(j,"ION-ICON",{class:!0,name:!0}),r(y).forEach(t),I=u(j),P=l(j,"SPAN",{});var F=r(P);N=n(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(k,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(y,"class","icon svelte-s12rf8"),ee(y,"name","rocket-sharp"),i(E,"class","svelte-s12rf8")},m(S,O){f(S,p,O),e(p,m),f(S,g,O),f(S,h,O),e(h,v),e(h,k),e(k,w),e(h,T),f(S,x,O),f(S,E,O),e(E,y),e(E,I),e(E,P),e(P,N),G||(D=Re(E,"click",_[11]),G=!0)},p(S,O){var z;O&64&&b!==(b=((z=S[6].profile)==null?void 0:z.githubUsername)+"")&&ce(w,b)},d(S){S&&t(p),S&&t(g),S&&t(h),S&&t(x),S&&t(E),G=!1,D()}}}function EL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G;return{c(){p=a("p"),m=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),g=c(),h=a("label"),v=o("Github username:"),k=c(),b=a("input"),T=c(),x=a("button"),E=a("ion-icon"),y=c(),I=a("span"),P=o("Request Permission"),this.h()},l(D){p=l(D,"P",{class:!0});var A=r(p);m=n(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),g=u(D),h=l(D,"LABEL",{for:!0});var S=r(h);v=n(S,"Github username:"),S.forEach(t),k=u(D),b=l(D,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),T=u(D),x=l(D,"BUTTON",{class:!0});var O=r(x);E=l(O,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=u(O),I=l(O,"SPAN",{});var z=r(I);P=n(z,"Request Permission"),z.forEach(t),O.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"for","username"),i(b,"name","username"),i(b,"id","username"),i(b,"placeholder","enter a username"),i(b,"type","text"),b.required="true",i(b,"class",w=_[4]?"validation-error":""),ee(E,"class","icon svelte-s12rf8"),ee(E,"name","rocket-sharp"),i(x,"class","svelte-s12rf8")},m(D,A){f(D,p,A),e(p,m),f(D,g,A),f(D,h,A),e(h,v),f(D,k,A),f(D,b,A),RA(b,_[3]),f(D,T,A),f(D,x,A),e(x,E),e(x,y),e(x,I),e(I,P),N||(G=Re(b,"input",_[14]),N=!0)},p(D,A){A&16&&w!==(w=D[4]?"validation-error":"")&&i(b,"class",w),A&8&&b.value!==D[3]&&RA(b,D[3])},d(D){D&&t(p),D&&t(g),D&&t(h),D&&t(k),D&&t(b),D&&t(T),D&&t(x),N=!1,G()}}}function bL(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[13]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function xL(_){var I;let p,m,g,h=((I=_[6].profile)==null?void 0:I.githubUsername)+"",v,k,b,w,T,x,E,y;return{c(){p=a("p"),m=o("This content can grant access to a private GitHub repository. Allow "),g=a("span"),v=o(h),k=o(" access to this repo?"),b=c(),w=a("button"),T=a("ion-icon"),x=c(),E=a("span"),y=o("Request Permission"),this.h()},l(P){p=l(P,"P",{class:!0});var N=r(p);m=n(N,"This content can grant access to a private GitHub repository. Allow "),g=l(N,"SPAN",{class:!0});var G=r(g);v=n(G,h),G.forEach(t),k=n(N," access to this repo?"),N.forEach(t),b=u(P),w=l(P,"BUTTON",{class:!0});var D=r(w);T=l(D,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),x=u(D),E=l(D,"SPAN",{});var A=r(E);y=n(A,"Request Permission"),A.forEach(t),D.forEach(t),this.h()},h(){i(g,"class","highlight svelte-s12rf8"),i(p,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","rocket-sharp"),i(w,"class","svelte-s12rf8")},m(P,N){f(P,p,N),e(p,m),e(p,g),e(g,v),e(p,k),f(P,b,N),f(P,w,N),e(w,T),e(w,x),e(w,E),e(E,y)},p(P,N){var G;N&64&&h!==(h=((G=P[6].profile)==null?void 0:G.githubUsername)+"")&&ce(v,h)},d(P){P&&t(p),P&&t(b),P&&t(w)}}}function yL(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[12]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function wL(_){let p;function m(v,k){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?dL:fL}let g=m(_),h=g(_);return{c(){h.c(),p=wf()},l(v){h.l(v),p=wf()},m(v,k){h.m(v,k),f(v,p,k)},p(v,[k]){g===(g=m(v))&&h?h.p(v,k):(h.d(1),h=g(v),h&&(h.c(),h.m(p.parentNode,p)))},i:J7,o:J7,d(v){h.d(v),v&&t(p)}}}function Q7(_){window.open(_,"_blank")||window.location.replace(_)}function TL(_,p,m){let{id:g}=p,{spacelabDefaultTitle:h="Spacelab Content"}=p,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=p,k={},b="",w=!1,T="",x;Z7.subscribe(S=>{m(6,x=S)}),aL(async()=>{if(typeof(x==null?void 0:x.token)!="undefined"){const S=await fetch(`${X7().serviceUrl}/education/spacelab/${g}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors"});if(S.status===401){Z7.set({}),Z7.deleteLocalStorage();return}let O=await S.json();m(2,k=O)}else m(2,k.success=!1,k)});async function E(S){S.preventDefault();const O={};try{const z=await fetch(`${X7().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}async function y(S){if(S.preventDefault(),!b.trim()){m(4,w=!0),m(5,T="Please enter a valid GitHub username.");return}m(4,w=!1);const O={github_username:b};try{const z=await fetch(`${X7().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}const I=()=>window.open(k.url,"_blank"),P=()=>Q7(`https://github.com/${k.github_repo_name}`),N=()=>Q7(`https://github.com/${k.github_repo_name}`),G=()=>Q7(`https://github.com/${k.github_repo_name}`);function D(){b=this.value,m(3,b)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=S=>{"id"in S&&m(9,g=S.id),"spacelabDefaultTitle"in S&&m(0,h=S.spacelabDefaultTitle),"spacelabDefaultContent"in S&&m(1,v=S.spacelabDefaultContent)},[h,v,k,b,w,T,x,E,y,g,I,P,N,G,D,A]}class RL extends Tv{constructor(p){super(),Rv(this,p,TL,wL,Sv,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const SL=_=>({}),OA=_=>({});function DL(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function AL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P;const N=_[7]["slider-label"],G=lL(N,_,_[6],OA),D=G||DL();return{c(){p=a("div"),m=a("img"),h=c(),v=a("img"),b=c(),w=a("label"),T=a("span"),D&&D.c(),x=c(),E=a("input"),this.h()},l(A){p=l(A,"DIV",{class:!0,style:!0,"data-testid":!0});var S=r(p);m=l(S,"IMG",{src:!0,alt:!0,class:!0}),h=u(S),v=l(S,"IMG",{src:!0,alt:!0,class:!0}),b=u(S),w=l(S,"LABEL",{class:!0});var O=r(w);T=l(O,"SPAN",{class:!0});var z=r(T);D&&D.l(z),z.forEach(t),x=u(O),E=l(O,"INPUT",{type:!0,min:!0,max:!0,class:!0}),O.forEach(t),S.forEach(t),this.h()},h(){Ut(m.src,g=_[0])||i(m,"src",g),i(m,"alt",_[1]),i(m,"class","left-img svelte-1po6qlg"),Ut(v.src,k=_[2])||i(v,"src",k),i(v,"alt",_[3]),i(v,"class","right-img svelte-1po6qlg"),i(T,"class","visually-hidden svelte-1po6qlg"),i(E,"type","range"),i(E,"min","0"),i(E,"max","100"),E.value=_[4],i(E,"class","svelte-1po6qlg"),i(w,"class","svelte-1po6qlg"),i(p,"class","svelte-compare-image-container svelte-1po6qlg"),Mt(p,"--slider-position",_[4]+"%"),i(p,"data-testid","svelte-compare-image")},m(A,S){f(A,p,S),e(p,m),e(p,h),e(p,v),e(p,b),e(p,w),e(w,T),D&&D.m(T,null),e(w,x),e(w,E),y=!0,I||(P=[Re(E,"input",_[5]),Re(E,"change",_[5]),Re(E,"click",LL)],I=!0)},p(A,[S]){(!y||S&1&&!Ut(m.src,g=A[0]))&&i(m,"src",g),(!y||S&2)&&i(m,"alt",A[1]),(!y||S&4&&!Ut(v.src,k=A[2]))&&i(v,"src",k),(!y||S&8)&&i(v,"alt",A[3]),G&&G.p&&(!y||S&64)&&rL(G,N,A,A[6],y?oL(N,A[6],S,SL):iL(A[6]),OA),(!y||S&16)&&(E.value=A[4]),(!y||S&16)&&Mt(p,"--slider-position",A[4]+"%")},i(A){y||(Bt(D,A),y=!0)},o(A){Wt(D,A),y=!1},d(A){A&&t(p),D&&D.d(A),I=!1,nL(P)}}}function LL(_){_.target.focus()}function IL(_,p,m){let{$$slots:g={},$$scope:h}=p,{imageLeftSrc:v=""}=p,{imageLeftAlt:k=""}=p,{imageRightSrc:b=""}=p,{imageRightAlt:w=""}=p,T=50,x=null;function E(y){x&&cancelAnimationFrame(x),x=requestAnimationFrame(()=>{m(4,T=y.target.valueAsNumber)})}return _.$$set=y=>{"imageLeftSrc"in y&&m(0,v=y.imageLeftSrc),"imageLeftAlt"in y&&m(1,k=y.imageLeftAlt),"imageRightSrc"in y&&m(2,b=y.imageRightSrc),"imageRightAlt"in y&&m(3,w=y.imageRightAlt),"$$scope"in y&&m(6,h=y.$$scope)},[v,k,b,w,T,E,h,g]}class PL extends Tv{constructor(p){super(),Rv(this,p,IL,AL,Sv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function OL(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function zL(_){let p,m,g,h;return m=new PL({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[OL]},$$scope:{ctx:_}}}),{c(){p=a("div"),g=a("div"),lr(m.$$.fragment),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);g=l(k,"DIV",{style:!0});var b=r(g);rr(m.$$.fragment,b),k.forEach(t),this.h()},h(){Mt(g,"display","contents"),Mt(g,"--handle-size","2.5rem"),Mt(g,"--handle-background-color","rgba(0, 0, 0, 0.6)"),Mt(g,"--handle-background-image",_[4]),Mt(g,"--handle-border-width","0.125rem"),Mt(g,"--slider-color","#ffffff"),Mt(g,"--slider-width","0.125rem"),i(p,"class","image-compare-container svelte-s79nww")},m(v,k){f(v,p,k),e(p,g),ir(m,g,null),h=!0},p(v,[k]){const b={};k&1&&(b.imageLeftSrc=v[0]),k&2&&(b.imageLeftAlt=v[1]),k&4&&(b.imageRightSrc=v[2]),k&8&&(b.imageRightAlt=v[3]),k&32&&(b.$$scope={dirty:k,ctx:v}),m.$set(b)},i(v){h||(Bt(m.$$.fragment,v),h=!0)},o(v){Wt(m.$$.fragment,v),h=!1},d(v){v&&t(p),or(m)}}}function NL(_,p,m){const g=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=p,{imageLeftAlt:v="left"}=p,{imageRightSrc:k="https://via.placeholder.com/512x512/00aaff/ffffff/"}=p,{imageRightAlt:b="right"}=p;return _.$$set=w=>{"imageLeftSrc"in w&&m(0,h=w.imageLeftSrc),"imageLeftAlt"in w&&m(1,v=w.imageLeftAlt),"imageRightSrc"in w&&m(2,k=w.imageRightSrc),"imageRightAlt"in w&&m(3,b=w.imageRightAlt)},[h,v,k,b,g]}class wv extends Tv{constructor(p){super(),Rv(this,p,NL,zL,Sv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function CL(_){let p,m;return p=new RL({props:{id:qL,spacelabDefaultTitle:ML,spacelabDefaultContent:UL}}),{c(){lr(p.$$.fragment)},l(g){rr(p.$$.fragment,g)},m(g,h){ir(p,g,h),m=!0},p:J7,i(g){m||(Bt(p.$$.fragment,g),m=!0)},o(g){Wt(p.$$.fragment,g),m=!1},d(g){or(p,g)}}}function GL(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A,S,O,z,Q,j,F,B,C,L,H,Z,q,R,M,jt,Se,fe,Tf,qp,nr,Dv,Mp,Ft,Vt,Rf,Av,Up,cr,Lv,Bp,qa,ur,Iv,Wp,Ma,jp,fr,Pv,Fp,dr,Ov,Vp,pr,zv,Yp,At,hr,De,gr,Nv,Cv,mr,Gv,Hv,vr,qv,Mv,Ae,Le,_r,Sf,Uv,Bv,kr,Wv,jv,Er,Fv,Vv,Ie,br,Df,Yv,Kv,xr,Xv,Zv,yr,Qv,Jv,Pe,wr,Af,$v,e2,Tr,t2,s2,Rr,a2,Kp,Sr,l2,Xp,Dr,r2,Zp,Ua,Ar,i2,Qp,Yt,Kt,Lf,o2,Jp,Ba,If,n2,c2,$p,Wa,Pf,u2,f2,eh,ja,Of,d2,p2,th,Xt,Zt,zf,h2,sh,Fa,Nf,g2,m2,ah,Va,Cf,v2,_2,lh,Ya,Gf,k2,E2,rh,Qt,Jt,Hf,b2,ih,Ka,qf,x2,y2,oh,Oe,w2,Mf,T2,R2,Uf,S2,D2,nh,ze,Lr,Bf,A2,L2,I2,Ir,Wf,P2,O2,z2,$t,jf,N2,C2,Pr,G2,H2,ch,Xa,Or,q2,uh,es,ts,Ff,Vf,M2,fh,zr,U2,dh,Ne,Nr,Yf,B2,W2,j2,Cr,Kf,F2,V2,Y2,Gr,Xf,K2,X2,ph,ss,as,Zf,Qf,Z2,hh,Lt,Hr,Ce,qr,Jf,Q2,J2,Mr,$f,$2,e_,Ur,ed,t_,s_,de,Ge,Br,td,a_,l_,Wr,r_,i_,jr,o_,n_,He,Fr,sd,c_,u_,Vr,f_,d_,Yr,p_,h_,qe,Kr,ad,g_,m_,Xr,v_,__,Zr,k_,E_,Me,Qr,ld,b_,x_,Jr,y_,w_,$r,T_,gh,ls,rs,rd,R_,mh,It,ei,is,ti,S_,D_,si,A_,L_,pe,os,ai,id,I_,P_,li,O_,z_,ns,ri,od,N_,C_,ii,G_,H_,cs,oi,nd,q_,M_,ni,U_,B_,us,ci,cd,W_,j_,ui,F_,vh,fi,V_,_h,fs,ds,ud,Y_,kh,Za,NA=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,Eh,Qa,CA=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,bh,ps,hs,fd,K_,xh,Pt,di,Ue,pi,X_,Z_,hi,Q_,J_,gi,$_,e1,he,Be,mi,t1,s1,vi,a1,l1,_i,r1,i1,We,ki,o1,n1,Ei,c1,u1,bi,f1,d1,je,xi,p1,h1,yi,g1,m1,wi,v1,_1,Fe,Ti,k1,E1,Ri,b1,x1,Si,y1,yh,Di,w1,wh,Ai,T1,Th,Li,R1,Rh,Sh,Dh,gs,ms,dd,S1,Ah,vs,D1,Ja,A1,L1,Lh,_s,ks,pd,I1,Ih,Es,P1,$a,O1,z1,Ph,el,GA=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,Oh,bs,xs,hd,N1,zh,Ve,gd,C1,G1,md,H1,q1,vd,M1,Nh,ys,ws,_d,U1,Ch,Ye,kd,B1,W1,Ed,j1,F1,bd,V1,Gh,Ts,Rs,xd,Y1,Hh,tl,yd,K1,X1,qh,sl,HA=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,Mh,Ss,Ds,wd,Z1,Uh,Ke,Td,Q1,J1,Rd,$1,ek,Sd,tk,Bh,al,Ii,sk,Wh,As,Ls,Dd,ak,jh,ll,Ad,lk,rk,Fh,Pi,ik,Vh,Xe,rl,ok,Oi,nk,ck,uk,Ld,fk,dk,Id,pk,Yh,il,zi,hk,Kh,Is,Ps,Pd,gk,Xh,ol,Od,mk,vk,Zh,nl,qA=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Qh,Ni,_k,Jh,Ze,zd,kk,Ek,Nd,bk,xk,Cd,yk,$h,cl,Ci,wk,eg,Os,zs,Gd,Tk,tg,Ns,Rk,Hd,Sk,Dk,sg,ul,MA=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,ag,fl,UA=`<code class="language-python"><span class="token comment"># Cosine Annealing Example</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>
    optimizer<span class="token punctuation">,</span>
    T_max<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># Number of iterations per cycle</span>
    eta_min<span class="token operator">=</span><span class="token number">1e-7</span>  <span class="token comment"># Minimum learning rate</span>
<span class="token punctuation">)</span></code>`,lg,dl,qd,Ak,Lk,rg,Qe,Md,Ik,Pk,Ud,Ok,zk,Bd,Nk,ig,Ot,Gi,ge,Hi,Ck,Gk,qi,Hk,qk,Mi,Mk,Uk,Ui,Bk,Wk,le,me,Bi,jk,Fk,Wi,Vk,Yk,ji,Kk,Xk,Fi,Zk,Qk,ve,Vi,Jk,$k,Yi,eE,tE,Ki,sE,aE,Xi,lE,rE,_e,Zi,iE,oE,Qi,nE,cE,Cs,uE,Wd,fE,dE,pE,Je,hE,Ji,gE,mE,$i,vE,_E,kE,ke,eo,EE,bE,to,xE,yE,so,wE,TE,ao,RE,SE,Ee,lo,DE,AE,ro,LE,IE,io,PE,OE,oo,zE,og,ng,cg,Gs,Hs,jd,NE,ug,qs,CE,no,GE,HE,fg,ue,qE,co,ME,UE,uo,BE,WE,fo,jE,FE,po,VE,dg,ho,YE,pg,Ms,Us,Fd,KE,hg,$e,Vd,pl,Yd,XE,ZE,QE,JE,Kd,hl,Xd,$E,eb,tb,sb,Zd,gl,Qd,ab,lb,rb,gg,ml,mg,Bs,Ws,Jd,ib,vg,js,ob,vl,nb,cb,_g,et,ub,go,fb,db,mo,pb,hb,kg,J,$d,vo,gb,_o,mb,vb,ep,_l,_b,ko,kb,Eb,bb,tp,Y,xb,Eo,yb,wb,bo,Tb,Rb,xo,Sb,Db,yo,Ab,Lb,wo,Ib,Pb,To,Ob,zb,Ro,Nb,Cb,So,Gb,Hb,sp,$,qb,Do,Mb,Ub,Ao,Bb,Wb,Lo,jb,Fb,Io,Vb,Yb,Po,Kb,Xb,Oo,Zb,Qb,zo,Jb,$b,ap,K,ex,No,tx,sx,Co,ax,lx,Go,rx,ix,Ho,ox,nx,qo,cx,ux,Mo,fx,dx,Uo,px,hx,Bo,gx,mx,lp,Wo,vx,jo,_x,kx,rp,Fs,Ex,Fo,bx,xx,Vo,yx,Eg,tt,wx,Yo,Tx,Rx,Ko,Sx,Dx,bg,kl,xg,Vs,Ys,ip,Ax,yg,Xo,Lx,wg,be,Zo,El,Ix,Px,Ox,Qo,bl,zx,Nx,Cx,Jo,xl,Gx,Hx,qx,$o,yl,Mx,Ux,Tg,Ks,Xs,op,Bx,Rg,en,Wx,Sg,tn,jx,Dg,st,Zs,np,Fx,Vx,sn,Yx,Kx,Xx,at,cp,Zx,Qx,an,Jx,$x,ln,ey,ty,sy,rn,up,ay,ly,Ag,wl,BA=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,Lg,Qs,Tl,ry,on,iy,oy,ny,Rl,cy,nn,uy,fy,Ig,Js,cn,dy,un,py,hy,Sl,gy,fn,my,vy,Pg,$s,ea,fp,_y,Og,ta,ky,Dl,Ey,by,zg,Al,sa,xy,Ll,yy,wy,Ng,aa,la,dp,Ty,Cg,ra,Ry,dn,Sy,Dy,Gg,Il,WA=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Hg,pn,Ay,qg,Pl,jA='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Mg,lt,Ly,hn,Iy,Py,gn,Oy,zy,Ug,rt,Ny,mn,Cy,Gy,vn,Hy,qy,Bg,_n,My,Wg,ia,kn,Uy,pp,hp,By,Wy,En,jy,gp,mp,Fy,jg,bn,Vy,Fg,Ol,zl,t6,Vg,oa,na,vp,Yy,Yg,zt,Ky,xn,Xy,Zy,yn,Qy,Kg,Nt,wn,re,Tn,Jy,$y,Rn,e3,t3,Sn,s3,a3,Dn,l3,r3,An,i3,o3,Ln,ie,In,n3,c3,Pn,u3,f3,On,d3,p3,zn,h3,g3,Nn,m3,Xg,Cn,v3,Zg,Nl,FA=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Qg,U,Gn,Cl,_3,Hn,k3,E3,b3,x3,qn,Gl,y3,Mn,w3,T3,R3,S3,Un,Hl,D3,Bn,A3,L3,I3,P3,Wn,ql,O3,jn,z3,N3,C3,G3,Fn,Ml,H3,Vn,q3,M3,U3,B3,Yn,Ul,W3,Kn,j3,F3,V3,Y3,Xn,Bl,K3,Zn,X3,Z3,Q3,J3,Qn,Wl,$3,Jn,e4,t4,s4,a4,$n,jl,l4,ec,r4,i4,o4,n4,tc,Fl,c4,sc,u4,f4,d4,p4,ac,Vl,h4,lc,g4,m4,v4,Jg,ca,ua,_p,_4,$g,rc,k4,em,Yl,tm,fa,da,kp,E4,sm,pa,b4,Kl,x4,y4,am,ha,w4,ic,T4,R4,lm,oe,oc,S4,rm,D4,Ep,A4,L4,it,I4,nc,P4,O4,cc,z4,N4,uc,C4,G4,fc,H4,dc,q4,M4,ga,U4,pc,B4,W4,hc,j4,im,ot,F4,gc,V4,Y4,mc,K4,X4,om,xe,ma,Z4,vc,Q4,J4,_c,$4,e0,Xl,t0,kc,s0,a0,l0,bp,r0,i0,xp,o0,nm,va,_a,yp,n0,cm,ye,Ec,wp,c0,u0,f0,bc,Tp,d0,p0,h0,xc,Rp,g0,m0,v0,yc,Sp,_0,k0,um,wc,E0,fm,Zl,Ql,s6,dm,ka,Ea,Dp,b0,pm,Tc,x0,hm,nt,Jl,y0,Rc,w0,T0,R0,$l,S0,Sc,D0,A0,L0,Ap,I0,gm,Ct,Dc,ct,Ac,P0,O0,Lc,z0,N0,Ic,C0,G0,we,ut,Pc,H0,q0,Oc,M0,U0,zc,B0,W0,ft,Nc,j0,F0,Cc,V0,Y0,Gc,K0,X0,dt,Hc,Z0,Q0,qc,J0,$0,Mc,e5,t5,pt,Uc,s5,a5,Bc,l5,r5,Wc,i5,mm,ba,xa,Lp,o5,vm,jc,n5,_m,Gt,Fc,ht,Vc,c5,u5,Yc,f5,d5,Kc,p5,h5,W,gt,Xc,g5,m5,Zc,v5,_5,Qc,k5,E5,mt,Jc,b5,x5,$c,y5,w5,eu,T5,R5,vt,tu,S5,D5,su,A5,L5,au,I5,P5,_t,lu,O5,z5,ru,N5,C5,iu,G5,H5,kt,ou,q5,M5,nu,U5,B5,cu,W5,j5,Et,uu,F5,V5,fu,Y5,K5,du,X5,Z5,bt,pu,Q5,J5,hu,$5,ew,gu,tw,sw,xt,mu,aw,lw,vu,rw,iw,_u,ow,nw,yt,ku,cw,uw,Eu,fw,dw,bu,pw,hw,wt,xu,gw,mw,yu,vw,_w,wu,kw,km,ya,wa,Ip,Ew,Em,Tu,bw,bm,Ru,xw,xm,er,tr,a6,ym,Su,yw,wm,Ht,Ta,Pp,ww,Tm,Rm,Sm;Ma=new wv({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),ml=new wv({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),kl=new wv({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Yl=new wv({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let Te=zA&&CL();return{c(){p=a("p"),m=o("Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),g=c(),h=a("p"),v=o("I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),k=c(),b=a("h4"),w=a("a"),T=a("span"),x=o("Experiment 1: Anime-Inspired Heroism"),E=c(),y=a("p"),I=a("img"),N=c(),G=a("p"),D=o("I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),A=c(),S=a("ul"),O=a("li"),z=o("My action figure photos (for costume accuracy)."),Q=c(),j=a("li"),F=o("Stylized anime references (for anatomy and texture)."),B=c(),C=a("p"),L=o("The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),H=c(),Z=a("h4"),q=a("a"),R=a("span"),M=o("Experiment 2: Retro Cartoon Resurrection"),jt=c(),Se=a("p"),fe=a("img"),qp=c(),nr=a("p"),Dv=o("Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),Mp=c(),Ft=a("h2"),Vt=a("a"),Rf=a("span"),Av=o("What are Regularization Images?"),Up=c(),cr=a("p"),Lv=o("Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),Bp=c(),qa=a("blockquote"),ur=a("p"),Iv=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),Wp=c(),lr(Ma.$$.fragment),jp=c(),fr=a("p"),Pv=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Fp=c(),dr=a("p"),Ov=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),Vp=c(),pr=a("p"),zv=o("Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),Yp=c(),At=a("table"),hr=a("thead"),De=a("tr"),gr=a("th"),Nv=o("Aspect"),Cv=c(),mr=a("th"),Gv=o("Regularization"),Hv=c(),vr=a("th"),qv=o("No Regularization"),Mv=c(),Ae=a("tbody"),Le=a("tr"),_r=a("td"),Sf=a("strong"),Uv=o("Class Definition"),Bv=c(),kr=a("td"),Wv=o("Explicit class anchoring"),jv=c(),Er=a("td"),Fv=o("Implicit class learning"),Vv=c(),Ie=a("tr"),br=a("td"),Df=a("strong"),Yv=o("Failure Modes"),Kv=c(),xr=a("td"),Xv=o("Underfitting if overdone"),Zv=c(),yr=a("td"),Qv=o("Overfitting/drift"),Jv=c(),Pe=a("tr"),wr=a("td"),Af=a("strong"),$v=o("Data Efficiency"),e2=c(),Tr=a("td"),t2=o("Better generalization"),s2=c(),Rr=a("td"),a2=o("Requires more data"),Kp=c(),Sr=a("p"),l2=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Xp=c(),Dr=a("p"),r2=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Zp=c(),Ua=a("blockquote"),Ar=a("p"),i2=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Qp=c(),Yt=a("h4"),Kt=a("a"),Lf=a("span"),o2=o("Scenario 1: Limited Training Data"),Jp=c(),Ba=a("p"),If=a("strong"),n2=o("Situation"),c2=o(": You only have a few images of your cat and no other cat images."),$p=c(),Wa=a("p"),Pf=a("strong"),u2=o("Problem"),f2=o(": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),eh=c(),ja=a("p"),Of=a("strong"),d2=o("Solution"),p2=o(": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),th=c(),Xt=a("h4"),Zt=a("a"),zf=a("span"),h2=o("Scenario 2: Imbalanced Training Data"),sh=c(),Fa=a("p"),Nf=a("strong"),g2=o("Situation"),m2=o(": You have many images of other cats but only a few of your cat."),ah=c(),Va=a("p"),Cf=a("strong"),v2=o("Problem"),_2=o(": The model may focus too much on the other cats, failing to learn the unique features of your cat."),lh=c(),Ya=a("p"),Gf=a("strong"),k2=o("Solution"),E2=o(": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),rh=c(),Qt=a("h2"),Jt=a("a"),Hf=a("span"),b2=o("Divergence"),ih=c(),Ka=a("p"),qf=a("strong"),x2=o("Divergence"),y2=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),oh=c(),Oe=a("p"),w2=o("Preventing divergence starts with "),Mf=a("strong"),T2=o("careful dataset curation"),R2=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Uf=a("strong"),S2=o("regularization techniques"),D2=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),nh=c(),ze=a("ul"),Lr=a("li"),Bf=a("strong"),A2=o("Chaotic outputs"),L2=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),I2=c(),Ir=a("li"),Wf=a("strong"),P2=o("Exploding gradients"),O2=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),z2=c(),$t=a("li"),jf=a("strong"),N2=o("Loss value instability (NaN/infinity values)"),C2=o(" The training loss fluctuates wildly, sometimes becoming "),Pr=a("code"),G2=o("NaN"),H2=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),ch=c(),Xa=a("blockquote"),Or=a("p"),q2=o("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),uh=c(),es=a("h2"),ts=a("a"),Ff=a("span"),Vf=a("strong"),M2=o("Overfitting"),fh=c(),zr=a("p"),U2=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),dh=c(),Ne=a("ul"),Nr=a("li"),Yf=a("strong"),B2=o("Perfectly replicates training samples"),W2=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),j2=c(),Cr=a("li"),Kf=a("strong"),F2=o("Fails to generalize to new inputs"),V2=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Y2=c(),Gr=a("li"),Xf=a("strong"),K2=o("Shows excellent training loss but poor validation loss"),X2=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),ph=c(),ss=a("h3"),as=a("a"),Zf=a("span"),Qf=a("strong"),Z2=o("Key Differences"),hh=c(),Lt=a("table"),Hr=a("thead"),Ce=a("tr"),qr=a("th"),Jf=a("strong"),Q2=o("Aspect"),J2=c(),Mr=a("th"),$f=a("strong"),$2=o("Divergence"),e_=c(),Ur=a("th"),ed=a("strong"),t_=o("Overfitting"),s_=c(),de=a("tbody"),Ge=a("tr"),Br=a("td"),td=a("strong"),a_=o("Cause"),l_=c(),Wr=a("td"),r_=o("Excessive learning rate"),i_=c(),jr=a("td"),o_=o("Insufficient regularization"),n_=c(),He=a("tr"),Fr=a("td"),sd=a("strong"),c_=o("Loss Behavior"),u_=c(),Vr=a("td"),f_=o("Sudden spikes/NaN values"),d_=c(),Yr=a("td"),p_=o("Steady decrease then rise"),h_=c(),qe=a("tr"),Kr=a("td"),ad=a("strong"),g_=o("Output Quality"),m_=c(),Xr=a("td"),v_=o("Random noise/artifacts"),__=c(),Zr=a("td"),k_=o("Overly detailed replicas"),E_=c(),Me=a("tr"),Qr=a("td"),ld=a("strong"),b_=o("Recovery"),x_=c(),Jr=a("td"),y_=o("Requires restart"),w_=c(),$r=a("td"),T_=o("Early stopping works"),gh=c(),ls=a("h3"),rs=a("a"),rd=a("span"),R_=o("Preventing Divergence"),mh=c(),It=a("table"),ei=a("thead"),is=a("tr"),ti=a("th"),S_=o("Situation"),D_=c(),si=a("th"),A_=o("Outcome"),L_=c(),pe=a("tbody"),os=a("tr"),ai=a("td"),id=a("strong"),I_=o("Excessive or inconsistent data"),P_=c(),li=a("td"),O_=o("Model struggles to learn and produces unreliable predictions."),z_=c(),ns=a("tr"),ri=a("td"),od=a("strong"),N_=o("Lack of unique and consistent features"),C_=c(),ii=a("td"),G_=o("Poor generalization, leading to inaccurate or meaningless outputs."),H_=c(),cs=a("tr"),oi=a("td"),nd=a("strong"),q_=o("Carefully curated datasets"),M_=c(),ni=a("td"),U_=o("Improved learning by ensuring the model sees only relevant, high-quality data."),B_=c(),us=a("tr"),ci=a("td"),cd=a("strong"),W_=o("Effective use of regularization techniques"),j_=c(),ui=a("td"),F_=o("Helps maintain focus on essential features and prevents instability."),vh=c(),fi=a("p"),V_=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),_h=c(),fs=a("h3"),ds=a("a"),ud=a("span"),Y_=o("Implementing these Strategies"),kh=c(),Za=a("pre"),Eh=c(),Qa=a("pre"),bh=c(),ps=a("h3"),hs=a("a"),fd=a("span"),K_=o("Data Considerations"),xh=c(),Pt=a("table"),di=a("thead"),Ue=a("tr"),pi=a("th"),X_=o("Situation"),Z_=c(),hi=a("th"),Q_=o("Actual Risk"),J_=c(),gi=a("th"),$_=o("Solution"),e1=c(),he=a("tbody"),Be=a("tr"),mi=a("td"),t1=o("High LR + small batch size"),s1=c(),vi=a("td"),a1=o("Divergence"),l1=c(),_i=a("td"),r1=o("Lower LR, increase batch size"),i1=c(),We=a("tr"),ki=a("td"),o1=o("Inconsistent features"),n1=c(),Ei=a("td"),c1=o("Overfitting"),u1=c(),bi=a("td"),f1=o("Improve dataset consistency"),d1=c(),je=a("tr"),xi=a("td"),p1=o("Insufficient reg images"),h1=c(),yi=a("td"),g1=o("Class leakage"),m1=c(),wi=a("td"),v1=o("Add 100-300 class images"),_1=c(),Fe=a("tr"),Ti=a("td"),k1=o("High variance in training data"),E1=c(),Ri=a("td"),b1=o("Mode collapse"),x1=c(),Si=a("td"),y1=o("Curate focused dataset"),yh=c(),Di=a("p"),w1=o("This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs\u2014fix this by lowering the learning rate and increasing the batch size."),wh=c(),Ai=a("p"),T1=o("Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects\u2014adding 100-300 images helps."),Th=c(),Li=a("p"),R1=o("High variance in training data can result in mode collapse, producing repetitive outputs\u2014keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),Rh=c(),Sh=a("hr"),Dh=c(),gs=a("h2"),ms=a("a"),dd=a("span"),S1=o("Monitoring Tips"),Ah=c(),vs=a("p"),D1=o("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ja=a("a"),A1=o("kohya-ss/sd-scripts"),L1=o(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),Lh=c(),_s=a("h3"),ks=a("a"),pd=a("span"),I1=o("Track loss curves"),Ih=c(),Es=a("p"),P1=o("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),$a=a("a"),O1=o("TensorBoard"),z1=o(" to create these graphs."),Ph=c(),el=a("pre"),Oh=c(),bs=a("h4"),xs=a("a"),hd=a("span"),N1=o("What to Monitor:"),zh=c(),Ve=a("ul"),gd=a("li"),C1=o("Training Loss: Should decrease steadily but not too quickly."),G1=c(),md=a("li"),H1=o("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),q1=c(),vd=a("li"),M1=o("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),Nh=c(),ys=a("h4"),ws=a("a"),_d=a("span"),U1=o("Warning Signs:"),Ch=c(),Ye=a("ul"),kd=a("li"),B1=o("Sudden spikes in loss \u2192 Likely divergence."),W1=c(),Ed=a("li"),j1=o("Loss plateauing too early \u2192 Learning rate may be too low."),F1=c(),bd=a("li"),V1=o("Validation loss increasing while training loss decreases \u2192 Overfitting."),Gh=c(),Ts=a("h3"),Rs=a("a"),xd=a("span"),Y1=o("Generate validation images every 100 steps"),Hh=c(),tl=a("p"),yd=a("strong"),K1=o("Why It Matters"),X1=o(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),qh=c(),sl=a("pre"),Mh=c(),Ss=a("h4"),Ds=a("a"),wd=a("span"),Z1=o("What to Look For:"),Uh=c(),Ke=a("ul"),Td=a("li"),Q1=o("Consistency: Outputs should align with the training data style."),J1=c(),Rd=a("li"),$1=o("Artifacts: Check for distortions, noise, or unnatural features."),ek=c(),Sd=a("li"),tk=o("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),Bh=c(),al=a("blockquote"),Ii=a("p"),sk=o("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),Wh=c(),As=a("h4"),Ls=a("a"),Dd=a("span"),ak=o("Use Gradient Clipping"),jh=c(),ll=a("p"),Ad=a("strong"),lk=o("Why It Matters"),rk=o(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),Fh=c(),Pi=a("p"),ik=o("Key Insights:"),Vh=c(),Xe=a("ul"),rl=a("li"),ok=o("Gradient Norm "),Oi=a("code"),nk=o("<"),ck=o(" than 0.1: Training may stall due to tiny updates."),uk=c(),Ld=a("li"),fk=o("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),dk=c(),Id=a("li"),pk=o("Ideal Range: 0.1 to 2.0 for stable training."),Yh=c(),il=a("blockquote"),zi=a("p"),hk=o("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Kh=c(),Is=a("h4"),Ps=a("a"),Pd=a("span"),gk=o("Enable Mixed Precision Training"),Xh=c(),ol=a("p"),Od=a("strong"),mk=o("Why It Matters"),vk=o(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),Zh=c(),nl=a("pre"),Qh=c(),Ni=a("p"),_k=o("Benefits:"),Jh=c(),Ze=a("ul"),zd=a("li"),kk=o("2-3x Faster Training: Leverages GPU tensor cores."),Ek=c(),Nd=a("li"),bk=o("50% Less VRAM Usage: Allows larger batch sizes or models."),xk=c(),Cd=a("li"),yk=o("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),$h=c(),cl=a("blockquote"),Ci=a("p"),wk=o("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),eg=c(),Os=a("h4"),zs=a("a"),Gd=a("span"),Tk=o("Start with Conservative Learning Rates"),tg=c(),Ns=a("p"),Rk=o("Start off with 1e-5 to 1e-6.  "),Hd=a("strong"),Sk=o("Why It Matters"),Dk=o(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),sg=c(),ul=a("pre"),ag=c(),fl=a("pre"),lg=c(),dl=a("p"),qd=a("strong"),Ak=o("Warning Signs"),Lk=o(":"),rg=c(),Qe=a("ul"),Md=a("li"),Ik=o("Loss Spikes: Learning rate is too high."),Pk=c(),Ud=a("li"),Ok=o("Slow Convergence: Learning rate is too low."),zk=c(),Bd=a("li"),Nk=o("Oscillating Loss: Poor scheduling or unstable gradients."),ig=c(),Ot=a("table"),Gi=a("thead"),ge=a("tr"),Hi=a("th"),Ck=o("Practice"),Gk=c(),qi=a("th"),Hk=o("Key Benefit"),qk=c(),Mi=a("th"),Mk=o("Tool/Setting"),Uk=c(),Ui=a("th"),Bk=o("Warning Signs"),Wk=c(),le=a("tbody"),me=a("tr"),Bi=a("td"),jk=o("Track Loss Curves"),Fk=c(),Wi=a("td"),Vk=o("Detect overfitting/divergence early"),Yk=c(),ji=a("td"),Kk=o("TensorBoard, Weights & Biases"),Xk=c(),Fi=a("td"),Zk=o("Spikes, plateaus, growing gaps"),Qk=c(),ve=a("tr"),Vi=a("td"),Jk=o("Generate Validation Images"),$k=c(),Yi=a("td"),eE=o("Visualize model progress"),tE=c(),Ki=a("td"),sE=o("Fixed prompts/seeds"),aE=c(),Xi=a("td"),lE=o("Artifacts, mode collapse"),rE=c(),_e=a("tr"),Zi=a("td"),iE=o("Gradient Clipping"),oE=c(),Qi=a("td"),nE=o("Prevent exploding gradients"),cE=c(),Cs=a("td"),uE=o("clip"),Wd=a("em"),fE=o("grad_norm"),dE=o(" (1.0-2.0)"),pE=c(),Je=a("td"),hE=o("Norm "),Ji=a("code"),gE=o(">"),mE=o(" 10.0 or "),$i=a("code"),vE=o("<"),_E=o(" 0.1"),kE=c(),ke=a("tr"),eo=a("td"),EE=o("Mixed Precision Training"),bE=c(),to=a("td"),xE=o("Faster training, lower VRAM usage"),yE=c(),so=a("td"),wE=o("PyTorch AMP (torch.cuda.amp)"),TE=c(),ao=a("td"),RE=o("NaN values (disable if unstable)"),SE=c(),Ee=a("tr"),lo=a("td"),DE=o("Conservative Learning Rates"),AE=c(),ro=a("td"),LE=o("Stable training, avoid divergence"),IE=c(),io=a("td"),PE=o("Start at 1e-5 to 1e-6, use scheduler"),OE=c(),oo=a("td"),zE=o("Spikes, slow convergence"),og=c(),ng=a("hr"),cg=c(),Gs=a("h2"),Hs=a("a"),jd=a("span"),NE=o("Generating Regularization images"),ug=c(),qs=a("p"),CE=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),no=a("code"),GE=o("1boy"),HE=o(")."),fg=c(),ue=a("p"),qE=o("According to the Dreambooth technique, "),co=a("code"),ME=o("200"),UE=o(" regularization images per training image.  For example, if you have "),uo=a("code"),BE=o("16"),WE=o(" images: "),fo=a("code"),jE=o("200 * 16 = 3200"),FE=o(" total regularization images.  When training, the math involved for calculating total steps is: "),po=a("code"),VE=o("repeats * training images >= repeats * regularization images"),dg=c(),ho=a("p"),YE=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),pg=c(),Ms=a("h4"),Us=a("a"),Fd=a("span"),KE=o("Important considerations"),hg=c(),$e=a("ol"),Vd=a("li"),pl=a("p"),Yd=a("strong"),XE=o("Use the same base model for regularization images and training"),ZE=a("br"),QE=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),JE=c(),Kd=a("li"),hl=a("p"),Xd=a("strong"),$E=o("Maintain consistent class representation"),eb=a("br"),tb=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),sb=c(),Zd=a("li"),gl=a("p"),Qd=a("strong"),ab=o("Match output resolution to training data"),lb=a("br"),rb=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),gg=c(),lr(ml.$$.fragment),mg=c(),Bs=a("h4"),Ws=a("a"),Jd=a("span"),ib=o("Generate using Stable Diffusion web UI"),vg=c(),js=a("p"),ob=o("We\u2019re going to use "),vl=a("a"),nb=o("Stable Diffusion web UI"),cb=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),_g=c(),et=a("p"),ub=o("We\u2019re going to use the "),go=a("code"),fb=o("X/Y/Z plot"),db=o(" script to use "),mo=a("code"),pb=o("Prompt Search & Replace"),hb=o(" to dynamically build a prompt that will generate hundreds of regularization images."),kg=c(),J=a("ol"),$d=a("li"),vo=a("p"),gb=o("Select the text 2 image tab.  Enter a generic prompt "),_o=a("code"),mb=o("princeadam, portrait, looking_at_viewer, forest"),vb=c(),ep=a("li"),_l=a("p"),_b=o("In generation parameters and select the "),ko=a("code"),kb=o("X/Y/Z plot"),Eb=o(" script."),bb=c(),tp=a("li"),Y=a("p"),xb=o("Select the "),Eo=a("code"),yb=o("X"),wb=o(" parameter and "),bo=a("code"),Tb=o("Prompt SR"),Rb=o(" for Prompt Replace.  We\u2019re going to replace "),xo=a("code"),Sb=o("portrait"),Db=o(" with different camera angle tags: "),yo=a("code"),Ab=o("close-up"),Lb=o(", "),wo=a("code"),Ib=o("upper_body"),Pb=o(", "),To=a("code"),Ob=o("from_below"),zb=o(", "),Ro=a("code"),Nb=o("from_above"),Cb=o(", "),So=a("code"),Gb=o("dutch_angle"),Hb=c(),sp=a("li"),$=a("p"),qb=o("Select the "),Do=a("code"),Mb=o("Y"),Ub=o(" parameter and "),Ao=a("code"),Bb=o("Prompt SR"),Wb=o(" for Prompt Replace.  Replace "),Lo=a("code"),jb=o("looking_at_viewer"),Fb=o(": "),Io=a("code"),Vb=o("looking_away"),Yb=o(", "),Po=a("code"),Kb=o("looking_to_the_side"),Xb=o(", "),Oo=a("code"),Zb=o("looking_ahead"),Qb=o(", "),zo=a("code"),Jb=o("looking_down"),$b=c(),ap=a("li"),K=a("p"),ex=o("Select the "),No=a("code"),tx=o("Z"),sx=o(" parameter and "),Co=a("code"),ax=o("Prompt SR"),lx=o(" for Prompt Replace. Replace "),Go=a("code"),rx=o("forest"),ix=o(" with a vareity of locatinos: "),Ho=a("code"),ox=o("castle"),nx=o(", "),qo=a("code"),cx=o("mountain"),ux=o(", "),Mo=a("code"),fx=o("cave"),dx=o(", "),Uo=a("code"),px=o("farm"),hx=o(", "),Bo=a("code"),gx=o("ocean"),mx=c(),lp=a("li"),Wo=a("p"),vx=o("Select a fast sampler like "),jo=a("code"),_x=o("DPM2 KARRAS"),kx=c(),rp=a("li"),Fs=a("p"),Ex=o("CFG Scale set to "),Fo=a("code"),bx=o("7"),xx=o(" and Steps to "),Vo=a("code"),yx=o("20"),Eg=c(),tt=a("p"),wx=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Yo=a("code"),Tx=o("150"),Rx=o(" - "),Ko=a("code"),Sx=o("200"),Dx=o(" and keep in mind we can add and remove as we try different training settings with different output."),bg=c(),lr(kl.$$.fragment),xg=c(),Vs=a("h4"),Ys=a("a"),ip=a("span"),Ax=o("Download images"),yg=c(),Xo=a("p"),Lx=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),wg=c(),be=a("ul"),Zo=a("li"),El=a("a"),Ix=o("3ee Games regularization images"),Px=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),Ox=c(),Qo=a("li"),bl=a("a"),zx=o("Pre-Rendered Regularization Images"),Nx=o(": Includes 1500 regularization images."),Cx=c(),Jo=a("li"),xl=a("a"),Gx=o("Stable Diffusion 1.5 Regularization Images"),Hx=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),qx=c(),$o=a("li"),yl=a("a"),Mx=o("Aitrepreneur SDXL image set"),Ux=o(": a large image set generated with Stable Diffusion SDXL."),Tg=c(),Ks=a("h4"),Xs=a("a"),op=a("span"),Bx=o("Captioning Regularization images"),Rg=c(),en=a("p"),Wx=o("While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),Sg=c(),tn=a("p"),jx=o("Here\u2019s the workflow I used:"),Dg=c(),st=a("ul"),Zs=a("li"),np=a("strong"),Fx=o("Structured Filenames"),Vx=o(": Stable Diffusion Web UI automatically embeds prompts in filenames (e.g., "),sn=a("code"),Yx=o("princeadam_1boy_closeup.png"),Kx=o(")."),Xx=c(),at=a("li"),cp=a("strong"),Zx=o("Automated Extraction"),Qx=o(": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),an=a("code"),Jx=o("1boy"),$x=o(" or "),ln=a("code"),ey=o("purple_vest"),ty=o("."),sy=c(),rn=a("li"),up=a("strong"),ay=o("Manual Verification"),ly=o(": Spot-checked captions to ensure accuracy."),Ag=c(),wl=a("pre"),Lg=c(),Qs=a("ol"),Tl=a("li"),ry=o("Save this file as "),on=a("code"),iy=o("filename2txt.bat"),oy=o(" and place it into the regularization images directory"),ny=c(),Rl=a("li"),cy=o("Run: "),nn=a("code"),uy=o(".\\filename2txt.bat"),fy=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Ig=c(),Js=a("ul"),cn=a("li"),dy=o("Example filename: "),un=a("code"),py=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),hy=c(),Sl=a("li"),gy=o("Output: "),fn=a("code"),my=o("aburbres,princeadam,1boy,close-up,purple_vest"),vy=o(" saved in a text file with the same name as image."),Pg=c(),$s=a("h2"),ea=a("a"),fp=a("span"),_y=o("Training a LoRA"),Og=c(),ta=a("p"),ky=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),Dl=a("a"),Ey=o("kohya-ss/sd-scripts"),by=o("."),zg=c(),Al=a("blockquote"),sa=a("p"),xy=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Ll=a("a"),yy=o("Kohya SD script documentation"),wy=o("."),Ng=c(),aa=a("h3"),la=a("a"),dp=a("span"),Ty=o("Directory setup"),Cg=c(),ra=a("p"),Ry=o("In your configuration json, use "),dn=a("code"),Sy=o("reg_data_dir"),Dy=o(" to point to the directory with your regularization images:"),Gg=c(),Il=a("pre"),Hg=c(),pn=a("p"),Ay=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),qg=c(),Pl=a("pre"),Mg=c(),lt=a("p"),Ly=o("Set the "),hn=a("code"),Iy=o("number of iterations"),Py=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),gn=a("code"),Oy=o("training images \xD7 iterations"),zy=o(". If there are more regularization images than this, the extras won\u2019t be used."),Ug=c(),rt=a("p"),Ny=o("Create folders in the training image folder with the format "),mn=a("code"),Cy=o("<repetition count>_<class>"),Gy=o(" multiple times, and similarly create folders in the regularization image folder with the format "),vn=a("code"),Hy=o("<repetition count>_<class>"),qy=o("."),Bg=c(),_n=a("p"),My=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Wg=c(),ia=a("ul"),kn=a("li"),Uy=o("train_data_dir"),pp=a("ul"),hp=a("li"),By=o("10_princeadam"),Wy=c(),En=a("li"),jy=o("reg_dir"),gp=a("ul"),mp=a("li"),Fy=o("1_1boy"),jg=c(),bn=a("p"),Vy=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),Fg=c(),Ol=a("p"),zl=a("img"),Vg=c(),oa=a("h3"),na=a("a"),vp=a("span"),Yy=o("Training Settings"),Yg=c(),zt=a("p"),Ky=o("The training setup we\u2019re going to use is:  "),xn=a("code"),Xy=o("Number of images * repeats * epoch / batch size = total steps"),Zy=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),yn=a("code"),Qy=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Kg=c(),Nt=a("table"),wn=a("thead"),re=a("tr"),Tn=a("th"),Jy=o("Number of Images"),$y=c(),Rn=a("th"),e3=o("Repeats"),t3=c(),Sn=a("th"),s3=o("Epochs"),a3=c(),Dn=a("th"),l3=o("Batch Size"),r3=c(),An=a("th"),i3=o("Total Steps"),o3=c(),Ln=a("tbody"),ie=a("tr"),In=a("td"),n3=o("45"),c3=c(),Pn=a("td"),u3=o("10"),f3=c(),On=a("td"),d3=o("20"),p3=c(),zn=a("td"),h3=o("2"),g3=c(),Nn=a("td"),m3=o("4500"),Xg=c(),Cn=a("p"),v3=o("Now let\u2019s focus on these training settings:"),Zg=c(),Nl=a("pre"),Qg=c(),U=a("ul"),Gn=a("li"),Cl=a("strong"),_3=o("Learning Rate ("),Hn=a("code"),k3=o("learning_rate"),E3=o(")"),b3=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),x3=c(),qn=a("li"),Gl=a("strong"),y3=o("Text Encoder Learning Rate ("),Mn=a("code"),w3=o("text_encoder_lr"),T3=o(")"),R3=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),S3=c(),Un=a("li"),Hl=a("strong"),D3=o("UNet Learning Rate ("),Bn=a("code"),A3=o("unet_lr"),L3=o(")"),I3=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),P3=c(),Wn=a("li"),ql=a("strong"),O3=o("Learning Rate Scheduler ("),jn=a("code"),z3=o("lr_scheduler"),N3=o(")"),C3=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),G3=c(),Fn=a("li"),Ml=a("strong"),H3=o("Number of Cycles in Learning Rate Scheduler ("),Vn=a("code"),q3=o("lr_scheduler_num_cycles"),M3=o(")"),U3=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),B3=c(),Yn=a("li"),Ul=a("strong"),W3=o("Network Dimension ("),Kn=a("code"),j3=o("network_dim"),F3=o(")"),V3=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Y3=c(),Xn=a("li"),Bl=a("strong"),K3=o("Network Alpha ("),Zn=a("code"),X3=o("network_alpha"),Z3=o(")"),Q3=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),J3=c(),Qn=a("li"),Wl=a("strong"),$3=o("Clip Skip ("),Jn=a("code"),e4=o("clip_skip"),t4=o(")"),s4=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),a4=c(),$n=a("li"),jl=a("strong"),l4=o("Max Token Length ("),ec=a("code"),r4=o("max_token_length"),i4=o(")"),o4=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),n4=c(),tc=a("li"),Fl=a("strong"),c4=o("Noise Offset ("),sc=a("code"),u4=o("noise_offset"),f4=o(")"),d4=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),p4=c(),ac=a("li"),Vl=a("strong"),h4=o("Regularization Data Directory ("),lc=a("code"),g4=o("reg_data_dir"),m4=o(")"),v4=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Jg=c(),ca=a("h3"),ua=a("a"),_p=a("span"),_4=o("Fine Tuning"),$g=c(),rc=a("p"),k4=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),em=c(),lr(Yl.$$.fragment),tm=c(),fa=a("h4"),da=a("a"),kp=a("span"),E4=o("Workflow with Auto1111 WebUI"),sm=c(),pa=a("p"),b4=o("We\u2019re going to use "),Kl=a("a"),x4=o("Stable Diffusion web UI"),y4=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),am=c(),ha=a("p"),w4=o("We\u2019re going to use the "),ic=a("code"),T4=o("X/Y/Z plot"),R4=o(" script to compare different epochs."),lm=c(),oe=a("ul"),oc=a("li"),S4=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),rm=a("princeadam0001:0.7"),D4=c(),Ep=a("li"),A4=o("In generation parameters and select the X/Y/Z plot script."),L4=c(),it=a("li"),I4=o("Select "),nc=a("code"),P4=o("Prompt SR"),O4=o(" for Prompt Replace.  We\u2019re going to replace "),cc=a("code"),z4=o("<princeadam0001:0.7>"),N4=o(" with different epoch: "),uc=a("code"),C4=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),G4=c(),fc=a("li"),H4=o("Select a fast sampler like "),dc=a("code"),q4=o("DPM2 KARRAS"),M4=c(),ga=a("li"),U4=o("CFG Scale set to "),pc=a("code"),B4=o("7"),W4=o(" and Steps to "),hc=a("code"),j4=o("20"),im=c(),ot=a("p"),F4=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),gc=a("code"),V4=o("network_dim"),Y4=o(" and "),mc=a("code"),K4=o("network_alpha"),X4=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),om=c(),xe=a("ul"),ma=a("li"),Z4=o("Select "),vc=a("code"),Q4=o("Prompt SR"),J4=o(" for Prompt Replace.  We\u2019re going to replace the weights "),_c=a("code"),$4=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),e0=c(),Xl=a("li"),t0=o("Use Prompt SR to generate a variety of angles: Select "),kc=a("code"),s0=o("Prompt SR"),a0=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),l0=c(),bp=a("li"),r0=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),i0=c(),xp=a("li"),o0=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),nm=c(),va=a("h4"),_a=a("a"),yp=a("span"),n0=o("Issues to look for"),cm=c(),ye=a("ul"),Ec=a("li"),wp=a("strong"),c0=o("Undercooked:"),u0=o(" Lacks output, adjust unet learning rate or extend training duration."),f0=c(),bc=a("li"),Tp=a("strong"),d0=o("Overcooked:"),p0=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),h0=c(),xc=a("li"),Rp=a("strong"),g0=o("Overfit:"),m0=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),v0=c(),yc=a("li"),Sp=a("strong"),_0=o("Mismatched:"),k0=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),um=c(),wc=a("p"),E0=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),fm=c(),Zl=a("p"),Ql=a("img"),dm=c(),ka=a("h2"),Ea=a("a"),Dp=a("span"),b0=o("Troubleshooting"),pm=c(),Tc=a("p"),x0=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),hm=c(),nt=a("ul"),Jl=a("li"),y0=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Rc=a("code"),w0=o("200"),T0=o(" regularization images per training image."),R0=c(),$l=a("li"),S0=o("Repeats of regularization images, but may overfit more.  Increasing the "),Sc=a("code"),D0=o("repetition_count"),A0=o(" will cycle through the images more but the results may have results that overfit the model."),L0=c(),Ap=a("li"),I0=o("Create more regularization images without increasing repeats will help with the overfitting."),gm=c(),Ct=a("table"),Dc=a("thead"),ct=a("tr"),Ac=a("th"),P0=o("Issue"),O0=c(),Lc=a("th"),z0=o("Situation"),N0=c(),Ic=a("th"),C0=o("Recommendation"),G0=c(),we=a("tbody"),ut=a("tr"),Pc=a("td"),H0=o("Varying quality"),q0=c(),Oc=a("td"),M0=o("Results differ from expectations"),U0=c(),zc=a("td"),B0=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),W0=c(),ft=a("tr"),Nc=a("td"),j0=o("Inadequate regularization for input data"),F0=c(),Cc=a("td"),V0=o("Lower input images, less regularization needed"),Y0=c(),Gc=a("td"),K0=o("Reduce the number of input images or increasing the quantity of reg images."),X0=c(),dt=a("tr"),Hc=a("td"),Z0=o("Overfitting due to repetition"),Q0=c(),qc=a("td"),J0=o("Repeats of reg images, risk of overfitting"),$0=c(),Mc=a("td"),e5=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),t5=c(),pt=a("tr"),Uc=a("td"),s5=o("Mitigate overfitting while increasing diversity"),a5=c(),Bc=a("td"),l5=o("Create more reg images without repeats"),r5=c(),Wc=a("td"),i5=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),mm=c(),ba=a("h4"),xa=a("a"),Lp=a("span"),o5=o("More Solutions"),vm=c(),jc=a("p"),n5=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),_m=c(),Gt=a("table"),Fc=a("thead"),ht=a("tr"),Vc=a("th"),c5=o("Symptom"),u5=c(),Yc=a("th"),f5=o("Likely Cause"),d5=c(),Kc=a("th"),p5=o("Solution"),h5=c(),W=a("tbody"),gt=a("tr"),Xc=a("td"),g5=o("Plastic texture persists"),m5=c(),Zc=a("td"),v5=o("Insufficient human reg images"),_5=c(),Qc=a("td"),k5=o("Add real photos to reg set"),E5=c(),mt=a("tr"),Jc=a("td"),b5=o("Loss plateaus early"),x5=c(),$c=a("td"),y5=o("Learning rate too low"),w5=c(),eu=a("td"),T5=o("Increase LR by 10x"),R5=c(),vt=a("tr"),tu=a("td"),S5=o("Features blurry"),D5=c(),su=a("td"),A5=o("Network dimension too small"),L5=c(),au=a("td"),I5=o("Increase network_dim to 64+"),P5=c(),_t=a("tr"),lu=a("td"),O5=o("Color distortion"),z5=c(),ru=a("td"),N5=o("Noise offset conflict"),C5=c(),iu=a("td"),G5=o("Try noise_offset 0.05-0.1"),H5=c(),kt=a("tr"),ou=a("td"),q5=o("Overly stylized outputs"),M5=c(),nu=a("td"),U5=o("Reg image style mismatch"),B5=c(),cu=a("td"),W5=o("Regenerate reg images with base model"),j5=c(),Et=a("tr"),uu=a("td"),F5=o("Training instability"),V5=c(),fu=a("td"),Y5=o("Batch size too large"),K5=c(),du=a("td"),X5=o("Reduce batch_size to 1-2"),Z5=c(),bt=a("tr"),pu=a("td"),Q5=o("Slow convergence"),J5=c(),hu=a("td"),$5=o("Network_alpha too high"),ew=c(),gu=a("td"),tw=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),sw=c(),xt=a("tr"),mu=a("td"),aw=o("Loss divergence"),lw=c(),vu=a("td"),rw=o("Text encoder LR too high"),iw=c(),_u=a("td"),ow=o("Reduce text_encoder_lr by 10x"),nw=c(),yt=a("tr"),ku=a("td"),cw=o("Poor prompt adherence"),uw=c(),Eu=a("td"),fw=o("Clip skip too high"),dw=c(),bu=a("td"),pw=o("Reduce clip_skip to 1-2"),hw=c(),wt=a("tr"),xu=a("td"),gw=o("Memory errors"),mw=c(),yu=a("td"),vw=o("Resolution too high"),_w=c(),wu=a("td"),kw=o("Reduce to 512-768px, enable gradient checkpointing"),km=c(),ya=a("h2"),wa=a("a"),Ip=a("span"),Ew=o("Results"),Em=c(),Tu=a("p"),bw=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),bm=c(),Ru=a("p"),xw=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),xm=c(),er=a("p"),tr=a("img"),ym=c(),Su=a("p"),yw=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),wm=c(),Ht=a("h2"),Ta=a("a"),Pp=a("span"),ww=o("spacelab"),Tm=c(),Te&&Te.c(),Rm=wf(),this.h()},l(s){p=l(s,"P",{});var d=r(p);m=n(d,"Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),d.forEach(t),g=u(s),h=l(s,"P",{});var l6=r(h);v=n(l6,"I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),l6.forEach(t),k=u(s),b=l(s,"H4",{id:!0});var Tw=r(b);w=l(Tw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r6=r(w);T=l(r6,"SPAN",{class:!0}),r(T).forEach(t),r6.forEach(t),x=n(Tw,"Experiment 1: Anime-Inspired Heroism"),Tw.forEach(t),E=u(s),y=l(s,"P",{class:!0});var i6=r(y);I=l(i6,"IMG",{src:!0,alt:!0,class:!0}),i6.forEach(t),N=u(s),G=l(s,"P",{});var o6=r(G);D=n(o6,"I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),o6.forEach(t),A=u(s),S=l(s,"UL",{});var Dm=r(S);O=l(Dm,"LI",{});var n6=r(O);z=n(n6,"My action figure photos (for costume accuracy)."),n6.forEach(t),Q=u(Dm),j=l(Dm,"LI",{});var c6=r(j);F=n(c6,"Stylized anime references (for anatomy and texture)."),c6.forEach(t),Dm.forEach(t),B=u(s),C=l(s,"P",{});var u6=r(C);L=n(u6,"The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),u6.forEach(t),H=u(s),Z=l(s,"H4",{id:!0});var Rw=r(Z);q=l(Rw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var f6=r(q);R=l(f6,"SPAN",{class:!0}),r(R).forEach(t),f6.forEach(t),M=n(Rw,"Experiment 2: Retro Cartoon Resurrection"),Rw.forEach(t),jt=u(s),Se=l(s,"P",{class:!0});var d6=r(Se);fe=l(d6,"IMG",{src:!0,alt:!0,class:!0}),d6.forEach(t),qp=u(s),nr=l(s,"P",{});var p6=r(nr);Dv=n(p6,"Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),p6.forEach(t),Mp=u(s),Ft=l(s,"H2",{id:!0});var Sw=r(Ft);Vt=l(Sw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var h6=r(Vt);Rf=l(h6,"SPAN",{class:!0}),r(Rf).forEach(t),h6.forEach(t),Av=n(Sw,"What are Regularization Images?"),Sw.forEach(t),Up=u(s),cr=l(s,"P",{});var g6=r(cr);Lv=n(g6,"Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),g6.forEach(t),Bp=u(s),qa=l(s,"BLOCKQUOTE",{class:!0});var m6=r(qa);ur=l(m6,"P",{class:!0});var v6=r(ur);Iv=n(v6,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),v6.forEach(t),m6.forEach(t),Wp=u(s),rr(Ma.$$.fragment,s),jp=u(s),fr=l(s,"P",{});var _6=r(fr);Pv=n(_6,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),_6.forEach(t),Fp=u(s),dr=l(s,"P",{});var k6=r(dr);Ov=n(k6,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),k6.forEach(t),Vp=u(s),pr=l(s,"P",{});var E6=r(pr);zv=n(E6,"Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),E6.forEach(t),Yp=u(s),At=l(s,"TABLE",{class:!0});var Am=r(At);hr=l(Am,"THEAD",{class:!0});var b6=r(hr);De=l(b6,"TR",{class:!0});var Du=r(De);gr=l(Du,"TH",{class:!0});var x6=r(gr);Nv=n(x6,"Aspect"),x6.forEach(t),Cv=u(Du),mr=l(Du,"TH",{class:!0});var y6=r(mr);Gv=n(y6,"Regularization"),y6.forEach(t),Hv=u(Du),vr=l(Du,"TH",{class:!0});var w6=r(vr);qv=n(w6,"No Regularization"),w6.forEach(t),Du.forEach(t),b6.forEach(t),Mv=u(Am),Ae=l(Am,"TBODY",{class:!0});var Au=r(Ae);Le=l(Au,"TR",{class:!0});var Lu=r(Le);_r=l(Lu,"TD",{class:!0});var T6=r(_r);Sf=l(T6,"STRONG",{});var R6=r(Sf);Uv=n(R6,"Class Definition"),R6.forEach(t),T6.forEach(t),Bv=u(Lu),kr=l(Lu,"TD",{class:!0});var S6=r(kr);Wv=n(S6,"Explicit class anchoring"),S6.forEach(t),jv=u(Lu),Er=l(Lu,"TD",{class:!0});var D6=r(Er);Fv=n(D6,"Implicit class learning"),D6.forEach(t),Lu.forEach(t),Vv=u(Au),Ie=l(Au,"TR",{class:!0});var Iu=r(Ie);br=l(Iu,"TD",{class:!0});var A6=r(br);Df=l(A6,"STRONG",{});var L6=r(Df);Yv=n(L6,"Failure Modes"),L6.forEach(t),A6.forEach(t),Kv=u(Iu),xr=l(Iu,"TD",{class:!0});var I6=r(xr);Xv=n(I6,"Underfitting if overdone"),I6.forEach(t),Zv=u(Iu),yr=l(Iu,"TD",{class:!0});var P6=r(yr);Qv=n(P6,"Overfitting/drift"),P6.forEach(t),Iu.forEach(t),Jv=u(Au),Pe=l(Au,"TR",{class:!0});var Pu=r(Pe);wr=l(Pu,"TD",{class:!0});var O6=r(wr);Af=l(O6,"STRONG",{});var z6=r(Af);$v=n(z6,"Data Efficiency"),z6.forEach(t),O6.forEach(t),e2=u(Pu),Tr=l(Pu,"TD",{class:!0});var N6=r(Tr);t2=n(N6,"Better generalization"),N6.forEach(t),s2=u(Pu),Rr=l(Pu,"TD",{class:!0});var C6=r(Rr);a2=n(C6,"Requires more data"),C6.forEach(t),Pu.forEach(t),Au.forEach(t),Am.forEach(t),Kp=u(s),Sr=l(s,"P",{});var G6=r(Sr);l2=n(G6,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),G6.forEach(t),Xp=u(s),Dr=l(s,"P",{});var H6=r(Dr);r2=n(H6,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),H6.forEach(t),Zp=u(s),Ua=l(s,"BLOCKQUOTE",{class:!0});var q6=r(Ua);Ar=l(q6,"P",{class:!0});var M6=r(Ar);i2=n(M6,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),M6.forEach(t),q6.forEach(t),Qp=u(s),Yt=l(s,"H4",{id:!0});var Dw=r(Yt);Kt=l(Dw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var U6=r(Kt);Lf=l(U6,"SPAN",{class:!0}),r(Lf).forEach(t),U6.forEach(t),o2=n(Dw,"Scenario 1: Limited Training Data"),Dw.forEach(t),Jp=u(s),Ba=l(s,"P",{});var Aw=r(Ba);If=l(Aw,"STRONG",{});var B6=r(If);n2=n(B6,"Situation"),B6.forEach(t),c2=n(Aw,": You only have a few images of your cat and no other cat images."),Aw.forEach(t),$p=u(s),Wa=l(s,"P",{});var Lw=r(Wa);Pf=l(Lw,"STRONG",{});var W6=r(Pf);u2=n(W6,"Problem"),W6.forEach(t),f2=n(Lw,": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),Lw.forEach(t),eh=u(s),ja=l(s,"P",{});var Iw=r(ja);Of=l(Iw,"STRONG",{});var j6=r(Of);d2=n(j6,"Solution"),j6.forEach(t),p2=n(Iw,": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Iw.forEach(t),th=u(s),Xt=l(s,"H4",{id:!0});var Pw=r(Xt);Zt=l(Pw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var F6=r(Zt);zf=l(F6,"SPAN",{class:!0}),r(zf).forEach(t),F6.forEach(t),h2=n(Pw,"Scenario 2: Imbalanced Training Data"),Pw.forEach(t),sh=u(s),Fa=l(s,"P",{});var Ow=r(Fa);Nf=l(Ow,"STRONG",{});var V6=r(Nf);g2=n(V6,"Situation"),V6.forEach(t),m2=n(Ow,": You have many images of other cats but only a few of your cat."),Ow.forEach(t),ah=u(s),Va=l(s,"P",{});var zw=r(Va);Cf=l(zw,"STRONG",{});var Y6=r(Cf);v2=n(Y6,"Problem"),Y6.forEach(t),_2=n(zw,": The model may focus too much on the other cats, failing to learn the unique features of your cat."),zw.forEach(t),lh=u(s),Ya=l(s,"P",{});var Nw=r(Ya);Gf=l(Nw,"STRONG",{});var K6=r(Gf);k2=n(K6,"Solution"),K6.forEach(t),E2=n(Nw,": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Nw.forEach(t),rh=u(s),Qt=l(s,"H2",{id:!0});var Cw=r(Qt);Jt=l(Cw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var X6=r(Jt);Hf=l(X6,"SPAN",{class:!0}),r(Hf).forEach(t),X6.forEach(t),b2=n(Cw,"Divergence"),Cw.forEach(t),ih=u(s),Ka=l(s,"P",{});var Gw=r(Ka);qf=l(Gw,"STRONG",{});var Z6=r(qf);x2=n(Z6,"Divergence"),Z6.forEach(t),y2=n(Gw," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Gw.forEach(t),oh=u(s),Oe=l(s,"P",{});var Ou=r(Oe);w2=n(Ou,"Preventing divergence starts with "),Mf=l(Ou,"STRONG",{});var Q6=r(Mf);T2=n(Q6,"careful dataset curation"),Q6.forEach(t),R2=n(Ou,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Uf=l(Ou,"STRONG",{});var J6=r(Uf);S2=n(J6,"regularization techniques"),J6.forEach(t),D2=n(Ou," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Ou.forEach(t),nh=u(s),ze=l(s,"UL",{});var zu=r(ze);Lr=l(zu,"LI",{});var Hw=r(Lr);Bf=l(Hw,"STRONG",{});var $6=r(Bf);A2=n($6,"Chaotic outputs"),$6.forEach(t),L2=n(Hw," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),Hw.forEach(t),I2=u(zu),Ir=l(zu,"LI",{});var qw=r(Ir);Wf=l(qw,"STRONG",{});var eT=r(Wf);P2=n(eT,"Exploding gradients"),eT.forEach(t),O2=n(qw," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),qw.forEach(t),z2=u(zu),$t=l(zu,"LI",{});var Op=r($t);jf=l(Op,"STRONG",{});var tT=r(jf);N2=n(tT,"Loss value instability (NaN/infinity values)"),tT.forEach(t),C2=n(Op," The training loss fluctuates wildly, sometimes becoming "),Pr=l(Op,"CODE",{class:!0});var sT=r(Pr);G2=n(sT,"NaN"),sT.forEach(t),H2=n(Op," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Op.forEach(t),zu.forEach(t),ch=u(s),Xa=l(s,"BLOCKQUOTE",{class:!0});var aT=r(Xa);Or=l(aT,"P",{class:!0});var lT=r(Or);q2=n(lT,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),lT.forEach(t),aT.forEach(t),uh=u(s),es=l(s,"H2",{id:!0});var Mw=r(es);ts=l(Mw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var rT=r(ts);Ff=l(rT,"SPAN",{class:!0}),r(Ff).forEach(t),rT.forEach(t),Vf=l(Mw,"STRONG",{});var iT=r(Vf);M2=n(iT,"Overfitting"),iT.forEach(t),Mw.forEach(t),fh=u(s),zr=l(s,"P",{});var oT=r(zr);U2=n(oT,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),oT.forEach(t),dh=u(s),Ne=l(s,"UL",{});var Nu=r(Ne);Nr=l(Nu,"LI",{});var Uw=r(Nr);Yf=l(Uw,"STRONG",{});var nT=r(Yf);B2=n(nT,"Perfectly replicates training samples"),nT.forEach(t),W2=n(Uw," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),Uw.forEach(t),j2=u(Nu),Cr=l(Nu,"LI",{});var Bw=r(Cr);Kf=l(Bw,"STRONG",{});var cT=r(Kf);F2=n(cT,"Fails to generalize to new inputs"),cT.forEach(t),V2=n(Bw," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Bw.forEach(t),Y2=u(Nu),Gr=l(Nu,"LI",{});var Ww=r(Gr);Xf=l(Ww,"STRONG",{});var uT=r(Xf);K2=n(uT,"Shows excellent training loss but poor validation loss"),uT.forEach(t),X2=n(Ww," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),Ww.forEach(t),Nu.forEach(t),ph=u(s),ss=l(s,"H3",{id:!0});var jw=r(ss);as=l(jw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var fT=r(as);Zf=l(fT,"SPAN",{class:!0}),r(Zf).forEach(t),fT.forEach(t),Qf=l(jw,"STRONG",{});var dT=r(Qf);Z2=n(dT,"Key Differences"),dT.forEach(t),jw.forEach(t),hh=u(s),Lt=l(s,"TABLE",{class:!0});var Lm=r(Lt);Hr=l(Lm,"THEAD",{class:!0});var pT=r(Hr);Ce=l(pT,"TR",{class:!0});var Cu=r(Ce);qr=l(Cu,"TH",{class:!0});var hT=r(qr);Jf=l(hT,"STRONG",{});var gT=r(Jf);Q2=n(gT,"Aspect"),gT.forEach(t),hT.forEach(t),J2=u(Cu),Mr=l(Cu,"TH",{class:!0});var mT=r(Mr);$f=l(mT,"STRONG",{});var vT=r($f);$2=n(vT,"Divergence"),vT.forEach(t),mT.forEach(t),e_=u(Cu),Ur=l(Cu,"TH",{class:!0});var _T=r(Ur);ed=l(_T,"STRONG",{});var kT=r(ed);t_=n(kT,"Overfitting"),kT.forEach(t),_T.forEach(t),Cu.forEach(t),pT.forEach(t),s_=u(Lm),de=l(Lm,"TBODY",{class:!0});var Ra=r(de);Ge=l(Ra,"TR",{class:!0});var Gu=r(Ge);Br=l(Gu,"TD",{class:!0});var ET=r(Br);td=l(ET,"STRONG",{});var bT=r(td);a_=n(bT,"Cause"),bT.forEach(t),ET.forEach(t),l_=u(Gu),Wr=l(Gu,"TD",{class:!0});var xT=r(Wr);r_=n(xT,"Excessive learning rate"),xT.forEach(t),i_=u(Gu),jr=l(Gu,"TD",{class:!0});var yT=r(jr);o_=n(yT,"Insufficient regularization"),yT.forEach(t),Gu.forEach(t),n_=u(Ra),He=l(Ra,"TR",{class:!0});var Hu=r(He);Fr=l(Hu,"TD",{class:!0});var wT=r(Fr);sd=l(wT,"STRONG",{});var TT=r(sd);c_=n(TT,"Loss Behavior"),TT.forEach(t),wT.forEach(t),u_=u(Hu),Vr=l(Hu,"TD",{class:!0});var RT=r(Vr);f_=n(RT,"Sudden spikes/NaN values"),RT.forEach(t),d_=u(Hu),Yr=l(Hu,"TD",{class:!0});var ST=r(Yr);p_=n(ST,"Steady decrease then rise"),ST.forEach(t),Hu.forEach(t),h_=u(Ra),qe=l(Ra,"TR",{class:!0});var qu=r(qe);Kr=l(qu,"TD",{class:!0});var DT=r(Kr);ad=l(DT,"STRONG",{});var AT=r(ad);g_=n(AT,"Output Quality"),AT.forEach(t),DT.forEach(t),m_=u(qu),Xr=l(qu,"TD",{class:!0});var LT=r(Xr);v_=n(LT,"Random noise/artifacts"),LT.forEach(t),__=u(qu),Zr=l(qu,"TD",{class:!0});var IT=r(Zr);k_=n(IT,"Overly detailed replicas"),IT.forEach(t),qu.forEach(t),E_=u(Ra),Me=l(Ra,"TR",{class:!0});var Mu=r(Me);Qr=l(Mu,"TD",{class:!0});var PT=r(Qr);ld=l(PT,"STRONG",{});var OT=r(ld);b_=n(OT,"Recovery"),OT.forEach(t),PT.forEach(t),x_=u(Mu),Jr=l(Mu,"TD",{class:!0});var zT=r(Jr);y_=n(zT,"Requires restart"),zT.forEach(t),w_=u(Mu),$r=l(Mu,"TD",{class:!0});var NT=r($r);T_=n(NT,"Early stopping works"),NT.forEach(t),Mu.forEach(t),Ra.forEach(t),Lm.forEach(t),gh=u(s),ls=l(s,"H3",{id:!0});var Fw=r(ls);rs=l(Fw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var CT=r(rs);rd=l(CT,"SPAN",{class:!0}),r(rd).forEach(t),CT.forEach(t),R_=n(Fw,"Preventing Divergence"),Fw.forEach(t),mh=u(s),It=l(s,"TABLE",{class:!0});var Im=r(It);ei=l(Im,"THEAD",{class:!0});var GT=r(ei);is=l(GT,"TR",{class:!0});var Pm=r(is);ti=l(Pm,"TH",{class:!0});var HT=r(ti);S_=n(HT,"Situation"),HT.forEach(t),D_=u(Pm),si=l(Pm,"TH",{class:!0});var qT=r(si);A_=n(qT,"Outcome"),qT.forEach(t),Pm.forEach(t),GT.forEach(t),L_=u(Im),pe=l(Im,"TBODY",{class:!0});var Sa=r(pe);os=l(Sa,"TR",{class:!0});var Om=r(os);ai=l(Om,"TD",{class:!0});var MT=r(ai);id=l(MT,"STRONG",{});var UT=r(id);I_=n(UT,"Excessive or inconsistent data"),UT.forEach(t),MT.forEach(t),P_=u(Om),li=l(Om,"TD",{class:!0});var BT=r(li);O_=n(BT,"Model struggles to learn and produces unreliable predictions."),BT.forEach(t),Om.forEach(t),z_=u(Sa),ns=l(Sa,"TR",{class:!0});var zm=r(ns);ri=l(zm,"TD",{class:!0});var WT=r(ri);od=l(WT,"STRONG",{});var jT=r(od);N_=n(jT,"Lack of unique and consistent features"),jT.forEach(t),WT.forEach(t),C_=u(zm),ii=l(zm,"TD",{class:!0});var FT=r(ii);G_=n(FT,"Poor generalization, leading to inaccurate or meaningless outputs."),FT.forEach(t),zm.forEach(t),H_=u(Sa),cs=l(Sa,"TR",{class:!0});var Nm=r(cs);oi=l(Nm,"TD",{class:!0});var VT=r(oi);nd=l(VT,"STRONG",{});var YT=r(nd);q_=n(YT,"Carefully curated datasets"),YT.forEach(t),VT.forEach(t),M_=u(Nm),ni=l(Nm,"TD",{class:!0});var KT=r(ni);U_=n(KT,"Improved learning by ensuring the model sees only relevant, high-quality data."),KT.forEach(t),Nm.forEach(t),B_=u(Sa),us=l(Sa,"TR",{class:!0});var Cm=r(us);ci=l(Cm,"TD",{class:!0});var XT=r(ci);cd=l(XT,"STRONG",{});var ZT=r(cd);W_=n(ZT,"Effective use of regularization techniques"),ZT.forEach(t),XT.forEach(t),j_=u(Cm),ui=l(Cm,"TD",{class:!0});var QT=r(ui);F_=n(QT,"Helps maintain focus on essential features and prevents instability."),QT.forEach(t),Cm.forEach(t),Sa.forEach(t),Im.forEach(t),vh=u(s),fi=l(s,"P",{});var JT=r(fi);V_=n(JT,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),JT.forEach(t),_h=u(s),fs=l(s,"H3",{id:!0});var Vw=r(fs);ds=l(Vw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var $T=r(ds);ud=l($T,"SPAN",{class:!0}),r(ud).forEach(t),$T.forEach(t),Y_=n(Vw,"Implementing these Strategies"),Vw.forEach(t),kh=u(s),Za=l(s,"PRE",{class:!0});var VA=r(Za);VA.forEach(t),Eh=u(s),Qa=l(s,"PRE",{class:!0});var YA=r(Qa);YA.forEach(t),bh=u(s),ps=l(s,"H3",{id:!0});var Yw=r(ps);hs=l(Yw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var e8=r(hs);fd=l(e8,"SPAN",{class:!0}),r(fd).forEach(t),e8.forEach(t),K_=n(Yw,"Data Considerations"),Yw.forEach(t),xh=u(s),Pt=l(s,"TABLE",{class:!0});var Gm=r(Pt);di=l(Gm,"THEAD",{class:!0});var t8=r(di);Ue=l(t8,"TR",{class:!0});var Uu=r(Ue);pi=l(Uu,"TH",{class:!0});var s8=r(pi);X_=n(s8,"Situation"),s8.forEach(t),Z_=u(Uu),hi=l(Uu,"TH",{class:!0});var a8=r(hi);Q_=n(a8,"Actual Risk"),a8.forEach(t),J_=u(Uu),gi=l(Uu,"TH",{class:!0});var l8=r(gi);$_=n(l8,"Solution"),l8.forEach(t),Uu.forEach(t),t8.forEach(t),e1=u(Gm),he=l(Gm,"TBODY",{class:!0});var Da=r(he);Be=l(Da,"TR",{class:!0});var Bu=r(Be);mi=l(Bu,"TD",{class:!0});var r8=r(mi);t1=n(r8,"High LR + small batch size"),r8.forEach(t),s1=u(Bu),vi=l(Bu,"TD",{class:!0});var i8=r(vi);a1=n(i8,"Divergence"),i8.forEach(t),l1=u(Bu),_i=l(Bu,"TD",{class:!0});var o8=r(_i);r1=n(o8,"Lower LR, increase batch size"),o8.forEach(t),Bu.forEach(t),i1=u(Da),We=l(Da,"TR",{class:!0});var Wu=r(We);ki=l(Wu,"TD",{class:!0});var n8=r(ki);o1=n(n8,"Inconsistent features"),n8.forEach(t),n1=u(Wu),Ei=l(Wu,"TD",{class:!0});var c8=r(Ei);c1=n(c8,"Overfitting"),c8.forEach(t),u1=u(Wu),bi=l(Wu,"TD",{class:!0});var u8=r(bi);f1=n(u8,"Improve dataset consistency"),u8.forEach(t),Wu.forEach(t),d1=u(Da),je=l(Da,"TR",{class:!0});var ju=r(je);xi=l(ju,"TD",{class:!0});var f8=r(xi);p1=n(f8,"Insufficient reg images"),f8.forEach(t),h1=u(ju),yi=l(ju,"TD",{class:!0});var d8=r(yi);g1=n(d8,"Class leakage"),d8.forEach(t),m1=u(ju),wi=l(ju,"TD",{class:!0});var p8=r(wi);v1=n(p8,"Add 100-300 class images"),p8.forEach(t),ju.forEach(t),_1=u(Da),Fe=l(Da,"TR",{class:!0});var Fu=r(Fe);Ti=l(Fu,"TD",{class:!0});var h8=r(Ti);k1=n(h8,"High variance in training data"),h8.forEach(t),E1=u(Fu),Ri=l(Fu,"TD",{class:!0});var g8=r(Ri);b1=n(g8,"Mode collapse"),g8.forEach(t),x1=u(Fu),Si=l(Fu,"TD",{class:!0});var m8=r(Si);y1=n(m8,"Curate focused dataset"),m8.forEach(t),Fu.forEach(t),Da.forEach(t),Gm.forEach(t),yh=u(s),Di=l(s,"P",{});var v8=r(Di);w1=n(v8,"This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs\u2014fix this by lowering the learning rate and increasing the batch size."),v8.forEach(t),wh=u(s),Ai=l(s,"P",{});var _8=r(Ai);T1=n(_8,"Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects\u2014adding 100-300 images helps."),_8.forEach(t),Th=u(s),Li=l(s,"P",{});var k8=r(Li);R1=n(k8,"High variance in training data can result in mode collapse, producing repetitive outputs\u2014keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),k8.forEach(t),Rh=u(s),Sh=l(s,"HR",{}),Dh=u(s),gs=l(s,"H2",{id:!0});var Kw=r(gs);ms=l(Kw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var E8=r(ms);dd=l(E8,"SPAN",{class:!0}),r(dd).forEach(t),E8.forEach(t),S1=n(Kw,"Monitoring Tips"),Kw.forEach(t),Ah=u(s),vs=l(s,"P",{});var Hm=r(vs);D1=n(Hm,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ja=l(Hm,"A",{href:!0,rel:!0});var b8=r(Ja);A1=n(b8,"kohya-ss/sd-scripts"),b8.forEach(t),L1=n(Hm,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),Hm.forEach(t),Lh=u(s),_s=l(s,"H3",{id:!0});var Xw=r(_s);ks=l(Xw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var x8=r(ks);pd=l(x8,"SPAN",{class:!0}),r(pd).forEach(t),x8.forEach(t),I1=n(Xw,"Track loss curves"),Xw.forEach(t),Ih=u(s),Es=l(s,"P",{});var qm=r(Es);P1=n(qm,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),$a=l(qm,"A",{href:!0,rel:!0});var y8=r($a);O1=n(y8,"TensorBoard"),y8.forEach(t),z1=n(qm," to create these graphs."),qm.forEach(t),Ph=u(s),el=l(s,"PRE",{class:!0});var KA=r(el);KA.forEach(t),Oh=u(s),bs=l(s,"H4",{id:!0});var Zw=r(bs);xs=l(Zw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w8=r(xs);hd=l(w8,"SPAN",{class:!0}),r(hd).forEach(t),w8.forEach(t),N1=n(Zw,"What to Monitor:"),Zw.forEach(t),zh=u(s),Ve=l(s,"UL",{});var Vu=r(Ve);gd=l(Vu,"LI",{});var T8=r(gd);C1=n(T8,"Training Loss: Should decrease steadily but not too quickly."),T8.forEach(t),G1=u(Vu),md=l(Vu,"LI",{});var R8=r(md);H1=n(R8,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),R8.forEach(t),q1=u(Vu),vd=l(Vu,"LI",{});var S8=r(vd);M1=n(S8,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),S8.forEach(t),Vu.forEach(t),Nh=u(s),ys=l(s,"H4",{id:!0});var Qw=r(ys);ws=l(Qw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var D8=r(ws);_d=l(D8,"SPAN",{class:!0}),r(_d).forEach(t),D8.forEach(t),U1=n(Qw,"Warning Signs:"),Qw.forEach(t),Ch=u(s),Ye=l(s,"UL",{});var Yu=r(Ye);kd=l(Yu,"LI",{});var A8=r(kd);B1=n(A8,"Sudden spikes in loss \u2192 Likely divergence."),A8.forEach(t),W1=u(Yu),Ed=l(Yu,"LI",{});var L8=r(Ed);j1=n(L8,"Loss plateauing too early \u2192 Learning rate may be too low."),L8.forEach(t),F1=u(Yu),bd=l(Yu,"LI",{});var I8=r(bd);V1=n(I8,"Validation loss increasing while training loss decreases \u2192 Overfitting."),I8.forEach(t),Yu.forEach(t),Gh=u(s),Ts=l(s,"H3",{id:!0});var Jw=r(Ts);Rs=l(Jw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var P8=r(Rs);xd=l(P8,"SPAN",{class:!0}),r(xd).forEach(t),P8.forEach(t),Y1=n(Jw,"Generate validation images every 100 steps"),Jw.forEach(t),Hh=u(s),tl=l(s,"P",{});var $w=r(tl);yd=l($w,"STRONG",{});var O8=r(yd);K1=n(O8,"Why It Matters"),O8.forEach(t),X1=n($w," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),$w.forEach(t),qh=u(s),sl=l(s,"PRE",{class:!0});var XA=r(sl);XA.forEach(t),Mh=u(s),Ss=l(s,"H4",{id:!0});var e7=r(Ss);Ds=l(e7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var z8=r(Ds);wd=l(z8,"SPAN",{class:!0}),r(wd).forEach(t),z8.forEach(t),Z1=n(e7,"What to Look For:"),e7.forEach(t),Uh=u(s),Ke=l(s,"UL",{});var Ku=r(Ke);Td=l(Ku,"LI",{});var N8=r(Td);Q1=n(N8,"Consistency: Outputs should align with the training data style."),N8.forEach(t),J1=u(Ku),Rd=l(Ku,"LI",{});var C8=r(Rd);$1=n(C8,"Artifacts: Check for distortions, noise, or unnatural features."),C8.forEach(t),ek=u(Ku),Sd=l(Ku,"LI",{});var G8=r(Sd);tk=n(G8,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),G8.forEach(t),Ku.forEach(t),Bh=u(s),al=l(s,"BLOCKQUOTE",{class:!0});var H8=r(al);Ii=l(H8,"P",{class:!0});var q8=r(Ii);sk=n(q8,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),q8.forEach(t),H8.forEach(t),Wh=u(s),As=l(s,"H4",{id:!0});var t7=r(As);Ls=l(t7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var M8=r(Ls);Dd=l(M8,"SPAN",{class:!0}),r(Dd).forEach(t),M8.forEach(t),ak=n(t7,"Use Gradient Clipping"),t7.forEach(t),jh=u(s),ll=l(s,"P",{});var s7=r(ll);Ad=l(s7,"STRONG",{});var U8=r(Ad);lk=n(U8,"Why It Matters"),U8.forEach(t),rk=n(s7,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),s7.forEach(t),Fh=u(s),Pi=l(s,"P",{});var B8=r(Pi);ik=n(B8,"Key Insights:"),B8.forEach(t),Vh=u(s),Xe=l(s,"UL",{});var Xu=r(Xe);rl=l(Xu,"LI",{});var Mm=r(rl);ok=n(Mm,"Gradient Norm "),Oi=l(Mm,"CODE",{class:!0});var W8=r(Oi);nk=n(W8,"<"),W8.forEach(t),ck=n(Mm," than 0.1: Training may stall due to tiny updates."),Mm.forEach(t),uk=u(Xu),Ld=l(Xu,"LI",{});var j8=r(Ld);fk=n(j8,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),j8.forEach(t),dk=u(Xu),Id=l(Xu,"LI",{});var F8=r(Id);pk=n(F8,"Ideal Range: 0.1 to 2.0 for stable training."),F8.forEach(t),Xu.forEach(t),Yh=u(s),il=l(s,"BLOCKQUOTE",{class:!0});var V8=r(il);zi=l(V8,"P",{class:!0});var Y8=r(zi);hk=n(Y8,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Y8.forEach(t),V8.forEach(t),Kh=u(s),Is=l(s,"H4",{id:!0});var a7=r(Is);Ps=l(a7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var K8=r(Ps);Pd=l(K8,"SPAN",{class:!0}),r(Pd).forEach(t),K8.forEach(t),gk=n(a7,"Enable Mixed Precision Training"),a7.forEach(t),Xh=u(s),ol=l(s,"P",{});var l7=r(ol);Od=l(l7,"STRONG",{});var X8=r(Od);mk=n(X8,"Why It Matters"),X8.forEach(t),vk=n(l7,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),l7.forEach(t),Zh=u(s),nl=l(s,"PRE",{class:!0});var ZA=r(nl);ZA.forEach(t),Qh=u(s),Ni=l(s,"P",{});var Z8=r(Ni);_k=n(Z8,"Benefits:"),Z8.forEach(t),Jh=u(s),Ze=l(s,"UL",{});var Zu=r(Ze);zd=l(Zu,"LI",{});var Q8=r(zd);kk=n(Q8,"2-3x Faster Training: Leverages GPU tensor cores."),Q8.forEach(t),Ek=u(Zu),Nd=l(Zu,"LI",{});var J8=r(Nd);bk=n(J8,"50% Less VRAM Usage: Allows larger batch sizes or models."),J8.forEach(t),xk=u(Zu),Cd=l(Zu,"LI",{});var $8=r(Cd);yk=n($8,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),$8.forEach(t),Zu.forEach(t),$h=u(s),cl=l(s,"BLOCKQUOTE",{class:!0});var eR=r(cl);Ci=l(eR,"P",{class:!0});var tR=r(Ci);wk=n(tR,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),tR.forEach(t),eR.forEach(t),eg=u(s),Os=l(s,"H4",{id:!0});var r7=r(Os);zs=l(r7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var sR=r(zs);Gd=l(sR,"SPAN",{class:!0}),r(Gd).forEach(t),sR.forEach(t),Tk=n(r7,"Start with Conservative Learning Rates"),r7.forEach(t),tg=u(s),Ns=l(s,"P",{});var Um=r(Ns);Rk=n(Um,"Start off with 1e-5 to 1e-6.  "),Hd=l(Um,"STRONG",{});var aR=r(Hd);Sk=n(aR,"Why It Matters"),aR.forEach(t),Dk=n(Um,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Um.forEach(t),sg=u(s),ul=l(s,"PRE",{class:!0});var QA=r(ul);QA.forEach(t),ag=u(s),fl=l(s,"PRE",{class:!0});var JA=r(fl);JA.forEach(t),lg=u(s),dl=l(s,"P",{});var i7=r(dl);qd=l(i7,"STRONG",{});var lR=r(qd);Ak=n(lR,"Warning Signs"),lR.forEach(t),Lk=n(i7,":"),i7.forEach(t),rg=u(s),Qe=l(s,"UL",{});var Qu=r(Qe);Md=l(Qu,"LI",{});var rR=r(Md);Ik=n(rR,"Loss Spikes: Learning rate is too high."),rR.forEach(t),Pk=u(Qu),Ud=l(Qu,"LI",{});var iR=r(Ud);Ok=n(iR,"Slow Convergence: Learning rate is too low."),iR.forEach(t),zk=u(Qu),Bd=l(Qu,"LI",{});var oR=r(Bd);Nk=n(oR,"Oscillating Loss: Poor scheduling or unstable gradients."),oR.forEach(t),Qu.forEach(t),ig=u(s),Ot=l(s,"TABLE",{class:!0});var Bm=r(Ot);Gi=l(Bm,"THEAD",{class:!0});var nR=r(Gi);ge=l(nR,"TR",{class:!0});var Aa=r(ge);Hi=l(Aa,"TH",{class:!0});var cR=r(Hi);Ck=n(cR,"Practice"),cR.forEach(t),Gk=u(Aa),qi=l(Aa,"TH",{class:!0});var uR=r(qi);Hk=n(uR,"Key Benefit"),uR.forEach(t),qk=u(Aa),Mi=l(Aa,"TH",{class:!0});var fR=r(Mi);Mk=n(fR,"Tool/Setting"),fR.forEach(t),Uk=u(Aa),Ui=l(Aa,"TH",{class:!0});var dR=r(Ui);Bk=n(dR,"Warning Signs"),dR.forEach(t),Aa.forEach(t),nR.forEach(t),Wk=u(Bm),le=l(Bm,"TBODY",{class:!0});var Tt=r(le);me=l(Tt,"TR",{class:!0});var La=r(me);Bi=l(La,"TD",{class:!0});var pR=r(Bi);jk=n(pR,"Track Loss Curves"),pR.forEach(t),Fk=u(La),Wi=l(La,"TD",{class:!0});var hR=r(Wi);Vk=n(hR,"Detect overfitting/divergence early"),hR.forEach(t),Yk=u(La),ji=l(La,"TD",{class:!0});var gR=r(ji);Kk=n(gR,"TensorBoard, Weights & Biases"),gR.forEach(t),Xk=u(La),Fi=l(La,"TD",{class:!0});var mR=r(Fi);Zk=n(mR,"Spikes, plateaus, growing gaps"),mR.forEach(t),La.forEach(t),Qk=u(Tt),ve=l(Tt,"TR",{class:!0});var Ia=r(ve);Vi=l(Ia,"TD",{class:!0});var vR=r(Vi);Jk=n(vR,"Generate Validation Images"),vR.forEach(t),$k=u(Ia),Yi=l(Ia,"TD",{class:!0});var _R=r(Yi);eE=n(_R,"Visualize model progress"),_R.forEach(t),tE=u(Ia),Ki=l(Ia,"TD",{class:!0});var kR=r(Ki);sE=n(kR,"Fixed prompts/seeds"),kR.forEach(t),aE=u(Ia),Xi=l(Ia,"TD",{class:!0});var ER=r(Xi);lE=n(ER,"Artifacts, mode collapse"),ER.forEach(t),Ia.forEach(t),rE=u(Tt),_e=l(Tt,"TR",{class:!0});var Pa=r(_e);Zi=l(Pa,"TD",{class:!0});var bR=r(Zi);iE=n(bR,"Gradient Clipping"),bR.forEach(t),oE=u(Pa),Qi=l(Pa,"TD",{class:!0});var xR=r(Qi);nE=n(xR,"Prevent exploding gradients"),xR.forEach(t),cE=u(Pa),Cs=l(Pa,"TD",{class:!0});var Wm=r(Cs);uE=n(Wm,"clip"),Wd=l(Wm,"EM",{});var yR=r(Wd);fE=n(yR,"grad_norm"),yR.forEach(t),dE=n(Wm," (1.0-2.0)"),Wm.forEach(t),pE=u(Pa),Je=l(Pa,"TD",{class:!0});var Ju=r(Je);hE=n(Ju,"Norm "),Ji=l(Ju,"CODE",{class:!0});var wR=r(Ji);gE=n(wR,">"),wR.forEach(t),mE=n(Ju," 10.0 or "),$i=l(Ju,"CODE",{class:!0});var TR=r($i);vE=n(TR,"<"),TR.forEach(t),_E=n(Ju," 0.1"),Ju.forEach(t),Pa.forEach(t),kE=u(Tt),ke=l(Tt,"TR",{class:!0});var Oa=r(ke);eo=l(Oa,"TD",{class:!0});var RR=r(eo);EE=n(RR,"Mixed Precision Training"),RR.forEach(t),bE=u(Oa),to=l(Oa,"TD",{class:!0});var SR=r(to);xE=n(SR,"Faster training, lower VRAM usage"),SR.forEach(t),yE=u(Oa),so=l(Oa,"TD",{class:!0});var DR=r(so);wE=n(DR,"PyTorch AMP (torch.cuda.amp)"),DR.forEach(t),TE=u(Oa),ao=l(Oa,"TD",{class:!0});var AR=r(ao);RE=n(AR,"NaN values (disable if unstable)"),AR.forEach(t),Oa.forEach(t),SE=u(Tt),Ee=l(Tt,"TR",{class:!0});var za=r(Ee);lo=l(za,"TD",{class:!0});var LR=r(lo);DE=n(LR,"Conservative Learning Rates"),LR.forEach(t),AE=u(za),ro=l(za,"TD",{class:!0});var IR=r(ro);LE=n(IR,"Stable training, avoid divergence"),IR.forEach(t),IE=u(za),io=l(za,"TD",{class:!0});var PR=r(io);PE=n(PR,"Start at 1e-5 to 1e-6, use scheduler"),PR.forEach(t),OE=u(za),oo=l(za,"TD",{class:!0});var OR=r(oo);zE=n(OR,"Spikes, slow convergence"),OR.forEach(t),za.forEach(t),Tt.forEach(t),Bm.forEach(t),og=u(s),ng=l(s,"HR",{}),cg=u(s),Gs=l(s,"H2",{id:!0});var o7=r(Gs);Hs=l(o7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var zR=r(Hs);jd=l(zR,"SPAN",{class:!0}),r(jd).forEach(t),zR.forEach(t),NE=n(o7,"Generating Regularization images"),o7.forEach(t),ug=u(s),qs=l(s,"P",{});var jm=r(qs);CE=n(jm,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),no=l(jm,"CODE",{class:!0});var NR=r(no);GE=n(NR,"1boy"),NR.forEach(t),HE=n(jm,")."),jm.forEach(t),fg=u(s),ue=l(s,"P",{});var qt=r(ue);qE=n(qt,"According to the Dreambooth technique, "),co=l(qt,"CODE",{class:!0});var CR=r(co);ME=n(CR,"200"),CR.forEach(t),UE=n(qt," regularization images per training image.  For example, if you have "),uo=l(qt,"CODE",{class:!0});var GR=r(uo);BE=n(GR,"16"),GR.forEach(t),WE=n(qt," images: "),fo=l(qt,"CODE",{class:!0});var HR=r(fo);jE=n(HR,"200 * 16 = 3200"),HR.forEach(t),FE=n(qt," total regularization images.  When training, the math involved for calculating total steps is: "),po=l(qt,"CODE",{class:!0});var qR=r(po);VE=n(qR,"repeats * training images >= repeats * regularization images"),qR.forEach(t),qt.forEach(t),dg=u(s),ho=l(s,"P",{});var MR=r(ho);YE=n(MR,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),MR.forEach(t),pg=u(s),Ms=l(s,"H4",{id:!0});var n7=r(Ms);Us=l(n7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var UR=r(Us);Fd=l(UR,"SPAN",{class:!0}),r(Fd).forEach(t),UR.forEach(t),KE=n(n7,"Important considerations"),n7.forEach(t),hg=u(s),$e=l(s,"OL",{});var $u=r($e);Vd=l($u,"LI",{});var BR=r(Vd);pl=l(BR,"P",{});var Fm=r(pl);Yd=l(Fm,"STRONG",{});var WR=r(Yd);XE=n(WR,"Use the same base model for regularization images and training"),WR.forEach(t),ZE=l(Fm,"BR",{}),QE=n(Fm,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Fm.forEach(t),BR.forEach(t),JE=u($u),Kd=l($u,"LI",{});var jR=r(Kd);hl=l(jR,"P",{});var Vm=r(hl);Xd=l(Vm,"STRONG",{});var FR=r(Xd);$E=n(FR,"Maintain consistent class representation"),FR.forEach(t),eb=l(Vm,"BR",{}),tb=n(Vm,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Vm.forEach(t),jR.forEach(t),sb=u($u),Zd=l($u,"LI",{});var VR=r(Zd);gl=l(VR,"P",{});var Ym=r(gl);Qd=l(Ym,"STRONG",{});var YR=r(Qd);ab=n(YR,"Match output resolution to training data"),YR.forEach(t),lb=l(Ym,"BR",{}),rb=n(Ym,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Ym.forEach(t),VR.forEach(t),$u.forEach(t),gg=u(s),rr(ml.$$.fragment,s),mg=u(s),Bs=l(s,"H4",{id:!0});var c7=r(Bs);Ws=l(c7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var KR=r(Ws);Jd=l(KR,"SPAN",{class:!0}),r(Jd).forEach(t),KR.forEach(t),ib=n(c7,"Generate using Stable Diffusion web UI"),c7.forEach(t),vg=u(s),js=l(s,"P",{});var Km=r(js);ob=n(Km,"We\u2019re going to use "),vl=l(Km,"A",{href:!0,rel:!0});var XR=r(vl);nb=n(XR,"Stable Diffusion web UI"),XR.forEach(t),cb=n(Km," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Km.forEach(t),_g=u(s),et=l(s,"P",{});var ef=r(et);ub=n(ef,"We\u2019re going to use the "),go=l(ef,"CODE",{class:!0});var ZR=r(go);fb=n(ZR,"X/Y/Z plot"),ZR.forEach(t),db=n(ef," script to use "),mo=l(ef,"CODE",{class:!0});var QR=r(mo);pb=n(QR,"Prompt Search & Replace"),QR.forEach(t),hb=n(ef," to dynamically build a prompt that will generate hundreds of regularization images."),ef.forEach(t),kg=u(s),J=l(s,"OL",{});var ne=r(J);$d=l(ne,"LI",{});var JR=r($d);vo=l(JR,"P",{});var u7=r(vo);gb=n(u7,"Select the text 2 image tab.  Enter a generic prompt "),_o=l(u7,"CODE",{class:!0});var $R=r(_o);mb=n($R,"princeadam, portrait, looking_at_viewer, forest"),$R.forEach(t),u7.forEach(t),JR.forEach(t),vb=u(ne),ep=l(ne,"LI",{});var eS=r(ep);_l=l(eS,"P",{});var Xm=r(_l);_b=n(Xm,"In generation parameters and select the "),ko=l(Xm,"CODE",{class:!0});var tS=r(ko);kb=n(tS,"X/Y/Z plot"),tS.forEach(t),Eb=n(Xm," script."),Xm.forEach(t),eS.forEach(t),bb=u(ne),tp=l(ne,"LI",{});var sS=r(tp);Y=l(sS,"P",{});var te=r(Y);xb=n(te,"Select the "),Eo=l(te,"CODE",{class:!0});var aS=r(Eo);yb=n(aS,"X"),aS.forEach(t),wb=n(te," parameter and "),bo=l(te,"CODE",{class:!0});var lS=r(bo);Tb=n(lS,"Prompt SR"),lS.forEach(t),Rb=n(te," for Prompt Replace.  We\u2019re going to replace "),xo=l(te,"CODE",{class:!0});var rS=r(xo);Sb=n(rS,"portrait"),rS.forEach(t),Db=n(te," with different camera angle tags: "),yo=l(te,"CODE",{class:!0});var iS=r(yo);Ab=n(iS,"close-up"),iS.forEach(t),Lb=n(te,", "),wo=l(te,"CODE",{class:!0});var oS=r(wo);Ib=n(oS,"upper_body"),oS.forEach(t),Pb=n(te,", "),To=l(te,"CODE",{class:!0});var nS=r(To);Ob=n(nS,"from_below"),nS.forEach(t),zb=n(te,", "),Ro=l(te,"CODE",{class:!0});var cS=r(Ro);Nb=n(cS,"from_above"),cS.forEach(t),Cb=n(te,", "),So=l(te,"CODE",{class:!0});var uS=r(So);Gb=n(uS,"dutch_angle"),uS.forEach(t),te.forEach(t),sS.forEach(t),Hb=u(ne),sp=l(ne,"LI",{});var fS=r(sp);$=l(fS,"P",{});var ae=r($);qb=n(ae,"Select the "),Do=l(ae,"CODE",{class:!0});var dS=r(Do);Mb=n(dS,"Y"),dS.forEach(t),Ub=n(ae," parameter and "),Ao=l(ae,"CODE",{class:!0});var pS=r(Ao);Bb=n(pS,"Prompt SR"),pS.forEach(t),Wb=n(ae," for Prompt Replace.  Replace "),Lo=l(ae,"CODE",{class:!0});var hS=r(Lo);jb=n(hS,"looking_at_viewer"),hS.forEach(t),Fb=n(ae,": "),Io=l(ae,"CODE",{class:!0});var gS=r(Io);Vb=n(gS,"looking_away"),gS.forEach(t),Yb=n(ae,", "),Po=l(ae,"CODE",{class:!0});var mS=r(Po);Kb=n(mS,"looking_to_the_side"),mS.forEach(t),Xb=n(ae,", "),Oo=l(ae,"CODE",{class:!0});var vS=r(Oo);Zb=n(vS,"looking_ahead"),vS.forEach(t),Qb=n(ae,", "),zo=l(ae,"CODE",{class:!0});var _S=r(zo);Jb=n(_S,"looking_down"),_S.forEach(t),ae.forEach(t),fS.forEach(t),$b=u(ne),ap=l(ne,"LI",{});var kS=r(ap);K=l(kS,"P",{});var se=r(K);ex=n(se,"Select the "),No=l(se,"CODE",{class:!0});var ES=r(No);tx=n(ES,"Z"),ES.forEach(t),sx=n(se," parameter and "),Co=l(se,"CODE",{class:!0});var bS=r(Co);ax=n(bS,"Prompt SR"),bS.forEach(t),lx=n(se," for Prompt Replace. Replace "),Go=l(se,"CODE",{class:!0});var xS=r(Go);rx=n(xS,"forest"),xS.forEach(t),ix=n(se," with a vareity of locatinos: "),Ho=l(se,"CODE",{class:!0});var yS=r(Ho);ox=n(yS,"castle"),yS.forEach(t),nx=n(se,", "),qo=l(se,"CODE",{class:!0});var wS=r(qo);cx=n(wS,"mountain"),wS.forEach(t),ux=n(se,", "),Mo=l(se,"CODE",{class:!0});var TS=r(Mo);fx=n(TS,"cave"),TS.forEach(t),dx=n(se,", "),Uo=l(se,"CODE",{class:!0});var RS=r(Uo);px=n(RS,"farm"),RS.forEach(t),hx=n(se,", "),Bo=l(se,"CODE",{class:!0});var SS=r(Bo);gx=n(SS,"ocean"),SS.forEach(t),se.forEach(t),kS.forEach(t),mx=u(ne),lp=l(ne,"LI",{});var DS=r(lp);Wo=l(DS,"P",{});var f7=r(Wo);vx=n(f7,"Select a fast sampler like "),jo=l(f7,"CODE",{class:!0});var AS=r(jo);_x=n(AS,"DPM2 KARRAS"),AS.forEach(t),f7.forEach(t),DS.forEach(t),kx=u(ne),rp=l(ne,"LI",{});var LS=r(rp);Fs=l(LS,"P",{});var zp=r(Fs);Ex=n(zp,"CFG Scale set to "),Fo=l(zp,"CODE",{class:!0});var IS=r(Fo);bx=n(IS,"7"),IS.forEach(t),xx=n(zp," and Steps to "),Vo=l(zp,"CODE",{class:!0});var PS=r(Vo);yx=n(PS,"20"),PS.forEach(t),zp.forEach(t),LS.forEach(t),ne.forEach(t),Eg=u(s),tt=l(s,"P",{});var tf=r(tt);wx=n(tf,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Yo=l(tf,"CODE",{class:!0});var OS=r(Yo);Tx=n(OS,"150"),OS.forEach(t),Rx=n(tf," - "),Ko=l(tf,"CODE",{class:!0});var zS=r(Ko);Sx=n(zS,"200"),zS.forEach(t),Dx=n(tf," and keep in mind we can add and remove as we try different training settings with different output."),tf.forEach(t),bg=u(s),rr(kl.$$.fragment,s),xg=u(s),Vs=l(s,"H4",{id:!0});var d7=r(Vs);Ys=l(d7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var NS=r(Ys);ip=l(NS,"SPAN",{class:!0}),r(ip).forEach(t),NS.forEach(t),Ax=n(d7,"Download images"),d7.forEach(t),yg=u(s),Xo=l(s,"P",{});var CS=r(Xo);Lx=n(CS,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),CS.forEach(t),wg=u(s),be=l(s,"UL",{});var Na=r(be);Zo=l(Na,"LI",{});var p7=r(Zo);El=l(p7,"A",{href:!0,rel:!0});var GS=r(El);Ix=n(GS,"3ee Games regularization images"),GS.forEach(t),Px=n(p7,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),p7.forEach(t),Ox=u(Na),Qo=l(Na,"LI",{});var h7=r(Qo);bl=l(h7,"A",{href:!0,rel:!0});var HS=r(bl);zx=n(HS,"Pre-Rendered Regularization Images"),HS.forEach(t),Nx=n(h7,": Includes 1500 regularization images."),h7.forEach(t),Cx=u(Na),Jo=l(Na,"LI",{});var g7=r(Jo);xl=l(g7,"A",{href:!0,rel:!0});var qS=r(xl);Gx=n(qS,"Stable Diffusion 1.5 Regularization Images"),qS.forEach(t),Hx=n(g7,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),g7.forEach(t),qx=u(Na),$o=l(Na,"LI",{});var m7=r($o);yl=l(m7,"A",{href:!0,rel:!0});var MS=r(yl);Mx=n(MS,"Aitrepreneur SDXL image set"),MS.forEach(t),Ux=n(m7,": a large image set generated with Stable Diffusion SDXL."),m7.forEach(t),Na.forEach(t),Tg=u(s),Ks=l(s,"H4",{id:!0});var v7=r(Ks);Xs=l(v7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var US=r(Xs);op=l(US,"SPAN",{class:!0}),r(op).forEach(t),US.forEach(t),Bx=n(v7,"Captioning Regularization images"),v7.forEach(t),Rg=u(s),en=l(s,"P",{});var BS=r(en);Wx=n(BS,"While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),BS.forEach(t),Sg=u(s),tn=l(s,"P",{});var WS=r(tn);jx=n(WS,"Here\u2019s the workflow I used:"),WS.forEach(t),Dg=u(s),st=l(s,"UL",{});var sf=r(st);Zs=l(sf,"LI",{});var Np=r(Zs);np=l(Np,"STRONG",{});var jS=r(np);Fx=n(jS,"Structured Filenames"),jS.forEach(t),Vx=n(Np,": Stable Diffusion Web UI automatically embeds prompts in filenames (e.g., "),sn=l(Np,"CODE",{class:!0});var FS=r(sn);Yx=n(FS,"princeadam_1boy_closeup.png"),FS.forEach(t),Kx=n(Np,")."),Np.forEach(t),Xx=u(sf),at=l(sf,"LI",{});var sr=r(at);cp=l(sr,"STRONG",{});var VS=r(cp);Zx=n(VS,"Automated Extraction"),VS.forEach(t),Qx=n(sr,": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),an=l(sr,"CODE",{class:!0});var YS=r(an);Jx=n(YS,"1boy"),YS.forEach(t),$x=n(sr," or "),ln=l(sr,"CODE",{class:!0});var KS=r(ln);ey=n(KS,"purple_vest"),KS.forEach(t),ty=n(sr,"."),sr.forEach(t),sy=u(sf),rn=l(sf,"LI",{});var _7=r(rn);up=l(_7,"STRONG",{});var XS=r(up);ay=n(XS,"Manual Verification"),XS.forEach(t),ly=n(_7,": Spot-checked captions to ensure accuracy."),_7.forEach(t),sf.forEach(t),Ag=u(s),wl=l(s,"PRE",{class:!0});var $A=r(wl);$A.forEach(t),Lg=u(s),Qs=l(s,"OL",{});var Zm=r(Qs);Tl=l(Zm,"LI",{});var Qm=r(Tl);ry=n(Qm,"Save this file as "),on=l(Qm,"CODE",{class:!0});var ZS=r(on);iy=n(ZS,"filename2txt.bat"),ZS.forEach(t),oy=n(Qm," and place it into the regularization images directory"),Qm.forEach(t),ny=u(Zm),Rl=l(Zm,"LI",{});var Jm=r(Rl);cy=n(Jm,"Run: "),nn=l(Jm,"CODE",{class:!0});var QS=r(nn);uy=n(QS,".\\filename2txt.bat"),QS.forEach(t),fy=n(Jm,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Jm.forEach(t),Zm.forEach(t),Ig=u(s),Js=l(s,"UL",{});var $m=r(Js);cn=l($m,"LI",{});var k7=r(cn);dy=n(k7,"Example filename: "),un=l(k7,"CODE",{class:!0});var JS=r(un);py=n(JS,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),JS.forEach(t),k7.forEach(t),hy=u($m),Sl=l($m,"LI",{});var ev=r(Sl);gy=n(ev,"Output: "),fn=l(ev,"CODE",{class:!0});var $S=r(fn);my=n($S,"aburbres,princeadam,1boy,close-up,purple_vest"),$S.forEach(t),vy=n(ev," saved in a text file with the same name as image."),ev.forEach(t),$m.forEach(t),Pg=u(s),$s=l(s,"H2",{id:!0});var E7=r($s);ea=l(E7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var eD=r(ea);fp=l(eD,"SPAN",{class:!0}),r(fp).forEach(t),eD.forEach(t),_y=n(E7,"Training a LoRA"),E7.forEach(t),Og=u(s),ta=l(s,"P",{});var tv=r(ta);ky=n(tv,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),Dl=l(tv,"A",{href:!0,rel:!0});var tD=r(Dl);Ey=n(tD,"kohya-ss/sd-scripts"),tD.forEach(t),by=n(tv,"."),tv.forEach(t),zg=u(s),Al=l(s,"BLOCKQUOTE",{class:!0});var sD=r(Al);sa=l(sD,"P",{class:!0});var sv=r(sa);xy=n(sv,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Ll=l(sv,"A",{href:!0,rel:!0});var aD=r(Ll);yy=n(aD,"Kohya SD script documentation"),aD.forEach(t),wy=n(sv,"."),sv.forEach(t),sD.forEach(t),Ng=u(s),aa=l(s,"H3",{id:!0});var b7=r(aa);la=l(b7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var lD=r(la);dp=l(lD,"SPAN",{class:!0}),r(dp).forEach(t),lD.forEach(t),Ty=n(b7,"Directory setup"),b7.forEach(t),Cg=u(s),ra=l(s,"P",{});var av=r(ra);Ry=n(av,"In your configuration json, use "),dn=l(av,"CODE",{class:!0});var rD=r(dn);Sy=n(rD,"reg_data_dir"),rD.forEach(t),Dy=n(av," to point to the directory with your regularization images:"),av.forEach(t),Gg=u(s),Il=l(s,"PRE",{class:!0});var eL=r(Il);eL.forEach(t),Hg=u(s),pn=l(s,"P",{});var iD=r(pn);Ay=n(iD,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),iD.forEach(t),qg=u(s),Pl=l(s,"PRE",{class:!0});var tL=r(Pl);tL.forEach(t),Mg=u(s),lt=l(s,"P",{});var af=r(lt);Ly=n(af,"Set the "),hn=l(af,"CODE",{class:!0});var oD=r(hn);Iy=n(oD,"number of iterations"),oD.forEach(t),Py=n(af," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),gn=l(af,"CODE",{class:!0});var nD=r(gn);Oy=n(nD,"training images \xD7 iterations"),nD.forEach(t),zy=n(af,". If there are more regularization images than this, the extras won\u2019t be used."),af.forEach(t),Ug=u(s),rt=l(s,"P",{});var lf=r(rt);Ny=n(lf,"Create folders in the training image folder with the format "),mn=l(lf,"CODE",{class:!0});var cD=r(mn);Cy=n(cD,"<repetition count>_<class>"),cD.forEach(t),Gy=n(lf," multiple times, and similarly create folders in the regularization image folder with the format "),vn=l(lf,"CODE",{class:!0});var uD=r(vn);Hy=n(uD,"<repetition count>_<class>"),uD.forEach(t),qy=n(lf,"."),lf.forEach(t),Bg=u(s),_n=l(s,"P",{});var fD=r(_n);My=n(fD,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),fD.forEach(t),Wg=u(s),ia=l(s,"UL",{});var lv=r(ia);kn=l(lv,"LI",{});var x7=r(kn);Uy=n(x7,"train_data_dir"),pp=l(x7,"UL",{});var dD=r(pp);hp=l(dD,"LI",{});var pD=r(hp);By=n(pD,"10_princeadam"),pD.forEach(t),dD.forEach(t),x7.forEach(t),Wy=u(lv),En=l(lv,"LI",{});var y7=r(En);jy=n(y7,"reg_dir"),gp=l(y7,"UL",{});var hD=r(gp);mp=l(hD,"LI",{});var gD=r(mp);Fy=n(gD,"1_1boy"),gD.forEach(t),hD.forEach(t),y7.forEach(t),lv.forEach(t),jg=u(s),bn=l(s,"P",{});var mD=r(bn);Vy=n(mD,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),mD.forEach(t),Fg=u(s),Ol=l(s,"P",{class:!0});var vD=r(Ol);zl=l(vD,"IMG",{src:!0,alt:!0,class:!0}),vD.forEach(t),Vg=u(s),oa=l(s,"H3",{id:!0});var w7=r(oa);na=l(w7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _D=r(na);vp=l(_D,"SPAN",{class:!0}),r(vp).forEach(t),_D.forEach(t),Yy=n(w7,"Training Settings"),w7.forEach(t),Yg=u(s),zt=l(s,"P",{});var Cp=r(zt);Ky=n(Cp,"The training setup we\u2019re going to use is:  "),xn=l(Cp,"CODE",{class:!0});var kD=r(xn);Xy=n(kD,"Number of images * repeats * epoch / batch size = total steps"),kD.forEach(t),Zy=n(Cp,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),yn=l(Cp,"CODE",{class:!0});var ED=r(yn);Qy=n(ED,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),ED.forEach(t),Cp.forEach(t),Kg=u(s),Nt=l(s,"TABLE",{class:!0});var rv=r(Nt);wn=l(rv,"THEAD",{class:!0});var bD=r(wn);re=l(bD,"TR",{class:!0});var Rt=r(re);Tn=l(Rt,"TH",{class:!0});var xD=r(Tn);Jy=n(xD,"Number of Images"),xD.forEach(t),$y=u(Rt),Rn=l(Rt,"TH",{class:!0});var yD=r(Rn);e3=n(yD,"Repeats"),yD.forEach(t),t3=u(Rt),Sn=l(Rt,"TH",{class:!0});var wD=r(Sn);s3=n(wD,"Epochs"),wD.forEach(t),a3=u(Rt),Dn=l(Rt,"TH",{class:!0});var TD=r(Dn);l3=n(TD,"Batch Size"),TD.forEach(t),r3=u(Rt),An=l(Rt,"TH",{class:!0});var RD=r(An);i3=n(RD,"Total Steps"),RD.forEach(t),Rt.forEach(t),bD.forEach(t),o3=u(rv),Ln=l(rv,"TBODY",{class:!0});var SD=r(Ln);ie=l(SD,"TR",{class:!0});var St=r(ie);In=l(St,"TD",{class:!0});var DD=r(In);n3=n(DD,"45"),DD.forEach(t),c3=u(St),Pn=l(St,"TD",{class:!0});var AD=r(Pn);u3=n(AD,"10"),AD.forEach(t),f3=u(St),On=l(St,"TD",{class:!0});var LD=r(On);d3=n(LD,"20"),LD.forEach(t),p3=u(St),zn=l(St,"TD",{class:!0});var ID=r(zn);h3=n(ID,"2"),ID.forEach(t),g3=u(St),Nn=l(St,"TD",{class:!0});var PD=r(Nn);m3=n(PD,"4500"),PD.forEach(t),St.forEach(t),SD.forEach(t),rv.forEach(t),Xg=u(s),Cn=l(s,"P",{});var OD=r(Cn);v3=n(OD,"Now let\u2019s focus on these training settings:"),OD.forEach(t),Zg=u(s),Nl=l(s,"PRE",{class:!0});var sL=r(Nl);sL.forEach(t),Qg=u(s),U=l(s,"UL",{});var V=r(U);Gn=l(V,"LI",{});var T7=r(Gn);Cl=l(T7,"STRONG",{});var iv=r(Cl);_3=n(iv,"Learning Rate ("),Hn=l(iv,"CODE",{class:!0});var zD=r(Hn);k3=n(zD,"learning_rate"),zD.forEach(t),E3=n(iv,")"),iv.forEach(t),b3=n(T7,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),T7.forEach(t),x3=u(V),qn=l(V,"LI",{});var R7=r(qn);Gl=l(R7,"STRONG",{});var ov=r(Gl);y3=n(ov,"Text Encoder Learning Rate ("),Mn=l(ov,"CODE",{class:!0});var ND=r(Mn);w3=n(ND,"text_encoder_lr"),ND.forEach(t),T3=n(ov,")"),ov.forEach(t),R3=n(R7,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),R7.forEach(t),S3=u(V),Un=l(V,"LI",{});var S7=r(Un);Hl=l(S7,"STRONG",{});var nv=r(Hl);D3=n(nv,"UNet Learning Rate ("),Bn=l(nv,"CODE",{class:!0});var CD=r(Bn);A3=n(CD,"unet_lr"),CD.forEach(t),L3=n(nv,")"),nv.forEach(t),I3=n(S7,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),S7.forEach(t),P3=u(V),Wn=l(V,"LI",{});var D7=r(Wn);ql=l(D7,"STRONG",{});var cv=r(ql);O3=n(cv,"Learning Rate Scheduler ("),jn=l(cv,"CODE",{class:!0});var GD=r(jn);z3=n(GD,"lr_scheduler"),GD.forEach(t),N3=n(cv,")"),cv.forEach(t),C3=n(D7,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),D7.forEach(t),G3=u(V),Fn=l(V,"LI",{});var A7=r(Fn);Ml=l(A7,"STRONG",{});var uv=r(Ml);H3=n(uv,"Number of Cycles in Learning Rate Scheduler ("),Vn=l(uv,"CODE",{class:!0});var HD=r(Vn);q3=n(HD,"lr_scheduler_num_cycles"),HD.forEach(t),M3=n(uv,")"),uv.forEach(t),U3=n(A7,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),A7.forEach(t),B3=u(V),Yn=l(V,"LI",{});var L7=r(Yn);Ul=l(L7,"STRONG",{});var fv=r(Ul);W3=n(fv,"Network Dimension ("),Kn=l(fv,"CODE",{class:!0});var qD=r(Kn);j3=n(qD,"network_dim"),qD.forEach(t),F3=n(fv,")"),fv.forEach(t),V3=n(L7,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),L7.forEach(t),Y3=u(V),Xn=l(V,"LI",{});var I7=r(Xn);Bl=l(I7,"STRONG",{});var dv=r(Bl);K3=n(dv,"Network Alpha ("),Zn=l(dv,"CODE",{class:!0});var MD=r(Zn);X3=n(MD,"network_alpha"),MD.forEach(t),Z3=n(dv,")"),dv.forEach(t),Q3=n(I7,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),I7.forEach(t),J3=u(V),Qn=l(V,"LI",{});var P7=r(Qn);Wl=l(P7,"STRONG",{});var pv=r(Wl);$3=n(pv,"Clip Skip ("),Jn=l(pv,"CODE",{class:!0});var UD=r(Jn);e4=n(UD,"clip_skip"),UD.forEach(t),t4=n(pv,")"),pv.forEach(t),s4=n(P7,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),P7.forEach(t),a4=u(V),$n=l(V,"LI",{});var O7=r($n);jl=l(O7,"STRONG",{});var hv=r(jl);l4=n(hv,"Max Token Length ("),ec=l(hv,"CODE",{class:!0});var BD=r(ec);r4=n(BD,"max_token_length"),BD.forEach(t),i4=n(hv,")"),hv.forEach(t),o4=n(O7,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),O7.forEach(t),n4=u(V),tc=l(V,"LI",{});var z7=r(tc);Fl=l(z7,"STRONG",{});var gv=r(Fl);c4=n(gv,"Noise Offset ("),sc=l(gv,"CODE",{class:!0});var WD=r(sc);u4=n(WD,"noise_offset"),WD.forEach(t),f4=n(gv,")"),gv.forEach(t),d4=n(z7,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),z7.forEach(t),p4=u(V),ac=l(V,"LI",{});var N7=r(ac);Vl=l(N7,"STRONG",{});var mv=r(Vl);h4=n(mv,"Regularization Data Directory ("),lc=l(mv,"CODE",{class:!0});var jD=r(lc);g4=n(jD,"reg_data_dir"),jD.forEach(t),m4=n(mv,")"),mv.forEach(t),v4=n(N7,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),N7.forEach(t),V.forEach(t),Jg=u(s),ca=l(s,"H3",{id:!0});var C7=r(ca);ua=l(C7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var FD=r(ua);_p=l(FD,"SPAN",{class:!0}),r(_p).forEach(t),FD.forEach(t),_4=n(C7,"Fine Tuning"),C7.forEach(t),$g=u(s),rc=l(s,"P",{});var VD=r(rc);k4=n(VD,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),VD.forEach(t),em=u(s),rr(Yl.$$.fragment,s),tm=u(s),fa=l(s,"H4",{id:!0});var G7=r(fa);da=l(G7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var YD=r(da);kp=l(YD,"SPAN",{class:!0}),r(kp).forEach(t),YD.forEach(t),E4=n(G7,"Workflow with Auto1111 WebUI"),G7.forEach(t),sm=u(s),pa=l(s,"P",{});var vv=r(pa);b4=n(vv,"We\u2019re going to use "),Kl=l(vv,"A",{href:!0,rel:!0});var KD=r(Kl);x4=n(KD,"Stable Diffusion web UI"),KD.forEach(t),y4=n(vv," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),vv.forEach(t),am=u(s),ha=l(s,"P",{});var _v=r(ha);w4=n(_v,"We\u2019re going to use the "),ic=l(_v,"CODE",{class:!0});var XD=r(ic);T4=n(XD,"X/Y/Z plot"),XD.forEach(t),R4=n(_v," script to compare different epochs."),_v.forEach(t),lm=u(s),oe=l(s,"UL",{});var Dt=r(oe);oc=l(Dt,"LI",{});var H7=r(oc);S4=n(H7,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),rm=l(H7,"PRINCEADAM0001:0.7",{}),r(rm).forEach(t),H7.forEach(t),D4=u(Dt),Ep=l(Dt,"LI",{});var ZD=r(Ep);A4=n(ZD,"In generation parameters and select the X/Y/Z plot script."),ZD.forEach(t),L4=u(Dt),it=l(Dt,"LI",{});var ar=r(it);I4=n(ar,"Select "),nc=l(ar,"CODE",{class:!0});var QD=r(nc);P4=n(QD,"Prompt SR"),QD.forEach(t),O4=n(ar," for Prompt Replace.  We\u2019re going to replace "),cc=l(ar,"CODE",{class:!0});var JD=r(cc);z4=n(JD,"<princeadam0001:0.7>"),JD.forEach(t),N4=n(ar," with different epoch: "),uc=l(ar,"CODE",{class:!0});var $D=r(uc);C4=n($D,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),$D.forEach(t),ar.forEach(t),G4=u(Dt),fc=l(Dt,"LI",{});var q7=r(fc);H4=n(q7,"Select a fast sampler like "),dc=l(q7,"CODE",{class:!0});var e9=r(dc);q4=n(e9,"DPM2 KARRAS"),e9.forEach(t),q7.forEach(t),M4=u(Dt),ga=l(Dt,"LI",{});var Gp=r(ga);U4=n(Gp,"CFG Scale set to "),pc=l(Gp,"CODE",{class:!0});var t9=r(pc);B4=n(t9,"7"),t9.forEach(t),W4=n(Gp," and Steps to "),hc=l(Gp,"CODE",{class:!0});var s9=r(hc);j4=n(s9,"20"),s9.forEach(t),Gp.forEach(t),Dt.forEach(t),im=u(s),ot=l(s,"P",{});var rf=r(ot);F4=n(rf,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),gc=l(rf,"CODE",{class:!0});var a9=r(gc);V4=n(a9,"network_dim"),a9.forEach(t),Y4=n(rf," and "),mc=l(rf,"CODE",{class:!0});var l9=r(mc);K4=n(l9,"network_alpha"),l9.forEach(t),X4=n(rf,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),rf.forEach(t),om=u(s),xe=l(s,"UL",{});var Ca=r(xe);ma=l(Ca,"LI",{});var Hp=r(ma);Z4=n(Hp,"Select "),vc=l(Hp,"CODE",{class:!0});var r9=r(vc);Q4=n(r9,"Prompt SR"),r9.forEach(t),J4=n(Hp," for Prompt Replace.  We\u2019re going to replace the weights "),_c=l(Hp,"CODE",{class:!0});var i9=r(_c);$4=n(i9,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),i9.forEach(t),Hp.forEach(t),e0=u(Ca),Xl=l(Ca,"LI",{});var kv=r(Xl);t0=n(kv,"Use Prompt SR to generate a variety of angles: Select "),kc=l(kv,"CODE",{class:!0});var o9=r(kc);s0=n(o9,"Prompt SR"),o9.forEach(t),a0=n(kv," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),kv.forEach(t),l0=u(Ca),bp=l(Ca,"LI",{});var n9=r(bp);r0=n(n9,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),n9.forEach(t),i0=u(Ca),xp=l(Ca,"LI",{});var c9=r(xp);o0=n(c9,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),c9.forEach(t),Ca.forEach(t),nm=u(s),va=l(s,"H4",{id:!0});var M7=r(va);_a=l(M7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var u9=r(_a);yp=l(u9,"SPAN",{class:!0}),r(yp).forEach(t),u9.forEach(t),n0=n(M7,"Issues to look for"),M7.forEach(t),cm=u(s),ye=l(s,"UL",{});var Ga=r(ye);Ec=l(Ga,"LI",{});var U7=r(Ec);wp=l(U7,"STRONG",{});var f9=r(wp);c0=n(f9,"Undercooked:"),f9.forEach(t),u0=n(U7," Lacks output, adjust unet learning rate or extend training duration."),U7.forEach(t),f0=u(Ga),bc=l(Ga,"LI",{});var B7=r(bc);Tp=l(B7,"STRONG",{});var d9=r(Tp);d0=n(d9,"Overcooked:"),d9.forEach(t),p0=n(B7," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),B7.forEach(t),h0=u(Ga),xc=l(Ga,"LI",{});var W7=r(xc);Rp=l(W7,"STRONG",{});var p9=r(Rp);g0=n(p9,"Overfit:"),p9.forEach(t),m0=n(W7," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),W7.forEach(t),v0=u(Ga),yc=l(Ga,"LI",{});var j7=r(yc);Sp=l(j7,"STRONG",{});var h9=r(Sp);_0=n(h9,"Mismatched:"),h9.forEach(t),k0=n(j7," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),j7.forEach(t),Ga.forEach(t),um=u(s),wc=l(s,"P",{});var g9=r(wc);E0=n(g9,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),g9.forEach(t),fm=u(s),Zl=l(s,"P",{class:!0});var m9=r(Zl);Ql=l(m9,"IMG",{src:!0,alt:!0,class:!0}),m9.forEach(t),dm=u(s),ka=l(s,"H2",{id:!0});var F7=r(ka);Ea=l(F7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var v9=r(Ea);Dp=l(v9,"SPAN",{class:!0}),r(Dp).forEach(t),v9.forEach(t),b0=n(F7,"Troubleshooting"),F7.forEach(t),pm=u(s),Tc=l(s,"P",{});var _9=r(Tc);x0=n(_9,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),_9.forEach(t),hm=u(s),nt=l(s,"UL",{});var of=r(nt);Jl=l(of,"LI",{});var Ev=r(Jl);y0=n(Ev,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Rc=l(Ev,"CODE",{class:!0});var k9=r(Rc);w0=n(k9,"200"),k9.forEach(t),T0=n(Ev," regularization images per training image."),Ev.forEach(t),R0=u(of),$l=l(of,"LI",{});var bv=r($l);S0=n(bv,"Repeats of regularization images, but may overfit more.  Increasing the "),Sc=l(bv,"CODE",{class:!0});var E9=r(Sc);D0=n(E9,"repetition_count"),E9.forEach(t),A0=n(bv," will cycle through the images more but the results may have results that overfit the model."),bv.forEach(t),L0=u(of),Ap=l(of,"LI",{});var b9=r(Ap);I0=n(b9,"Create more regularization images without increasing repeats will help with the overfitting."),b9.forEach(t),of.forEach(t),gm=u(s),Ct=l(s,"TABLE",{class:!0});var xv=r(Ct);Dc=l(xv,"THEAD",{class:!0});var x9=r(Dc);ct=l(x9,"TR",{class:!0});var nf=r(ct);Ac=l(nf,"TH",{class:!0});var y9=r(Ac);P0=n(y9,"Issue"),y9.forEach(t),O0=u(nf),Lc=l(nf,"TH",{class:!0});var w9=r(Lc);z0=n(w9,"Situation"),w9.forEach(t),N0=u(nf),Ic=l(nf,"TH",{class:!0});var T9=r(Ic);C0=n(T9,"Recommendation"),T9.forEach(t),nf.forEach(t),x9.forEach(t),G0=u(xv),we=l(xv,"TBODY",{class:!0});var Ha=r(we);ut=l(Ha,"TR",{class:!0});var cf=r(ut);Pc=l(cf,"TD",{class:!0});var R9=r(Pc);H0=n(R9,"Varying quality"),R9.forEach(t),q0=u(cf),Oc=l(cf,"TD",{class:!0});var S9=r(Oc);M0=n(S9,"Results differ from expectations"),S9.forEach(t),U0=u(cf),zc=l(cf,"TD",{class:!0});var D9=r(zc);B0=n(D9,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),D9.forEach(t),cf.forEach(t),W0=u(Ha),ft=l(Ha,"TR",{class:!0});var uf=r(ft);Nc=l(uf,"TD",{class:!0});var A9=r(Nc);j0=n(A9,"Inadequate regularization for input data"),A9.forEach(t),F0=u(uf),Cc=l(uf,"TD",{class:!0});var L9=r(Cc);V0=n(L9,"Lower input images, less regularization needed"),L9.forEach(t),Y0=u(uf),Gc=l(uf,"TD",{class:!0});var I9=r(Gc);K0=n(I9,"Reduce the number of input images or increasing the quantity of reg images."),I9.forEach(t),uf.forEach(t),X0=u(Ha),dt=l(Ha,"TR",{class:!0});var ff=r(dt);Hc=l(ff,"TD",{class:!0});var P9=r(Hc);Z0=n(P9,"Overfitting due to repetition"),P9.forEach(t),Q0=u(ff),qc=l(ff,"TD",{class:!0});var O9=r(qc);J0=n(O9,"Repeats of reg images, risk of overfitting"),O9.forEach(t),$0=u(ff),Mc=l(ff,"TD",{class:!0});var z9=r(Mc);e5=n(z9,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),z9.forEach(t),ff.forEach(t),t5=u(Ha),pt=l(Ha,"TR",{class:!0});var df=r(pt);Uc=l(df,"TD",{class:!0});var N9=r(Uc);s5=n(N9,"Mitigate overfitting while increasing diversity"),N9.forEach(t),a5=u(df),Bc=l(df,"TD",{class:!0});var C9=r(Bc);l5=n(C9,"Create more reg images without repeats"),C9.forEach(t),r5=u(df),Wc=l(df,"TD",{class:!0});var G9=r(Wc);i5=n(G9,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),G9.forEach(t),df.forEach(t),Ha.forEach(t),xv.forEach(t),mm=u(s),ba=l(s,"H4",{id:!0});var V7=r(ba);xa=l(V7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var H9=r(xa);Lp=l(H9,"SPAN",{class:!0}),r(Lp).forEach(t),H9.forEach(t),o5=n(V7,"More Solutions"),V7.forEach(t),vm=u(s),jc=l(s,"P",{});var q9=r(jc);n5=n(q9,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),q9.forEach(t),_m=u(s),Gt=l(s,"TABLE",{class:!0});var yv=r(Gt);Fc=l(yv,"THEAD",{class:!0});var M9=r(Fc);ht=l(M9,"TR",{class:!0});var pf=r(ht);Vc=l(pf,"TH",{class:!0});var U9=r(Vc);c5=n(U9,"Symptom"),U9.forEach(t),u5=u(pf),Yc=l(pf,"TH",{class:!0});var B9=r(Yc);f5=n(B9,"Likely Cause"),B9.forEach(t),d5=u(pf),Kc=l(pf,"TH",{class:!0});var W9=r(Kc);p5=n(W9,"Solution"),W9.forEach(t),pf.forEach(t),M9.forEach(t),h5=u(yv),W=l(yv,"TBODY",{class:!0});var X=r(W);gt=l(X,"TR",{class:!0});var hf=r(gt);Xc=l(hf,"TD",{class:!0});var j9=r(Xc);g5=n(j9,"Plastic texture persists"),j9.forEach(t),m5=u(hf),Zc=l(hf,"TD",{class:!0});var F9=r(Zc);v5=n(F9,"Insufficient human reg images"),F9.forEach(t),_5=u(hf),Qc=l(hf,"TD",{class:!0});var V9=r(Qc);k5=n(V9,"Add real photos to reg set"),V9.forEach(t),hf.forEach(t),E5=u(X),mt=l(X,"TR",{class:!0});var gf=r(mt);Jc=l(gf,"TD",{class:!0});var Y9=r(Jc);b5=n(Y9,"Loss plateaus early"),Y9.forEach(t),x5=u(gf),$c=l(gf,"TD",{class:!0});var K9=r($c);y5=n(K9,"Learning rate too low"),K9.forEach(t),w5=u(gf),eu=l(gf,"TD",{class:!0});var X9=r(eu);T5=n(X9,"Increase LR by 10x"),X9.forEach(t),gf.forEach(t),R5=u(X),vt=l(X,"TR",{class:!0});var mf=r(vt);tu=l(mf,"TD",{class:!0});var Z9=r(tu);S5=n(Z9,"Features blurry"),Z9.forEach(t),D5=u(mf),su=l(mf,"TD",{class:!0});var Q9=r(su);A5=n(Q9,"Network dimension too small"),Q9.forEach(t),L5=u(mf),au=l(mf,"TD",{class:!0});var J9=r(au);I5=n(J9,"Increase network_dim to 64+"),J9.forEach(t),mf.forEach(t),P5=u(X),_t=l(X,"TR",{class:!0});var vf=r(_t);lu=l(vf,"TD",{class:!0});var $9=r(lu);O5=n($9,"Color distortion"),$9.forEach(t),z5=u(vf),ru=l(vf,"TD",{class:!0});var eA=r(ru);N5=n(eA,"Noise offset conflict"),eA.forEach(t),C5=u(vf),iu=l(vf,"TD",{class:!0});var tA=r(iu);G5=n(tA,"Try noise_offset 0.05-0.1"),tA.forEach(t),vf.forEach(t),H5=u(X),kt=l(X,"TR",{class:!0});var _f=r(kt);ou=l(_f,"TD",{class:!0});var sA=r(ou);q5=n(sA,"Overly stylized outputs"),sA.forEach(t),M5=u(_f),nu=l(_f,"TD",{class:!0});var aA=r(nu);U5=n(aA,"Reg image style mismatch"),aA.forEach(t),B5=u(_f),cu=l(_f,"TD",{class:!0});var lA=r(cu);W5=n(lA,"Regenerate reg images with base model"),lA.forEach(t),_f.forEach(t),j5=u(X),Et=l(X,"TR",{class:!0});var kf=r(Et);uu=l(kf,"TD",{class:!0});var rA=r(uu);F5=n(rA,"Training instability"),rA.forEach(t),V5=u(kf),fu=l(kf,"TD",{class:!0});var iA=r(fu);Y5=n(iA,"Batch size too large"),iA.forEach(t),K5=u(kf),du=l(kf,"TD",{class:!0});var oA=r(du);X5=n(oA,"Reduce batch_size to 1-2"),oA.forEach(t),kf.forEach(t),Z5=u(X),bt=l(X,"TR",{class:!0});var Ef=r(bt);pu=l(Ef,"TD",{class:!0});var nA=r(pu);Q5=n(nA,"Slow convergence"),nA.forEach(t),J5=u(Ef),hu=l(Ef,"TD",{class:!0});var cA=r(hu);$5=n(cA,"Network_alpha too high"),cA.forEach(t),ew=u(Ef),gu=l(Ef,"TD",{class:!0});var uA=r(gu);tw=n(uA,"Set alpha = dim/2 (e.g., 64/2 = 32)"),uA.forEach(t),Ef.forEach(t),sw=u(X),xt=l(X,"TR",{class:!0});var bf=r(xt);mu=l(bf,"TD",{class:!0});var fA=r(mu);aw=n(fA,"Loss divergence"),fA.forEach(t),lw=u(bf),vu=l(bf,"TD",{class:!0});var dA=r(vu);rw=n(dA,"Text encoder LR too high"),dA.forEach(t),iw=u(bf),_u=l(bf,"TD",{class:!0});var pA=r(_u);ow=n(pA,"Reduce text_encoder_lr by 10x"),pA.forEach(t),bf.forEach(t),nw=u(X),yt=l(X,"TR",{class:!0});var xf=r(yt);ku=l(xf,"TD",{class:!0});var hA=r(ku);cw=n(hA,"Poor prompt adherence"),hA.forEach(t),uw=u(xf),Eu=l(xf,"TD",{class:!0});var gA=r(Eu);fw=n(gA,"Clip skip too high"),gA.forEach(t),dw=u(xf),bu=l(xf,"TD",{class:!0});var mA=r(bu);pw=n(mA,"Reduce clip_skip to 1-2"),mA.forEach(t),xf.forEach(t),hw=u(X),wt=l(X,"TR",{class:!0});var yf=r(wt);xu=l(yf,"TD",{class:!0});var vA=r(xu);gw=n(vA,"Memory errors"),vA.forEach(t),mw=u(yf),yu=l(yf,"TD",{class:!0});var _A=r(yu);vw=n(_A,"Resolution too high"),_A.forEach(t),_w=u(yf),wu=l(yf,"TD",{class:!0});var kA=r(wu);kw=n(kA,"Reduce to 512-768px, enable gradient checkpointing"),kA.forEach(t),yf.forEach(t),X.forEach(t),yv.forEach(t),km=u(s),ya=l(s,"H2",{id:!0});var Y7=r(ya);wa=l(Y7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var EA=r(wa);Ip=l(EA,"SPAN",{class:!0}),r(Ip).forEach(t),EA.forEach(t),Ew=n(Y7,"Results"),Y7.forEach(t),Em=u(s),Tu=l(s,"P",{});var bA=r(Tu);bw=n(bA,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),bA.forEach(t),bm=u(s),Ru=l(s,"P",{});var xA=r(Ru);xw=n(xA,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),xA.forEach(t),xm=u(s),er=l(s,"P",{class:!0});var yA=r(er);tr=l(yA,"IMG",{src:!0,alt:!0,class:!0}),yA.forEach(t),ym=u(s),Su=l(s,"P",{});var wA=r(Su);yw=n(wA,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),wA.forEach(t),wm=u(s),Ht=l(s,"H2",{id:!0,class:!0});var K7=r(Ht);Ta=l(K7,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var TA=r(Ta);Pp=l(TA,"SPAN",{class:!0}),r(Pp).forEach(t),TA.forEach(t),ww=n(K7,"spacelab"),K7.forEach(t),Tm=u(s),Te&&Te.l(s),Rm=wf(),this.h()},h(){i(T,"class","icon icon-link"),i(w,"aria-hidden","true"),i(w,"tabindex","-1"),i(w,"href","#experiment-1-anime-inspired-heroism"),i(b,"id","experiment-1-anime-inspired-heroism"),Ut(I.src,P="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png")||i(I,"src",P),i(I,"alt","image"),i(I,"class","svelte-x2kgxs"),i(y,"class","svelte-x2kgxs"),i(R,"class","icon icon-link"),i(q,"aria-hidden","true"),i(q,"tabindex","-1"),i(q,"href","#experiment-2-retro-cartoon-resurrection"),i(Z,"id","experiment-2-retro-cartoon-resurrection"),Ut(fe.src,Tf="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1738190889/blog/fiz3ariex9rpsoovdccl.png")||i(fe,"src",Tf),i(fe,"alt","image"),i(fe,"class","svelte-x2kgxs"),i(Se,"class","svelte-x2kgxs"),i(Rf,"class","icon icon-link"),i(Vt,"aria-hidden","true"),i(Vt,"tabindex","-1"),i(Vt,"href","#what-are-regularization-images"),i(Ft,"id","what-are-regularization-images"),i(ur,"class","svelte-x2kgxs"),i(qa,"class","svelte-x2kgxs"),i(gr,"class","svelte-x2kgxs"),i(mr,"class","svelte-x2kgxs"),i(vr,"class","svelte-x2kgxs"),i(De,"class","svelte-x2kgxs"),i(hr,"class","svelte-x2kgxs"),i(_r,"class","svelte-x2kgxs"),i(kr,"class","svelte-x2kgxs"),i(Er,"class","svelte-x2kgxs"),i(Le,"class","svelte-x2kgxs"),i(br,"class","svelte-x2kgxs"),i(xr,"class","svelte-x2kgxs"),i(yr,"class","svelte-x2kgxs"),i(Ie,"class","svelte-x2kgxs"),i(wr,"class","svelte-x2kgxs"),i(Tr,"class","svelte-x2kgxs"),i(Rr,"class","svelte-x2kgxs"),i(Pe,"class","svelte-x2kgxs"),i(Ae,"class","svelte-x2kgxs"),i(At,"class","svelte-x2kgxs"),i(Ar,"class","svelte-x2kgxs"),i(Ua,"class","svelte-x2kgxs"),i(Lf,"class","icon icon-link"),i(Kt,"aria-hidden","true"),i(Kt,"tabindex","-1"),i(Kt,"href","#scenario-1-limited-training-data"),i(Yt,"id","scenario-1-limited-training-data"),i(zf,"class","icon icon-link"),i(Zt,"aria-hidden","true"),i(Zt,"tabindex","-1"),i(Zt,"href","#scenario-2-imbalanced-training-data"),i(Xt,"id","scenario-2-imbalanced-training-data"),i(Hf,"class","icon icon-link"),i(Jt,"aria-hidden","true"),i(Jt,"tabindex","-1"),i(Jt,"href","#divergence"),i(Qt,"id","divergence"),i(Pr,"class","svelte-x2kgxs"),i(Or,"class","svelte-x2kgxs"),i(Xa,"class","svelte-x2kgxs"),i(Ff,"class","icon icon-link"),i(ts,"aria-hidden","true"),i(ts,"tabindex","-1"),i(ts,"href","#overfitting"),i(es,"id","overfitting"),i(Zf,"class","icon icon-link"),i(as,"aria-hidden","true"),i(as,"tabindex","-1"),i(as,"href","#key-differences"),i(ss,"id","key-differences"),i(qr,"class","svelte-x2kgxs"),i(Mr,"class","svelte-x2kgxs"),i(Ur,"class","svelte-x2kgxs"),i(Ce,"class","svelte-x2kgxs"),i(Hr,"class","svelte-x2kgxs"),i(Br,"class","svelte-x2kgxs"),i(Wr,"class","svelte-x2kgxs"),i(jr,"class","svelte-x2kgxs"),i(Ge,"class","svelte-x2kgxs"),i(Fr,"class","svelte-x2kgxs"),i(Vr,"class","svelte-x2kgxs"),i(Yr,"class","svelte-x2kgxs"),i(He,"class","svelte-x2kgxs"),i(Kr,"class","svelte-x2kgxs"),i(Xr,"class","svelte-x2kgxs"),i(Zr,"class","svelte-x2kgxs"),i(qe,"class","svelte-x2kgxs"),i(Qr,"class","svelte-x2kgxs"),i(Jr,"class","svelte-x2kgxs"),i($r,"class","svelte-x2kgxs"),i(Me,"class","svelte-x2kgxs"),i(de,"class","svelte-x2kgxs"),i(Lt,"class","svelte-x2kgxs"),i(rd,"class","icon icon-link"),i(rs,"aria-hidden","true"),i(rs,"tabindex","-1"),i(rs,"href","#preventing-divergence"),i(ls,"id","preventing-divergence"),i(ti,"class","svelte-x2kgxs"),i(si,"class","svelte-x2kgxs"),i(is,"class","svelte-x2kgxs"),i(ei,"class","svelte-x2kgxs"),i(ai,"class","svelte-x2kgxs"),i(li,"class","svelte-x2kgxs"),i(os,"class","svelte-x2kgxs"),i(ri,"class","svelte-x2kgxs"),i(ii,"class","svelte-x2kgxs"),i(ns,"class","svelte-x2kgxs"),i(oi,"class","svelte-x2kgxs"),i(ni,"class","svelte-x2kgxs"),i(cs,"class","svelte-x2kgxs"),i(ci,"class","svelte-x2kgxs"),i(ui,"class","svelte-x2kgxs"),i(us,"class","svelte-x2kgxs"),i(pe,"class","svelte-x2kgxs"),i(It,"class","svelte-x2kgxs"),i(ud,"class","icon icon-link"),i(ds,"aria-hidden","true"),i(ds,"tabindex","-1"),i(ds,"href","#implementing-these-strategies"),i(fs,"id","implementing-these-strategies"),i(Za,"class","language-python"),i(Qa,"class","language-python"),i(fd,"class","icon icon-link"),i(hs,"aria-hidden","true"),i(hs,"tabindex","-1"),i(hs,"href","#data-considerations"),i(ps,"id","data-considerations"),i(pi,"class","svelte-x2kgxs"),i(hi,"class","svelte-x2kgxs"),i(gi,"class","svelte-x2kgxs"),i(Ue,"class","svelte-x2kgxs"),i(di,"class","svelte-x2kgxs"),i(mi,"class","svelte-x2kgxs"),i(vi,"class","svelte-x2kgxs"),i(_i,"class","svelte-x2kgxs"),i(Be,"class","svelte-x2kgxs"),i(ki,"class","svelte-x2kgxs"),i(Ei,"class","svelte-x2kgxs"),i(bi,"class","svelte-x2kgxs"),i(We,"class","svelte-x2kgxs"),i(xi,"class","svelte-x2kgxs"),i(yi,"class","svelte-x2kgxs"),i(wi,"class","svelte-x2kgxs"),i(je,"class","svelte-x2kgxs"),i(Ti,"class","svelte-x2kgxs"),i(Ri,"class","svelte-x2kgxs"),i(Si,"class","svelte-x2kgxs"),i(Fe,"class","svelte-x2kgxs"),i(he,"class","svelte-x2kgxs"),i(Pt,"class","svelte-x2kgxs"),i(dd,"class","icon icon-link"),i(ms,"aria-hidden","true"),i(ms,"tabindex","-1"),i(ms,"href","#monitoring-tips"),i(gs,"id","monitoring-tips"),i(Ja,"href","https://github.com/kohya-ss/sd-scripts"),i(Ja,"rel","nofollow"),i(pd,"class","icon icon-link"),i(ks,"aria-hidden","true"),i(ks,"tabindex","-1"),i(ks,"href","#track-loss-curves"),i(_s,"id","track-loss-curves"),i($a,"href","https://www.tensorflow.org/tensorboard"),i($a,"rel","nofollow"),i(el,"class","language-bash"),i(hd,"class","icon icon-link"),i(xs,"aria-hidden","true"),i(xs,"tabindex","-1"),i(xs,"href","#what-to-monitor"),i(bs,"id","what-to-monitor"),i(_d,"class","icon icon-link"),i(ws,"aria-hidden","true"),i(ws,"tabindex","-1"),i(ws,"href","#warning-signs"),i(ys,"id","warning-signs"),i(xd,"class","icon icon-link"),i(Rs,"aria-hidden","true"),i(Rs,"tabindex","-1"),i(Rs,"href","#generate-validation-images-every-100-steps"),i(Ts,"id","generate-validation-images-every-100-steps"),i(sl,"class","language-json"),i(wd,"class","icon icon-link"),i(Ds,"aria-hidden","true"),i(Ds,"tabindex","-1"),i(Ds,"href","#what-to-look-for"),i(Ss,"id","what-to-look-for"),i(Ii,"class","svelte-x2kgxs"),i(al,"class","svelte-x2kgxs"),i(Dd,"class","icon icon-link"),i(Ls,"aria-hidden","true"),i(Ls,"tabindex","-1"),i(Ls,"href","#use-gradient-clipping"),i(As,"id","use-gradient-clipping"),i(Oi,"class","svelte-x2kgxs"),i(zi,"class","svelte-x2kgxs"),i(il,"class","svelte-x2kgxs"),i(Pd,"class","icon icon-link"),i(Ps,"aria-hidden","true"),i(Ps,"tabindex","-1"),i(Ps,"href","#enable-mixed-precision-training"),i(Is,"id","enable-mixed-precision-training"),i(nl,"class","language-python"),i(Ci,"class","svelte-x2kgxs"),i(cl,"class","svelte-x2kgxs"),i(Gd,"class","icon icon-link"),i(zs,"aria-hidden","true"),i(zs,"tabindex","-1"),i(zs,"href","#start-with-conservative-learning-rates"),i(Os,"id","start-with-conservative-learning-rates"),i(ul,"class","language-yml"),i(fl,"class","language-python"),i(Hi,"class","svelte-x2kgxs"),i(qi,"class","svelte-x2kgxs"),i(Mi,"class","svelte-x2kgxs"),i(Ui,"class","svelte-x2kgxs"),i(ge,"class","svelte-x2kgxs"),i(Gi,"class","svelte-x2kgxs"),i(Bi,"class","svelte-x2kgxs"),i(Wi,"class","svelte-x2kgxs"),i(ji,"class","svelte-x2kgxs"),i(Fi,"class","svelte-x2kgxs"),i(me,"class","svelte-x2kgxs"),i(Vi,"class","svelte-x2kgxs"),i(Yi,"class","svelte-x2kgxs"),i(Ki,"class","svelte-x2kgxs"),i(Xi,"class","svelte-x2kgxs"),i(ve,"class","svelte-x2kgxs"),i(Zi,"class","svelte-x2kgxs"),i(Qi,"class","svelte-x2kgxs"),i(Cs,"class","svelte-x2kgxs"),i(Ji,"class","svelte-x2kgxs"),i($i,"class","svelte-x2kgxs"),i(Je,"class","svelte-x2kgxs"),i(_e,"class","svelte-x2kgxs"),i(eo,"class","svelte-x2kgxs"),i(to,"class","svelte-x2kgxs"),i(so,"class","svelte-x2kgxs"),i(ao,"class","svelte-x2kgxs"),i(ke,"class","svelte-x2kgxs"),i(lo,"class","svelte-x2kgxs"),i(ro,"class","svelte-x2kgxs"),i(io,"class","svelte-x2kgxs"),i(oo,"class","svelte-x2kgxs"),i(Ee,"class","svelte-x2kgxs"),i(le,"class","svelte-x2kgxs"),i(Ot,"class","svelte-x2kgxs"),i(jd,"class","icon icon-link"),i(Hs,"aria-hidden","true"),i(Hs,"tabindex","-1"),i(Hs,"href","#generating-regularization-images"),i(Gs,"id","generating-regularization-images"),i(no,"class","svelte-x2kgxs"),i(co,"class","svelte-x2kgxs"),i(uo,"class","svelte-x2kgxs"),i(fo,"class","svelte-x2kgxs"),i(po,"class","svelte-x2kgxs"),i(Fd,"class","icon icon-link"),i(Us,"aria-hidden","true"),i(Us,"tabindex","-1"),i(Us,"href","#important-considerations"),i(Ms,"id","important-considerations"),i(Jd,"class","icon icon-link"),i(Ws,"aria-hidden","true"),i(Ws,"tabindex","-1"),i(Ws,"href","#generate-using-stable-diffusion-web-ui"),i(Bs,"id","generate-using-stable-diffusion-web-ui"),i(vl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(vl,"rel","nofollow"),i(go,"class","svelte-x2kgxs"),i(mo,"class","svelte-x2kgxs"),i(_o,"class","svelte-x2kgxs"),i(ko,"class","svelte-x2kgxs"),i(Eo,"class","svelte-x2kgxs"),i(bo,"class","svelte-x2kgxs"),i(xo,"class","svelte-x2kgxs"),i(yo,"class","svelte-x2kgxs"),i(wo,"class","svelte-x2kgxs"),i(To,"class","svelte-x2kgxs"),i(Ro,"class","svelte-x2kgxs"),i(So,"class","svelte-x2kgxs"),i(Do,"class","svelte-x2kgxs"),i(Ao,"class","svelte-x2kgxs"),i(Lo,"class","svelte-x2kgxs"),i(Io,"class","svelte-x2kgxs"),i(Po,"class","svelte-x2kgxs"),i(Oo,"class","svelte-x2kgxs"),i(zo,"class","svelte-x2kgxs"),i(No,"class","svelte-x2kgxs"),i(Co,"class","svelte-x2kgxs"),i(Go,"class","svelte-x2kgxs"),i(Ho,"class","svelte-x2kgxs"),i(qo,"class","svelte-x2kgxs"),i(Mo,"class","svelte-x2kgxs"),i(Uo,"class","svelte-x2kgxs"),i(Bo,"class","svelte-x2kgxs"),i(jo,"class","svelte-x2kgxs"),i(Fo,"class","svelte-x2kgxs"),i(Vo,"class","svelte-x2kgxs"),i(Yo,"class","svelte-x2kgxs"),i(Ko,"class","svelte-x2kgxs"),i(ip,"class","icon icon-link"),i(Ys,"aria-hidden","true"),i(Ys,"tabindex","-1"),i(Ys,"href","#download-images"),i(Vs,"id","download-images"),i(El,"href","https://huggingface.co/3ee"),i(El,"rel","nofollow"),i(bl,"href","https://github.com/Luehrsen/sd_regularization_images"),i(bl,"rel","nofollow"),i(xl,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(xl,"rel","nofollow"),i(yl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(yl,"rel","nofollow"),i(op,"class","icon icon-link"),i(Xs,"aria-hidden","true"),i(Xs,"tabindex","-1"),i(Xs,"href","#captioning-regularization-images"),i(Ks,"id","captioning-regularization-images"),i(sn,"class","svelte-x2kgxs"),i(an,"class","svelte-x2kgxs"),i(ln,"class","svelte-x2kgxs"),i(wl,"class","language-shell"),i(on,"class","svelte-x2kgxs"),i(nn,"class","svelte-x2kgxs"),i(un,"class","svelte-x2kgxs"),i(fn,"class","svelte-x2kgxs"),i(fp,"class","icon icon-link"),i(ea,"aria-hidden","true"),i(ea,"tabindex","-1"),i(ea,"href","#training-a-lora"),i($s,"id","training-a-lora"),i(Dl,"href","https://github.com/kohya-ss/sd-scripts"),i(Dl,"rel","nofollow"),i(Ll,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(Ll,"rel","nofollow"),i(sa,"class","svelte-x2kgxs"),i(Al,"class","svelte-x2kgxs"),i(dp,"class","icon icon-link"),i(la,"aria-hidden","true"),i(la,"tabindex","-1"),i(la,"href","#directory-setup"),i(aa,"id","directory-setup"),i(dn,"class","svelte-x2kgxs"),i(Il,"class","language-json"),i(Pl,"class","language-xml"),i(hn,"class","svelte-x2kgxs"),i(gn,"class","svelte-x2kgxs"),i(mn,"class","svelte-x2kgxs"),i(vn,"class","svelte-x2kgxs"),Ut(zl.src,t6="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(zl,"src",t6),i(zl,"alt","image"),i(zl,"class","svelte-x2kgxs"),i(Ol,"class","svelte-x2kgxs"),i(vp,"class","icon icon-link"),i(na,"aria-hidden","true"),i(na,"tabindex","-1"),i(na,"href","#training-settings"),i(oa,"id","training-settings"),i(xn,"class","svelte-x2kgxs"),i(yn,"class","svelte-x2kgxs"),i(Tn,"class","svelte-x2kgxs"),i(Rn,"class","svelte-x2kgxs"),i(Sn,"class","svelte-x2kgxs"),i(Dn,"class","svelte-x2kgxs"),i(An,"class","svelte-x2kgxs"),i(re,"class","svelte-x2kgxs"),i(wn,"class","svelte-x2kgxs"),i(In,"class","svelte-x2kgxs"),i(Pn,"class","svelte-x2kgxs"),i(On,"class","svelte-x2kgxs"),i(zn,"class","svelte-x2kgxs"),i(Nn,"class","svelte-x2kgxs"),i(ie,"class","svelte-x2kgxs"),i(Ln,"class","svelte-x2kgxs"),i(Nt,"class","svelte-x2kgxs"),i(Nl,"class","language-json"),i(Hn,"class","svelte-x2kgxs"),i(Mn,"class","svelte-x2kgxs"),i(Bn,"class","svelte-x2kgxs"),i(jn,"class","svelte-x2kgxs"),i(Vn,"class","svelte-x2kgxs"),i(Kn,"class","svelte-x2kgxs"),i(Zn,"class","svelte-x2kgxs"),i(Jn,"class","svelte-x2kgxs"),i(ec,"class","svelte-x2kgxs"),i(sc,"class","svelte-x2kgxs"),i(lc,"class","svelte-x2kgxs"),i(_p,"class","icon icon-link"),i(ua,"aria-hidden","true"),i(ua,"tabindex","-1"),i(ua,"href","#fine-tuning"),i(ca,"id","fine-tuning"),i(kp,"class","icon icon-link"),i(da,"aria-hidden","true"),i(da,"tabindex","-1"),i(da,"href","#workflow-with-auto1111-webui"),i(fa,"id","workflow-with-auto1111-webui"),i(Kl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(Kl,"rel","nofollow"),i(ic,"class","svelte-x2kgxs"),i(nc,"class","svelte-x2kgxs"),i(cc,"class","svelte-x2kgxs"),i(uc,"class","svelte-x2kgxs"),i(dc,"class","svelte-x2kgxs"),i(pc,"class","svelte-x2kgxs"),i(hc,"class","svelte-x2kgxs"),i(gc,"class","svelte-x2kgxs"),i(mc,"class","svelte-x2kgxs"),i(vc,"class","svelte-x2kgxs"),i(_c,"class","svelte-x2kgxs"),i(kc,"class","svelte-x2kgxs"),i(yp,"class","icon icon-link"),i(_a,"aria-hidden","true"),i(_a,"tabindex","-1"),i(_a,"href","#issues-to-look-for"),i(va,"id","issues-to-look-for"),Ut(Ql.src,s6="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(Ql,"src",s6),i(Ql,"alt","image"),i(Ql,"class","svelte-x2kgxs"),i(Zl,"class","svelte-x2kgxs"),i(Dp,"class","icon icon-link"),i(Ea,"aria-hidden","true"),i(Ea,"tabindex","-1"),i(Ea,"href","#troubleshooting"),i(ka,"id","troubleshooting"),i(Rc,"class","svelte-x2kgxs"),i(Sc,"class","svelte-x2kgxs"),i(Ac,"class","svelte-x2kgxs"),i(Lc,"class","svelte-x2kgxs"),i(Ic,"class","svelte-x2kgxs"),i(ct,"class","svelte-x2kgxs"),i(Dc,"class","svelte-x2kgxs"),i(Pc,"class","svelte-x2kgxs"),i(Oc,"class","svelte-x2kgxs"),i(zc,"class","svelte-x2kgxs"),i(ut,"class","svelte-x2kgxs"),i(Nc,"class","svelte-x2kgxs"),i(Cc,"class","svelte-x2kgxs"),i(Gc,"class","svelte-x2kgxs"),i(ft,"class","svelte-x2kgxs"),i(Hc,"class","svelte-x2kgxs"),i(qc,"class","svelte-x2kgxs"),i(Mc,"class","svelte-x2kgxs"),i(dt,"class","svelte-x2kgxs"),i(Uc,"class","svelte-x2kgxs"),i(Bc,"class","svelte-x2kgxs"),i(Wc,"class","svelte-x2kgxs"),i(pt,"class","svelte-x2kgxs"),i(we,"class","svelte-x2kgxs"),i(Ct,"class","svelte-x2kgxs"),i(Lp,"class","icon icon-link"),i(xa,"aria-hidden","true"),i(xa,"tabindex","-1"),i(xa,"href","#more-solutions"),i(ba,"id","more-solutions"),i(Vc,"class","svelte-x2kgxs"),i(Yc,"class","svelte-x2kgxs"),i(Kc,"class","svelte-x2kgxs"),i(ht,"class","svelte-x2kgxs"),i(Fc,"class","svelte-x2kgxs"),i(Xc,"class","svelte-x2kgxs"),i(Zc,"class","svelte-x2kgxs"),i(Qc,"class","svelte-x2kgxs"),i(gt,"class","svelte-x2kgxs"),i(Jc,"class","svelte-x2kgxs"),i($c,"class","svelte-x2kgxs"),i(eu,"class","svelte-x2kgxs"),i(mt,"class","svelte-x2kgxs"),i(tu,"class","svelte-x2kgxs"),i(su,"class","svelte-x2kgxs"),i(au,"class","svelte-x2kgxs"),i(vt,"class","svelte-x2kgxs"),i(lu,"class","svelte-x2kgxs"),i(ru,"class","svelte-x2kgxs"),i(iu,"class","svelte-x2kgxs"),i(_t,"class","svelte-x2kgxs"),i(ou,"class","svelte-x2kgxs"),i(nu,"class","svelte-x2kgxs"),i(cu,"class","svelte-x2kgxs"),i(kt,"class","svelte-x2kgxs"),i(uu,"class","svelte-x2kgxs"),i(fu,"class","svelte-x2kgxs"),i(du,"class","svelte-x2kgxs"),i(Et,"class","svelte-x2kgxs"),i(pu,"class","svelte-x2kgxs"),i(hu,"class","svelte-x2kgxs"),i(gu,"class","svelte-x2kgxs"),i(bt,"class","svelte-x2kgxs"),i(mu,"class","svelte-x2kgxs"),i(vu,"class","svelte-x2kgxs"),i(_u,"class","svelte-x2kgxs"),i(xt,"class","svelte-x2kgxs"),i(ku,"class","svelte-x2kgxs"),i(Eu,"class","svelte-x2kgxs"),i(bu,"class","svelte-x2kgxs"),i(yt,"class","svelte-x2kgxs"),i(xu,"class","svelte-x2kgxs"),i(yu,"class","svelte-x2kgxs"),i(wu,"class","svelte-x2kgxs"),i(wt,"class","svelte-x2kgxs"),i(W,"class","svelte-x2kgxs"),i(Gt,"class","svelte-x2kgxs"),i(Ip,"class","icon icon-link"),i(wa,"aria-hidden","true"),i(wa,"tabindex","-1"),i(wa,"href","#results"),i(ya,"id","results"),Ut(tr.src,a6="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(tr,"src",a6),i(tr,"alt","image"),i(tr,"class","svelte-x2kgxs"),i(er,"class","svelte-x2kgxs"),i(Pp,"class","icon icon-link"),i(Ta,"aria-hidden","true"),i(Ta,"tabindex","-1"),i(Ta,"href","#spacelab"),i(Ht,"id","spacelab"),i(Ht,"class","svelte-x2kgxs")},m(s,d){f(s,p,d),e(p,m),f(s,g,d),f(s,h,d),e(h,v),f(s,k,d),f(s,b,d),e(b,w),e(w,T),e(b,x),f(s,E,d),f(s,y,d),e(y,I),f(s,N,d),f(s,G,d),e(G,D),f(s,A,d),f(s,S,d),e(S,O),e(O,z),e(S,Q),e(S,j),e(j,F),f(s,B,d),f(s,C,d),e(C,L),f(s,H,d),f(s,Z,d),e(Z,q),e(q,R),e(Z,M),f(s,jt,d),f(s,Se,d),e(Se,fe),f(s,qp,d),f(s,nr,d),e(nr,Dv),f(s,Mp,d),f(s,Ft,d),e(Ft,Vt),e(Vt,Rf),e(Ft,Av),f(s,Up,d),f(s,cr,d),e(cr,Lv),f(s,Bp,d),f(s,qa,d),e(qa,ur),e(ur,Iv),f(s,Wp,d),ir(Ma,s,d),f(s,jp,d),f(s,fr,d),e(fr,Pv),f(s,Fp,d),f(s,dr,d),e(dr,Ov),f(s,Vp,d),f(s,pr,d),e(pr,zv),f(s,Yp,d),f(s,At,d),e(At,hr),e(hr,De),e(De,gr),e(gr,Nv),e(De,Cv),e(De,mr),e(mr,Gv),e(De,Hv),e(De,vr),e(vr,qv),e(At,Mv),e(At,Ae),e(Ae,Le),e(Le,_r),e(_r,Sf),e(Sf,Uv),e(Le,Bv),e(Le,kr),e(kr,Wv),e(Le,jv),e(Le,Er),e(Er,Fv),e(Ae,Vv),e(Ae,Ie),e(Ie,br),e(br,Df),e(Df,Yv),e(Ie,Kv),e(Ie,xr),e(xr,Xv),e(Ie,Zv),e(Ie,yr),e(yr,Qv),e(Ae,Jv),e(Ae,Pe),e(Pe,wr),e(wr,Af),e(Af,$v),e(Pe,e2),e(Pe,Tr),e(Tr,t2),e(Pe,s2),e(Pe,Rr),e(Rr,a2),f(s,Kp,d),f(s,Sr,d),e(Sr,l2),f(s,Xp,d),f(s,Dr,d),e(Dr,r2),f(s,Zp,d),f(s,Ua,d),e(Ua,Ar),e(Ar,i2),f(s,Qp,d),f(s,Yt,d),e(Yt,Kt),e(Kt,Lf),e(Yt,o2),f(s,Jp,d),f(s,Ba,d),e(Ba,If),e(If,n2),e(Ba,c2),f(s,$p,d),f(s,Wa,d),e(Wa,Pf),e(Pf,u2),e(Wa,f2),f(s,eh,d),f(s,ja,d),e(ja,Of),e(Of,d2),e(ja,p2),f(s,th,d),f(s,Xt,d),e(Xt,Zt),e(Zt,zf),e(Xt,h2),f(s,sh,d),f(s,Fa,d),e(Fa,Nf),e(Nf,g2),e(Fa,m2),f(s,ah,d),f(s,Va,d),e(Va,Cf),e(Cf,v2),e(Va,_2),f(s,lh,d),f(s,Ya,d),e(Ya,Gf),e(Gf,k2),e(Ya,E2),f(s,rh,d),f(s,Qt,d),e(Qt,Jt),e(Jt,Hf),e(Qt,b2),f(s,ih,d),f(s,Ka,d),e(Ka,qf),e(qf,x2),e(Ka,y2),f(s,oh,d),f(s,Oe,d),e(Oe,w2),e(Oe,Mf),e(Mf,T2),e(Oe,R2),e(Oe,Uf),e(Uf,S2),e(Oe,D2),f(s,nh,d),f(s,ze,d),e(ze,Lr),e(Lr,Bf),e(Bf,A2),e(Lr,L2),e(ze,I2),e(ze,Ir),e(Ir,Wf),e(Wf,P2),e(Ir,O2),e(ze,z2),e(ze,$t),e($t,jf),e(jf,N2),e($t,C2),e($t,Pr),e(Pr,G2),e($t,H2),f(s,ch,d),f(s,Xa,d),e(Xa,Or),e(Or,q2),f(s,uh,d),f(s,es,d),e(es,ts),e(ts,Ff),e(es,Vf),e(Vf,M2),f(s,fh,d),f(s,zr,d),e(zr,U2),f(s,dh,d),f(s,Ne,d),e(Ne,Nr),e(Nr,Yf),e(Yf,B2),e(Nr,W2),e(Ne,j2),e(Ne,Cr),e(Cr,Kf),e(Kf,F2),e(Cr,V2),e(Ne,Y2),e(Ne,Gr),e(Gr,Xf),e(Xf,K2),e(Gr,X2),f(s,ph,d),f(s,ss,d),e(ss,as),e(as,Zf),e(ss,Qf),e(Qf,Z2),f(s,hh,d),f(s,Lt,d),e(Lt,Hr),e(Hr,Ce),e(Ce,qr),e(qr,Jf),e(Jf,Q2),e(Ce,J2),e(Ce,Mr),e(Mr,$f),e($f,$2),e(Ce,e_),e(Ce,Ur),e(Ur,ed),e(ed,t_),e(Lt,s_),e(Lt,de),e(de,Ge),e(Ge,Br),e(Br,td),e(td,a_),e(Ge,l_),e(Ge,Wr),e(Wr,r_),e(Ge,i_),e(Ge,jr),e(jr,o_),e(de,n_),e(de,He),e(He,Fr),e(Fr,sd),e(sd,c_),e(He,u_),e(He,Vr),e(Vr,f_),e(He,d_),e(He,Yr),e(Yr,p_),e(de,h_),e(de,qe),e(qe,Kr),e(Kr,ad),e(ad,g_),e(qe,m_),e(qe,Xr),e(Xr,v_),e(qe,__),e(qe,Zr),e(Zr,k_),e(de,E_),e(de,Me),e(Me,Qr),e(Qr,ld),e(ld,b_),e(Me,x_),e(Me,Jr),e(Jr,y_),e(Me,w_),e(Me,$r),e($r,T_),f(s,gh,d),f(s,ls,d),e(ls,rs),e(rs,rd),e(ls,R_),f(s,mh,d),f(s,It,d),e(It,ei),e(ei,is),e(is,ti),e(ti,S_),e(is,D_),e(is,si),e(si,A_),e(It,L_),e(It,pe),e(pe,os),e(os,ai),e(ai,id),e(id,I_),e(os,P_),e(os,li),e(li,O_),e(pe,z_),e(pe,ns),e(ns,ri),e(ri,od),e(od,N_),e(ns,C_),e(ns,ii),e(ii,G_),e(pe,H_),e(pe,cs),e(cs,oi),e(oi,nd),e(nd,q_),e(cs,M_),e(cs,ni),e(ni,U_),e(pe,B_),e(pe,us),e(us,ci),e(ci,cd),e(cd,W_),e(us,j_),e(us,ui),e(ui,F_),f(s,vh,d),f(s,fi,d),e(fi,V_),f(s,_h,d),f(s,fs,d),e(fs,ds),e(ds,ud),e(fs,Y_),f(s,kh,d),f(s,Za,d),Za.innerHTML=NA,f(s,Eh,d),f(s,Qa,d),Qa.innerHTML=CA,f(s,bh,d),f(s,ps,d),e(ps,hs),e(hs,fd),e(ps,K_),f(s,xh,d),f(s,Pt,d),e(Pt,di),e(di,Ue),e(Ue,pi),e(pi,X_),e(Ue,Z_),e(Ue,hi),e(hi,Q_),e(Ue,J_),e(Ue,gi),e(gi,$_),e(Pt,e1),e(Pt,he),e(he,Be),e(Be,mi),e(mi,t1),e(Be,s1),e(Be,vi),e(vi,a1),e(Be,l1),e(Be,_i),e(_i,r1),e(he,i1),e(he,We),e(We,ki),e(ki,o1),e(We,n1),e(We,Ei),e(Ei,c1),e(We,u1),e(We,bi),e(bi,f1),e(he,d1),e(he,je),e(je,xi),e(xi,p1),e(je,h1),e(je,yi),e(yi,g1),e(je,m1),e(je,wi),e(wi,v1),e(he,_1),e(he,Fe),e(Fe,Ti),e(Ti,k1),e(Fe,E1),e(Fe,Ri),e(Ri,b1),e(Fe,x1),e(Fe,Si),e(Si,y1),f(s,yh,d),f(s,Di,d),e(Di,w1),f(s,wh,d),f(s,Ai,d),e(Ai,T1),f(s,Th,d),f(s,Li,d),e(Li,R1),f(s,Rh,d),f(s,Sh,d),f(s,Dh,d),f(s,gs,d),e(gs,ms),e(ms,dd),e(gs,S1),f(s,Ah,d),f(s,vs,d),e(vs,D1),e(vs,Ja),e(Ja,A1),e(vs,L1),f(s,Lh,d),f(s,_s,d),e(_s,ks),e(ks,pd),e(_s,I1),f(s,Ih,d),f(s,Es,d),e(Es,P1),e(Es,$a),e($a,O1),e(Es,z1),f(s,Ph,d),f(s,el,d),el.innerHTML=GA,f(s,Oh,d),f(s,bs,d),e(bs,xs),e(xs,hd),e(bs,N1),f(s,zh,d),f(s,Ve,d),e(Ve,gd),e(gd,C1),e(Ve,G1),e(Ve,md),e(md,H1),e(Ve,q1),e(Ve,vd),e(vd,M1),f(s,Nh,d),f(s,ys,d),e(ys,ws),e(ws,_d),e(ys,U1),f(s,Ch,d),f(s,Ye,d),e(Ye,kd),e(kd,B1),e(Ye,W1),e(Ye,Ed),e(Ed,j1),e(Ye,F1),e(Ye,bd),e(bd,V1),f(s,Gh,d),f(s,Ts,d),e(Ts,Rs),e(Rs,xd),e(Ts,Y1),f(s,Hh,d),f(s,tl,d),e(tl,yd),e(yd,K1),e(tl,X1),f(s,qh,d),f(s,sl,d),sl.innerHTML=HA,f(s,Mh,d),f(s,Ss,d),e(Ss,Ds),e(Ds,wd),e(Ss,Z1),f(s,Uh,d),f(s,Ke,d),e(Ke,Td),e(Td,Q1),e(Ke,J1),e(Ke,Rd),e(Rd,$1),e(Ke,ek),e(Ke,Sd),e(Sd,tk),f(s,Bh,d),f(s,al,d),e(al,Ii),e(Ii,sk),f(s,Wh,d),f(s,As,d),e(As,Ls),e(Ls,Dd),e(As,ak),f(s,jh,d),f(s,ll,d),e(ll,Ad),e(Ad,lk),e(ll,rk),f(s,Fh,d),f(s,Pi,d),e(Pi,ik),f(s,Vh,d),f(s,Xe,d),e(Xe,rl),e(rl,ok),e(rl,Oi),e(Oi,nk),e(rl,ck),e(Xe,uk),e(Xe,Ld),e(Ld,fk),e(Xe,dk),e(Xe,Id),e(Id,pk),f(s,Yh,d),f(s,il,d),e(il,zi),e(zi,hk),f(s,Kh,d),f(s,Is,d),e(Is,Ps),e(Ps,Pd),e(Is,gk),f(s,Xh,d),f(s,ol,d),e(ol,Od),e(Od,mk),e(ol,vk),f(s,Zh,d),f(s,nl,d),nl.innerHTML=qA,f(s,Qh,d),f(s,Ni,d),e(Ni,_k),f(s,Jh,d),f(s,Ze,d),e(Ze,zd),e(zd,kk),e(Ze,Ek),e(Ze,Nd),e(Nd,bk),e(Ze,xk),e(Ze,Cd),e(Cd,yk),f(s,$h,d),f(s,cl,d),e(cl,Ci),e(Ci,wk),f(s,eg,d),f(s,Os,d),e(Os,zs),e(zs,Gd),e(Os,Tk),f(s,tg,d),f(s,Ns,d),e(Ns,Rk),e(Ns,Hd),e(Hd,Sk),e(Ns,Dk),f(s,sg,d),f(s,ul,d),ul.innerHTML=MA,f(s,ag,d),f(s,fl,d),fl.innerHTML=UA,f(s,lg,d),f(s,dl,d),e(dl,qd),e(qd,Ak),e(dl,Lk),f(s,rg,d),f(s,Qe,d),e(Qe,Md),e(Md,Ik),e(Qe,Pk),e(Qe,Ud),e(Ud,Ok),e(Qe,zk),e(Qe,Bd),e(Bd,Nk),f(s,ig,d),f(s,Ot,d),e(Ot,Gi),e(Gi,ge),e(ge,Hi),e(Hi,Ck),e(ge,Gk),e(ge,qi),e(qi,Hk),e(ge,qk),e(ge,Mi),e(Mi,Mk),e(ge,Uk),e(ge,Ui),e(Ui,Bk),e(Ot,Wk),e(Ot,le),e(le,me),e(me,Bi),e(Bi,jk),e(me,Fk),e(me,Wi),e(Wi,Vk),e(me,Yk),e(me,ji),e(ji,Kk),e(me,Xk),e(me,Fi),e(Fi,Zk),e(le,Qk),e(le,ve),e(ve,Vi),e(Vi,Jk),e(ve,$k),e(ve,Yi),e(Yi,eE),e(ve,tE),e(ve,Ki),e(Ki,sE),e(ve,aE),e(ve,Xi),e(Xi,lE),e(le,rE),e(le,_e),e(_e,Zi),e(Zi,iE),e(_e,oE),e(_e,Qi),e(Qi,nE),e(_e,cE),e(_e,Cs),e(Cs,uE),e(Cs,Wd),e(Wd,fE),e(Cs,dE),e(_e,pE),e(_e,Je),e(Je,hE),e(Je,Ji),e(Ji,gE),e(Je,mE),e(Je,$i),e($i,vE),e(Je,_E),e(le,kE),e(le,ke),e(ke,eo),e(eo,EE),e(ke,bE),e(ke,to),e(to,xE),e(ke,yE),e(ke,so),e(so,wE),e(ke,TE),e(ke,ao),e(ao,RE),e(le,SE),e(le,Ee),e(Ee,lo),e(lo,DE),e(Ee,AE),e(Ee,ro),e(ro,LE),e(Ee,IE),e(Ee,io),e(io,PE),e(Ee,OE),e(Ee,oo),e(oo,zE),f(s,og,d),f(s,ng,d),f(s,cg,d),f(s,Gs,d),e(Gs,Hs),e(Hs,jd),e(Gs,NE),f(s,ug,d),f(s,qs,d),e(qs,CE),e(qs,no),e(no,GE),e(qs,HE),f(s,fg,d),f(s,ue,d),e(ue,qE),e(ue,co),e(co,ME),e(ue,UE),e(ue,uo),e(uo,BE),e(ue,WE),e(ue,fo),e(fo,jE),e(ue,FE),e(ue,po),e(po,VE),f(s,dg,d),f(s,ho,d),e(ho,YE),f(s,pg,d),f(s,Ms,d),e(Ms,Us),e(Us,Fd),e(Ms,KE),f(s,hg,d),f(s,$e,d),e($e,Vd),e(Vd,pl),e(pl,Yd),e(Yd,XE),e(pl,ZE),e(pl,QE),e($e,JE),e($e,Kd),e(Kd,hl),e(hl,Xd),e(Xd,$E),e(hl,eb),e(hl,tb),e($e,sb),e($e,Zd),e(Zd,gl),e(gl,Qd),e(Qd,ab),e(gl,lb),e(gl,rb),f(s,gg,d),ir(ml,s,d),f(s,mg,d),f(s,Bs,d),e(Bs,Ws),e(Ws,Jd),e(Bs,ib),f(s,vg,d),f(s,js,d),e(js,ob),e(js,vl),e(vl,nb),e(js,cb),f(s,_g,d),f(s,et,d),e(et,ub),e(et,go),e(go,fb),e(et,db),e(et,mo),e(mo,pb),e(et,hb),f(s,kg,d),f(s,J,d),e(J,$d),e($d,vo),e(vo,gb),e(vo,_o),e(_o,mb),e(J,vb),e(J,ep),e(ep,_l),e(_l,_b),e(_l,ko),e(ko,kb),e(_l,Eb),e(J,bb),e(J,tp),e(tp,Y),e(Y,xb),e(Y,Eo),e(Eo,yb),e(Y,wb),e(Y,bo),e(bo,Tb),e(Y,Rb),e(Y,xo),e(xo,Sb),e(Y,Db),e(Y,yo),e(yo,Ab),e(Y,Lb),e(Y,wo),e(wo,Ib),e(Y,Pb),e(Y,To),e(To,Ob),e(Y,zb),e(Y,Ro),e(Ro,Nb),e(Y,Cb),e(Y,So),e(So,Gb),e(J,Hb),e(J,sp),e(sp,$),e($,qb),e($,Do),e(Do,Mb),e($,Ub),e($,Ao),e(Ao,Bb),e($,Wb),e($,Lo),e(Lo,jb),e($,Fb),e($,Io),e(Io,Vb),e($,Yb),e($,Po),e(Po,Kb),e($,Xb),e($,Oo),e(Oo,Zb),e($,Qb),e($,zo),e(zo,Jb),e(J,$b),e(J,ap),e(ap,K),e(K,ex),e(K,No),e(No,tx),e(K,sx),e(K,Co),e(Co,ax),e(K,lx),e(K,Go),e(Go,rx),e(K,ix),e(K,Ho),e(Ho,ox),e(K,nx),e(K,qo),e(qo,cx),e(K,ux),e(K,Mo),e(Mo,fx),e(K,dx),e(K,Uo),e(Uo,px),e(K,hx),e(K,Bo),e(Bo,gx),e(J,mx),e(J,lp),e(lp,Wo),e(Wo,vx),e(Wo,jo),e(jo,_x),e(J,kx),e(J,rp),e(rp,Fs),e(Fs,Ex),e(Fs,Fo),e(Fo,bx),e(Fs,xx),e(Fs,Vo),e(Vo,yx),f(s,Eg,d),f(s,tt,d),e(tt,wx),e(tt,Yo),e(Yo,Tx),e(tt,Rx),e(tt,Ko),e(Ko,Sx),e(tt,Dx),f(s,bg,d),ir(kl,s,d),f(s,xg,d),f(s,Vs,d),e(Vs,Ys),e(Ys,ip),e(Vs,Ax),f(s,yg,d),f(s,Xo,d),e(Xo,Lx),f(s,wg,d),f(s,be,d),e(be,Zo),e(Zo,El),e(El,Ix),e(Zo,Px),e(be,Ox),e(be,Qo),e(Qo,bl),e(bl,zx),e(Qo,Nx),e(be,Cx),e(be,Jo),e(Jo,xl),e(xl,Gx),e(Jo,Hx),e(be,qx),e(be,$o),e($o,yl),e(yl,Mx),e($o,Ux),f(s,Tg,d),f(s,Ks,d),e(Ks,Xs),e(Xs,op),e(Ks,Bx),f(s,Rg,d),f(s,en,d),e(en,Wx),f(s,Sg,d),f(s,tn,d),e(tn,jx),f(s,Dg,d),f(s,st,d),e(st,Zs),e(Zs,np),e(np,Fx),e(Zs,Vx),e(Zs,sn),e(sn,Yx),e(Zs,Kx),e(st,Xx),e(st,at),e(at,cp),e(cp,Zx),e(at,Qx),e(at,an),e(an,Jx),e(at,$x),e(at,ln),e(ln,ey),e(at,ty),e(st,sy),e(st,rn),e(rn,up),e(up,ay),e(rn,ly),f(s,Ag,d),f(s,wl,d),wl.innerHTML=BA,f(s,Lg,d),f(s,Qs,d),e(Qs,Tl),e(Tl,ry),e(Tl,on),e(on,iy),e(Tl,oy),e(Qs,ny),e(Qs,Rl),e(Rl,cy),e(Rl,nn),e(nn,uy),e(Rl,fy),f(s,Ig,d),f(s,Js,d),e(Js,cn),e(cn,dy),e(cn,un),e(un,py),e(Js,hy),e(Js,Sl),e(Sl,gy),e(Sl,fn),e(fn,my),e(Sl,vy),f(s,Pg,d),f(s,$s,d),e($s,ea),e(ea,fp),e($s,_y),f(s,Og,d),f(s,ta,d),e(ta,ky),e(ta,Dl),e(Dl,Ey),e(ta,by),f(s,zg,d),f(s,Al,d),e(Al,sa),e(sa,xy),e(sa,Ll),e(Ll,yy),e(sa,wy),f(s,Ng,d),f(s,aa,d),e(aa,la),e(la,dp),e(aa,Ty),f(s,Cg,d),f(s,ra,d),e(ra,Ry),e(ra,dn),e(dn,Sy),e(ra,Dy),f(s,Gg,d),f(s,Il,d),Il.innerHTML=WA,f(s,Hg,d),f(s,pn,d),e(pn,Ay),f(s,qg,d),f(s,Pl,d),Pl.innerHTML=jA,f(s,Mg,d),f(s,lt,d),e(lt,Ly),e(lt,hn),e(hn,Iy),e(lt,Py),e(lt,gn),e(gn,Oy),e(lt,zy),f(s,Ug,d),f(s,rt,d),e(rt,Ny),e(rt,mn),e(mn,Cy),e(rt,Gy),e(rt,vn),e(vn,Hy),e(rt,qy),f(s,Bg,d),f(s,_n,d),e(_n,My),f(s,Wg,d),f(s,ia,d),e(ia,kn),e(kn,Uy),e(kn,pp),e(pp,hp),e(hp,By),e(ia,Wy),e(ia,En),e(En,jy),e(En,gp),e(gp,mp),e(mp,Fy),f(s,jg,d),f(s,bn,d),e(bn,Vy),f(s,Fg,d),f(s,Ol,d),e(Ol,zl),f(s,Vg,d),f(s,oa,d),e(oa,na),e(na,vp),e(oa,Yy),f(s,Yg,d),f(s,zt,d),e(zt,Ky),e(zt,xn),e(xn,Xy),e(zt,Zy),e(zt,yn),e(yn,Qy),f(s,Kg,d),f(s,Nt,d),e(Nt,wn),e(wn,re),e(re,Tn),e(Tn,Jy),e(re,$y),e(re,Rn),e(Rn,e3),e(re,t3),e(re,Sn),e(Sn,s3),e(re,a3),e(re,Dn),e(Dn,l3),e(re,r3),e(re,An),e(An,i3),e(Nt,o3),e(Nt,Ln),e(Ln,ie),e(ie,In),e(In,n3),e(ie,c3),e(ie,Pn),e(Pn,u3),e(ie,f3),e(ie,On),e(On,d3),e(ie,p3),e(ie,zn),e(zn,h3),e(ie,g3),e(ie,Nn),e(Nn,m3),f(s,Xg,d),f(s,Cn,d),e(Cn,v3),f(s,Zg,d),f(s,Nl,d),Nl.innerHTML=FA,f(s,Qg,d),f(s,U,d),e(U,Gn),e(Gn,Cl),e(Cl,_3),e(Cl,Hn),e(Hn,k3),e(Cl,E3),e(Gn,b3),e(U,x3),e(U,qn),e(qn,Gl),e(Gl,y3),e(Gl,Mn),e(Mn,w3),e(Gl,T3),e(qn,R3),e(U,S3),e(U,Un),e(Un,Hl),e(Hl,D3),e(Hl,Bn),e(Bn,A3),e(Hl,L3),e(Un,I3),e(U,P3),e(U,Wn),e(Wn,ql),e(ql,O3),e(ql,jn),e(jn,z3),e(ql,N3),e(Wn,C3),e(U,G3),e(U,Fn),e(Fn,Ml),e(Ml,H3),e(Ml,Vn),e(Vn,q3),e(Ml,M3),e(Fn,U3),e(U,B3),e(U,Yn),e(Yn,Ul),e(Ul,W3),e(Ul,Kn),e(Kn,j3),e(Ul,F3),e(Yn,V3),e(U,Y3),e(U,Xn),e(Xn,Bl),e(Bl,K3),e(Bl,Zn),e(Zn,X3),e(Bl,Z3),e(Xn,Q3),e(U,J3),e(U,Qn),e(Qn,Wl),e(Wl,$3),e(Wl,Jn),e(Jn,e4),e(Wl,t4),e(Qn,s4),e(U,a4),e(U,$n),e($n,jl),e(jl,l4),e(jl,ec),e(ec,r4),e(jl,i4),e($n,o4),e(U,n4),e(U,tc),e(tc,Fl),e(Fl,c4),e(Fl,sc),e(sc,u4),e(Fl,f4),e(tc,d4),e(U,p4),e(U,ac),e(ac,Vl),e(Vl,h4),e(Vl,lc),e(lc,g4),e(Vl,m4),e(ac,v4),f(s,Jg,d),f(s,ca,d),e(ca,ua),e(ua,_p),e(ca,_4),f(s,$g,d),f(s,rc,d),e(rc,k4),f(s,em,d),ir(Yl,s,d),f(s,tm,d),f(s,fa,d),e(fa,da),e(da,kp),e(fa,E4),f(s,sm,d),f(s,pa,d),e(pa,b4),e(pa,Kl),e(Kl,x4),e(pa,y4),f(s,am,d),f(s,ha,d),e(ha,w4),e(ha,ic),e(ic,T4),e(ha,R4),f(s,lm,d),f(s,oe,d),e(oe,oc),e(oc,S4),e(oc,rm),e(oe,D4),e(oe,Ep),e(Ep,A4),e(oe,L4),e(oe,it),e(it,I4),e(it,nc),e(nc,P4),e(it,O4),e(it,cc),e(cc,z4),e(it,N4),e(it,uc),e(uc,C4),e(oe,G4),e(oe,fc),e(fc,H4),e(fc,dc),e(dc,q4),e(oe,M4),e(oe,ga),e(ga,U4),e(ga,pc),e(pc,B4),e(ga,W4),e(ga,hc),e(hc,j4),f(s,im,d),f(s,ot,d),e(ot,F4),e(ot,gc),e(gc,V4),e(ot,Y4),e(ot,mc),e(mc,K4),e(ot,X4),f(s,om,d),f(s,xe,d),e(xe,ma),e(ma,Z4),e(ma,vc),e(vc,Q4),e(ma,J4),e(ma,_c),e(_c,$4),e(xe,e0),e(xe,Xl),e(Xl,t0),e(Xl,kc),e(kc,s0),e(Xl,a0),e(xe,l0),e(xe,bp),e(bp,r0),e(xe,i0),e(xe,xp),e(xp,o0),f(s,nm,d),f(s,va,d),e(va,_a),e(_a,yp),e(va,n0),f(s,cm,d),f(s,ye,d),e(ye,Ec),e(Ec,wp),e(wp,c0),e(Ec,u0),e(ye,f0),e(ye,bc),e(bc,Tp),e(Tp,d0),e(bc,p0),e(ye,h0),e(ye,xc),e(xc,Rp),e(Rp,g0),e(xc,m0),e(ye,v0),e(ye,yc),e(yc,Sp),e(Sp,_0),e(yc,k0),f(s,um,d),f(s,wc,d),e(wc,E0),f(s,fm,d),f(s,Zl,d),e(Zl,Ql),f(s,dm,d),f(s,ka,d),e(ka,Ea),e(Ea,Dp),e(ka,b0),f(s,pm,d),f(s,Tc,d),e(Tc,x0),f(s,hm,d),f(s,nt,d),e(nt,Jl),e(Jl,y0),e(Jl,Rc),e(Rc,w0),e(Jl,T0),e(nt,R0),e(nt,$l),e($l,S0),e($l,Sc),e(Sc,D0),e($l,A0),e(nt,L0),e(nt,Ap),e(Ap,I0),f(s,gm,d),f(s,Ct,d),e(Ct,Dc),e(Dc,ct),e(ct,Ac),e(Ac,P0),e(ct,O0),e(ct,Lc),e(Lc,z0),e(ct,N0),e(ct,Ic),e(Ic,C0),e(Ct,G0),e(Ct,we),e(we,ut),e(ut,Pc),e(Pc,H0),e(ut,q0),e(ut,Oc),e(Oc,M0),e(ut,U0),e(ut,zc),e(zc,B0),e(we,W0),e(we,ft),e(ft,Nc),e(Nc,j0),e(ft,F0),e(ft,Cc),e(Cc,V0),e(ft,Y0),e(ft,Gc),e(Gc,K0),e(we,X0),e(we,dt),e(dt,Hc),e(Hc,Z0),e(dt,Q0),e(dt,qc),e(qc,J0),e(dt,$0),e(dt,Mc),e(Mc,e5),e(we,t5),e(we,pt),e(pt,Uc),e(Uc,s5),e(pt,a5),e(pt,Bc),e(Bc,l5),e(pt,r5),e(pt,Wc),e(Wc,i5),f(s,mm,d),f(s,ba,d),e(ba,xa),e(xa,Lp),e(ba,o5),f(s,vm,d),f(s,jc,d),e(jc,n5),f(s,_m,d),f(s,Gt,d),e(Gt,Fc),e(Fc,ht),e(ht,Vc),e(Vc,c5),e(ht,u5),e(ht,Yc),e(Yc,f5),e(ht,d5),e(ht,Kc),e(Kc,p5),e(Gt,h5),e(Gt,W),e(W,gt),e(gt,Xc),e(Xc,g5),e(gt,m5),e(gt,Zc),e(Zc,v5),e(gt,_5),e(gt,Qc),e(Qc,k5),e(W,E5),e(W,mt),e(mt,Jc),e(Jc,b5),e(mt,x5),e(mt,$c),e($c,y5),e(mt,w5),e(mt,eu),e(eu,T5),e(W,R5),e(W,vt),e(vt,tu),e(tu,S5),e(vt,D5),e(vt,su),e(su,A5),e(vt,L5),e(vt,au),e(au,I5),e(W,P5),e(W,_t),e(_t,lu),e(lu,O5),e(_t,z5),e(_t,ru),e(ru,N5),e(_t,C5),e(_t,iu),e(iu,G5),e(W,H5),e(W,kt),e(kt,ou),e(ou,q5),e(kt,M5),e(kt,nu),e(nu,U5),e(kt,B5),e(kt,cu),e(cu,W5),e(W,j5),e(W,Et),e(Et,uu),e(uu,F5),e(Et,V5),e(Et,fu),e(fu,Y5),e(Et,K5),e(Et,du),e(du,X5),e(W,Z5),e(W,bt),e(bt,pu),e(pu,Q5),e(bt,J5),e(bt,hu),e(hu,$5),e(bt,ew),e(bt,gu),e(gu,tw),e(W,sw),e(W,xt),e(xt,mu),e(mu,aw),e(xt,lw),e(xt,vu),e(vu,rw),e(xt,iw),e(xt,_u),e(_u,ow),e(W,nw),e(W,yt),e(yt,ku),e(ku,cw),e(yt,uw),e(yt,Eu),e(Eu,fw),e(yt,dw),e(yt,bu),e(bu,pw),e(W,hw),e(W,wt),e(wt,xu),e(xu,gw),e(wt,mw),e(wt,yu),e(yu,vw),e(wt,_w),e(wt,wu),e(wu,kw),f(s,km,d),f(s,ya,d),e(ya,wa),e(wa,Ip),e(ya,Ew),f(s,Em,d),f(s,Tu,d),e(Tu,bw),f(s,bm,d),f(s,Ru,d),e(Ru,xw),f(s,xm,d),f(s,er,d),e(er,tr),f(s,ym,d),f(s,Su,d),e(Su,yw),f(s,wm,d),f(s,Ht,d),e(Ht,Ta),e(Ta,Pp),e(Ht,ww),f(s,Tm,d),Te&&Te.m(s,d),f(s,Rm,d),Sm=!0},p(s,d){zA&&Te.p(s,d)},i(s){Sm||(Bt(Ma.$$.fragment,s),Bt(ml.$$.fragment,s),Bt(kl.$$.fragment,s),Bt(Yl.$$.fragment,s),Bt(Te),Sm=!0)},o(s){Wt(Ma.$$.fragment,s),Wt(ml.$$.fragment,s),Wt(kl.$$.fragment,s),Wt(Yl.$$.fragment,s),Wt(Te),Sm=!1},d(s){s&&t(p),s&&t(g),s&&t(h),s&&t(k),s&&t(b),s&&t(E),s&&t(y),s&&t(N),s&&t(G),s&&t(A),s&&t(S),s&&t(B),s&&t(C),s&&t(H),s&&t(Z),s&&t(jt),s&&t(Se),s&&t(qp),s&&t(nr),s&&t(Mp),s&&t(Ft),s&&t(Up),s&&t(cr),s&&t(Bp),s&&t(qa),s&&t(Wp),or(Ma,s),s&&t(jp),s&&t(fr),s&&t(Fp),s&&t(dr),s&&t(Vp),s&&t(pr),s&&t(Yp),s&&t(At),s&&t(Kp),s&&t(Sr),s&&t(Xp),s&&t(Dr),s&&t(Zp),s&&t(Ua),s&&t(Qp),s&&t(Yt),s&&t(Jp),s&&t(Ba),s&&t($p),s&&t(Wa),s&&t(eh),s&&t(ja),s&&t(th),s&&t(Xt),s&&t(sh),s&&t(Fa),s&&t(ah),s&&t(Va),s&&t(lh),s&&t(Ya),s&&t(rh),s&&t(Qt),s&&t(ih),s&&t(Ka),s&&t(oh),s&&t(Oe),s&&t(nh),s&&t(ze),s&&t(ch),s&&t(Xa),s&&t(uh),s&&t(es),s&&t(fh),s&&t(zr),s&&t(dh),s&&t(Ne),s&&t(ph),s&&t(ss),s&&t(hh),s&&t(Lt),s&&t(gh),s&&t(ls),s&&t(mh),s&&t(It),s&&t(vh),s&&t(fi),s&&t(_h),s&&t(fs),s&&t(kh),s&&t(Za),s&&t(Eh),s&&t(Qa),s&&t(bh),s&&t(ps),s&&t(xh),s&&t(Pt),s&&t(yh),s&&t(Di),s&&t(wh),s&&t(Ai),s&&t(Th),s&&t(Li),s&&t(Rh),s&&t(Sh),s&&t(Dh),s&&t(gs),s&&t(Ah),s&&t(vs),s&&t(Lh),s&&t(_s),s&&t(Ih),s&&t(Es),s&&t(Ph),s&&t(el),s&&t(Oh),s&&t(bs),s&&t(zh),s&&t(Ve),s&&t(Nh),s&&t(ys),s&&t(Ch),s&&t(Ye),s&&t(Gh),s&&t(Ts),s&&t(Hh),s&&t(tl),s&&t(qh),s&&t(sl),s&&t(Mh),s&&t(Ss),s&&t(Uh),s&&t(Ke),s&&t(Bh),s&&t(al),s&&t(Wh),s&&t(As),s&&t(jh),s&&t(ll),s&&t(Fh),s&&t(Pi),s&&t(Vh),s&&t(Xe),s&&t(Yh),s&&t(il),s&&t(Kh),s&&t(Is),s&&t(Xh),s&&t(ol),s&&t(Zh),s&&t(nl),s&&t(Qh),s&&t(Ni),s&&t(Jh),s&&t(Ze),s&&t($h),s&&t(cl),s&&t(eg),s&&t(Os),s&&t(tg),s&&t(Ns),s&&t(sg),s&&t(ul),s&&t(ag),s&&t(fl),s&&t(lg),s&&t(dl),s&&t(rg),s&&t(Qe),s&&t(ig),s&&t(Ot),s&&t(og),s&&t(ng),s&&t(cg),s&&t(Gs),s&&t(ug),s&&t(qs),s&&t(fg),s&&t(ue),s&&t(dg),s&&t(ho),s&&t(pg),s&&t(Ms),s&&t(hg),s&&t($e),s&&t(gg),or(ml,s),s&&t(mg),s&&t(Bs),s&&t(vg),s&&t(js),s&&t(_g),s&&t(et),s&&t(kg),s&&t(J),s&&t(Eg),s&&t(tt),s&&t(bg),or(kl,s),s&&t(xg),s&&t(Vs),s&&t(yg),s&&t(Xo),s&&t(wg),s&&t(be),s&&t(Tg),s&&t(Ks),s&&t(Rg),s&&t(en),s&&t(Sg),s&&t(tn),s&&t(Dg),s&&t(st),s&&t(Ag),s&&t(wl),s&&t(Lg),s&&t(Qs),s&&t(Ig),s&&t(Js),s&&t(Pg),s&&t($s),s&&t(Og),s&&t(ta),s&&t(zg),s&&t(Al),s&&t(Ng),s&&t(aa),s&&t(Cg),s&&t(ra),s&&t(Gg),s&&t(Il),s&&t(Hg),s&&t(pn),s&&t(qg),s&&t(Pl),s&&t(Mg),s&&t(lt),s&&t(Ug),s&&t(rt),s&&t(Bg),s&&t(_n),s&&t(Wg),s&&t(ia),s&&t(jg),s&&t(bn),s&&t(Fg),s&&t(Ol),s&&t(Vg),s&&t(oa),s&&t(Yg),s&&t(zt),s&&t(Kg),s&&t(Nt),s&&t(Xg),s&&t(Cn),s&&t(Zg),s&&t(Nl),s&&t(Qg),s&&t(U),s&&t(Jg),s&&t(ca),s&&t($g),s&&t(rc),s&&t(em),or(Yl,s),s&&t(tm),s&&t(fa),s&&t(sm),s&&t(pa),s&&t(am),s&&t(ha),s&&t(lm),s&&t(oe),s&&t(im),s&&t(ot),s&&t(om),s&&t(xe),s&&t(nm),s&&t(va),s&&t(cm),s&&t(ye),s&&t(um),s&&t(wc),s&&t(fm),s&&t(Zl),s&&t(dm),s&&t(ka),s&&t(pm),s&&t(Tc),s&&t(hm),s&&t(nt),s&&t(gm),s&&t(Ct),s&&t(mm),s&&t(ba),s&&t(vm),s&&t(jc),s&&t(_m),s&&t(Gt),s&&t(km),s&&t(ya),s&&t(Em),s&&t(Tu),s&&t(bm),s&&t(Ru),s&&t(xm),s&&t(er),s&&t(ym),s&&t(Su),s&&t(wm),s&&t(Ht),s&&t(Tm),Te&&Te.d(s),s&&t(Rm)}}}function HL(_){let p,m;const g=[_[0],e6];let h={$$slots:{default:[GL]},$$scope:{ctx:_}};for(let v=0;v<g.length;v+=1)h=$7(h,g[v]);return p=new uL({props:h}),{c(){lr(p.$$.fragment)},l(v){rr(p.$$.fragment,v)},m(v,k){ir(p,v,k),m=!0},p(v,[k]){const b=k&1?cL(g,[k&1&&SA(v[0]),k&0&&SA(e6)]):{};k&2&&(b.$$scope={dirty:k,ctx:v}),p.$set(b)},i(v){m||(Bt(p.$$.fragment,v),m=!0)},o(v){Wt(p.$$.fragment,v),m=!1},d(v){or(p,v)}}}const e6={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Monitoring",icon:"\u{1F4C9}",url:"/blog/action-figure-art/#monitoring-tips"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:QL,date:JL,modifiedDate:$L,categories:eI,svg:tI,seoImage:sI,shortDescription:aI,author:lI,spacelab:zA,id:qL,spacelabDefaultTitle:ML,spacelabDefaultContent:UL,menu:rI,keywords:iI}=e6;function BL(_,p,m){return _.$$set=g=>{m(0,p=$7($7({},p),DA(g)))},p=DA(p),[p]}class oI extends Tv{constructor(p){super(),Rv(this,p,BL,HL,Sv,{})}}export{oI as default,e6 as metadata};
