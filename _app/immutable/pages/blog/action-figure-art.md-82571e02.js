import{S as vp,i as _p,s as kp,l as ic,g as f,E as Xx,d as t,v as u6,e as a,t as o,c as l,a as r,h as n,b as i,G as e,j as ce,k as c,m as u,F as ee,H as be,N as j0,Y as f6,J as ja,f as yt,Z as d6,_ as p6,$ as h6,q as pt,o as ht,O as g6,w as Us,x as Ms,y as Bs,B as js,C as Zx,z as m6,A as W0,a1 as F0}from"../../chunks/index-2a82a4a8.js";import{P as v6}from"../../chunks/_post-913f18eb.js";import{g as Wx}from"../../chunks/config-201c2df4.js";import{a as Fx}from"../../chunks/accountStore-3492c591.js";import{R as _6}from"../../chunks/ResponsivePicture-526d3695.js";import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function k6(_){let d,m,g,h,v,k,E,T,R,x,b,y,I,O,z,q,D,A;function S(L,H){return typeof L[2].title!="undefined"?x6:E6}let P=S(_),N=P(_);function Q(L,H){return typeof L[2].description!="undefined"?w6:y6}let W=Q(_),F=W(_),B=typeof _[2].list_description!="undefined"&&Y0(_),C=typeof _[2].footer_description!="undefined"&&X0(_);return{c(){d=a("hr"),m=c(),g=a("div"),N.c(),h=c(),v=a("p"),k=a("ion-icon"),E=o("SpaceLab Content"),T=c(),F.c(),R=c(),B&&B.c(),x=c(),C&&C.c(),b=c(),y=a("button"),I=a("ion-icon"),O=c(),z=a("span"),q=o("SpaceLab"),this.h()},l(L){d=l(L,"HR",{}),m=u(L),g=l(L,"DIV",{class:!0});var H=r(g);N.l(H),h=u(H),v=l(H,"P",{class:!0});var X=r(v);k=l(X,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),E=n(X,"SpaceLab Content"),X.forEach(t),T=u(H),F.l(H),R=u(H),B&&B.l(H),x=u(H),C&&C.l(H),b=u(H),y=l(H,"BUTTON",{class:!0});var U=r(y);I=l(U,"ION-ICON",{class:!0,name:!0}),r(I).forEach(t),O=u(U),z=l(U,"SPAN",{});var w=r(z);q=n(w,"SpaceLab"),w.forEach(t),U.forEach(t),H.forEach(t),this.h()},h(){ee(k,"class","icon svelte-s12rf8"),ee(k,"name","lock-closed"),i(v,"class","highlight large svelte-s12rf8"),ee(I,"class","icon svelte-s12rf8"),ee(I,"name","planet"),i(y,"class","button subscribe svelte-s12rf8"),i(g,"class","subscribe svelte-s12rf8")},m(L,H){f(L,d,H),f(L,m,H),f(L,g,H),N.m(g,null),e(g,h),e(g,v),e(v,k),e(v,E),e(g,T),F.m(g,null),e(g,R),B&&B.m(g,null),e(g,x),C&&C.m(g,null),e(g,b),e(g,y),e(y,I),e(y,O),e(y,z),e(z,q),D||(A=be(y,"click",_[15]),D=!0)},p(L,H){P===(P=S(L))&&N?N.p(L,H):(N.d(1),N=P(L),N&&(N.c(),N.m(g,h))),W===(W=Q(L))&&F?F.p(L,H):(F.d(1),F=W(L),F&&(F.c(),F.m(g,R))),typeof L[2].list_description!="undefined"?B?B.p(L,H):(B=Y0(L),B.c(),B.m(g,x)):B&&(B.d(1),B=null),typeof L[2].footer_description!="undefined"?C?C.p(L,H):(C=X0(L),C.c(),C.m(g,b)):C&&(C.d(1),C=null)},d(L){L&&t(d),L&&t(m),L&&t(g),N.d(),F.d(),B&&B.d(),C&&C.d(),D=!1,A()}}}function b6(_){let d,m,g,h=_[2].title+"",v,k,E,T,R,x,b,y=_[2].description+"",I,O,z,q,D,A,S,P,N,Q,W,F,B,C=typeof _[2].list_description!="undefined"&&Z0(_),L=typeof _[2].footer_description!="undefined"&&K0(_);function H(w,G){if(w[2].github_private_repo&&w[2].github_state==="LOG_EXISTS")return D6;if(w[2].github_private_repo&&w[2].github_state==="NO_LOGS")return R6;if(w[2].github_private_repo&&w[2].github_state==="NO_GITHUB_USERNAME")return T6}let X=H(_),U=X&&X(_);return{c(){d=a("hr"),m=c(),g=a("h2"),v=o(h),k=c(),E=a("p"),T=a("ion-icon"),R=o("SpaceLab Content"),x=c(),b=a("p"),I=o(y),O=c(),C&&C.c(),z=c(),L&&L.c(),q=c(),D=a("button"),A=a("ion-icon"),S=c(),P=a("span"),N=o("Download"),Q=c(),U&&U.c(),W=ic(),this.h()},l(w){d=l(w,"HR",{}),m=u(w),g=l(w,"H2",{class:!0});var G=r(g);v=n(G,h),G.forEach(t),k=u(w),E=l(w,"P",{class:!0});var Ws=r(E);T=l(Ws,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),R=n(Ws,"SpaceLab Content"),Ws.forEach(t),x=u(w),b=l(w,"P",{class:!0});var Wa=r(b);I=n(Wa,y),Wa.forEach(t),O=u(w),C&&C.l(w),z=u(w),L&&L.l(w),q=u(w),D=l(w,"BUTTON",{class:!0});var _e=r(D);A=l(_e,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),S=u(_e),P=l(_e,"SPAN",{});var Fa=r(P);N=n(Fa,"Download"),Fa.forEach(t),_e.forEach(t),Q=u(w),U&&U.l(w),W=ic(),this.h()},h(){i(g,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","planet-sharp"),i(E,"class","highlight large svelte-s12rf8"),i(b,"class","svelte-s12rf8"),ee(A,"class","icon svelte-s12rf8"),ee(A,"name","cloud-download"),i(D,"class","button svelte-s12rf8")},m(w,G){f(w,d,G),f(w,m,G),f(w,g,G),e(g,v),f(w,k,G),f(w,E,G),e(E,T),e(E,R),f(w,x,G),f(w,b,G),e(b,I),f(w,O,G),C&&C.m(w,G),f(w,z,G),L&&L.m(w,G),f(w,q,G),f(w,D,G),e(D,A),e(D,S),e(D,P),e(P,N),f(w,Q,G),U&&U.m(w,G),f(w,W,G),F||(B=be(D,"click",_[10]),F=!0)},p(w,G){G&4&&h!==(h=w[2].title+"")&&ce(v,h),G&4&&y!==(y=w[2].description+"")&&ce(I,y),typeof w[2].list_description!="undefined"?C?C.p(w,G):(C=Z0(w),C.c(),C.m(z.parentNode,z)):C&&(C.d(1),C=null),typeof w[2].footer_description!="undefined"?L?L.p(w,G):(L=K0(w),L.c(),L.m(q.parentNode,q)):L&&(L.d(1),L=null),X===(X=H(w))&&U?U.p(w,G):(U&&U.d(1),U=X&&X(w),U&&(U.c(),U.m(W.parentNode,W)))},d(w){w&&t(d),w&&t(m),w&&t(g),w&&t(k),w&&t(E),w&&t(x),w&&t(b),w&&t(O),C&&C.d(w),w&&t(z),L&&L.d(w),w&&t(q),w&&t(D),w&&t(Q),U&&U.d(w),w&&t(W),F=!1,B()}}}function E6(_){let d,m;return{c(){d=a("h2"),m=o(_[0]),this.h()},l(g){d=l(g,"H2",{class:!0});var h=r(d);m=n(h,_[0]),h.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(g,h){f(g,d,h),e(d,m)},p(g,h){h&1&&ce(m,g[0])},d(g){g&&t(d)}}}function x6(_){let d,m=_[2].title+"",g;return{c(){d=a("h2"),g=o(m),this.h()},l(h){d=l(h,"H2",{class:!0});var v=r(d);g=n(v,m),v.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,g)},p(h,v){v&4&&m!==(m=h[2].title+"")&&ce(g,m)},d(h){h&&t(d)}}}function y6(_){let d,m;return{c(){d=a("p"),m=o(_[1]),this.h()},l(g){d=l(g,"P",{class:!0});var h=r(d);m=n(h,_[1]),h.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(g,h){f(g,d,h),e(d,m)},p(g,h){h&2&&ce(m,g[1])},d(g){g&&t(d)}}}function w6(_){let d,m=_[2].description+"",g;return{c(){d=a("p"),g=o(m),this.h()},l(h){d=l(h,"P",{class:!0});var v=r(d);g=n(v,m),v.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,g)},p(h,v){v&4&&m!==(m=h[2].description+"")&&ce(g,m)},d(h){h&&t(d)}}}function Y0(_){let d,m,g=_[2].list_description+"",h;return{c(){d=a("div"),m=a("p"),h=o(g),this.h()},l(v){d=l(v,"DIV",{class:!0});var k=r(d);m=l(k,"P",{class:!0});var E=r(m);h=n(E,g),E.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(d,"class","list-description svelte-s12rf8")},m(v,k){f(v,d,k),e(d,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(d)}}}function X0(_){let d,m=_[2].footer_description+"",g;return{c(){d=a("p"),g=o(m),this.h()},l(h){d=l(h,"P",{class:!0});var v=r(d);g=n(v,m),v.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(d)}}}function Z0(_){let d,m,g=_[2].list_description+"",h;return{c(){d=a("div"),m=a("p"),h=o(g),this.h()},l(v){d=l(v,"DIV",{class:!0});var k=r(d);m=l(k,"P",{class:!0});var E=r(m);h=n(E,g),E.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(d,"class","list-description svelte-s12rf8")},m(v,k){f(v,d,k),e(d,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(d)}}}function K0(_){let d,m=_[2].footer_description+"",g;return{c(){d=a("p"),g=o(m),this.h()},l(h){d=l(h,"P",{class:!0});var v=r(d);g=n(v,m),v.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(d)}}}function T6(_){let d,m,g,h,v,k;function E(x,b){return x[5]?A6:S6}let T=E(_),R=T(_);return{c(){d=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),R.c(),this.h()},l(x){d=l(x,"H2",{class:!0});var b=r(d);m=n(b,"Private GitHub Access"),b.forEach(t),g=u(x),h=l(x,"FORM",{class:!0});var y=r(h);R.l(y),y.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(x,b){f(x,d,b),e(d,m),f(x,g,b),f(x,h,b),R.m(h,null),v||(k=be(h,"submit",_[8]),v=!0)},p(x,b){T===(T=E(x))&&R?R.p(x,b):(R.d(1),R=T(x),R&&(R.c(),R.m(h,null)))},d(x){x&&t(d),x&&t(g),x&&t(h),R.d(),v=!1,k()}}}function R6(_){let d,m,g,h,v,k;function E(x,b){return x[5]?L6:O6}let T=E(_),R=T(_);return{c(){d=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),R.c(),this.h()},l(x){d=l(x,"H2",{class:!0});var b=r(d);m=n(b,"Private GitHub Access"),b.forEach(t),g=u(x),h=l(x,"FORM",{});var y=r(h);R.l(y),y.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8")},m(x,b){f(x,d,b),e(d,m),f(x,g,b),f(x,h,b),R.m(h,null),v||(k=be(h,"submit",_[7]),v=!0)},p(x,b){T===(T=E(x))&&R?R.p(x,b):(R.d(1),R=T(x),R&&(R.c(),R.m(h,null)))},d(x){x&&t(d),x&&t(g),x&&t(h),R.d(),v=!1,k()}}}function D6(_){var A;let d,m,g,h,v,k,E=((A=_[6].profile)==null?void 0:A.githubUsername)+"",T,R,x,b,y,I,O,z,q,D;return{c(){d=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("p"),v=o("Your GitHub account "),k=a("span"),T=o(E),R=o(` is
			linked to this content.`),x=c(),b=a("button"),y=a("ion-icon"),I=c(),O=a("span"),z=o("Open Repository"),this.h()},l(S){d=l(S,"H2",{class:!0});var P=r(d);m=n(P,"Private GitHub Access"),P.forEach(t),g=u(S),h=l(S,"P",{class:!0});var N=r(h);v=n(N,"Your GitHub account "),k=l(N,"SPAN",{class:!0});var Q=r(k);T=n(Q,E),Q.forEach(t),R=n(N,` is
			linked to this content.`),N.forEach(t),x=u(S),b=l(S,"BUTTON",{class:!0});var W=r(b);y=l(W,"ION-ICON",{class:!0,name:!0}),r(y).forEach(t),I=u(W),O=l(W,"SPAN",{});var F=r(O);z=n(F,"Open Repository"),F.forEach(t),W.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8"),i(k,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(y,"class","icon svelte-s12rf8"),ee(y,"name","rocket-sharp"),i(b,"class","svelte-s12rf8")},m(S,P){f(S,d,P),e(d,m),f(S,g,P),f(S,h,P),e(h,v),e(h,k),e(k,T),e(h,R),f(S,x,P),f(S,b,P),e(b,y),e(b,I),e(b,O),e(O,z),q||(D=be(b,"click",_[11]),q=!0)},p(S,P){var N;P&64&&E!==(E=((N=S[6].profile)==null?void 0:N.githubUsername)+"")&&ce(T,E)},d(S){S&&t(d),S&&t(g),S&&t(h),S&&t(x),S&&t(b),q=!1,D()}}}function S6(_){let d,m,g,h,v,k,E,T,R,x,b,y,I,O,z,q;return{c(){d=a("p"),m=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),g=c(),h=a("label"),v=o("Github username:"),k=c(),E=a("input"),R=c(),x=a("button"),b=a("ion-icon"),y=c(),I=a("span"),O=o("Request Permission"),this.h()},l(D){d=l(D,"P",{class:!0});var A=r(d);m=n(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),g=u(D),h=l(D,"LABEL",{for:!0});var S=r(h);v=n(S,"Github username:"),S.forEach(t),k=u(D),E=l(D,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),R=u(D),x=l(D,"BUTTON",{class:!0});var P=r(x);b=l(P,"ION-ICON",{class:!0,name:!0}),r(b).forEach(t),y=u(P),I=l(P,"SPAN",{});var N=r(I);O=n(N,"Request Permission"),N.forEach(t),P.forEach(t),this.h()},h(){i(d,"class","svelte-s12rf8"),i(h,"for","username"),i(E,"name","username"),i(E,"id","username"),i(E,"placeholder","enter a username"),i(E,"type","text"),E.required="true",i(E,"class",T=_[4]?"validation-error":""),ee(b,"class","icon svelte-s12rf8"),ee(b,"name","rocket-sharp"),i(x,"class","svelte-s12rf8")},m(D,A){f(D,d,A),e(d,m),f(D,g,A),f(D,h,A),e(h,v),f(D,k,A),f(D,E,A),j0(E,_[3]),f(D,R,A),f(D,x,A),e(x,b),e(x,y),e(x,I),e(I,O),z||(q=be(E,"input",_[14]),z=!0)},p(D,A){A&16&&T!==(T=D[4]?"validation-error":"")&&i(E,"class",T),A&8&&E.value!==D[3]&&j0(E,D[3])},d(D){D&&t(d),D&&t(g),D&&t(h),D&&t(k),D&&t(E),D&&t(R),D&&t(x),z=!1,q()}}}function A6(_){let d,m,g,h,v,k,E,T,R,x;return{c(){d=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),E=a("span"),T=o("Open Repository"),this.h()},l(b){d=l(b,"P",{class:!0});var y=r(d);m=n(y,_[5]),y.forEach(t),g=u(b),h=l(b,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),E=l(I,"SPAN",{});var O=r(E);T=n(O,"Open Repository"),O.forEach(t),I.forEach(t),this.h()},h(){i(d,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(b,y){f(b,d,y),e(d,m),f(b,g,y),f(b,h,y),e(h,v),e(h,k),e(h,E),e(E,T),R||(x=be(h,"click",_[13]),R=!0)},p(b,y){y&32&&ce(m,b[5])},d(b){b&&t(d),b&&t(g),b&&t(h),R=!1,x()}}}function O6(_){var I;let d,m,g,h=((I=_[6].profile)==null?void 0:I.githubUsername)+"",v,k,E,T,R,x,b,y;return{c(){d=a("p"),m=o("This content can grant access to a private GitHub repository. Allow "),g=a("span"),v=o(h),k=o(" access to this repo?"),E=c(),T=a("button"),R=a("ion-icon"),x=c(),b=a("span"),y=o("Request Permission"),this.h()},l(O){d=l(O,"P",{class:!0});var z=r(d);m=n(z,"This content can grant access to a private GitHub repository. Allow "),g=l(z,"SPAN",{class:!0});var q=r(g);v=n(q,h),q.forEach(t),k=n(z," access to this repo?"),z.forEach(t),E=u(O),T=l(O,"BUTTON",{class:!0});var D=r(T);R=l(D,"ION-ICON",{class:!0,name:!0}),r(R).forEach(t),x=u(D),b=l(D,"SPAN",{});var A=r(b);y=n(A,"Request Permission"),A.forEach(t),D.forEach(t),this.h()},h(){i(g,"class","highlight svelte-s12rf8"),i(d,"class","svelte-s12rf8"),ee(R,"class","icon svelte-s12rf8"),ee(R,"name","rocket-sharp"),i(T,"class","svelte-s12rf8")},m(O,z){f(O,d,z),e(d,m),e(d,g),e(g,v),e(d,k),f(O,E,z),f(O,T,z),e(T,R),e(T,x),e(T,b),e(b,y)},p(O,z){var q;z&64&&h!==(h=((q=O[6].profile)==null?void 0:q.githubUsername)+"")&&ce(v,h)},d(O){O&&t(d),O&&t(E),O&&t(T)}}}function L6(_){let d,m,g,h,v,k,E,T,R,x;return{c(){d=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),E=a("span"),T=o("Open Repository"),this.h()},l(b){d=l(b,"P",{class:!0});var y=r(d);m=n(y,_[5]),y.forEach(t),g=u(b),h=l(b,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),E=l(I,"SPAN",{});var O=r(E);T=n(O,"Open Repository"),O.forEach(t),I.forEach(t),this.h()},h(){i(d,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(b,y){f(b,d,y),e(d,m),f(b,g,y),f(b,h,y),e(h,v),e(h,k),e(h,E),e(E,T),R||(x=be(h,"click",_[12]),R=!0)},p(b,y){y&32&&ce(m,b[5])},d(b){b&&t(d),b&&t(g),b&&t(h),R=!1,x()}}}function I6(_){let d;function m(v,k){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?b6:k6}let g=m(_),h=g(_);return{c(){h.c(),d=ic()},l(v){h.l(v),d=ic()},m(v,k){h.m(v,k),f(v,d,k)},p(v,[k]){g===(g=m(v))&&h?h.p(v,k):(h.d(1),h=g(v),h&&(h.c(),h.m(d.parentNode,d)))},i:Xx,o:Xx,d(v){h.d(v),v&&t(d)}}}function Yx(_){window.open(_,"_blank")||window.location.replace(_)}function z6(_,d,m){let{id:g}=d,{spacelabDefaultTitle:h="Spacelab Content"}=d,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=d,k={},E="",T=!1,R="",x;Fx.subscribe(S=>{m(6,x=S)}),u6(async()=>{if(typeof(x==null?void 0:x.token)!="undefined"){const S=await fetch(`${Wx().serviceUrl}/education/spacelab/${g}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors"});if(S.status===401){Fx.set({}),Fx.deleteLocalStorage();return}let P=await S.json();m(2,k=P)}else m(2,k.success=!1,k)});async function b(S){S.preventDefault();const P={};try{const N=await fetch(`${Wx().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(P)});if(N.ok)m(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await N.json();m(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),m(5,R="An unexpected error occurred. Please try again later.")}}async function y(S){if(S.preventDefault(),!E.trim()){m(4,T=!0),m(5,R="Please enter a valid GitHub username.");return}m(4,T=!1);const P={github_username:E};try{const N=await fetch(`${Wx().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(P)});if(N.ok)m(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await N.json();m(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),m(5,R="An unexpected error occurred. Please try again later.")}}const I=()=>window.open(k.url,"_blank"),O=()=>Yx(`https://github.com/${k.github_repo_name}`),z=()=>Yx(`https://github.com/${k.github_repo_name}`),q=()=>Yx(`https://github.com/${k.github_repo_name}`);function D(){E=this.value,m(3,E)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=S=>{"id"in S&&m(9,g=S.id),"spacelabDefaultTitle"in S&&m(0,h=S.spacelabDefaultTitle),"spacelabDefaultContent"in S&&m(1,v=S.spacelabDefaultContent)},[h,v,k,E,T,R,x,b,y,g,I,O,z,q,D,A]}class P6 extends vp{constructor(d){super(),_p(this,d,z6,I6,kp,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const N6=_=>({}),V0=_=>({});function C6(_){let d;return{c(){d=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(m){d=n(m,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(m,g){f(m,d,g)},d(m){m&&t(d)}}}function q6(_){let d,m,g,h,v,k,E,T,R,x,b,y,I,O;const z=_[7]["slider-label"],q=f6(z,_,_[6],V0),D=q||C6();return{c(){d=a("div"),m=a("img"),h=c(),v=a("img"),E=c(),T=a("label"),R=a("span"),D&&D.c(),x=c(),b=a("input"),this.h()},l(A){d=l(A,"DIV",{class:!0,style:!0,"data-testid":!0});var S=r(d);m=l(S,"IMG",{src:!0,alt:!0,class:!0}),h=u(S),v=l(S,"IMG",{src:!0,alt:!0,class:!0}),E=u(S),T=l(S,"LABEL",{class:!0});var P=r(T);R=l(P,"SPAN",{class:!0});var N=r(R);D&&D.l(N),N.forEach(t),x=u(P),b=l(P,"INPUT",{type:!0,min:!0,max:!0,class:!0}),P.forEach(t),S.forEach(t),this.h()},h(){ja(m.src,g=_[0])||i(m,"src",g),i(m,"alt",_[1]),i(m,"class","left-img svelte-1po6qlg"),ja(v.src,k=_[2])||i(v,"src",k),i(v,"alt",_[3]),i(v,"class","right-img svelte-1po6qlg"),i(R,"class","visually-hidden svelte-1po6qlg"),i(b,"type","range"),i(b,"min","0"),i(b,"max","100"),b.value=_[4],i(b,"class","svelte-1po6qlg"),i(T,"class","svelte-1po6qlg"),i(d,"class","svelte-compare-image-container svelte-1po6qlg"),yt(d,"--slider-position",_[4]+"%"),i(d,"data-testid","svelte-compare-image")},m(A,S){f(A,d,S),e(d,m),e(d,h),e(d,v),e(d,E),e(d,T),e(T,R),D&&D.m(R,null),e(T,x),e(T,b),y=!0,I||(O=[be(b,"input",_[5]),be(b,"change",_[5]),be(b,"click",G6)],I=!0)},p(A,[S]){(!y||S&1&&!ja(m.src,g=A[0]))&&i(m,"src",g),(!y||S&2)&&i(m,"alt",A[1]),(!y||S&4&&!ja(v.src,k=A[2]))&&i(v,"src",k),(!y||S&8)&&i(v,"alt",A[3]),q&&q.p&&(!y||S&64)&&d6(q,z,A,A[6],y?h6(z,A[6],S,N6):p6(A[6]),V0),(!y||S&16)&&(b.value=A[4]),(!y||S&16)&&yt(d,"--slider-position",A[4]+"%")},i(A){y||(pt(D,A),y=!0)},o(A){ht(D,A),y=!1},d(A){A&&t(d),D&&D.d(A),I=!1,g6(O)}}}function G6(_){_.target.focus()}function H6(_,d,m){let{$$slots:g={},$$scope:h}=d,{imageLeftSrc:v=""}=d,{imageLeftAlt:k=""}=d,{imageRightSrc:E=""}=d,{imageRightAlt:T=""}=d,R=50,x=null;function b(y){x&&cancelAnimationFrame(x),x=requestAnimationFrame(()=>{m(4,R=y.target.valueAsNumber)})}return _.$$set=y=>{"imageLeftSrc"in y&&m(0,v=y.imageLeftSrc),"imageLeftAlt"in y&&m(1,k=y.imageLeftAlt),"imageRightSrc"in y&&m(2,E=y.imageRightSrc),"imageRightAlt"in y&&m(3,T=y.imageRightAlt),"$$scope"in y&&m(6,h=y.$$scope)},[v,k,E,T,R,b,h,g]}class U6 extends vp{constructor(d){super(),_p(this,d,H6,q6,kp,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function M6(_){let d;return{c(){d=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(m){d=n(m,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(m,g){f(m,d,g)},d(m){m&&t(d)}}}function B6(_){let d,m,g,h;return m=new U6({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[M6]},$$scope:{ctx:_}}}),{c(){d=a("div"),g=a("div"),Us(m.$$.fragment),this.h()},l(v){d=l(v,"DIV",{class:!0});var k=r(d);g=l(k,"DIV",{style:!0});var E=r(g);Ms(m.$$.fragment,E),k.forEach(t),this.h()},h(){yt(g,"display","contents"),yt(g,"--handle-size","2.5rem"),yt(g,"--handle-background-color","rgba(0, 0, 0, 0.6)"),yt(g,"--handle-background-image",_[4]),yt(g,"--handle-border-width","0.125rem"),yt(g,"--slider-color","#ffffff"),yt(g,"--slider-width","0.125rem"),i(d,"class","image-compare-container svelte-s79nww")},m(v,k){f(v,d,k),e(d,g),Bs(m,g,null),h=!0},p(v,[k]){const E={};k&1&&(E.imageLeftSrc=v[0]),k&2&&(E.imageLeftAlt=v[1]),k&4&&(E.imageRightSrc=v[2]),k&8&&(E.imageRightAlt=v[3]),k&32&&(E.$$scope={dirty:k,ctx:v}),m.$set(E)},i(v){h||(pt(m.$$.fragment,v),h=!0)},o(v){ht(m.$$.fragment,v),h=!1},d(v){v&&t(d),js(m)}}}function j6(_,d,m){const g=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=d,{imageLeftAlt:v="left"}=d,{imageRightSrc:k="https://via.placeholder.com/512x512/00aaff/ffffff/"}=d,{imageRightAlt:E="right"}=d;return _.$$set=T=>{"imageLeftSrc"in T&&m(0,h=T.imageLeftSrc),"imageLeftAlt"in T&&m(1,v=T.imageLeftAlt),"imageRightSrc"in T&&m(2,k=T.imageRightSrc),"imageRightAlt"in T&&m(3,E=T.imageRightAlt)},[h,v,k,E,g]}class mp extends vp{constructor(d){super(),_p(this,d,j6,B6,kp,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function W6(_){let d,m;return d=new P6({props:{id:X6,spacelabDefaultTitle:Z6,spacelabDefaultContent:K6}}),{c(){Us(d.$$.fragment)},l(g){Ms(d.$$.fragment,g)},m(g,h){Bs(d,g,h),m=!0},p:Xx,i(g){m||(pt(d.$$.fragment,g),m=!0)},o(g){ht(d.$$.fragment,g),m=!1},d(g){js(d,g)}}}function F6(_){let d,m,g,h,v,k,E,T,R,x,b,y,I,O,z,q,D,A,S,P,N,Q,W,F,B,C,L,H,X,U,w,G,Ws,Wa,_e,Fa,bp,Ya,Ep,xp,Ee,xe,Xa,oc,yp,wp,Za,Tp,Rp,Ka,Dp,Sp,ye,Va,nc,Ap,Op,Qa,Lp,Ip,Ja,zp,Pp,we,$a,cc,Np,Cp,el,qp,Gp,tl,Hp,Gu,sl,Up,Hu,al,Mp,Uu,Fs,ll,Bp,Mu,Ys,uc,jp,Wp,Bu,Xs,fc,Fp,Yp,ju,Zs,dc,Xp,Zp,Wu,Ks,pc,Kp,Vp,Fu,wt,Tt,hc,Qp,Yu,Vs,gc,Jp,$p,Xu,Te,eh,mc,th,sh,vc,ah,lh,Zu,Re,rl,_c,rh,ih,oh,il,kc,nh,ch,uh,Rt,bc,fh,dh,ol,ph,hh,Ku,Dt,St,Ec,xc,gh,Vu,nl,mh,Qu,De,cl,yc,vh,_h,kh,ul,wc,bh,Eh,xh,fl,Tc,yh,wh,Ju,At,Ot,Rc,Dc,Th,$u,gt,dl,Se,pl,Sc,Rh,Dh,hl,Ac,Sh,Ah,gl,Oc,Oh,Lh,ue,Ae,ml,Lc,Ih,zh,vl,Ph,Nh,_l,Ch,qh,Oe,kl,Ic,Gh,Hh,bl,Uh,Mh,El,Bh,jh,Le,xl,zc,Wh,Fh,yl,Yh,Xh,wl,Zh,Kh,Ie,Tl,Pc,Vh,Qh,Rl,Jh,$h,Dl,eg,ef,Lt,It,Nc,tg,tf,mt,Sl,zt,Al,sg,ag,Ol,lg,rg,fe,Pt,Ll,Cc,ig,og,Il,ng,cg,Nt,zl,qc,ug,fg,Pl,dg,pg,Ct,Nl,Gc,hg,gg,Cl,mg,vg,qt,ql,Hc,_g,kg,Gl,bg,sf,Hl,Eg,af,Gt,Ht,Uc,xg,lf,Qs,J0=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,rf,Js,$0=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,of,Ut,Mt,Mc,yg,nf,vt,Ul,ze,Ml,wg,Tg,Bl,Rg,Dg,jl,Sg,Ag,de,Pe,Wl,Og,Lg,Fl,Ig,zg,Yl,Pg,Ng,Ne,Xl,Cg,qg,Zl,Gg,Hg,Kl,Ug,Mg,Ce,Vl,Bg,jg,Ql,Wg,Fg,Jl,Yg,Xg,qe,$l,Zg,Kg,er,Vg,Qg,tr,Jg,cf,Bt,jt,Bc,$g,uf,le,sr,em,$s,tm,sm,jc,am,lm,Wc,rm,im,Fc,om,nm,Yc,cm,ff,Wt,Ft,Xc,um,df,Yt,fm,ar,dm,pm,pf,pe,hm,lr,gm,mm,rr,vm,_m,ir,km,bm,hf,ea,or,nr,Em,gf,cr,xm,mf,Xt,Zt,Zc,ym,vf,Ge,Kc,ta,Vc,wm,Tm,Rm,Dm,Qc,sa,Jc,Sm,Am,Om,Lm,$c,aa,eu,Im,zm,Pm,_f,la,kf,Kt,Vt,tu,Nm,bf,Qt,Cm,ra,qm,Gm,Ef,He,Hm,ur,Um,Mm,fr,Bm,jm,xf,J,su,dr,Wm,pr,Fm,Ym,au,ia,Xm,hr,Zm,Km,Vm,lu,Z,Qm,gr,Jm,$m,mr,ev,tv,vr,sv,av,_r,lv,rv,kr,iv,ov,br,nv,cv,Er,uv,fv,xr,dv,pv,ru,$,hv,yr,gv,mv,wr,vv,_v,Tr,kv,bv,Rr,Ev,xv,Dr,yv,wv,Sr,Tv,Rv,Ar,Dv,Sv,iu,K,Av,Or,Ov,Lv,Lr,Iv,zv,Ir,Pv,Nv,zr,Cv,qv,Pr,Gv,Hv,Nr,Uv,Mv,Cr,Bv,jv,qr,Wv,Fv,ou,Gr,Yv,Hr,Xv,Zv,nu,Jt,Kv,Ur,Vv,Qv,Mr,Jv,yf,Ue,$v,Br,e2,t2,jr,s2,a2,wf,oa,Tf,$t,es,cu,l2,Rf,Wr,r2,Df,he,Fr,na,i2,o2,n2,Yr,ca,c2,u2,f2,Xr,ua,d2,p2,h2,Zr,fa,g2,m2,Sf,ts,ss,uu,v2,Af,as,_2,Kr,k2,b2,Of,da,e6=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,Lf,Me,E2,Vr,x2,y2,Qr,w2,T2,If,pa,R2,Jr,D2,zf,ls,S2,$r,A2,O2,Pf,rs,is,fu,L2,Nf,os,I2,ha,z2,P2,Cf,ga,ns,N2,ma,C2,q2,qf,cs,us,du,G2,Gf,fs,H2,ei,U2,M2,Hf,va,t6=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Uf,ti,B2,Mf,_a,s6='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Bf,Be,j2,si,W2,F2,ai,Y2,X2,jf,je,Z2,li,K2,V2,ri,Q2,J2,Wf,ii,$2,Ff,ds,oi,e_,pu,hu,t_,s_,ni,a_,gu,mu,l_,Yf,ci,r_,Xf,ka,ba,Vx,Zf,ps,hs,vu,i_,Kf,_t,o_,ui,n_,c_,fi,u_,Vf,kt,di,re,pi,f_,d_,hi,p_,h_,gi,g_,m_,mi,v_,__,vi,k_,b_,_i,ie,ki,E_,x_,bi,y_,w_,Ei,T_,R_,xi,D_,S_,yi,A_,Qf,wi,O_,Jf,Ea,a6=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,$f,M,Ti,xa,L_,Ri,I_,z_,P_,N_,Di,ya,C_,Si,q_,G_,H_,U_,Ai,wa,M_,Oi,B_,j_,W_,F_,Li,Ta,Y_,Ii,X_,Z_,K_,V_,zi,Ra,Q_,Pi,J_,$_,e1,t1,Ni,Da,s1,Ci,a1,l1,r1,i1,qi,Sa,o1,Gi,n1,c1,u1,f1,Hi,Aa,d1,Ui,p1,h1,g1,m1,Mi,Oa,v1,Bi,_1,k1,b1,E1,ji,La,x1,Wi,y1,w1,T1,R1,Fi,Ia,D1,Yi,S1,A1,O1,ed,gs,ms,_u,L1,td,Xi,I1,sd,za,ad,vs,_s,ku,z1,ld,ks,P1,Pa,N1,C1,rd,bs,q1,Zi,G1,H1,id,oe,Ki,U1,od,M1,bu,B1,j1,We,W1,Vi,F1,Y1,Qi,X1,Z1,Ji,K1,V1,$i,Q1,eo,J1,$1,Es,ek,to,tk,sk,so,ak,nd,Fe,lk,ao,rk,ik,lo,ok,nk,cd,ge,xs,ck,ro,uk,fk,io,dk,pk,Na,hk,oo,gk,mk,vk,Eu,_k,kk,xu,bk,ud,ys,ws,yu,Ek,fd,me,no,wu,xk,yk,wk,co,Tu,Tk,Rk,Dk,uo,Ru,Sk,Ak,Ok,fo,Du,Lk,Ik,dd,po,zk,pd,Ca,qa,Qx,hd,Ts,Rs,Su,Pk,gd,ho,Nk,md,Ye,Ga,Ck,go,qk,Gk,Hk,Ha,Uk,mo,Mk,Bk,jk,Au,Wk,vd,bt,vo,Xe,_o,Fk,Yk,ko,Xk,Zk,bo,Kk,Vk,ve,Ze,Eo,Qk,Jk,xo,$k,eb,yo,tb,sb,Ke,wo,ab,lb,To,rb,ib,Ro,ob,nb,Ve,Do,cb,ub,So,fb,db,Ao,pb,hb,Qe,Oo,gb,mb,Lo,vb,_b,Io,kb,_d,Ds,Ss,Ou,bb,kd,zo,Eb,bd,Et,Po,Je,No,xb,yb,Co,wb,Tb,qo,Rb,Db,j,$e,Go,Sb,Ab,Ho,Ob,Lb,Uo,Ib,zb,et,Mo,Pb,Nb,Bo,Cb,qb,jo,Gb,Hb,tt,Wo,Ub,Mb,Fo,Bb,jb,Yo,Wb,Fb,st,Xo,Yb,Xb,Zo,Zb,Kb,Ko,Vb,Qb,at,Vo,Jb,$b,Qo,eE,tE,Jo,sE,aE,lt,$o,lE,rE,en,iE,oE,tn,nE,cE,rt,sn,uE,fE,an,dE,pE,ln,hE,gE,it,rn,mE,vE,on,_E,kE,nn,bE,EE,ot,cn,xE,yE,un,wE,TE,fn,RE,DE,nt,dn,SE,AE,pn,OE,LE,hn,IE,Ed,As,Os,Lu,zE,xd,gn,PE,yd,mn,NE,wd,Ua,Ma,Jx,Td,vn,CE,Rd,xt,Ls,Iu,qE,Dd,Sd,Ad;h=new _6({props:{smallImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png",largeImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png",alt:"Action Figure with reg images",largeWidth:"968",largeHeight:"512",smallWidth:"484",smallHeight:"256"}}),A=new mp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),la=new mp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),oa=new mp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),za=new mp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let ke=Q0&&W6();return{c(){d=a("p"),m=o("I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),g=c(),Us(h.$$.fragment),v=c(),k=a("h2"),E=a("a"),T=a("span"),R=o("What are Regularization Images?"),x=c(),b=a("p"),y=o("Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),I=c(),O=a("blockquote"),z=a("p"),q=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),D=c(),Us(A.$$.fragment),S=c(),P=a("p"),N=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Q=c(),W=a("p"),F=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),B=c(),C=a("p"),L=o("In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),H=c(),X=a("table"),U=a("thead"),w=a("tr"),G=a("th"),Ws=o("Aspect"),Wa=c(),_e=a("th"),Fa=o("Regularization"),bp=c(),Ya=a("th"),Ep=o("No Regularization"),xp=c(),Ee=a("tbody"),xe=a("tr"),Xa=a("td"),oc=a("strong"),yp=o("Class Definition"),wp=c(),Za=a("td"),Tp=o("Explicit class anchoring"),Rp=c(),Ka=a("td"),Dp=o("Implicit class learning"),Sp=c(),ye=a("tr"),Va=a("td"),nc=a("strong"),Ap=o("Failure Modes"),Op=c(),Qa=a("td"),Lp=o("Underfitting if overdone"),Ip=c(),Ja=a("td"),zp=o("Overfitting/drift"),Pp=c(),we=a("tr"),$a=a("td"),cc=a("strong"),Np=o("Data Efficiency"),Cp=c(),el=a("td"),qp=o("Better generalization"),Gp=c(),tl=a("td"),Hp=o("Requires more data"),Gu=c(),sl=a("p"),Up=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Hu=c(),al=a("p"),Mp=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Uu=c(),Fs=a("blockquote"),ll=a("p"),Bp=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Mu=c(),Ys=a("p"),uc=a("strong"),jp=o("Scenario 1"),Wp=o(": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),Bu=c(),Xs=a("p"),fc=a("strong"),Fp=o("Solution"),Yp=o(": consider using regularization images to help the model learn more about cat features."),ju=c(),Zs=a("p"),dc=a("strong"),Xp=o("Scenario 2"),Zp=o(": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),Wu=c(),Ks=a("p"),pc=a("strong"),Kp=o("Solution"),Vp=o(": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),Fu=c(),wt=a("h2"),Tt=a("a"),hc=a("span"),Qp=o("Divergence"),Yu=c(),Vs=a("p"),gc=a("strong"),Jp=o("Divergence"),$p=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Xu=c(),Te=a("p"),eh=o("Preventing divergence starts with "),mc=a("strong"),th=o("careful dataset curation"),sh=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),vc=a("strong"),ah=o("regularization techniques"),lh=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Zu=c(),Re=a("ul"),rl=a("li"),_c=a("strong"),rh=o("Chaotic outputs"),ih=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),oh=c(),il=a("li"),kc=a("strong"),nh=o("Exploding gradients"),ch=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),uh=c(),Rt=a("li"),bc=a("strong"),fh=o("Loss value instability (NaN/infinity values)"),dh=o(" The training loss fluctuates wildly, sometimes becoming "),ol=a("code"),ph=o("NaN"),hh=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Ku=c(),Dt=a("h2"),St=a("a"),Ec=a("span"),xc=a("strong"),gh=o("Overfitting"),Vu=c(),nl=a("p"),mh=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),Qu=c(),De=a("ul"),cl=a("li"),yc=a("strong"),vh=o("Perfectly replicates training samples"),_h=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),kh=c(),ul=a("li"),wc=a("strong"),bh=o("Fails to generalize to new inputs"),Eh=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),xh=c(),fl=a("li"),Tc=a("strong"),yh=o("Shows excellent training loss but poor validation loss"),wh=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),Ju=c(),At=a("h3"),Ot=a("a"),Rc=a("span"),Dc=a("strong"),Th=o("Key Differences"),$u=c(),gt=a("table"),dl=a("thead"),Se=a("tr"),pl=a("th"),Sc=a("strong"),Rh=o("Aspect"),Dh=c(),hl=a("th"),Ac=a("strong"),Sh=o("Divergence"),Ah=c(),gl=a("th"),Oc=a("strong"),Oh=o("Overfitting"),Lh=c(),ue=a("tbody"),Ae=a("tr"),ml=a("td"),Lc=a("strong"),Ih=o("Cause"),zh=c(),vl=a("td"),Ph=o("Excessive learning rate"),Nh=c(),_l=a("td"),Ch=o("Insufficient regularization"),qh=c(),Oe=a("tr"),kl=a("td"),Ic=a("strong"),Gh=o("Loss Behavior"),Hh=c(),bl=a("td"),Uh=o("Sudden spikes/NaN values"),Mh=c(),El=a("td"),Bh=o("Steady decrease then rise"),jh=c(),Le=a("tr"),xl=a("td"),zc=a("strong"),Wh=o("Output Quality"),Fh=c(),yl=a("td"),Yh=o("Random noise/artifacts"),Xh=c(),wl=a("td"),Zh=o("Overly detailed replicas"),Kh=c(),Ie=a("tr"),Tl=a("td"),Pc=a("strong"),Vh=o("Recovery"),Qh=c(),Rl=a("td"),Jh=o("Requires restart"),$h=c(),Dl=a("td"),eg=o("Early stopping works"),ef=c(),Lt=a("h3"),It=a("a"),Nc=a("span"),tg=o("Preventing Divergence"),tf=c(),mt=a("table"),Sl=a("thead"),zt=a("tr"),Al=a("th"),sg=o("Situation"),ag=c(),Ol=a("th"),lg=o("Outcome"),rg=c(),fe=a("tbody"),Pt=a("tr"),Ll=a("td"),Cc=a("strong"),ig=o("Excessive or inconsistent data"),og=c(),Il=a("td"),ng=o("Model struggles to learn and produces unreliable predictions."),cg=c(),Nt=a("tr"),zl=a("td"),qc=a("strong"),ug=o("Lack of unique and consistent features"),fg=c(),Pl=a("td"),dg=o("Poor generalization, leading to inaccurate or meaningless outputs."),pg=c(),Ct=a("tr"),Nl=a("td"),Gc=a("strong"),hg=o("Carefully curated datasets"),gg=c(),Cl=a("td"),mg=o("Improved learning by ensuring the model sees only relevant, high-quality data."),vg=c(),qt=a("tr"),ql=a("td"),Hc=a("strong"),_g=o("Effective use of regularization techniques"),kg=c(),Gl=a("td"),bg=o("Helps maintain focus on essential features and prevents instability."),sf=c(),Hl=a("p"),Eg=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),af=c(),Gt=a("h3"),Ht=a("a"),Uc=a("span"),xg=o("Implementing these Strategies"),lf=c(),Qs=a("pre"),rf=c(),Js=a("pre"),of=c(),Ut=a("h3"),Mt=a("a"),Mc=a("span"),yg=o("Data Considerations"),nf=c(),vt=a("table"),Ul=a("thead"),ze=a("tr"),Ml=a("th"),wg=o("Situation"),Tg=c(),Bl=a("th"),Rg=o("Actual Risk"),Dg=c(),jl=a("th"),Sg=o("Solution"),Ag=c(),de=a("tbody"),Pe=a("tr"),Wl=a("td"),Og=o("High LR + small batch size"),Lg=c(),Fl=a("td"),Ig=o("Divergence"),zg=c(),Yl=a("td"),Pg=o("Lower LR, increase batch size"),Ng=c(),Ne=a("tr"),Xl=a("td"),Cg=o("Inconsistent features"),qg=c(),Zl=a("td"),Gg=o("Overfitting"),Hg=c(),Kl=a("td"),Ug=o("Improve dataset consistency"),Mg=c(),Ce=a("tr"),Vl=a("td"),Bg=o("Insufficient reg images"),jg=c(),Ql=a("td"),Wg=o("Class leakage"),Fg=c(),Jl=a("td"),Yg=o("Add 100-300 class images"),Xg=c(),qe=a("tr"),$l=a("td"),Zg=o("High variance in training data"),Kg=c(),er=a("td"),Vg=o("Mode collapse"),Qg=c(),tr=a("td"),Jg=o("Curate focused dataset"),cf=c(),Bt=a("h3"),jt=a("a"),Bc=a("span"),$g=o("Monitoring Tips"),uf=c(),le=a("ul"),sr=a("li"),em=o("Track loss curves with tools like "),$s=a("a"),tm=o("TensorBoard"),sm=c(),jc=a("li"),am=o("Generate validation images every 100 steps"),lm=c(),Wc=a("li"),rm=o("Use gradient clipping (1.0-2.0 norm)"),im=c(),Fc=a("li"),om=o("Enable mixed precision training"),nm=c(),Yc=a("li"),cm=o("Start with conservative learning rates (1e-5 to 1e-6)"),ff=c(),Wt=a("h2"),Ft=a("a"),Xc=a("span"),um=o("Generating Regularization images"),df=c(),Yt=a("p"),fm=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),ar=a("code"),dm=o("1boy"),pm=o(")."),pf=c(),pe=a("p"),hm=o("According to the Dreambooth technique, "),lr=a("code"),gm=o("200"),mm=o(" regularization images per training image.  For example, if you have "),rr=a("code"),vm=o("16"),_m=o(" images: "),ir=a("code"),km=o("200 * 16 = 3200"),bm=o(" total regularization images.  When training, the math involved for calculating total steps is:"),hf=c(),ea=a("blockquote"),or=a("p"),nr=a("code"),Em=o("repeats * training images >= repeats * regularization images"),gf=c(),cr=a("p"),xm=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),mf=c(),Xt=a("h4"),Zt=a("a"),Zc=a("span"),ym=o("Important considerations"),vf=c(),Ge=a("ol"),Kc=a("li"),ta=a("p"),Vc=a("strong"),wm=o("Use the same base model for regularization images and training"),Tm=a("br"),Rm=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Dm=c(),Qc=a("li"),sa=a("p"),Jc=a("strong"),Sm=o("Maintain consistent class representation"),Am=a("br"),Om=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Lm=c(),$c=a("li"),aa=a("p"),eu=a("strong"),Im=o("Match output resolution to training data"),zm=a("br"),Pm=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),_f=c(),Us(la.$$.fragment),kf=c(),Kt=a("h4"),Vt=a("a"),tu=a("span"),Nm=o("Generate using Stable Diffusion web UI"),bf=c(),Qt=a("p"),Cm=o("We\u2019re going to use "),ra=a("a"),qm=o("Stable Diffusion web UI"),Gm=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Ef=c(),He=a("p"),Hm=o("We\u2019re going to use the "),ur=a("code"),Um=o("X/Y/Z plot"),Mm=o(" script to use "),fr=a("code"),Bm=o("Prompt Search & Replace"),jm=o(" to dynamically build a prompt that will generate hundreds of regularization images."),xf=c(),J=a("ol"),su=a("li"),dr=a("p"),Wm=o("Select the text 2 image tab.  Enter a generic prompt "),pr=a("code"),Fm=o("princeadam, portrait, looking_at_viewer, forest"),Ym=c(),au=a("li"),ia=a("p"),Xm=o("In generation parameters and select the "),hr=a("code"),Zm=o("X/Y/Z plot"),Km=o(" script."),Vm=c(),lu=a("li"),Z=a("p"),Qm=o("Select the "),gr=a("code"),Jm=o("X"),$m=o(" parameter and "),mr=a("code"),ev=o("Prompt SR"),tv=o(" for Prompt Replace.  We\u2019re going to replace "),vr=a("code"),sv=o("portrait"),av=o(" with different camera angle tags: "),_r=a("code"),lv=o("close-up"),rv=o(", "),kr=a("code"),iv=o("upper_body"),ov=o(", "),br=a("code"),nv=o("from_below"),cv=o(", "),Er=a("code"),uv=o("from_above"),fv=o(", "),xr=a("code"),dv=o("dutch_angle"),pv=c(),ru=a("li"),$=a("p"),hv=o("Select the "),yr=a("code"),gv=o("Y"),mv=o(" parameter and "),wr=a("code"),vv=o("Prompt SR"),_v=o(" for Prompt Replace.  Replace "),Tr=a("code"),kv=o("looking_at_viewer"),bv=o(": "),Rr=a("code"),Ev=o("looking_away"),xv=o(", "),Dr=a("code"),yv=o("looking_to_the_side"),wv=o(", "),Sr=a("code"),Tv=o("looking_ahead"),Rv=o(", "),Ar=a("code"),Dv=o("looking_down"),Sv=c(),iu=a("li"),K=a("p"),Av=o("Select the "),Or=a("code"),Ov=o("Z"),Lv=o(" parameter and "),Lr=a("code"),Iv=o("Prompt SR"),zv=o(" for Prompt Replace. Replace "),Ir=a("code"),Pv=o("forest"),Nv=o(" with a vareity of locatinos: "),zr=a("code"),Cv=o("castle"),qv=o(", "),Pr=a("code"),Gv=o("mountain"),Hv=o(", "),Nr=a("code"),Uv=o("cave"),Mv=o(", "),Cr=a("code"),Bv=o("farm"),jv=o(", "),qr=a("code"),Wv=o("ocean"),Fv=c(),ou=a("li"),Gr=a("p"),Yv=o("Select a fast sampler like "),Hr=a("code"),Xv=o("DPM2 KARRAS"),Zv=c(),nu=a("li"),Jt=a("p"),Kv=o("CFG Scale set to "),Ur=a("code"),Vv=o("7"),Qv=o(" and Steps to "),Mr=a("code"),Jv=o("20"),yf=c(),Ue=a("p"),$v=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Br=a("code"),e2=o("150"),t2=o(" - "),jr=a("code"),s2=o("200"),a2=o(" and keep in mind we can add and remove as we try different training settings with different output."),wf=c(),Us(oa.$$.fragment),Tf=c(),$t=a("h4"),es=a("a"),cu=a("span"),l2=o("Download images"),Rf=c(),Wr=a("p"),r2=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Df=c(),he=a("ul"),Fr=a("li"),na=a("a"),i2=o("3ee Games regularization images"),o2=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),n2=c(),Yr=a("li"),ca=a("a"),c2=o("Pre-Rendered Regularization Images"),u2=o(": Includes 1500 regularization images."),f2=c(),Xr=a("li"),ua=a("a"),d2=o("Stable Diffusion 1.5 Regularization Images"),p2=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),h2=c(),Zr=a("li"),fa=a("a"),g2=o("Aitrepreneur SDXL image set"),m2=o(": a large image set generated with Stable Diffusion SDXL."),Sf=c(),ts=a("h4"),ss=a("a"),uu=a("span"),v2=o("Captioning Regularization images"),Af=c(),as=a("p"),_2=o("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Kr=a("code"),k2=o("txt"),b2=o(" files with a shell script:"),Of=c(),da=a("pre"),Lf=c(),Me=a("p"),E2=o("Save this file as "),Vr=a("code"),x2=o("filename2txt.bat"),y2=o(" and place it into the regularization images directory and run: "),Qr=a("code"),w2=o(".\\filename2txt.bat"),T2=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),If=c(),pa=a("p"),R2=o("Example filename: "),Jr=a("code"),D2=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),zf=c(),ls=a("p"),S2=o("Output: "),$r=a("code"),A2=o("aburbres,princeadam,1boy,close-up,purple_vest"),O2=o(" saved in a text file with the same name as image."),Pf=c(),rs=a("h2"),is=a("a"),fu=a("span"),L2=o("Training a LoRA"),Nf=c(),os=a("p"),I2=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),ha=a("a"),z2=o("kohya-ss/sd-scripts"),P2=o("."),Cf=c(),ga=a("blockquote"),ns=a("p"),N2=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ma=a("a"),C2=o("Kohya SD script documentation"),q2=o("."),qf=c(),cs=a("h3"),us=a("a"),du=a("span"),G2=o("Directory setup"),Gf=c(),fs=a("p"),H2=o("In your configuration json, use "),ei=a("code"),U2=o("reg_data_dir"),M2=o(" to point to the directory with your regularization images:"),Hf=c(),va=a("pre"),Uf=c(),ti=a("p"),B2=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Mf=c(),_a=a("pre"),Bf=c(),Be=a("p"),j2=o("Set the "),si=a("code"),W2=o("number of iterations"),F2=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),ai=a("code"),Y2=o("training images \xD7 iterations"),X2=o(". If there are more regularization images than this, the extras won\u2019t be used."),jf=c(),je=a("p"),Z2=o("Create folders in the training image folder with the format "),li=a("code"),K2=o("<repetition count>_<class>"),V2=o(" multiple times, and similarly create folders in the regularization image folder with the format "),ri=a("code"),Q2=o("<repetition count>_<class>"),J2=o("."),Wf=c(),ii=a("p"),$2=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Ff=c(),ds=a("ul"),oi=a("li"),e_=o("train_data_dir"),pu=a("ul"),hu=a("li"),t_=o("10_princeadam"),s_=c(),ni=a("li"),a_=o("reg_dir"),gu=a("ul"),mu=a("li"),l_=o("1_1boy"),Yf=c(),ci=a("p"),r_=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),Xf=c(),ka=a("p"),ba=a("img"),Zf=c(),ps=a("h3"),hs=a("a"),vu=a("span"),i_=o("Training Settings"),Kf=c(),_t=a("p"),o_=o("The training setup we\u2019re going to use is:  "),ui=a("code"),n_=o("Number of images * repeats * epoch / batch size = total steps"),c_=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),fi=a("code"),u_=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Vf=c(),kt=a("table"),di=a("thead"),re=a("tr"),pi=a("th"),f_=o("Number of Images"),d_=c(),hi=a("th"),p_=o("Repeats"),h_=c(),gi=a("th"),g_=o("Epochs"),m_=c(),mi=a("th"),v_=o("Batch Size"),__=c(),vi=a("th"),k_=o("Total Steps"),b_=c(),_i=a("tbody"),ie=a("tr"),ki=a("td"),E_=o("45"),x_=c(),bi=a("td"),y_=o("10"),w_=c(),Ei=a("td"),T_=o("20"),R_=c(),xi=a("td"),D_=o("2"),S_=c(),yi=a("td"),A_=o("4500"),Qf=c(),wi=a("p"),O_=o("Now let\u2019s focus on these training settings:"),Jf=c(),Ea=a("pre"),$f=c(),M=a("ul"),Ti=a("li"),xa=a("strong"),L_=o("Learning Rate ("),Ri=a("code"),I_=o("learning_rate"),z_=o(")"),P_=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),N_=c(),Di=a("li"),ya=a("strong"),C_=o("Text Encoder Learning Rate ("),Si=a("code"),q_=o("text_encoder_lr"),G_=o(")"),H_=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),U_=c(),Ai=a("li"),wa=a("strong"),M_=o("UNet Learning Rate ("),Oi=a("code"),B_=o("unet_lr"),j_=o(")"),W_=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),F_=c(),Li=a("li"),Ta=a("strong"),Y_=o("Learning Rate Scheduler ("),Ii=a("code"),X_=o("lr_scheduler"),Z_=o(")"),K_=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),V_=c(),zi=a("li"),Ra=a("strong"),Q_=o("Number of Cycles in Learning Rate Scheduler ("),Pi=a("code"),J_=o("lr_scheduler_num_cycles"),$_=o(")"),e1=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),t1=c(),Ni=a("li"),Da=a("strong"),s1=o("Network Dimension ("),Ci=a("code"),a1=o("network_dim"),l1=o(")"),r1=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),i1=c(),qi=a("li"),Sa=a("strong"),o1=o("Network Alpha ("),Gi=a("code"),n1=o("network_alpha"),c1=o(")"),u1=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),f1=c(),Hi=a("li"),Aa=a("strong"),d1=o("Clip Skip ("),Ui=a("code"),p1=o("clip_skip"),h1=o(")"),g1=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),m1=c(),Mi=a("li"),Oa=a("strong"),v1=o("Max Token Length ("),Bi=a("code"),_1=o("max_token_length"),k1=o(")"),b1=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),E1=c(),ji=a("li"),La=a("strong"),x1=o("Noise Offset ("),Wi=a("code"),y1=o("noise_offset"),w1=o(")"),T1=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),R1=c(),Fi=a("li"),Ia=a("strong"),D1=o("Regularization Data Directory ("),Yi=a("code"),S1=o("reg_data_dir"),A1=o(")"),O1=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),ed=c(),gs=a("h3"),ms=a("a"),_u=a("span"),L1=o("Fine Tuning"),td=c(),Xi=a("p"),I1=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),sd=c(),Us(za.$$.fragment),ad=c(),vs=a("h4"),_s=a("a"),ku=a("span"),z1=o("Workflow with Auto1111 WebUI"),ld=c(),ks=a("p"),P1=o("We\u2019re going to use "),Pa=a("a"),N1=o("Stable Diffusion web UI"),C1=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),rd=c(),bs=a("p"),q1=o("We\u2019re going to use the "),Zi=a("code"),G1=o("X/Y/Z plot"),H1=o(" script to compare different epochs."),id=c(),oe=a("ul"),Ki=a("li"),U1=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),od=a("princeadam0001:0.7"),M1=c(),bu=a("li"),B1=o("In generation parameters and select the X/Y/Z plot script."),j1=c(),We=a("li"),W1=o("Select "),Vi=a("code"),F1=o("Prompt SR"),Y1=o(" for Prompt Replace.  We\u2019re going to replace "),Qi=a("code"),X1=o("<princeadam0001:0.7>"),Z1=o(" with different epoch: "),Ji=a("code"),K1=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),V1=c(),$i=a("li"),Q1=o("Select a fast sampler like "),eo=a("code"),J1=o("DPM2 KARRAS"),$1=c(),Es=a("li"),ek=o("CFG Scale set to "),to=a("code"),tk=o("7"),sk=o(" and Steps to "),so=a("code"),ak=o("20"),nd=c(),Fe=a("p"),lk=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),ao=a("code"),rk=o("network_dim"),ik=o(" and "),lo=a("code"),ok=o("network_alpha"),nk=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),cd=c(),ge=a("ul"),xs=a("li"),ck=o("Select "),ro=a("code"),uk=o("Prompt SR"),fk=o(" for Prompt Replace.  We\u2019re going to replace the weights "),io=a("code"),dk=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),pk=c(),Na=a("li"),hk=o("Use Prompt SR to generate a variety of angles: Select "),oo=a("code"),gk=o("Prompt SR"),mk=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),vk=c(),Eu=a("li"),_k=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),kk=c(),xu=a("li"),bk=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),ud=c(),ys=a("h4"),ws=a("a"),yu=a("span"),Ek=o("Issues to look for"),fd=c(),me=a("ul"),no=a("li"),wu=a("strong"),xk=o("Undercooked:"),yk=o(" Lacks output, adjust unet learning rate or extend training duration."),wk=c(),co=a("li"),Tu=a("strong"),Tk=o("Overcooked:"),Rk=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Dk=c(),uo=a("li"),Ru=a("strong"),Sk=o("Overfit:"),Ak=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),Ok=c(),fo=a("li"),Du=a("strong"),Lk=o("Mismatched:"),Ik=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),dd=c(),po=a("p"),zk=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),pd=c(),Ca=a("p"),qa=a("img"),hd=c(),Ts=a("h2"),Rs=a("a"),Su=a("span"),Pk=o("Troubleshooting"),gd=c(),ho=a("p"),Nk=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),md=c(),Ye=a("ul"),Ga=a("li"),Ck=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),go=a("code"),qk=o("200"),Gk=o(" regularization images per training image."),Hk=c(),Ha=a("li"),Uk=o("Repeats of regularization images, but may overfit more.  Increasing the "),mo=a("code"),Mk=o("repetition_count"),Bk=o(" will cycle through the images more but the results may have results that overfit the model."),jk=c(),Au=a("li"),Wk=o("Create more regularization images without increasing repeats will help with the overfitting."),vd=c(),bt=a("table"),vo=a("thead"),Xe=a("tr"),_o=a("th"),Fk=o("Issue"),Yk=c(),ko=a("th"),Xk=o("Situation"),Zk=c(),bo=a("th"),Kk=o("Recommendation"),Vk=c(),ve=a("tbody"),Ze=a("tr"),Eo=a("td"),Qk=o("Varying quality"),Jk=c(),xo=a("td"),$k=o("Results differ from expectations"),eb=c(),yo=a("td"),tb=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),sb=c(),Ke=a("tr"),wo=a("td"),ab=o("Inadequate regularization for input data"),lb=c(),To=a("td"),rb=o("Lower input images, less regularization needed"),ib=c(),Ro=a("td"),ob=o("Reduce the number of input images or increasing the quantity of reg images."),nb=c(),Ve=a("tr"),Do=a("td"),cb=o("Overfitting due to repetition"),ub=c(),So=a("td"),fb=o("Repeats of reg images, risk of overfitting"),db=c(),Ao=a("td"),pb=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),hb=c(),Qe=a("tr"),Oo=a("td"),gb=o("Mitigate overfitting while increasing diversity"),mb=c(),Lo=a("td"),vb=o("Create more reg images without repeats"),_b=c(),Io=a("td"),kb=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),_d=c(),Ds=a("h4"),Ss=a("a"),Ou=a("span"),bb=o("More Solutions"),kd=c(),zo=a("p"),Eb=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),bd=c(),Et=a("table"),Po=a("thead"),Je=a("tr"),No=a("th"),xb=o("Symptom"),yb=c(),Co=a("th"),wb=o("Likely Cause"),Tb=c(),qo=a("th"),Rb=o("Solution"),Db=c(),j=a("tbody"),$e=a("tr"),Go=a("td"),Sb=o("Plastic texture persists"),Ab=c(),Ho=a("td"),Ob=o("Insufficient human reg images"),Lb=c(),Uo=a("td"),Ib=o("Add real photos to reg set"),zb=c(),et=a("tr"),Mo=a("td"),Pb=o("Loss plateaus early"),Nb=c(),Bo=a("td"),Cb=o("Learning rate too low"),qb=c(),jo=a("td"),Gb=o("Increase LR by 10x"),Hb=c(),tt=a("tr"),Wo=a("td"),Ub=o("Features blurry"),Mb=c(),Fo=a("td"),Bb=o("Network dimension too small"),jb=c(),Yo=a("td"),Wb=o("Increase network_dim to 64+"),Fb=c(),st=a("tr"),Xo=a("td"),Yb=o("Color distortion"),Xb=c(),Zo=a("td"),Zb=o("Noise offset conflict"),Kb=c(),Ko=a("td"),Vb=o("Try noise_offset 0.05-0.1"),Qb=c(),at=a("tr"),Vo=a("td"),Jb=o("Overly stylized outputs"),$b=c(),Qo=a("td"),eE=o("Reg image style mismatch"),tE=c(),Jo=a("td"),sE=o("Regenerate reg images with base model"),aE=c(),lt=a("tr"),$o=a("td"),lE=o("Training instability"),rE=c(),en=a("td"),iE=o("Batch size too large"),oE=c(),tn=a("td"),nE=o("Reduce batch_size to 1-2"),cE=c(),rt=a("tr"),sn=a("td"),uE=o("Slow convergence"),fE=c(),an=a("td"),dE=o("Network_alpha too high"),pE=c(),ln=a("td"),hE=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),gE=c(),it=a("tr"),rn=a("td"),mE=o("Loss divergence"),vE=c(),on=a("td"),_E=o("Text encoder LR too high"),kE=c(),nn=a("td"),bE=o("Reduce text_encoder_lr by 10x"),EE=c(),ot=a("tr"),cn=a("td"),xE=o("Poor prompt adherence"),yE=c(),un=a("td"),wE=o("Clip skip too high"),TE=c(),fn=a("td"),RE=o("Reduce clip_skip to 1-2"),DE=c(),nt=a("tr"),dn=a("td"),SE=o("Memory errors"),AE=c(),pn=a("td"),OE=o("Resolution too high"),LE=c(),hn=a("td"),IE=o("Reduce to 512-768px, enable gradient checkpointing"),Ed=c(),As=a("h2"),Os=a("a"),Lu=a("span"),zE=o("Results"),xd=c(),gn=a("p"),PE=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),yd=c(),mn=a("p"),NE=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),wd=c(),Ua=a("p"),Ma=a("img"),Td=c(),vn=a("p"),CE=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),Rd=c(),xt=a("h2"),Ls=a("a"),Iu=a("span"),qE=o("spacelab"),Dd=c(),ke&&ke.c(),Sd=ic(),this.h()},l(s){d=l(s,"P",{});var p=r(d);m=n(p,"I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),p.forEach(t),g=u(s),Ms(h.$$.fragment,s),v=u(s),k=l(s,"H2",{id:!0});var GE=r(k);E=l(GE,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var $x=r(E);T=l($x,"SPAN",{class:!0}),r(T).forEach(t),$x.forEach(t),R=n(GE,"What are Regularization Images?"),GE.forEach(t),x=u(s),b=l(s,"P",{});var ey=r(b);y=n(ey,"Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),ey.forEach(t),I=u(s),O=l(s,"BLOCKQUOTE",{class:!0});var ty=r(O);z=l(ty,"P",{class:!0});var sy=r(z);q=n(sy,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),sy.forEach(t),ty.forEach(t),D=u(s),Ms(A.$$.fragment,s),S=u(s),P=l(s,"P",{});var ay=r(P);N=n(ay,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),ay.forEach(t),Q=u(s),W=l(s,"P",{});var ly=r(W);F=n(ly,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),ly.forEach(t),B=u(s),C=l(s,"P",{});var ry=r(C);L=n(ry,"In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),ry.forEach(t),H=u(s),X=l(s,"TABLE",{class:!0});var Od=r(X);U=l(Od,"THEAD",{class:!0});var iy=r(U);w=l(iy,"TR",{class:!0});var _n=r(w);G=l(_n,"TH",{class:!0});var oy=r(G);Ws=n(oy,"Aspect"),oy.forEach(t),Wa=u(_n),_e=l(_n,"TH",{class:!0});var ny=r(_e);Fa=n(ny,"Regularization"),ny.forEach(t),bp=u(_n),Ya=l(_n,"TH",{class:!0});var cy=r(Ya);Ep=n(cy,"No Regularization"),cy.forEach(t),_n.forEach(t),iy.forEach(t),xp=u(Od),Ee=l(Od,"TBODY",{class:!0});var kn=r(Ee);xe=l(kn,"TR",{class:!0});var bn=r(xe);Xa=l(bn,"TD",{class:!0});var uy=r(Xa);oc=l(uy,"STRONG",{});var fy=r(oc);yp=n(fy,"Class Definition"),fy.forEach(t),uy.forEach(t),wp=u(bn),Za=l(bn,"TD",{class:!0});var dy=r(Za);Tp=n(dy,"Explicit class anchoring"),dy.forEach(t),Rp=u(bn),Ka=l(bn,"TD",{class:!0});var py=r(Ka);Dp=n(py,"Implicit class learning"),py.forEach(t),bn.forEach(t),Sp=u(kn),ye=l(kn,"TR",{class:!0});var En=r(ye);Va=l(En,"TD",{class:!0});var hy=r(Va);nc=l(hy,"STRONG",{});var gy=r(nc);Ap=n(gy,"Failure Modes"),gy.forEach(t),hy.forEach(t),Op=u(En),Qa=l(En,"TD",{class:!0});var my=r(Qa);Lp=n(my,"Underfitting if overdone"),my.forEach(t),Ip=u(En),Ja=l(En,"TD",{class:!0});var vy=r(Ja);zp=n(vy,"Overfitting/drift"),vy.forEach(t),En.forEach(t),Pp=u(kn),we=l(kn,"TR",{class:!0});var xn=r(we);$a=l(xn,"TD",{class:!0});var _y=r($a);cc=l(_y,"STRONG",{});var ky=r(cc);Np=n(ky,"Data Efficiency"),ky.forEach(t),_y.forEach(t),Cp=u(xn),el=l(xn,"TD",{class:!0});var by=r(el);qp=n(by,"Better generalization"),by.forEach(t),Gp=u(xn),tl=l(xn,"TD",{class:!0});var Ey=r(tl);Hp=n(Ey,"Requires more data"),Ey.forEach(t),xn.forEach(t),kn.forEach(t),Od.forEach(t),Gu=u(s),sl=l(s,"P",{});var xy=r(sl);Up=n(xy,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),xy.forEach(t),Hu=u(s),al=l(s,"P",{});var yy=r(al);Mp=n(yy,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),yy.forEach(t),Uu=u(s),Fs=l(s,"BLOCKQUOTE",{class:!0});var wy=r(Fs);ll=l(wy,"P",{class:!0});var Ty=r(ll);Bp=n(Ty,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Ty.forEach(t),wy.forEach(t),Mu=u(s),Ys=l(s,"P",{});var HE=r(Ys);uc=l(HE,"STRONG",{});var Ry=r(uc);jp=n(Ry,"Scenario 1"),Ry.forEach(t),Wp=n(HE,": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),HE.forEach(t),Bu=u(s),Xs=l(s,"P",{});var UE=r(Xs);fc=l(UE,"STRONG",{});var Dy=r(fc);Fp=n(Dy,"Solution"),Dy.forEach(t),Yp=n(UE,": consider using regularization images to help the model learn more about cat features."),UE.forEach(t),ju=u(s),Zs=l(s,"P",{});var ME=r(Zs);dc=l(ME,"STRONG",{});var Sy=r(dc);Xp=n(Sy,"Scenario 2"),Sy.forEach(t),Zp=n(ME,": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),ME.forEach(t),Wu=u(s),Ks=l(s,"P",{});var BE=r(Ks);pc=l(BE,"STRONG",{});var Ay=r(pc);Kp=n(Ay,"Solution"),Ay.forEach(t),Vp=n(BE,": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),BE.forEach(t),Fu=u(s),wt=l(s,"H2",{id:!0});var jE=r(wt);Tt=l(jE,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Oy=r(Tt);hc=l(Oy,"SPAN",{class:!0}),r(hc).forEach(t),Oy.forEach(t),Qp=n(jE,"Divergence"),jE.forEach(t),Yu=u(s),Vs=l(s,"P",{});var WE=r(Vs);gc=l(WE,"STRONG",{});var Ly=r(gc);Jp=n(Ly,"Divergence"),Ly.forEach(t),$p=n(WE," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),WE.forEach(t),Xu=u(s),Te=l(s,"P",{});var yn=r(Te);eh=n(yn,"Preventing divergence starts with "),mc=l(yn,"STRONG",{});var Iy=r(mc);th=n(Iy,"careful dataset curation"),Iy.forEach(t),sh=n(yn,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),vc=l(yn,"STRONG",{});var zy=r(vc);ah=n(zy,"regularization techniques"),zy.forEach(t),lh=n(yn," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),yn.forEach(t),Zu=u(s),Re=l(s,"UL",{});var wn=r(Re);rl=l(wn,"LI",{});var FE=r(rl);_c=l(FE,"STRONG",{});var Py=r(_c);rh=n(Py,"Chaotic outputs"),Py.forEach(t),ih=n(FE," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),FE.forEach(t),oh=u(wn),il=l(wn,"LI",{});var YE=r(il);kc=l(YE,"STRONG",{});var Ny=r(kc);nh=n(Ny,"Exploding gradients"),Ny.forEach(t),ch=n(YE," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),YE.forEach(t),uh=u(wn),Rt=l(wn,"LI",{});var zu=r(Rt);bc=l(zu,"STRONG",{});var Cy=r(bc);fh=n(Cy,"Loss value instability (NaN/infinity values)"),Cy.forEach(t),dh=n(zu," The training loss fluctuates wildly, sometimes becoming "),ol=l(zu,"CODE",{class:!0});var qy=r(ol);ph=n(qy,"NaN"),qy.forEach(t),hh=n(zu," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),zu.forEach(t),wn.forEach(t),Ku=u(s),Dt=l(s,"H2",{id:!0});var XE=r(Dt);St=l(XE,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Gy=r(St);Ec=l(Gy,"SPAN",{class:!0}),r(Ec).forEach(t),Gy.forEach(t),xc=l(XE,"STRONG",{});var Hy=r(xc);gh=n(Hy,"Overfitting"),Hy.forEach(t),XE.forEach(t),Vu=u(s),nl=l(s,"P",{});var Uy=r(nl);mh=n(Uy,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),Uy.forEach(t),Qu=u(s),De=l(s,"UL",{});var Tn=r(De);cl=l(Tn,"LI",{});var ZE=r(cl);yc=l(ZE,"STRONG",{});var My=r(yc);vh=n(My,"Perfectly replicates training samples"),My.forEach(t),_h=n(ZE," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),ZE.forEach(t),kh=u(Tn),ul=l(Tn,"LI",{});var KE=r(ul);wc=l(KE,"STRONG",{});var By=r(wc);bh=n(By,"Fails to generalize to new inputs"),By.forEach(t),Eh=n(KE," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),KE.forEach(t),xh=u(Tn),fl=l(Tn,"LI",{});var VE=r(fl);Tc=l(VE,"STRONG",{});var jy=r(Tc);yh=n(jy,"Shows excellent training loss but poor validation loss"),jy.forEach(t),wh=n(VE," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),VE.forEach(t),Tn.forEach(t),Ju=u(s),At=l(s,"H3",{id:!0});var QE=r(At);Ot=l(QE,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Wy=r(Ot);Rc=l(Wy,"SPAN",{class:!0}),r(Rc).forEach(t),Wy.forEach(t),Dc=l(QE,"STRONG",{});var Fy=r(Dc);Th=n(Fy,"Key Differences"),Fy.forEach(t),QE.forEach(t),$u=u(s),gt=l(s,"TABLE",{class:!0});var Ld=r(gt);dl=l(Ld,"THEAD",{class:!0});var Yy=r(dl);Se=l(Yy,"TR",{class:!0});var Rn=r(Se);pl=l(Rn,"TH",{class:!0});var Xy=r(pl);Sc=l(Xy,"STRONG",{});var Zy=r(Sc);Rh=n(Zy,"Aspect"),Zy.forEach(t),Xy.forEach(t),Dh=u(Rn),hl=l(Rn,"TH",{class:!0});var Ky=r(hl);Ac=l(Ky,"STRONG",{});var Vy=r(Ac);Sh=n(Vy,"Divergence"),Vy.forEach(t),Ky.forEach(t),Ah=u(Rn),gl=l(Rn,"TH",{class:!0});var Qy=r(gl);Oc=l(Qy,"STRONG",{});var Jy=r(Oc);Oh=n(Jy,"Overfitting"),Jy.forEach(t),Qy.forEach(t),Rn.forEach(t),Yy.forEach(t),Lh=u(Ld),ue=l(Ld,"TBODY",{class:!0});var Is=r(ue);Ae=l(Is,"TR",{class:!0});var Dn=r(Ae);ml=l(Dn,"TD",{class:!0});var $y=r(ml);Lc=l($y,"STRONG",{});var e3=r(Lc);Ih=n(e3,"Cause"),e3.forEach(t),$y.forEach(t),zh=u(Dn),vl=l(Dn,"TD",{class:!0});var t3=r(vl);Ph=n(t3,"Excessive learning rate"),t3.forEach(t),Nh=u(Dn),_l=l(Dn,"TD",{class:!0});var s3=r(_l);Ch=n(s3,"Insufficient regularization"),s3.forEach(t),Dn.forEach(t),qh=u(Is),Oe=l(Is,"TR",{class:!0});var Sn=r(Oe);kl=l(Sn,"TD",{class:!0});var a3=r(kl);Ic=l(a3,"STRONG",{});var l3=r(Ic);Gh=n(l3,"Loss Behavior"),l3.forEach(t),a3.forEach(t),Hh=u(Sn),bl=l(Sn,"TD",{class:!0});var r3=r(bl);Uh=n(r3,"Sudden spikes/NaN values"),r3.forEach(t),Mh=u(Sn),El=l(Sn,"TD",{class:!0});var i3=r(El);Bh=n(i3,"Steady decrease then rise"),i3.forEach(t),Sn.forEach(t),jh=u(Is),Le=l(Is,"TR",{class:!0});var An=r(Le);xl=l(An,"TD",{class:!0});var o3=r(xl);zc=l(o3,"STRONG",{});var n3=r(zc);Wh=n(n3,"Output Quality"),n3.forEach(t),o3.forEach(t),Fh=u(An),yl=l(An,"TD",{class:!0});var c3=r(yl);Yh=n(c3,"Random noise/artifacts"),c3.forEach(t),Xh=u(An),wl=l(An,"TD",{class:!0});var u3=r(wl);Zh=n(u3,"Overly detailed replicas"),u3.forEach(t),An.forEach(t),Kh=u(Is),Ie=l(Is,"TR",{class:!0});var On=r(Ie);Tl=l(On,"TD",{class:!0});var f3=r(Tl);Pc=l(f3,"STRONG",{});var d3=r(Pc);Vh=n(d3,"Recovery"),d3.forEach(t),f3.forEach(t),Qh=u(On),Rl=l(On,"TD",{class:!0});var p3=r(Rl);Jh=n(p3,"Requires restart"),p3.forEach(t),$h=u(On),Dl=l(On,"TD",{class:!0});var h3=r(Dl);eg=n(h3,"Early stopping works"),h3.forEach(t),On.forEach(t),Is.forEach(t),Ld.forEach(t),ef=u(s),Lt=l(s,"H3",{id:!0});var JE=r(Lt);It=l(JE,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var g3=r(It);Nc=l(g3,"SPAN",{class:!0}),r(Nc).forEach(t),g3.forEach(t),tg=n(JE,"Preventing Divergence"),JE.forEach(t),tf=u(s),mt=l(s,"TABLE",{class:!0});var Id=r(mt);Sl=l(Id,"THEAD",{class:!0});var m3=r(Sl);zt=l(m3,"TR",{class:!0});var zd=r(zt);Al=l(zd,"TH",{class:!0});var v3=r(Al);sg=n(v3,"Situation"),v3.forEach(t),ag=u(zd),Ol=l(zd,"TH",{class:!0});var _3=r(Ol);lg=n(_3,"Outcome"),_3.forEach(t),zd.forEach(t),m3.forEach(t),rg=u(Id),fe=l(Id,"TBODY",{class:!0});var zs=r(fe);Pt=l(zs,"TR",{class:!0});var Pd=r(Pt);Ll=l(Pd,"TD",{class:!0});var k3=r(Ll);Cc=l(k3,"STRONG",{});var b3=r(Cc);ig=n(b3,"Excessive or inconsistent data"),b3.forEach(t),k3.forEach(t),og=u(Pd),Il=l(Pd,"TD",{class:!0});var E3=r(Il);ng=n(E3,"Model struggles to learn and produces unreliable predictions."),E3.forEach(t),Pd.forEach(t),cg=u(zs),Nt=l(zs,"TR",{class:!0});var Nd=r(Nt);zl=l(Nd,"TD",{class:!0});var x3=r(zl);qc=l(x3,"STRONG",{});var y3=r(qc);ug=n(y3,"Lack of unique and consistent features"),y3.forEach(t),x3.forEach(t),fg=u(Nd),Pl=l(Nd,"TD",{class:!0});var w3=r(Pl);dg=n(w3,"Poor generalization, leading to inaccurate or meaningless outputs."),w3.forEach(t),Nd.forEach(t),pg=u(zs),Ct=l(zs,"TR",{class:!0});var Cd=r(Ct);Nl=l(Cd,"TD",{class:!0});var T3=r(Nl);Gc=l(T3,"STRONG",{});var R3=r(Gc);hg=n(R3,"Carefully curated datasets"),R3.forEach(t),T3.forEach(t),gg=u(Cd),Cl=l(Cd,"TD",{class:!0});var D3=r(Cl);mg=n(D3,"Improved learning by ensuring the model sees only relevant, high-quality data."),D3.forEach(t),Cd.forEach(t),vg=u(zs),qt=l(zs,"TR",{class:!0});var qd=r(qt);ql=l(qd,"TD",{class:!0});var S3=r(ql);Hc=l(S3,"STRONG",{});var A3=r(Hc);_g=n(A3,"Effective use of regularization techniques"),A3.forEach(t),S3.forEach(t),kg=u(qd),Gl=l(qd,"TD",{class:!0});var O3=r(Gl);bg=n(O3,"Helps maintain focus on essential features and prevents instability."),O3.forEach(t),qd.forEach(t),zs.forEach(t),Id.forEach(t),sf=u(s),Hl=l(s,"P",{});var L3=r(Hl);Eg=n(L3,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),L3.forEach(t),af=u(s),Gt=l(s,"H3",{id:!0});var $E=r(Gt);Ht=l($E,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var I3=r(Ht);Uc=l(I3,"SPAN",{class:!0}),r(Uc).forEach(t),I3.forEach(t),xg=n($E,"Implementing these Strategies"),$E.forEach(t),lf=u(s),Qs=l(s,"PRE",{class:!0});var l6=r(Qs);l6.forEach(t),rf=u(s),Js=l(s,"PRE",{class:!0});var r6=r(Js);r6.forEach(t),of=u(s),Ut=l(s,"H3",{id:!0});var ex=r(Ut);Mt=l(ex,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var z3=r(Mt);Mc=l(z3,"SPAN",{class:!0}),r(Mc).forEach(t),z3.forEach(t),yg=n(ex,"Data Considerations"),ex.forEach(t),nf=u(s),vt=l(s,"TABLE",{class:!0});var Gd=r(vt);Ul=l(Gd,"THEAD",{class:!0});var P3=r(Ul);ze=l(P3,"TR",{class:!0});var Ln=r(ze);Ml=l(Ln,"TH",{class:!0});var N3=r(Ml);wg=n(N3,"Situation"),N3.forEach(t),Tg=u(Ln),Bl=l(Ln,"TH",{class:!0});var C3=r(Bl);Rg=n(C3,"Actual Risk"),C3.forEach(t),Dg=u(Ln),jl=l(Ln,"TH",{class:!0});var q3=r(jl);Sg=n(q3,"Solution"),q3.forEach(t),Ln.forEach(t),P3.forEach(t),Ag=u(Gd),de=l(Gd,"TBODY",{class:!0});var Ps=r(de);Pe=l(Ps,"TR",{class:!0});var In=r(Pe);Wl=l(In,"TD",{class:!0});var G3=r(Wl);Og=n(G3,"High LR + small batch size"),G3.forEach(t),Lg=u(In),Fl=l(In,"TD",{class:!0});var H3=r(Fl);Ig=n(H3,"Divergence"),H3.forEach(t),zg=u(In),Yl=l(In,"TD",{class:!0});var U3=r(Yl);Pg=n(U3,"Lower LR, increase batch size"),U3.forEach(t),In.forEach(t),Ng=u(Ps),Ne=l(Ps,"TR",{class:!0});var zn=r(Ne);Xl=l(zn,"TD",{class:!0});var M3=r(Xl);Cg=n(M3,"Inconsistent features"),M3.forEach(t),qg=u(zn),Zl=l(zn,"TD",{class:!0});var B3=r(Zl);Gg=n(B3,"Overfitting"),B3.forEach(t),Hg=u(zn),Kl=l(zn,"TD",{class:!0});var j3=r(Kl);Ug=n(j3,"Improve dataset consistency"),j3.forEach(t),zn.forEach(t),Mg=u(Ps),Ce=l(Ps,"TR",{class:!0});var Pn=r(Ce);Vl=l(Pn,"TD",{class:!0});var W3=r(Vl);Bg=n(W3,"Insufficient reg images"),W3.forEach(t),jg=u(Pn),Ql=l(Pn,"TD",{class:!0});var F3=r(Ql);Wg=n(F3,"Class leakage"),F3.forEach(t),Fg=u(Pn),Jl=l(Pn,"TD",{class:!0});var Y3=r(Jl);Yg=n(Y3,"Add 100-300 class images"),Y3.forEach(t),Pn.forEach(t),Xg=u(Ps),qe=l(Ps,"TR",{class:!0});var Nn=r(qe);$l=l(Nn,"TD",{class:!0});var X3=r($l);Zg=n(X3,"High variance in training data"),X3.forEach(t),Kg=u(Nn),er=l(Nn,"TD",{class:!0});var Z3=r(er);Vg=n(Z3,"Mode collapse"),Z3.forEach(t),Qg=u(Nn),tr=l(Nn,"TD",{class:!0});var K3=r(tr);Jg=n(K3,"Curate focused dataset"),K3.forEach(t),Nn.forEach(t),Ps.forEach(t),Gd.forEach(t),cf=u(s),Bt=l(s,"H3",{id:!0});var tx=r(Bt);jt=l(tx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var V3=r(jt);Bc=l(V3,"SPAN",{class:!0}),r(Bc).forEach(t),V3.forEach(t),$g=n(tx,"Monitoring Tips"),tx.forEach(t),uf=u(s),le=l(s,"UL",{});var ct=r(le);sr=l(ct,"LI",{});var sx=r(sr);em=n(sx,"Track loss curves with tools like "),$s=l(sx,"A",{href:!0,rel:!0});var Q3=r($s);tm=n(Q3,"TensorBoard"),Q3.forEach(t),sx.forEach(t),sm=u(ct),jc=l(ct,"LI",{});var J3=r(jc);am=n(J3,"Generate validation images every 100 steps"),J3.forEach(t),lm=u(ct),Wc=l(ct,"LI",{});var $3=r(Wc);rm=n($3,"Use gradient clipping (1.0-2.0 norm)"),$3.forEach(t),im=u(ct),Fc=l(ct,"LI",{});var e4=r(Fc);om=n(e4,"Enable mixed precision training"),e4.forEach(t),nm=u(ct),Yc=l(ct,"LI",{});var t4=r(Yc);cm=n(t4,"Start with conservative learning rates (1e-5 to 1e-6)"),t4.forEach(t),ct.forEach(t),ff=u(s),Wt=l(s,"H2",{id:!0});var ax=r(Wt);Ft=l(ax,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var s4=r(Ft);Xc=l(s4,"SPAN",{class:!0}),r(Xc).forEach(t),s4.forEach(t),um=n(ax,"Generating Regularization images"),ax.forEach(t),df=u(s),Yt=l(s,"P",{});var Hd=r(Yt);fm=n(Hd,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),ar=l(Hd,"CODE",{class:!0});var a4=r(ar);dm=n(a4,"1boy"),a4.forEach(t),pm=n(Hd,")."),Hd.forEach(t),pf=u(s),pe=l(s,"P",{});var Ns=r(pe);hm=n(Ns,"According to the Dreambooth technique, "),lr=l(Ns,"CODE",{class:!0});var l4=r(lr);gm=n(l4,"200"),l4.forEach(t),mm=n(Ns," regularization images per training image.  For example, if you have "),rr=l(Ns,"CODE",{class:!0});var r4=r(rr);vm=n(r4,"16"),r4.forEach(t),_m=n(Ns," images: "),ir=l(Ns,"CODE",{class:!0});var i4=r(ir);km=n(i4,"200 * 16 = 3200"),i4.forEach(t),bm=n(Ns," total regularization images.  When training, the math involved for calculating total steps is:"),Ns.forEach(t),hf=u(s),ea=l(s,"BLOCKQUOTE",{class:!0});var o4=r(ea);or=l(o4,"P",{class:!0});var n4=r(or);nr=l(n4,"CODE",{class:!0});var c4=r(nr);Em=n(c4,"repeats * training images >= repeats * regularization images"),c4.forEach(t),n4.forEach(t),o4.forEach(t),gf=u(s),cr=l(s,"P",{});var u4=r(cr);xm=n(u4,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),u4.forEach(t),mf=u(s),Xt=l(s,"H4",{id:!0});var lx=r(Xt);Zt=l(lx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var f4=r(Zt);Zc=l(f4,"SPAN",{class:!0}),r(Zc).forEach(t),f4.forEach(t),ym=n(lx,"Important considerations"),lx.forEach(t),vf=u(s),Ge=l(s,"OL",{});var Cn=r(Ge);Kc=l(Cn,"LI",{});var d4=r(Kc);ta=l(d4,"P",{});var Ud=r(ta);Vc=l(Ud,"STRONG",{});var p4=r(Vc);wm=n(p4,"Use the same base model for regularization images and training"),p4.forEach(t),Tm=l(Ud,"BR",{}),Rm=n(Ud,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Ud.forEach(t),d4.forEach(t),Dm=u(Cn),Qc=l(Cn,"LI",{});var h4=r(Qc);sa=l(h4,"P",{});var Md=r(sa);Jc=l(Md,"STRONG",{});var g4=r(Jc);Sm=n(g4,"Maintain consistent class representation"),g4.forEach(t),Am=l(Md,"BR",{}),Om=n(Md,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Md.forEach(t),h4.forEach(t),Lm=u(Cn),$c=l(Cn,"LI",{});var m4=r($c);aa=l(m4,"P",{});var Bd=r(aa);eu=l(Bd,"STRONG",{});var v4=r(eu);Im=n(v4,"Match output resolution to training data"),v4.forEach(t),zm=l(Bd,"BR",{}),Pm=n(Bd,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Bd.forEach(t),m4.forEach(t),Cn.forEach(t),_f=u(s),Ms(la.$$.fragment,s),kf=u(s),Kt=l(s,"H4",{id:!0});var rx=r(Kt);Vt=l(rx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _4=r(Vt);tu=l(_4,"SPAN",{class:!0}),r(tu).forEach(t),_4.forEach(t),Nm=n(rx,"Generate using Stable Diffusion web UI"),rx.forEach(t),bf=u(s),Qt=l(s,"P",{});var jd=r(Qt);Cm=n(jd,"We\u2019re going to use "),ra=l(jd,"A",{href:!0,rel:!0});var k4=r(ra);qm=n(k4,"Stable Diffusion web UI"),k4.forEach(t),Gm=n(jd," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),jd.forEach(t),Ef=u(s),He=l(s,"P",{});var qn=r(He);Hm=n(qn,"We\u2019re going to use the "),ur=l(qn,"CODE",{class:!0});var b4=r(ur);Um=n(b4,"X/Y/Z plot"),b4.forEach(t),Mm=n(qn," script to use "),fr=l(qn,"CODE",{class:!0});var E4=r(fr);Bm=n(E4,"Prompt Search & Replace"),E4.forEach(t),jm=n(qn," to dynamically build a prompt that will generate hundreds of regularization images."),qn.forEach(t),xf=u(s),J=l(s,"OL",{});var ne=r(J);su=l(ne,"LI",{});var x4=r(su);dr=l(x4,"P",{});var ix=r(dr);Wm=n(ix,"Select the text 2 image tab.  Enter a generic prompt "),pr=l(ix,"CODE",{class:!0});var y4=r(pr);Fm=n(y4,"princeadam, portrait, looking_at_viewer, forest"),y4.forEach(t),ix.forEach(t),x4.forEach(t),Ym=u(ne),au=l(ne,"LI",{});var w4=r(au);ia=l(w4,"P",{});var Wd=r(ia);Xm=n(Wd,"In generation parameters and select the "),hr=l(Wd,"CODE",{class:!0});var T4=r(hr);Zm=n(T4,"X/Y/Z plot"),T4.forEach(t),Km=n(Wd," script."),Wd.forEach(t),w4.forEach(t),Vm=u(ne),lu=l(ne,"LI",{});var R4=r(lu);Z=l(R4,"P",{});var te=r(Z);Qm=n(te,"Select the "),gr=l(te,"CODE",{class:!0});var D4=r(gr);Jm=n(D4,"X"),D4.forEach(t),$m=n(te," parameter and "),mr=l(te,"CODE",{class:!0});var S4=r(mr);ev=n(S4,"Prompt SR"),S4.forEach(t),tv=n(te," for Prompt Replace.  We\u2019re going to replace "),vr=l(te,"CODE",{class:!0});var A4=r(vr);sv=n(A4,"portrait"),A4.forEach(t),av=n(te," with different camera angle tags: "),_r=l(te,"CODE",{class:!0});var O4=r(_r);lv=n(O4,"close-up"),O4.forEach(t),rv=n(te,", "),kr=l(te,"CODE",{class:!0});var L4=r(kr);iv=n(L4,"upper_body"),L4.forEach(t),ov=n(te,", "),br=l(te,"CODE",{class:!0});var I4=r(br);nv=n(I4,"from_below"),I4.forEach(t),cv=n(te,", "),Er=l(te,"CODE",{class:!0});var z4=r(Er);uv=n(z4,"from_above"),z4.forEach(t),fv=n(te,", "),xr=l(te,"CODE",{class:!0});var P4=r(xr);dv=n(P4,"dutch_angle"),P4.forEach(t),te.forEach(t),R4.forEach(t),pv=u(ne),ru=l(ne,"LI",{});var N4=r(ru);$=l(N4,"P",{});var ae=r($);hv=n(ae,"Select the "),yr=l(ae,"CODE",{class:!0});var C4=r(yr);gv=n(C4,"Y"),C4.forEach(t),mv=n(ae," parameter and "),wr=l(ae,"CODE",{class:!0});var q4=r(wr);vv=n(q4,"Prompt SR"),q4.forEach(t),_v=n(ae," for Prompt Replace.  Replace "),Tr=l(ae,"CODE",{class:!0});var G4=r(Tr);kv=n(G4,"looking_at_viewer"),G4.forEach(t),bv=n(ae,": "),Rr=l(ae,"CODE",{class:!0});var H4=r(Rr);Ev=n(H4,"looking_away"),H4.forEach(t),xv=n(ae,", "),Dr=l(ae,"CODE",{class:!0});var U4=r(Dr);yv=n(U4,"looking_to_the_side"),U4.forEach(t),wv=n(ae,", "),Sr=l(ae,"CODE",{class:!0});var M4=r(Sr);Tv=n(M4,"looking_ahead"),M4.forEach(t),Rv=n(ae,", "),Ar=l(ae,"CODE",{class:!0});var B4=r(Ar);Dv=n(B4,"looking_down"),B4.forEach(t),ae.forEach(t),N4.forEach(t),Sv=u(ne),iu=l(ne,"LI",{});var j4=r(iu);K=l(j4,"P",{});var se=r(K);Av=n(se,"Select the "),Or=l(se,"CODE",{class:!0});var W4=r(Or);Ov=n(W4,"Z"),W4.forEach(t),Lv=n(se," parameter and "),Lr=l(se,"CODE",{class:!0});var F4=r(Lr);Iv=n(F4,"Prompt SR"),F4.forEach(t),zv=n(se," for Prompt Replace. Replace "),Ir=l(se,"CODE",{class:!0});var Y4=r(Ir);Pv=n(Y4,"forest"),Y4.forEach(t),Nv=n(se," with a vareity of locatinos: "),zr=l(se,"CODE",{class:!0});var X4=r(zr);Cv=n(X4,"castle"),X4.forEach(t),qv=n(se,", "),Pr=l(se,"CODE",{class:!0});var Z4=r(Pr);Gv=n(Z4,"mountain"),Z4.forEach(t),Hv=n(se,", "),Nr=l(se,"CODE",{class:!0});var K4=r(Nr);Uv=n(K4,"cave"),K4.forEach(t),Mv=n(se,", "),Cr=l(se,"CODE",{class:!0});var V4=r(Cr);Bv=n(V4,"farm"),V4.forEach(t),jv=n(se,", "),qr=l(se,"CODE",{class:!0});var Q4=r(qr);Wv=n(Q4,"ocean"),Q4.forEach(t),se.forEach(t),j4.forEach(t),Fv=u(ne),ou=l(ne,"LI",{});var J4=r(ou);Gr=l(J4,"P",{});var ox=r(Gr);Yv=n(ox,"Select a fast sampler like "),Hr=l(ox,"CODE",{class:!0});var $4=r(Hr);Xv=n($4,"DPM2 KARRAS"),$4.forEach(t),ox.forEach(t),J4.forEach(t),Zv=u(ne),nu=l(ne,"LI",{});var ew=r(nu);Jt=l(ew,"P",{});var Pu=r(Jt);Kv=n(Pu,"CFG Scale set to "),Ur=l(Pu,"CODE",{class:!0});var tw=r(Ur);Vv=n(tw,"7"),tw.forEach(t),Qv=n(Pu," and Steps to "),Mr=l(Pu,"CODE",{class:!0});var sw=r(Mr);Jv=n(sw,"20"),sw.forEach(t),Pu.forEach(t),ew.forEach(t),ne.forEach(t),yf=u(s),Ue=l(s,"P",{});var Gn=r(Ue);$v=n(Gn,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Br=l(Gn,"CODE",{class:!0});var aw=r(Br);e2=n(aw,"150"),aw.forEach(t),t2=n(Gn," - "),jr=l(Gn,"CODE",{class:!0});var lw=r(jr);s2=n(lw,"200"),lw.forEach(t),a2=n(Gn," and keep in mind we can add and remove as we try different training settings with different output."),Gn.forEach(t),wf=u(s),Ms(oa.$$.fragment,s),Tf=u(s),$t=l(s,"H4",{id:!0});var nx=r($t);es=l(nx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var rw=r(es);cu=l(rw,"SPAN",{class:!0}),r(cu).forEach(t),rw.forEach(t),l2=n(nx,"Download images"),nx.forEach(t),Rf=u(s),Wr=l(s,"P",{});var iw=r(Wr);r2=n(iw,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),iw.forEach(t),Df=u(s),he=l(s,"UL",{});var Cs=r(he);Fr=l(Cs,"LI",{});var cx=r(Fr);na=l(cx,"A",{href:!0,rel:!0});var ow=r(na);i2=n(ow,"3ee Games regularization images"),ow.forEach(t),o2=n(cx,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),cx.forEach(t),n2=u(Cs),Yr=l(Cs,"LI",{});var ux=r(Yr);ca=l(ux,"A",{href:!0,rel:!0});var nw=r(ca);c2=n(nw,"Pre-Rendered Regularization Images"),nw.forEach(t),u2=n(ux,": Includes 1500 regularization images."),ux.forEach(t),f2=u(Cs),Xr=l(Cs,"LI",{});var fx=r(Xr);ua=l(fx,"A",{href:!0,rel:!0});var cw=r(ua);d2=n(cw,"Stable Diffusion 1.5 Regularization Images"),cw.forEach(t),p2=n(fx,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),fx.forEach(t),h2=u(Cs),Zr=l(Cs,"LI",{});var dx=r(Zr);fa=l(dx,"A",{href:!0,rel:!0});var uw=r(fa);g2=n(uw,"Aitrepreneur SDXL image set"),uw.forEach(t),m2=n(dx,": a large image set generated with Stable Diffusion SDXL."),dx.forEach(t),Cs.forEach(t),Sf=u(s),ts=l(s,"H4",{id:!0});var px=r(ts);ss=l(px,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var fw=r(ss);uu=l(fw,"SPAN",{class:!0}),r(uu).forEach(t),fw.forEach(t),v2=n(px,"Captioning Regularization images"),px.forEach(t),Af=u(s),as=l(s,"P",{});var Fd=r(as);_2=n(Fd,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Kr=l(Fd,"CODE",{class:!0});var dw=r(Kr);k2=n(dw,"txt"),dw.forEach(t),b2=n(Fd," files with a shell script:"),Fd.forEach(t),Of=u(s),da=l(s,"PRE",{class:!0});var i6=r(da);i6.forEach(t),Lf=u(s),Me=l(s,"P",{});var Hn=r(Me);E2=n(Hn,"Save this file as "),Vr=l(Hn,"CODE",{class:!0});var pw=r(Vr);x2=n(pw,"filename2txt.bat"),pw.forEach(t),y2=n(Hn," and place it into the regularization images directory and run: "),Qr=l(Hn,"CODE",{class:!0});var hw=r(Qr);w2=n(hw,".\\filename2txt.bat"),hw.forEach(t),T2=n(Hn,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Hn.forEach(t),If=u(s),pa=l(s,"P",{});var hx=r(pa);R2=n(hx,"Example filename: "),Jr=l(hx,"CODE",{class:!0});var gw=r(Jr);D2=n(gw,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),gw.forEach(t),hx.forEach(t),zf=u(s),ls=l(s,"P",{});var Yd=r(ls);S2=n(Yd,"Output: "),$r=l(Yd,"CODE",{class:!0});var mw=r($r);A2=n(mw,"aburbres,princeadam,1boy,close-up,purple_vest"),mw.forEach(t),O2=n(Yd," saved in a text file with the same name as image."),Yd.forEach(t),Pf=u(s),rs=l(s,"H2",{id:!0});var gx=r(rs);is=l(gx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var vw=r(is);fu=l(vw,"SPAN",{class:!0}),r(fu).forEach(t),vw.forEach(t),L2=n(gx,"Training a LoRA"),gx.forEach(t),Nf=u(s),os=l(s,"P",{});var Xd=r(os);I2=n(Xd,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),ha=l(Xd,"A",{href:!0,rel:!0});var _w=r(ha);z2=n(_w,"kohya-ss/sd-scripts"),_w.forEach(t),P2=n(Xd,"."),Xd.forEach(t),Cf=u(s),ga=l(s,"BLOCKQUOTE",{class:!0});var kw=r(ga);ns=l(kw,"P",{class:!0});var Zd=r(ns);N2=n(Zd,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ma=l(Zd,"A",{href:!0,rel:!0});var bw=r(ma);C2=n(bw,"Kohya SD script documentation"),bw.forEach(t),q2=n(Zd,"."),Zd.forEach(t),kw.forEach(t),qf=u(s),cs=l(s,"H3",{id:!0});var mx=r(cs);us=l(mx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Ew=r(us);du=l(Ew,"SPAN",{class:!0}),r(du).forEach(t),Ew.forEach(t),G2=n(mx,"Directory setup"),mx.forEach(t),Gf=u(s),fs=l(s,"P",{});var Kd=r(fs);H2=n(Kd,"In your configuration json, use "),ei=l(Kd,"CODE",{class:!0});var xw=r(ei);U2=n(xw,"reg_data_dir"),xw.forEach(t),M2=n(Kd," to point to the directory with your regularization images:"),Kd.forEach(t),Hf=u(s),va=l(s,"PRE",{class:!0});var o6=r(va);o6.forEach(t),Uf=u(s),ti=l(s,"P",{});var yw=r(ti);B2=n(yw,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),yw.forEach(t),Mf=u(s),_a=l(s,"PRE",{class:!0});var n6=r(_a);n6.forEach(t),Bf=u(s),Be=l(s,"P",{});var Un=r(Be);j2=n(Un,"Set the "),si=l(Un,"CODE",{class:!0});var ww=r(si);W2=n(ww,"number of iterations"),ww.forEach(t),F2=n(Un," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),ai=l(Un,"CODE",{class:!0});var Tw=r(ai);Y2=n(Tw,"training images \xD7 iterations"),Tw.forEach(t),X2=n(Un,". If there are more regularization images than this, the extras won\u2019t be used."),Un.forEach(t),jf=u(s),je=l(s,"P",{});var Mn=r(je);Z2=n(Mn,"Create folders in the training image folder with the format "),li=l(Mn,"CODE",{class:!0});var Rw=r(li);K2=n(Rw,"<repetition count>_<class>"),Rw.forEach(t),V2=n(Mn," multiple times, and similarly create folders in the regularization image folder with the format "),ri=l(Mn,"CODE",{class:!0});var Dw=r(ri);Q2=n(Dw,"<repetition count>_<class>"),Dw.forEach(t),J2=n(Mn,"."),Mn.forEach(t),Wf=u(s),ii=l(s,"P",{});var Sw=r(ii);$2=n(Sw,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Sw.forEach(t),Ff=u(s),ds=l(s,"UL",{});var Vd=r(ds);oi=l(Vd,"LI",{});var vx=r(oi);e_=n(vx,"train_data_dir"),pu=l(vx,"UL",{});var Aw=r(pu);hu=l(Aw,"LI",{});var Ow=r(hu);t_=n(Ow,"10_princeadam"),Ow.forEach(t),Aw.forEach(t),vx.forEach(t),s_=u(Vd),ni=l(Vd,"LI",{});var _x=r(ni);a_=n(_x,"reg_dir"),gu=l(_x,"UL",{});var Lw=r(gu);mu=l(Lw,"LI",{});var Iw=r(mu);l_=n(Iw,"1_1boy"),Iw.forEach(t),Lw.forEach(t),_x.forEach(t),Vd.forEach(t),Yf=u(s),ci=l(s,"P",{});var zw=r(ci);r_=n(zw,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),zw.forEach(t),Xf=u(s),ka=l(s,"P",{class:!0});var Pw=r(ka);ba=l(Pw,"IMG",{src:!0,alt:!0,class:!0}),Pw.forEach(t),Zf=u(s),ps=l(s,"H3",{id:!0});var kx=r(ps);hs=l(kx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Nw=r(hs);vu=l(Nw,"SPAN",{class:!0}),r(vu).forEach(t),Nw.forEach(t),i_=n(kx,"Training Settings"),kx.forEach(t),Kf=u(s),_t=l(s,"P",{});var Nu=r(_t);o_=n(Nu,"The training setup we\u2019re going to use is:  "),ui=l(Nu,"CODE",{class:!0});var Cw=r(ui);n_=n(Cw,"Number of images * repeats * epoch / batch size = total steps"),Cw.forEach(t),c_=n(Nu,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),fi=l(Nu,"CODE",{class:!0});var qw=r(fi);u_=n(qw,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),qw.forEach(t),Nu.forEach(t),Vf=u(s),kt=l(s,"TABLE",{class:!0});var Qd=r(kt);di=l(Qd,"THEAD",{class:!0});var Gw=r(di);re=l(Gw,"TR",{class:!0});var ut=r(re);pi=l(ut,"TH",{class:!0});var Hw=r(pi);f_=n(Hw,"Number of Images"),Hw.forEach(t),d_=u(ut),hi=l(ut,"TH",{class:!0});var Uw=r(hi);p_=n(Uw,"Repeats"),Uw.forEach(t),h_=u(ut),gi=l(ut,"TH",{class:!0});var Mw=r(gi);g_=n(Mw,"Epochs"),Mw.forEach(t),m_=u(ut),mi=l(ut,"TH",{class:!0});var Bw=r(mi);v_=n(Bw,"Batch Size"),Bw.forEach(t),__=u(ut),vi=l(ut,"TH",{class:!0});var jw=r(vi);k_=n(jw,"Total Steps"),jw.forEach(t),ut.forEach(t),Gw.forEach(t),b_=u(Qd),_i=l(Qd,"TBODY",{class:!0});var Ww=r(_i);ie=l(Ww,"TR",{class:!0});var ft=r(ie);ki=l(ft,"TD",{class:!0});var Fw=r(ki);E_=n(Fw,"45"),Fw.forEach(t),x_=u(ft),bi=l(ft,"TD",{class:!0});var Yw=r(bi);y_=n(Yw,"10"),Yw.forEach(t),w_=u(ft),Ei=l(ft,"TD",{class:!0});var Xw=r(Ei);T_=n(Xw,"20"),Xw.forEach(t),R_=u(ft),xi=l(ft,"TD",{class:!0});var Zw=r(xi);D_=n(Zw,"2"),Zw.forEach(t),S_=u(ft),yi=l(ft,"TD",{class:!0});var Kw=r(yi);A_=n(Kw,"4500"),Kw.forEach(t),ft.forEach(t),Ww.forEach(t),Qd.forEach(t),Qf=u(s),wi=l(s,"P",{});var Vw=r(wi);O_=n(Vw,"Now let\u2019s focus on these training settings:"),Vw.forEach(t),Jf=u(s),Ea=l(s,"PRE",{class:!0});var c6=r(Ea);c6.forEach(t),$f=u(s),M=l(s,"UL",{});var Y=r(M);Ti=l(Y,"LI",{});var bx=r(Ti);xa=l(bx,"STRONG",{});var Jd=r(xa);L_=n(Jd,"Learning Rate ("),Ri=l(Jd,"CODE",{class:!0});var Qw=r(Ri);I_=n(Qw,"learning_rate"),Qw.forEach(t),z_=n(Jd,")"),Jd.forEach(t),P_=n(bx,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),bx.forEach(t),N_=u(Y),Di=l(Y,"LI",{});var Ex=r(Di);ya=l(Ex,"STRONG",{});var $d=r(ya);C_=n($d,"Text Encoder Learning Rate ("),Si=l($d,"CODE",{class:!0});var Jw=r(Si);q_=n(Jw,"text_encoder_lr"),Jw.forEach(t),G_=n($d,")"),$d.forEach(t),H_=n(Ex,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Ex.forEach(t),U_=u(Y),Ai=l(Y,"LI",{});var xx=r(Ai);wa=l(xx,"STRONG",{});var ep=r(wa);M_=n(ep,"UNet Learning Rate ("),Oi=l(ep,"CODE",{class:!0});var $w=r(Oi);B_=n($w,"unet_lr"),$w.forEach(t),j_=n(ep,")"),ep.forEach(t),W_=n(xx,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),xx.forEach(t),F_=u(Y),Li=l(Y,"LI",{});var yx=r(Li);Ta=l(yx,"STRONG",{});var tp=r(Ta);Y_=n(tp,"Learning Rate Scheduler ("),Ii=l(tp,"CODE",{class:!0});var e5=r(Ii);X_=n(e5,"lr_scheduler"),e5.forEach(t),Z_=n(tp,")"),tp.forEach(t),K_=n(yx,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),yx.forEach(t),V_=u(Y),zi=l(Y,"LI",{});var wx=r(zi);Ra=l(wx,"STRONG",{});var sp=r(Ra);Q_=n(sp,"Number of Cycles in Learning Rate Scheduler ("),Pi=l(sp,"CODE",{class:!0});var t5=r(Pi);J_=n(t5,"lr_scheduler_num_cycles"),t5.forEach(t),$_=n(sp,")"),sp.forEach(t),e1=n(wx,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),wx.forEach(t),t1=u(Y),Ni=l(Y,"LI",{});var Tx=r(Ni);Da=l(Tx,"STRONG",{});var ap=r(Da);s1=n(ap,"Network Dimension ("),Ci=l(ap,"CODE",{class:!0});var s5=r(Ci);a1=n(s5,"network_dim"),s5.forEach(t),l1=n(ap,")"),ap.forEach(t),r1=n(Tx,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Tx.forEach(t),i1=u(Y),qi=l(Y,"LI",{});var Rx=r(qi);Sa=l(Rx,"STRONG",{});var lp=r(Sa);o1=n(lp,"Network Alpha ("),Gi=l(lp,"CODE",{class:!0});var a5=r(Gi);n1=n(a5,"network_alpha"),a5.forEach(t),c1=n(lp,")"),lp.forEach(t),u1=n(Rx,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Rx.forEach(t),f1=u(Y),Hi=l(Y,"LI",{});var Dx=r(Hi);Aa=l(Dx,"STRONG",{});var rp=r(Aa);d1=n(rp,"Clip Skip ("),Ui=l(rp,"CODE",{class:!0});var l5=r(Ui);p1=n(l5,"clip_skip"),l5.forEach(t),h1=n(rp,")"),rp.forEach(t),g1=n(Dx,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Dx.forEach(t),m1=u(Y),Mi=l(Y,"LI",{});var Sx=r(Mi);Oa=l(Sx,"STRONG",{});var ip=r(Oa);v1=n(ip,"Max Token Length ("),Bi=l(ip,"CODE",{class:!0});var r5=r(Bi);_1=n(r5,"max_token_length"),r5.forEach(t),k1=n(ip,")"),ip.forEach(t),b1=n(Sx,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Sx.forEach(t),E1=u(Y),ji=l(Y,"LI",{});var Ax=r(ji);La=l(Ax,"STRONG",{});var op=r(La);x1=n(op,"Noise Offset ("),Wi=l(op,"CODE",{class:!0});var i5=r(Wi);y1=n(i5,"noise_offset"),i5.forEach(t),w1=n(op,")"),op.forEach(t),T1=n(Ax,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Ax.forEach(t),R1=u(Y),Fi=l(Y,"LI",{});var Ox=r(Fi);Ia=l(Ox,"STRONG",{});var np=r(Ia);D1=n(np,"Regularization Data Directory ("),Yi=l(np,"CODE",{class:!0});var o5=r(Yi);S1=n(o5,"reg_data_dir"),o5.forEach(t),A1=n(np,")"),np.forEach(t),O1=n(Ox,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Ox.forEach(t),Y.forEach(t),ed=u(s),gs=l(s,"H3",{id:!0});var Lx=r(gs);ms=l(Lx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var n5=r(ms);_u=l(n5,"SPAN",{class:!0}),r(_u).forEach(t),n5.forEach(t),L1=n(Lx,"Fine Tuning"),Lx.forEach(t),td=u(s),Xi=l(s,"P",{});var c5=r(Xi);I1=n(c5,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),c5.forEach(t),sd=u(s),Ms(za.$$.fragment,s),ad=u(s),vs=l(s,"H4",{id:!0});var Ix=r(vs);_s=l(Ix,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var u5=r(_s);ku=l(u5,"SPAN",{class:!0}),r(ku).forEach(t),u5.forEach(t),z1=n(Ix,"Workflow with Auto1111 WebUI"),Ix.forEach(t),ld=u(s),ks=l(s,"P",{});var cp=r(ks);P1=n(cp,"We\u2019re going to use "),Pa=l(cp,"A",{href:!0,rel:!0});var f5=r(Pa);N1=n(f5,"Stable Diffusion web UI"),f5.forEach(t),C1=n(cp," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),cp.forEach(t),rd=u(s),bs=l(s,"P",{});var up=r(bs);q1=n(up,"We\u2019re going to use the "),Zi=l(up,"CODE",{class:!0});var d5=r(Zi);G1=n(d5,"X/Y/Z plot"),d5.forEach(t),H1=n(up," script to compare different epochs."),up.forEach(t),id=u(s),oe=l(s,"UL",{});var dt=r(oe);Ki=l(dt,"LI",{});var zx=r(Ki);U1=n(zx,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),od=l(zx,"PRINCEADAM0001:0.7",{}),r(od).forEach(t),zx.forEach(t),M1=u(dt),bu=l(dt,"LI",{});var p5=r(bu);B1=n(p5,"In generation parameters and select the X/Y/Z plot script."),p5.forEach(t),j1=u(dt),We=l(dt,"LI",{});var Ba=r(We);W1=n(Ba,"Select "),Vi=l(Ba,"CODE",{class:!0});var h5=r(Vi);F1=n(h5,"Prompt SR"),h5.forEach(t),Y1=n(Ba," for Prompt Replace.  We\u2019re going to replace "),Qi=l(Ba,"CODE",{class:!0});var g5=r(Qi);X1=n(g5,"<princeadam0001:0.7>"),g5.forEach(t),Z1=n(Ba," with different epoch: "),Ji=l(Ba,"CODE",{class:!0});var m5=r(Ji);K1=n(m5,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),m5.forEach(t),Ba.forEach(t),V1=u(dt),$i=l(dt,"LI",{});var Px=r($i);Q1=n(Px,"Select a fast sampler like "),eo=l(Px,"CODE",{class:!0});var v5=r(eo);J1=n(v5,"DPM2 KARRAS"),v5.forEach(t),Px.forEach(t),$1=u(dt),Es=l(dt,"LI",{});var Cu=r(Es);ek=n(Cu,"CFG Scale set to "),to=l(Cu,"CODE",{class:!0});var _5=r(to);tk=n(_5,"7"),_5.forEach(t),sk=n(Cu," and Steps to "),so=l(Cu,"CODE",{class:!0});var k5=r(so);ak=n(k5,"20"),k5.forEach(t),Cu.forEach(t),dt.forEach(t),nd=u(s),Fe=l(s,"P",{});var Bn=r(Fe);lk=n(Bn,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),ao=l(Bn,"CODE",{class:!0});var b5=r(ao);rk=n(b5,"network_dim"),b5.forEach(t),ik=n(Bn," and "),lo=l(Bn,"CODE",{class:!0});var E5=r(lo);ok=n(E5,"network_alpha"),E5.forEach(t),nk=n(Bn,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Bn.forEach(t),cd=u(s),ge=l(s,"UL",{});var qs=r(ge);xs=l(qs,"LI",{});var qu=r(xs);ck=n(qu,"Select "),ro=l(qu,"CODE",{class:!0});var x5=r(ro);uk=n(x5,"Prompt SR"),x5.forEach(t),fk=n(qu," for Prompt Replace.  We\u2019re going to replace the weights "),io=l(qu,"CODE",{class:!0});var y5=r(io);dk=n(y5,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),y5.forEach(t),qu.forEach(t),pk=u(qs),Na=l(qs,"LI",{});var fp=r(Na);hk=n(fp,"Use Prompt SR to generate a variety of angles: Select "),oo=l(fp,"CODE",{class:!0});var w5=r(oo);gk=n(w5,"Prompt SR"),w5.forEach(t),mk=n(fp," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),fp.forEach(t),vk=u(qs),Eu=l(qs,"LI",{});var T5=r(Eu);_k=n(T5,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),T5.forEach(t),kk=u(qs),xu=l(qs,"LI",{});var R5=r(xu);bk=n(R5,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),R5.forEach(t),qs.forEach(t),ud=u(s),ys=l(s,"H4",{id:!0});var Nx=r(ys);ws=l(Nx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var D5=r(ws);yu=l(D5,"SPAN",{class:!0}),r(yu).forEach(t),D5.forEach(t),Ek=n(Nx,"Issues to look for"),Nx.forEach(t),fd=u(s),me=l(s,"UL",{});var Gs=r(me);no=l(Gs,"LI",{});var Cx=r(no);wu=l(Cx,"STRONG",{});var S5=r(wu);xk=n(S5,"Undercooked:"),S5.forEach(t),yk=n(Cx," Lacks output, adjust unet learning rate or extend training duration."),Cx.forEach(t),wk=u(Gs),co=l(Gs,"LI",{});var qx=r(co);Tu=l(qx,"STRONG",{});var A5=r(Tu);Tk=n(A5,"Overcooked:"),A5.forEach(t),Rk=n(qx," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),qx.forEach(t),Dk=u(Gs),uo=l(Gs,"LI",{});var Gx=r(uo);Ru=l(Gx,"STRONG",{});var O5=r(Ru);Sk=n(O5,"Overfit:"),O5.forEach(t),Ak=n(Gx," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),Gx.forEach(t),Ok=u(Gs),fo=l(Gs,"LI",{});var Hx=r(fo);Du=l(Hx,"STRONG",{});var L5=r(Du);Lk=n(L5,"Mismatched:"),L5.forEach(t),Ik=n(Hx," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Hx.forEach(t),Gs.forEach(t),dd=u(s),po=l(s,"P",{});var I5=r(po);zk=n(I5,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),I5.forEach(t),pd=u(s),Ca=l(s,"P",{class:!0});var z5=r(Ca);qa=l(z5,"IMG",{src:!0,alt:!0,class:!0}),z5.forEach(t),hd=u(s),Ts=l(s,"H2",{id:!0});var Ux=r(Ts);Rs=l(Ux,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var P5=r(Rs);Su=l(P5,"SPAN",{class:!0}),r(Su).forEach(t),P5.forEach(t),Pk=n(Ux,"Troubleshooting"),Ux.forEach(t),gd=u(s),ho=l(s,"P",{});var N5=r(ho);Nk=n(N5,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),N5.forEach(t),md=u(s),Ye=l(s,"UL",{});var jn=r(Ye);Ga=l(jn,"LI",{});var dp=r(Ga);Ck=n(dp,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),go=l(dp,"CODE",{class:!0});var C5=r(go);qk=n(C5,"200"),C5.forEach(t),Gk=n(dp," regularization images per training image."),dp.forEach(t),Hk=u(jn),Ha=l(jn,"LI",{});var pp=r(Ha);Uk=n(pp,"Repeats of regularization images, but may overfit more.  Increasing the "),mo=l(pp,"CODE",{class:!0});var q5=r(mo);Mk=n(q5,"repetition_count"),q5.forEach(t),Bk=n(pp," will cycle through the images more but the results may have results that overfit the model."),pp.forEach(t),jk=u(jn),Au=l(jn,"LI",{});var G5=r(Au);Wk=n(G5,"Create more regularization images without increasing repeats will help with the overfitting."),G5.forEach(t),jn.forEach(t),vd=u(s),bt=l(s,"TABLE",{class:!0});var hp=r(bt);vo=l(hp,"THEAD",{class:!0});var H5=r(vo);Xe=l(H5,"TR",{class:!0});var Wn=r(Xe);_o=l(Wn,"TH",{class:!0});var U5=r(_o);Fk=n(U5,"Issue"),U5.forEach(t),Yk=u(Wn),ko=l(Wn,"TH",{class:!0});var M5=r(ko);Xk=n(M5,"Situation"),M5.forEach(t),Zk=u(Wn),bo=l(Wn,"TH",{class:!0});var B5=r(bo);Kk=n(B5,"Recommendation"),B5.forEach(t),Wn.forEach(t),H5.forEach(t),Vk=u(hp),ve=l(hp,"TBODY",{class:!0});var Hs=r(ve);Ze=l(Hs,"TR",{class:!0});var Fn=r(Ze);Eo=l(Fn,"TD",{class:!0});var j5=r(Eo);Qk=n(j5,"Varying quality"),j5.forEach(t),Jk=u(Fn),xo=l(Fn,"TD",{class:!0});var W5=r(xo);$k=n(W5,"Results differ from expectations"),W5.forEach(t),eb=u(Fn),yo=l(Fn,"TD",{class:!0});var F5=r(yo);tb=n(F5,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),F5.forEach(t),Fn.forEach(t),sb=u(Hs),Ke=l(Hs,"TR",{class:!0});var Yn=r(Ke);wo=l(Yn,"TD",{class:!0});var Y5=r(wo);ab=n(Y5,"Inadequate regularization for input data"),Y5.forEach(t),lb=u(Yn),To=l(Yn,"TD",{class:!0});var X5=r(To);rb=n(X5,"Lower input images, less regularization needed"),X5.forEach(t),ib=u(Yn),Ro=l(Yn,"TD",{class:!0});var Z5=r(Ro);ob=n(Z5,"Reduce the number of input images or increasing the quantity of reg images."),Z5.forEach(t),Yn.forEach(t),nb=u(Hs),Ve=l(Hs,"TR",{class:!0});var Xn=r(Ve);Do=l(Xn,"TD",{class:!0});var K5=r(Do);cb=n(K5,"Overfitting due to repetition"),K5.forEach(t),ub=u(Xn),So=l(Xn,"TD",{class:!0});var V5=r(So);fb=n(V5,"Repeats of reg images, risk of overfitting"),V5.forEach(t),db=u(Xn),Ao=l(Xn,"TD",{class:!0});var Q5=r(Ao);pb=n(Q5,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),Q5.forEach(t),Xn.forEach(t),hb=u(Hs),Qe=l(Hs,"TR",{class:!0});var Zn=r(Qe);Oo=l(Zn,"TD",{class:!0});var J5=r(Oo);gb=n(J5,"Mitigate overfitting while increasing diversity"),J5.forEach(t),mb=u(Zn),Lo=l(Zn,"TD",{class:!0});var $5=r(Lo);vb=n($5,"Create more reg images without repeats"),$5.forEach(t),_b=u(Zn),Io=l(Zn,"TD",{class:!0});var e0=r(Io);kb=n(e0,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),e0.forEach(t),Zn.forEach(t),Hs.forEach(t),hp.forEach(t),_d=u(s),Ds=l(s,"H4",{id:!0});var Mx=r(Ds);Ss=l(Mx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var t0=r(Ss);Ou=l(t0,"SPAN",{class:!0}),r(Ou).forEach(t),t0.forEach(t),bb=n(Mx,"More Solutions"),Mx.forEach(t),kd=u(s),zo=l(s,"P",{});var s0=r(zo);Eb=n(s0,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),s0.forEach(t),bd=u(s),Et=l(s,"TABLE",{class:!0});var gp=r(Et);Po=l(gp,"THEAD",{class:!0});var a0=r(Po);Je=l(a0,"TR",{class:!0});var Kn=r(Je);No=l(Kn,"TH",{class:!0});var l0=r(No);xb=n(l0,"Symptom"),l0.forEach(t),yb=u(Kn),Co=l(Kn,"TH",{class:!0});var r0=r(Co);wb=n(r0,"Likely Cause"),r0.forEach(t),Tb=u(Kn),qo=l(Kn,"TH",{class:!0});var i0=r(qo);Rb=n(i0,"Solution"),i0.forEach(t),Kn.forEach(t),a0.forEach(t),Db=u(gp),j=l(gp,"TBODY",{class:!0});var V=r(j);$e=l(V,"TR",{class:!0});var Vn=r($e);Go=l(Vn,"TD",{class:!0});var o0=r(Go);Sb=n(o0,"Plastic texture persists"),o0.forEach(t),Ab=u(Vn),Ho=l(Vn,"TD",{class:!0});var n0=r(Ho);Ob=n(n0,"Insufficient human reg images"),n0.forEach(t),Lb=u(Vn),Uo=l(Vn,"TD",{class:!0});var c0=r(Uo);Ib=n(c0,"Add real photos to reg set"),c0.forEach(t),Vn.forEach(t),zb=u(V),et=l(V,"TR",{class:!0});var Qn=r(et);Mo=l(Qn,"TD",{class:!0});var u0=r(Mo);Pb=n(u0,"Loss plateaus early"),u0.forEach(t),Nb=u(Qn),Bo=l(Qn,"TD",{class:!0});var f0=r(Bo);Cb=n(f0,"Learning rate too low"),f0.forEach(t),qb=u(Qn),jo=l(Qn,"TD",{class:!0});var d0=r(jo);Gb=n(d0,"Increase LR by 10x"),d0.forEach(t),Qn.forEach(t),Hb=u(V),tt=l(V,"TR",{class:!0});var Jn=r(tt);Wo=l(Jn,"TD",{class:!0});var p0=r(Wo);Ub=n(p0,"Features blurry"),p0.forEach(t),Mb=u(Jn),Fo=l(Jn,"TD",{class:!0});var h0=r(Fo);Bb=n(h0,"Network dimension too small"),h0.forEach(t),jb=u(Jn),Yo=l(Jn,"TD",{class:!0});var g0=r(Yo);Wb=n(g0,"Increase network_dim to 64+"),g0.forEach(t),Jn.forEach(t),Fb=u(V),st=l(V,"TR",{class:!0});var $n=r(st);Xo=l($n,"TD",{class:!0});var m0=r(Xo);Yb=n(m0,"Color distortion"),m0.forEach(t),Xb=u($n),Zo=l($n,"TD",{class:!0});var v0=r(Zo);Zb=n(v0,"Noise offset conflict"),v0.forEach(t),Kb=u($n),Ko=l($n,"TD",{class:!0});var _0=r(Ko);Vb=n(_0,"Try noise_offset 0.05-0.1"),_0.forEach(t),$n.forEach(t),Qb=u(V),at=l(V,"TR",{class:!0});var ec=r(at);Vo=l(ec,"TD",{class:!0});var k0=r(Vo);Jb=n(k0,"Overly stylized outputs"),k0.forEach(t),$b=u(ec),Qo=l(ec,"TD",{class:!0});var b0=r(Qo);eE=n(b0,"Reg image style mismatch"),b0.forEach(t),tE=u(ec),Jo=l(ec,"TD",{class:!0});var E0=r(Jo);sE=n(E0,"Regenerate reg images with base model"),E0.forEach(t),ec.forEach(t),aE=u(V),lt=l(V,"TR",{class:!0});var tc=r(lt);$o=l(tc,"TD",{class:!0});var x0=r($o);lE=n(x0,"Training instability"),x0.forEach(t),rE=u(tc),en=l(tc,"TD",{class:!0});var y0=r(en);iE=n(y0,"Batch size too large"),y0.forEach(t),oE=u(tc),tn=l(tc,"TD",{class:!0});var w0=r(tn);nE=n(w0,"Reduce batch_size to 1-2"),w0.forEach(t),tc.forEach(t),cE=u(V),rt=l(V,"TR",{class:!0});var sc=r(rt);sn=l(sc,"TD",{class:!0});var T0=r(sn);uE=n(T0,"Slow convergence"),T0.forEach(t),fE=u(sc),an=l(sc,"TD",{class:!0});var R0=r(an);dE=n(R0,"Network_alpha too high"),R0.forEach(t),pE=u(sc),ln=l(sc,"TD",{class:!0});var D0=r(ln);hE=n(D0,"Set alpha = dim/2 (e.g., 64/2 = 32)"),D0.forEach(t),sc.forEach(t),gE=u(V),it=l(V,"TR",{class:!0});var ac=r(it);rn=l(ac,"TD",{class:!0});var S0=r(rn);mE=n(S0,"Loss divergence"),S0.forEach(t),vE=u(ac),on=l(ac,"TD",{class:!0});var A0=r(on);_E=n(A0,"Text encoder LR too high"),A0.forEach(t),kE=u(ac),nn=l(ac,"TD",{class:!0});var O0=r(nn);bE=n(O0,"Reduce text_encoder_lr by 10x"),O0.forEach(t),ac.forEach(t),EE=u(V),ot=l(V,"TR",{class:!0});var lc=r(ot);cn=l(lc,"TD",{class:!0});var L0=r(cn);xE=n(L0,"Poor prompt adherence"),L0.forEach(t),yE=u(lc),un=l(lc,"TD",{class:!0});var I0=r(un);wE=n(I0,"Clip skip too high"),I0.forEach(t),TE=u(lc),fn=l(lc,"TD",{class:!0});var z0=r(fn);RE=n(z0,"Reduce clip_skip to 1-2"),z0.forEach(t),lc.forEach(t),DE=u(V),nt=l(V,"TR",{class:!0});var rc=r(nt);dn=l(rc,"TD",{class:!0});var P0=r(dn);SE=n(P0,"Memory errors"),P0.forEach(t),AE=u(rc),pn=l(rc,"TD",{class:!0});var N0=r(pn);OE=n(N0,"Resolution too high"),N0.forEach(t),LE=u(rc),hn=l(rc,"TD",{class:!0});var C0=r(hn);IE=n(C0,"Reduce to 512-768px, enable gradient checkpointing"),C0.forEach(t),rc.forEach(t),V.forEach(t),gp.forEach(t),Ed=u(s),As=l(s,"H2",{id:!0});var Bx=r(As);Os=l(Bx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var q0=r(Os);Lu=l(q0,"SPAN",{class:!0}),r(Lu).forEach(t),q0.forEach(t),zE=n(Bx,"Results"),Bx.forEach(t),xd=u(s),gn=l(s,"P",{});var G0=r(gn);PE=n(G0,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),G0.forEach(t),yd=u(s),mn=l(s,"P",{});var H0=r(mn);NE=n(H0,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),H0.forEach(t),wd=u(s),Ua=l(s,"P",{class:!0});var U0=r(Ua);Ma=l(U0,"IMG",{src:!0,alt:!0,class:!0}),U0.forEach(t),Td=u(s),vn=l(s,"P",{});var M0=r(vn);CE=n(M0,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),M0.forEach(t),Rd=u(s),xt=l(s,"H2",{id:!0,class:!0});var jx=r(xt);Ls=l(jx,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var B0=r(Ls);Iu=l(B0,"SPAN",{class:!0}),r(Iu).forEach(t),B0.forEach(t),qE=n(jx,"spacelab"),jx.forEach(t),Dd=u(s),ke&&ke.l(s),Sd=ic(),this.h()},h(){i(T,"class","icon icon-link"),i(E,"aria-hidden","true"),i(E,"tabindex","-1"),i(E,"href","#what-are-regularization-images"),i(k,"id","what-are-regularization-images"),i(z,"class","svelte-x2kgxs"),i(O,"class","svelte-x2kgxs"),i(G,"class","svelte-x2kgxs"),i(_e,"class","svelte-x2kgxs"),i(Ya,"class","svelte-x2kgxs"),i(w,"class","svelte-x2kgxs"),i(U,"class","svelte-x2kgxs"),i(Xa,"class","svelte-x2kgxs"),i(Za,"class","svelte-x2kgxs"),i(Ka,"class","svelte-x2kgxs"),i(xe,"class","svelte-x2kgxs"),i(Va,"class","svelte-x2kgxs"),i(Qa,"class","svelte-x2kgxs"),i(Ja,"class","svelte-x2kgxs"),i(ye,"class","svelte-x2kgxs"),i($a,"class","svelte-x2kgxs"),i(el,"class","svelte-x2kgxs"),i(tl,"class","svelte-x2kgxs"),i(we,"class","svelte-x2kgxs"),i(Ee,"class","svelte-x2kgxs"),i(X,"class","svelte-x2kgxs"),i(ll,"class","svelte-x2kgxs"),i(Fs,"class","svelte-x2kgxs"),i(hc,"class","icon icon-link"),i(Tt,"aria-hidden","true"),i(Tt,"tabindex","-1"),i(Tt,"href","#divergence"),i(wt,"id","divergence"),i(ol,"class","svelte-x2kgxs"),i(Ec,"class","icon icon-link"),i(St,"aria-hidden","true"),i(St,"tabindex","-1"),i(St,"href","#overfitting"),i(Dt,"id","overfitting"),i(Rc,"class","icon icon-link"),i(Ot,"aria-hidden","true"),i(Ot,"tabindex","-1"),i(Ot,"href","#key-differences"),i(At,"id","key-differences"),i(pl,"class","svelte-x2kgxs"),i(hl,"class","svelte-x2kgxs"),i(gl,"class","svelte-x2kgxs"),i(Se,"class","svelte-x2kgxs"),i(dl,"class","svelte-x2kgxs"),i(ml,"class","svelte-x2kgxs"),i(vl,"class","svelte-x2kgxs"),i(_l,"class","svelte-x2kgxs"),i(Ae,"class","svelte-x2kgxs"),i(kl,"class","svelte-x2kgxs"),i(bl,"class","svelte-x2kgxs"),i(El,"class","svelte-x2kgxs"),i(Oe,"class","svelte-x2kgxs"),i(xl,"class","svelte-x2kgxs"),i(yl,"class","svelte-x2kgxs"),i(wl,"class","svelte-x2kgxs"),i(Le,"class","svelte-x2kgxs"),i(Tl,"class","svelte-x2kgxs"),i(Rl,"class","svelte-x2kgxs"),i(Dl,"class","svelte-x2kgxs"),i(Ie,"class","svelte-x2kgxs"),i(ue,"class","svelte-x2kgxs"),i(gt,"class","svelte-x2kgxs"),i(Nc,"class","icon icon-link"),i(It,"aria-hidden","true"),i(It,"tabindex","-1"),i(It,"href","#preventing-divergence"),i(Lt,"id","preventing-divergence"),i(Al,"class","svelte-x2kgxs"),i(Ol,"class","svelte-x2kgxs"),i(zt,"class","svelte-x2kgxs"),i(Sl,"class","svelte-x2kgxs"),i(Ll,"class","svelte-x2kgxs"),i(Il,"class","svelte-x2kgxs"),i(Pt,"class","svelte-x2kgxs"),i(zl,"class","svelte-x2kgxs"),i(Pl,"class","svelte-x2kgxs"),i(Nt,"class","svelte-x2kgxs"),i(Nl,"class","svelte-x2kgxs"),i(Cl,"class","svelte-x2kgxs"),i(Ct,"class","svelte-x2kgxs"),i(ql,"class","svelte-x2kgxs"),i(Gl,"class","svelte-x2kgxs"),i(qt,"class","svelte-x2kgxs"),i(fe,"class","svelte-x2kgxs"),i(mt,"class","svelte-x2kgxs"),i(Uc,"class","icon icon-link"),i(Ht,"aria-hidden","true"),i(Ht,"tabindex","-1"),i(Ht,"href","#implementing-these-strategies"),i(Gt,"id","implementing-these-strategies"),i(Qs,"class","language-python"),i(Js,"class","language-python"),i(Mc,"class","icon icon-link"),i(Mt,"aria-hidden","true"),i(Mt,"tabindex","-1"),i(Mt,"href","#data-considerations"),i(Ut,"id","data-considerations"),i(Ml,"class","svelte-x2kgxs"),i(Bl,"class","svelte-x2kgxs"),i(jl,"class","svelte-x2kgxs"),i(ze,"class","svelte-x2kgxs"),i(Ul,"class","svelte-x2kgxs"),i(Wl,"class","svelte-x2kgxs"),i(Fl,"class","svelte-x2kgxs"),i(Yl,"class","svelte-x2kgxs"),i(Pe,"class","svelte-x2kgxs"),i(Xl,"class","svelte-x2kgxs"),i(Zl,"class","svelte-x2kgxs"),i(Kl,"class","svelte-x2kgxs"),i(Ne,"class","svelte-x2kgxs"),i(Vl,"class","svelte-x2kgxs"),i(Ql,"class","svelte-x2kgxs"),i(Jl,"class","svelte-x2kgxs"),i(Ce,"class","svelte-x2kgxs"),i($l,"class","svelte-x2kgxs"),i(er,"class","svelte-x2kgxs"),i(tr,"class","svelte-x2kgxs"),i(qe,"class","svelte-x2kgxs"),i(de,"class","svelte-x2kgxs"),i(vt,"class","svelte-x2kgxs"),i(Bc,"class","icon icon-link"),i(jt,"aria-hidden","true"),i(jt,"tabindex","-1"),i(jt,"href","#monitoring-tips"),i(Bt,"id","monitoring-tips"),i($s,"href","https://www.tensorflow.org/tensorboard"),i($s,"rel","nofollow"),i(Xc,"class","icon icon-link"),i(Ft,"aria-hidden","true"),i(Ft,"tabindex","-1"),i(Ft,"href","#generating-regularization-images"),i(Wt,"id","generating-regularization-images"),i(ar,"class","svelte-x2kgxs"),i(lr,"class","svelte-x2kgxs"),i(rr,"class","svelte-x2kgxs"),i(ir,"class","svelte-x2kgxs"),i(nr,"class","svelte-x2kgxs"),i(or,"class","svelte-x2kgxs"),i(ea,"class","svelte-x2kgxs"),i(Zc,"class","icon icon-link"),i(Zt,"aria-hidden","true"),i(Zt,"tabindex","-1"),i(Zt,"href","#important-considerations"),i(Xt,"id","important-considerations"),i(tu,"class","icon icon-link"),i(Vt,"aria-hidden","true"),i(Vt,"tabindex","-1"),i(Vt,"href","#generate-using-stable-diffusion-web-ui"),i(Kt,"id","generate-using-stable-diffusion-web-ui"),i(ra,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(ra,"rel","nofollow"),i(ur,"class","svelte-x2kgxs"),i(fr,"class","svelte-x2kgxs"),i(pr,"class","svelte-x2kgxs"),i(hr,"class","svelte-x2kgxs"),i(gr,"class","svelte-x2kgxs"),i(mr,"class","svelte-x2kgxs"),i(vr,"class","svelte-x2kgxs"),i(_r,"class","svelte-x2kgxs"),i(kr,"class","svelte-x2kgxs"),i(br,"class","svelte-x2kgxs"),i(Er,"class","svelte-x2kgxs"),i(xr,"class","svelte-x2kgxs"),i(yr,"class","svelte-x2kgxs"),i(wr,"class","svelte-x2kgxs"),i(Tr,"class","svelte-x2kgxs"),i(Rr,"class","svelte-x2kgxs"),i(Dr,"class","svelte-x2kgxs"),i(Sr,"class","svelte-x2kgxs"),i(Ar,"class","svelte-x2kgxs"),i(Or,"class","svelte-x2kgxs"),i(Lr,"class","svelte-x2kgxs"),i(Ir,"class","svelte-x2kgxs"),i(zr,"class","svelte-x2kgxs"),i(Pr,"class","svelte-x2kgxs"),i(Nr,"class","svelte-x2kgxs"),i(Cr,"class","svelte-x2kgxs"),i(qr,"class","svelte-x2kgxs"),i(Hr,"class","svelte-x2kgxs"),i(Ur,"class","svelte-x2kgxs"),i(Mr,"class","svelte-x2kgxs"),i(Br,"class","svelte-x2kgxs"),i(jr,"class","svelte-x2kgxs"),i(cu,"class","icon icon-link"),i(es,"aria-hidden","true"),i(es,"tabindex","-1"),i(es,"href","#download-images"),i($t,"id","download-images"),i(na,"href","https://huggingface.co/3ee"),i(na,"rel","nofollow"),i(ca,"href","https://github.com/Luehrsen/sd_regularization_images"),i(ca,"rel","nofollow"),i(ua,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(ua,"rel","nofollow"),i(fa,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(fa,"rel","nofollow"),i(uu,"class","icon icon-link"),i(ss,"aria-hidden","true"),i(ss,"tabindex","-1"),i(ss,"href","#captioning-regularization-images"),i(ts,"id","captioning-regularization-images"),i(Kr,"class","svelte-x2kgxs"),i(da,"class","language-shell"),i(Vr,"class","svelte-x2kgxs"),i(Qr,"class","svelte-x2kgxs"),i(Jr,"class","svelte-x2kgxs"),i($r,"class","svelte-x2kgxs"),i(fu,"class","icon icon-link"),i(is,"aria-hidden","true"),i(is,"tabindex","-1"),i(is,"href","#training-a-lora"),i(rs,"id","training-a-lora"),i(ha,"href","https://github.com/kohya-ss/sd-scripts"),i(ha,"rel","nofollow"),i(ma,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(ma,"rel","nofollow"),i(ns,"class","svelte-x2kgxs"),i(ga,"class","svelte-x2kgxs"),i(du,"class","icon icon-link"),i(us,"aria-hidden","true"),i(us,"tabindex","-1"),i(us,"href","#directory-setup"),i(cs,"id","directory-setup"),i(ei,"class","svelte-x2kgxs"),i(va,"class","language-json"),i(_a,"class","language-xml"),i(si,"class","svelte-x2kgxs"),i(ai,"class","svelte-x2kgxs"),i(li,"class","svelte-x2kgxs"),i(ri,"class","svelte-x2kgxs"),ja(ba.src,Vx="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(ba,"src",Vx),i(ba,"alt","image"),i(ba,"class","svelte-x2kgxs"),i(ka,"class","svelte-x2kgxs"),i(vu,"class","icon icon-link"),i(hs,"aria-hidden","true"),i(hs,"tabindex","-1"),i(hs,"href","#training-settings"),i(ps,"id","training-settings"),i(ui,"class","svelte-x2kgxs"),i(fi,"class","svelte-x2kgxs"),i(pi,"class","svelte-x2kgxs"),i(hi,"class","svelte-x2kgxs"),i(gi,"class","svelte-x2kgxs"),i(mi,"class","svelte-x2kgxs"),i(vi,"class","svelte-x2kgxs"),i(re,"class","svelte-x2kgxs"),i(di,"class","svelte-x2kgxs"),i(ki,"class","svelte-x2kgxs"),i(bi,"class","svelte-x2kgxs"),i(Ei,"class","svelte-x2kgxs"),i(xi,"class","svelte-x2kgxs"),i(yi,"class","svelte-x2kgxs"),i(ie,"class","svelte-x2kgxs"),i(_i,"class","svelte-x2kgxs"),i(kt,"class","svelte-x2kgxs"),i(Ea,"class","language-json"),i(Ri,"class","svelte-x2kgxs"),i(Si,"class","svelte-x2kgxs"),i(Oi,"class","svelte-x2kgxs"),i(Ii,"class","svelte-x2kgxs"),i(Pi,"class","svelte-x2kgxs"),i(Ci,"class","svelte-x2kgxs"),i(Gi,"class","svelte-x2kgxs"),i(Ui,"class","svelte-x2kgxs"),i(Bi,"class","svelte-x2kgxs"),i(Wi,"class","svelte-x2kgxs"),i(Yi,"class","svelte-x2kgxs"),i(_u,"class","icon icon-link"),i(ms,"aria-hidden","true"),i(ms,"tabindex","-1"),i(ms,"href","#fine-tuning"),i(gs,"id","fine-tuning"),i(ku,"class","icon icon-link"),i(_s,"aria-hidden","true"),i(_s,"tabindex","-1"),i(_s,"href","#workflow-with-auto1111-webui"),i(vs,"id","workflow-with-auto1111-webui"),i(Pa,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(Pa,"rel","nofollow"),i(Zi,"class","svelte-x2kgxs"),i(Vi,"class","svelte-x2kgxs"),i(Qi,"class","svelte-x2kgxs"),i(Ji,"class","svelte-x2kgxs"),i(eo,"class","svelte-x2kgxs"),i(to,"class","svelte-x2kgxs"),i(so,"class","svelte-x2kgxs"),i(ao,"class","svelte-x2kgxs"),i(lo,"class","svelte-x2kgxs"),i(ro,"class","svelte-x2kgxs"),i(io,"class","svelte-x2kgxs"),i(oo,"class","svelte-x2kgxs"),i(yu,"class","icon icon-link"),i(ws,"aria-hidden","true"),i(ws,"tabindex","-1"),i(ws,"href","#issues-to-look-for"),i(ys,"id","issues-to-look-for"),ja(qa.src,Qx="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(qa,"src",Qx),i(qa,"alt","image"),i(qa,"class","svelte-x2kgxs"),i(Ca,"class","svelte-x2kgxs"),i(Su,"class","icon icon-link"),i(Rs,"aria-hidden","true"),i(Rs,"tabindex","-1"),i(Rs,"href","#troubleshooting"),i(Ts,"id","troubleshooting"),i(go,"class","svelte-x2kgxs"),i(mo,"class","svelte-x2kgxs"),i(_o,"class","svelte-x2kgxs"),i(ko,"class","svelte-x2kgxs"),i(bo,"class","svelte-x2kgxs"),i(Xe,"class","svelte-x2kgxs"),i(vo,"class","svelte-x2kgxs"),i(Eo,"class","svelte-x2kgxs"),i(xo,"class","svelte-x2kgxs"),i(yo,"class","svelte-x2kgxs"),i(Ze,"class","svelte-x2kgxs"),i(wo,"class","svelte-x2kgxs"),i(To,"class","svelte-x2kgxs"),i(Ro,"class","svelte-x2kgxs"),i(Ke,"class","svelte-x2kgxs"),i(Do,"class","svelte-x2kgxs"),i(So,"class","svelte-x2kgxs"),i(Ao,"class","svelte-x2kgxs"),i(Ve,"class","svelte-x2kgxs"),i(Oo,"class","svelte-x2kgxs"),i(Lo,"class","svelte-x2kgxs"),i(Io,"class","svelte-x2kgxs"),i(Qe,"class","svelte-x2kgxs"),i(ve,"class","svelte-x2kgxs"),i(bt,"class","svelte-x2kgxs"),i(Ou,"class","icon icon-link"),i(Ss,"aria-hidden","true"),i(Ss,"tabindex","-1"),i(Ss,"href","#more-solutions"),i(Ds,"id","more-solutions"),i(No,"class","svelte-x2kgxs"),i(Co,"class","svelte-x2kgxs"),i(qo,"class","svelte-x2kgxs"),i(Je,"class","svelte-x2kgxs"),i(Po,"class","svelte-x2kgxs"),i(Go,"class","svelte-x2kgxs"),i(Ho,"class","svelte-x2kgxs"),i(Uo,"class","svelte-x2kgxs"),i($e,"class","svelte-x2kgxs"),i(Mo,"class","svelte-x2kgxs"),i(Bo,"class","svelte-x2kgxs"),i(jo,"class","svelte-x2kgxs"),i(et,"class","svelte-x2kgxs"),i(Wo,"class","svelte-x2kgxs"),i(Fo,"class","svelte-x2kgxs"),i(Yo,"class","svelte-x2kgxs"),i(tt,"class","svelte-x2kgxs"),i(Xo,"class","svelte-x2kgxs"),i(Zo,"class","svelte-x2kgxs"),i(Ko,"class","svelte-x2kgxs"),i(st,"class","svelte-x2kgxs"),i(Vo,"class","svelte-x2kgxs"),i(Qo,"class","svelte-x2kgxs"),i(Jo,"class","svelte-x2kgxs"),i(at,"class","svelte-x2kgxs"),i($o,"class","svelte-x2kgxs"),i(en,"class","svelte-x2kgxs"),i(tn,"class","svelte-x2kgxs"),i(lt,"class","svelte-x2kgxs"),i(sn,"class","svelte-x2kgxs"),i(an,"class","svelte-x2kgxs"),i(ln,"class","svelte-x2kgxs"),i(rt,"class","svelte-x2kgxs"),i(rn,"class","svelte-x2kgxs"),i(on,"class","svelte-x2kgxs"),i(nn,"class","svelte-x2kgxs"),i(it,"class","svelte-x2kgxs"),i(cn,"class","svelte-x2kgxs"),i(un,"class","svelte-x2kgxs"),i(fn,"class","svelte-x2kgxs"),i(ot,"class","svelte-x2kgxs"),i(dn,"class","svelte-x2kgxs"),i(pn,"class","svelte-x2kgxs"),i(hn,"class","svelte-x2kgxs"),i(nt,"class","svelte-x2kgxs"),i(j,"class","svelte-x2kgxs"),i(Et,"class","svelte-x2kgxs"),i(Lu,"class","icon icon-link"),i(Os,"aria-hidden","true"),i(Os,"tabindex","-1"),i(Os,"href","#results"),i(As,"id","results"),ja(Ma.src,Jx="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(Ma,"src",Jx),i(Ma,"alt","image"),i(Ma,"class","svelte-x2kgxs"),i(Ua,"class","svelte-x2kgxs"),i(Iu,"class","icon icon-link"),i(Ls,"aria-hidden","true"),i(Ls,"tabindex","-1"),i(Ls,"href","#spacelab"),i(xt,"id","spacelab"),i(xt,"class","svelte-x2kgxs")},m(s,p){f(s,d,p),e(d,m),f(s,g,p),Bs(h,s,p),f(s,v,p),f(s,k,p),e(k,E),e(E,T),e(k,R),f(s,x,p),f(s,b,p),e(b,y),f(s,I,p),f(s,O,p),e(O,z),e(z,q),f(s,D,p),Bs(A,s,p),f(s,S,p),f(s,P,p),e(P,N),f(s,Q,p),f(s,W,p),e(W,F),f(s,B,p),f(s,C,p),e(C,L),f(s,H,p),f(s,X,p),e(X,U),e(U,w),e(w,G),e(G,Ws),e(w,Wa),e(w,_e),e(_e,Fa),e(w,bp),e(w,Ya),e(Ya,Ep),e(X,xp),e(X,Ee),e(Ee,xe),e(xe,Xa),e(Xa,oc),e(oc,yp),e(xe,wp),e(xe,Za),e(Za,Tp),e(xe,Rp),e(xe,Ka),e(Ka,Dp),e(Ee,Sp),e(Ee,ye),e(ye,Va),e(Va,nc),e(nc,Ap),e(ye,Op),e(ye,Qa),e(Qa,Lp),e(ye,Ip),e(ye,Ja),e(Ja,zp),e(Ee,Pp),e(Ee,we),e(we,$a),e($a,cc),e(cc,Np),e(we,Cp),e(we,el),e(el,qp),e(we,Gp),e(we,tl),e(tl,Hp),f(s,Gu,p),f(s,sl,p),e(sl,Up),f(s,Hu,p),f(s,al,p),e(al,Mp),f(s,Uu,p),f(s,Fs,p),e(Fs,ll),e(ll,Bp),f(s,Mu,p),f(s,Ys,p),e(Ys,uc),e(uc,jp),e(Ys,Wp),f(s,Bu,p),f(s,Xs,p),e(Xs,fc),e(fc,Fp),e(Xs,Yp),f(s,ju,p),f(s,Zs,p),e(Zs,dc),e(dc,Xp),e(Zs,Zp),f(s,Wu,p),f(s,Ks,p),e(Ks,pc),e(pc,Kp),e(Ks,Vp),f(s,Fu,p),f(s,wt,p),e(wt,Tt),e(Tt,hc),e(wt,Qp),f(s,Yu,p),f(s,Vs,p),e(Vs,gc),e(gc,Jp),e(Vs,$p),f(s,Xu,p),f(s,Te,p),e(Te,eh),e(Te,mc),e(mc,th),e(Te,sh),e(Te,vc),e(vc,ah),e(Te,lh),f(s,Zu,p),f(s,Re,p),e(Re,rl),e(rl,_c),e(_c,rh),e(rl,ih),e(Re,oh),e(Re,il),e(il,kc),e(kc,nh),e(il,ch),e(Re,uh),e(Re,Rt),e(Rt,bc),e(bc,fh),e(Rt,dh),e(Rt,ol),e(ol,ph),e(Rt,hh),f(s,Ku,p),f(s,Dt,p),e(Dt,St),e(St,Ec),e(Dt,xc),e(xc,gh),f(s,Vu,p),f(s,nl,p),e(nl,mh),f(s,Qu,p),f(s,De,p),e(De,cl),e(cl,yc),e(yc,vh),e(cl,_h),e(De,kh),e(De,ul),e(ul,wc),e(wc,bh),e(ul,Eh),e(De,xh),e(De,fl),e(fl,Tc),e(Tc,yh),e(fl,wh),f(s,Ju,p),f(s,At,p),e(At,Ot),e(Ot,Rc),e(At,Dc),e(Dc,Th),f(s,$u,p),f(s,gt,p),e(gt,dl),e(dl,Se),e(Se,pl),e(pl,Sc),e(Sc,Rh),e(Se,Dh),e(Se,hl),e(hl,Ac),e(Ac,Sh),e(Se,Ah),e(Se,gl),e(gl,Oc),e(Oc,Oh),e(gt,Lh),e(gt,ue),e(ue,Ae),e(Ae,ml),e(ml,Lc),e(Lc,Ih),e(Ae,zh),e(Ae,vl),e(vl,Ph),e(Ae,Nh),e(Ae,_l),e(_l,Ch),e(ue,qh),e(ue,Oe),e(Oe,kl),e(kl,Ic),e(Ic,Gh),e(Oe,Hh),e(Oe,bl),e(bl,Uh),e(Oe,Mh),e(Oe,El),e(El,Bh),e(ue,jh),e(ue,Le),e(Le,xl),e(xl,zc),e(zc,Wh),e(Le,Fh),e(Le,yl),e(yl,Yh),e(Le,Xh),e(Le,wl),e(wl,Zh),e(ue,Kh),e(ue,Ie),e(Ie,Tl),e(Tl,Pc),e(Pc,Vh),e(Ie,Qh),e(Ie,Rl),e(Rl,Jh),e(Ie,$h),e(Ie,Dl),e(Dl,eg),f(s,ef,p),f(s,Lt,p),e(Lt,It),e(It,Nc),e(Lt,tg),f(s,tf,p),f(s,mt,p),e(mt,Sl),e(Sl,zt),e(zt,Al),e(Al,sg),e(zt,ag),e(zt,Ol),e(Ol,lg),e(mt,rg),e(mt,fe),e(fe,Pt),e(Pt,Ll),e(Ll,Cc),e(Cc,ig),e(Pt,og),e(Pt,Il),e(Il,ng),e(fe,cg),e(fe,Nt),e(Nt,zl),e(zl,qc),e(qc,ug),e(Nt,fg),e(Nt,Pl),e(Pl,dg),e(fe,pg),e(fe,Ct),e(Ct,Nl),e(Nl,Gc),e(Gc,hg),e(Ct,gg),e(Ct,Cl),e(Cl,mg),e(fe,vg),e(fe,qt),e(qt,ql),e(ql,Hc),e(Hc,_g),e(qt,kg),e(qt,Gl),e(Gl,bg),f(s,sf,p),f(s,Hl,p),e(Hl,Eg),f(s,af,p),f(s,Gt,p),e(Gt,Ht),e(Ht,Uc),e(Gt,xg),f(s,lf,p),f(s,Qs,p),Qs.innerHTML=J0,f(s,rf,p),f(s,Js,p),Js.innerHTML=$0,f(s,of,p),f(s,Ut,p),e(Ut,Mt),e(Mt,Mc),e(Ut,yg),f(s,nf,p),f(s,vt,p),e(vt,Ul),e(Ul,ze),e(ze,Ml),e(Ml,wg),e(ze,Tg),e(ze,Bl),e(Bl,Rg),e(ze,Dg),e(ze,jl),e(jl,Sg),e(vt,Ag),e(vt,de),e(de,Pe),e(Pe,Wl),e(Wl,Og),e(Pe,Lg),e(Pe,Fl),e(Fl,Ig),e(Pe,zg),e(Pe,Yl),e(Yl,Pg),e(de,Ng),e(de,Ne),e(Ne,Xl),e(Xl,Cg),e(Ne,qg),e(Ne,Zl),e(Zl,Gg),e(Ne,Hg),e(Ne,Kl),e(Kl,Ug),e(de,Mg),e(de,Ce),e(Ce,Vl),e(Vl,Bg),e(Ce,jg),e(Ce,Ql),e(Ql,Wg),e(Ce,Fg),e(Ce,Jl),e(Jl,Yg),e(de,Xg),e(de,qe),e(qe,$l),e($l,Zg),e(qe,Kg),e(qe,er),e(er,Vg),e(qe,Qg),e(qe,tr),e(tr,Jg),f(s,cf,p),f(s,Bt,p),e(Bt,jt),e(jt,Bc),e(Bt,$g),f(s,uf,p),f(s,le,p),e(le,sr),e(sr,em),e(sr,$s),e($s,tm),e(le,sm),e(le,jc),e(jc,am),e(le,lm),e(le,Wc),e(Wc,rm),e(le,im),e(le,Fc),e(Fc,om),e(le,nm),e(le,Yc),e(Yc,cm),f(s,ff,p),f(s,Wt,p),e(Wt,Ft),e(Ft,Xc),e(Wt,um),f(s,df,p),f(s,Yt,p),e(Yt,fm),e(Yt,ar),e(ar,dm),e(Yt,pm),f(s,pf,p),f(s,pe,p),e(pe,hm),e(pe,lr),e(lr,gm),e(pe,mm),e(pe,rr),e(rr,vm),e(pe,_m),e(pe,ir),e(ir,km),e(pe,bm),f(s,hf,p),f(s,ea,p),e(ea,or),e(or,nr),e(nr,Em),f(s,gf,p),f(s,cr,p),e(cr,xm),f(s,mf,p),f(s,Xt,p),e(Xt,Zt),e(Zt,Zc),e(Xt,ym),f(s,vf,p),f(s,Ge,p),e(Ge,Kc),e(Kc,ta),e(ta,Vc),e(Vc,wm),e(ta,Tm),e(ta,Rm),e(Ge,Dm),e(Ge,Qc),e(Qc,sa),e(sa,Jc),e(Jc,Sm),e(sa,Am),e(sa,Om),e(Ge,Lm),e(Ge,$c),e($c,aa),e(aa,eu),e(eu,Im),e(aa,zm),e(aa,Pm),f(s,_f,p),Bs(la,s,p),f(s,kf,p),f(s,Kt,p),e(Kt,Vt),e(Vt,tu),e(Kt,Nm),f(s,bf,p),f(s,Qt,p),e(Qt,Cm),e(Qt,ra),e(ra,qm),e(Qt,Gm),f(s,Ef,p),f(s,He,p),e(He,Hm),e(He,ur),e(ur,Um),e(He,Mm),e(He,fr),e(fr,Bm),e(He,jm),f(s,xf,p),f(s,J,p),e(J,su),e(su,dr),e(dr,Wm),e(dr,pr),e(pr,Fm),e(J,Ym),e(J,au),e(au,ia),e(ia,Xm),e(ia,hr),e(hr,Zm),e(ia,Km),e(J,Vm),e(J,lu),e(lu,Z),e(Z,Qm),e(Z,gr),e(gr,Jm),e(Z,$m),e(Z,mr),e(mr,ev),e(Z,tv),e(Z,vr),e(vr,sv),e(Z,av),e(Z,_r),e(_r,lv),e(Z,rv),e(Z,kr),e(kr,iv),e(Z,ov),e(Z,br),e(br,nv),e(Z,cv),e(Z,Er),e(Er,uv),e(Z,fv),e(Z,xr),e(xr,dv),e(J,pv),e(J,ru),e(ru,$),e($,hv),e($,yr),e(yr,gv),e($,mv),e($,wr),e(wr,vv),e($,_v),e($,Tr),e(Tr,kv),e($,bv),e($,Rr),e(Rr,Ev),e($,xv),e($,Dr),e(Dr,yv),e($,wv),e($,Sr),e(Sr,Tv),e($,Rv),e($,Ar),e(Ar,Dv),e(J,Sv),e(J,iu),e(iu,K),e(K,Av),e(K,Or),e(Or,Ov),e(K,Lv),e(K,Lr),e(Lr,Iv),e(K,zv),e(K,Ir),e(Ir,Pv),e(K,Nv),e(K,zr),e(zr,Cv),e(K,qv),e(K,Pr),e(Pr,Gv),e(K,Hv),e(K,Nr),e(Nr,Uv),e(K,Mv),e(K,Cr),e(Cr,Bv),e(K,jv),e(K,qr),e(qr,Wv),e(J,Fv),e(J,ou),e(ou,Gr),e(Gr,Yv),e(Gr,Hr),e(Hr,Xv),e(J,Zv),e(J,nu),e(nu,Jt),e(Jt,Kv),e(Jt,Ur),e(Ur,Vv),e(Jt,Qv),e(Jt,Mr),e(Mr,Jv),f(s,yf,p),f(s,Ue,p),e(Ue,$v),e(Ue,Br),e(Br,e2),e(Ue,t2),e(Ue,jr),e(jr,s2),e(Ue,a2),f(s,wf,p),Bs(oa,s,p),f(s,Tf,p),f(s,$t,p),e($t,es),e(es,cu),e($t,l2),f(s,Rf,p),f(s,Wr,p),e(Wr,r2),f(s,Df,p),f(s,he,p),e(he,Fr),e(Fr,na),e(na,i2),e(Fr,o2),e(he,n2),e(he,Yr),e(Yr,ca),e(ca,c2),e(Yr,u2),e(he,f2),e(he,Xr),e(Xr,ua),e(ua,d2),e(Xr,p2),e(he,h2),e(he,Zr),e(Zr,fa),e(fa,g2),e(Zr,m2),f(s,Sf,p),f(s,ts,p),e(ts,ss),e(ss,uu),e(ts,v2),f(s,Af,p),f(s,as,p),e(as,_2),e(as,Kr),e(Kr,k2),e(as,b2),f(s,Of,p),f(s,da,p),da.innerHTML=e6,f(s,Lf,p),f(s,Me,p),e(Me,E2),e(Me,Vr),e(Vr,x2),e(Me,y2),e(Me,Qr),e(Qr,w2),e(Me,T2),f(s,If,p),f(s,pa,p),e(pa,R2),e(pa,Jr),e(Jr,D2),f(s,zf,p),f(s,ls,p),e(ls,S2),e(ls,$r),e($r,A2),e(ls,O2),f(s,Pf,p),f(s,rs,p),e(rs,is),e(is,fu),e(rs,L2),f(s,Nf,p),f(s,os,p),e(os,I2),e(os,ha),e(ha,z2),e(os,P2),f(s,Cf,p),f(s,ga,p),e(ga,ns),e(ns,N2),e(ns,ma),e(ma,C2),e(ns,q2),f(s,qf,p),f(s,cs,p),e(cs,us),e(us,du),e(cs,G2),f(s,Gf,p),f(s,fs,p),e(fs,H2),e(fs,ei),e(ei,U2),e(fs,M2),f(s,Hf,p),f(s,va,p),va.innerHTML=t6,f(s,Uf,p),f(s,ti,p),e(ti,B2),f(s,Mf,p),f(s,_a,p),_a.innerHTML=s6,f(s,Bf,p),f(s,Be,p),e(Be,j2),e(Be,si),e(si,W2),e(Be,F2),e(Be,ai),e(ai,Y2),e(Be,X2),f(s,jf,p),f(s,je,p),e(je,Z2),e(je,li),e(li,K2),e(je,V2),e(je,ri),e(ri,Q2),e(je,J2),f(s,Wf,p),f(s,ii,p),e(ii,$2),f(s,Ff,p),f(s,ds,p),e(ds,oi),e(oi,e_),e(oi,pu),e(pu,hu),e(hu,t_),e(ds,s_),e(ds,ni),e(ni,a_),e(ni,gu),e(gu,mu),e(mu,l_),f(s,Yf,p),f(s,ci,p),e(ci,r_),f(s,Xf,p),f(s,ka,p),e(ka,ba),f(s,Zf,p),f(s,ps,p),e(ps,hs),e(hs,vu),e(ps,i_),f(s,Kf,p),f(s,_t,p),e(_t,o_),e(_t,ui),e(ui,n_),e(_t,c_),e(_t,fi),e(fi,u_),f(s,Vf,p),f(s,kt,p),e(kt,di),e(di,re),e(re,pi),e(pi,f_),e(re,d_),e(re,hi),e(hi,p_),e(re,h_),e(re,gi),e(gi,g_),e(re,m_),e(re,mi),e(mi,v_),e(re,__),e(re,vi),e(vi,k_),e(kt,b_),e(kt,_i),e(_i,ie),e(ie,ki),e(ki,E_),e(ie,x_),e(ie,bi),e(bi,y_),e(ie,w_),e(ie,Ei),e(Ei,T_),e(ie,R_),e(ie,xi),e(xi,D_),e(ie,S_),e(ie,yi),e(yi,A_),f(s,Qf,p),f(s,wi,p),e(wi,O_),f(s,Jf,p),f(s,Ea,p),Ea.innerHTML=a6,f(s,$f,p),f(s,M,p),e(M,Ti),e(Ti,xa),e(xa,L_),e(xa,Ri),e(Ri,I_),e(xa,z_),e(Ti,P_),e(M,N_),e(M,Di),e(Di,ya),e(ya,C_),e(ya,Si),e(Si,q_),e(ya,G_),e(Di,H_),e(M,U_),e(M,Ai),e(Ai,wa),e(wa,M_),e(wa,Oi),e(Oi,B_),e(wa,j_),e(Ai,W_),e(M,F_),e(M,Li),e(Li,Ta),e(Ta,Y_),e(Ta,Ii),e(Ii,X_),e(Ta,Z_),e(Li,K_),e(M,V_),e(M,zi),e(zi,Ra),e(Ra,Q_),e(Ra,Pi),e(Pi,J_),e(Ra,$_),e(zi,e1),e(M,t1),e(M,Ni),e(Ni,Da),e(Da,s1),e(Da,Ci),e(Ci,a1),e(Da,l1),e(Ni,r1),e(M,i1),e(M,qi),e(qi,Sa),e(Sa,o1),e(Sa,Gi),e(Gi,n1),e(Sa,c1),e(qi,u1),e(M,f1),e(M,Hi),e(Hi,Aa),e(Aa,d1),e(Aa,Ui),e(Ui,p1),e(Aa,h1),e(Hi,g1),e(M,m1),e(M,Mi),e(Mi,Oa),e(Oa,v1),e(Oa,Bi),e(Bi,_1),e(Oa,k1),e(Mi,b1),e(M,E1),e(M,ji),e(ji,La),e(La,x1),e(La,Wi),e(Wi,y1),e(La,w1),e(ji,T1),e(M,R1),e(M,Fi),e(Fi,Ia),e(Ia,D1),e(Ia,Yi),e(Yi,S1),e(Ia,A1),e(Fi,O1),f(s,ed,p),f(s,gs,p),e(gs,ms),e(ms,_u),e(gs,L1),f(s,td,p),f(s,Xi,p),e(Xi,I1),f(s,sd,p),Bs(za,s,p),f(s,ad,p),f(s,vs,p),e(vs,_s),e(_s,ku),e(vs,z1),f(s,ld,p),f(s,ks,p),e(ks,P1),e(ks,Pa),e(Pa,N1),e(ks,C1),f(s,rd,p),f(s,bs,p),e(bs,q1),e(bs,Zi),e(Zi,G1),e(bs,H1),f(s,id,p),f(s,oe,p),e(oe,Ki),e(Ki,U1),e(Ki,od),e(oe,M1),e(oe,bu),e(bu,B1),e(oe,j1),e(oe,We),e(We,W1),e(We,Vi),e(Vi,F1),e(We,Y1),e(We,Qi),e(Qi,X1),e(We,Z1),e(We,Ji),e(Ji,K1),e(oe,V1),e(oe,$i),e($i,Q1),e($i,eo),e(eo,J1),e(oe,$1),e(oe,Es),e(Es,ek),e(Es,to),e(to,tk),e(Es,sk),e(Es,so),e(so,ak),f(s,nd,p),f(s,Fe,p),e(Fe,lk),e(Fe,ao),e(ao,rk),e(Fe,ik),e(Fe,lo),e(lo,ok),e(Fe,nk),f(s,cd,p),f(s,ge,p),e(ge,xs),e(xs,ck),e(xs,ro),e(ro,uk),e(xs,fk),e(xs,io),e(io,dk),e(ge,pk),e(ge,Na),e(Na,hk),e(Na,oo),e(oo,gk),e(Na,mk),e(ge,vk),e(ge,Eu),e(Eu,_k),e(ge,kk),e(ge,xu),e(xu,bk),f(s,ud,p),f(s,ys,p),e(ys,ws),e(ws,yu),e(ys,Ek),f(s,fd,p),f(s,me,p),e(me,no),e(no,wu),e(wu,xk),e(no,yk),e(me,wk),e(me,co),e(co,Tu),e(Tu,Tk),e(co,Rk),e(me,Dk),e(me,uo),e(uo,Ru),e(Ru,Sk),e(uo,Ak),e(me,Ok),e(me,fo),e(fo,Du),e(Du,Lk),e(fo,Ik),f(s,dd,p),f(s,po,p),e(po,zk),f(s,pd,p),f(s,Ca,p),e(Ca,qa),f(s,hd,p),f(s,Ts,p),e(Ts,Rs),e(Rs,Su),e(Ts,Pk),f(s,gd,p),f(s,ho,p),e(ho,Nk),f(s,md,p),f(s,Ye,p),e(Ye,Ga),e(Ga,Ck),e(Ga,go),e(go,qk),e(Ga,Gk),e(Ye,Hk),e(Ye,Ha),e(Ha,Uk),e(Ha,mo),e(mo,Mk),e(Ha,Bk),e(Ye,jk),e(Ye,Au),e(Au,Wk),f(s,vd,p),f(s,bt,p),e(bt,vo),e(vo,Xe),e(Xe,_o),e(_o,Fk),e(Xe,Yk),e(Xe,ko),e(ko,Xk),e(Xe,Zk),e(Xe,bo),e(bo,Kk),e(bt,Vk),e(bt,ve),e(ve,Ze),e(Ze,Eo),e(Eo,Qk),e(Ze,Jk),e(Ze,xo),e(xo,$k),e(Ze,eb),e(Ze,yo),e(yo,tb),e(ve,sb),e(ve,Ke),e(Ke,wo),e(wo,ab),e(Ke,lb),e(Ke,To),e(To,rb),e(Ke,ib),e(Ke,Ro),e(Ro,ob),e(ve,nb),e(ve,Ve),e(Ve,Do),e(Do,cb),e(Ve,ub),e(Ve,So),e(So,fb),e(Ve,db),e(Ve,Ao),e(Ao,pb),e(ve,hb),e(ve,Qe),e(Qe,Oo),e(Oo,gb),e(Qe,mb),e(Qe,Lo),e(Lo,vb),e(Qe,_b),e(Qe,Io),e(Io,kb),f(s,_d,p),f(s,Ds,p),e(Ds,Ss),e(Ss,Ou),e(Ds,bb),f(s,kd,p),f(s,zo,p),e(zo,Eb),f(s,bd,p),f(s,Et,p),e(Et,Po),e(Po,Je),e(Je,No),e(No,xb),e(Je,yb),e(Je,Co),e(Co,wb),e(Je,Tb),e(Je,qo),e(qo,Rb),e(Et,Db),e(Et,j),e(j,$e),e($e,Go),e(Go,Sb),e($e,Ab),e($e,Ho),e(Ho,Ob),e($e,Lb),e($e,Uo),e(Uo,Ib),e(j,zb),e(j,et),e(et,Mo),e(Mo,Pb),e(et,Nb),e(et,Bo),e(Bo,Cb),e(et,qb),e(et,jo),e(jo,Gb),e(j,Hb),e(j,tt),e(tt,Wo),e(Wo,Ub),e(tt,Mb),e(tt,Fo),e(Fo,Bb),e(tt,jb),e(tt,Yo),e(Yo,Wb),e(j,Fb),e(j,st),e(st,Xo),e(Xo,Yb),e(st,Xb),e(st,Zo),e(Zo,Zb),e(st,Kb),e(st,Ko),e(Ko,Vb),e(j,Qb),e(j,at),e(at,Vo),e(Vo,Jb),e(at,$b),e(at,Qo),e(Qo,eE),e(at,tE),e(at,Jo),e(Jo,sE),e(j,aE),e(j,lt),e(lt,$o),e($o,lE),e(lt,rE),e(lt,en),e(en,iE),e(lt,oE),e(lt,tn),e(tn,nE),e(j,cE),e(j,rt),e(rt,sn),e(sn,uE),e(rt,fE),e(rt,an),e(an,dE),e(rt,pE),e(rt,ln),e(ln,hE),e(j,gE),e(j,it),e(it,rn),e(rn,mE),e(it,vE),e(it,on),e(on,_E),e(it,kE),e(it,nn),e(nn,bE),e(j,EE),e(j,ot),e(ot,cn),e(cn,xE),e(ot,yE),e(ot,un),e(un,wE),e(ot,TE),e(ot,fn),e(fn,RE),e(j,DE),e(j,nt),e(nt,dn),e(dn,SE),e(nt,AE),e(nt,pn),e(pn,OE),e(nt,LE),e(nt,hn),e(hn,IE),f(s,Ed,p),f(s,As,p),e(As,Os),e(Os,Lu),e(As,zE),f(s,xd,p),f(s,gn,p),e(gn,PE),f(s,yd,p),f(s,mn,p),e(mn,NE),f(s,wd,p),f(s,Ua,p),e(Ua,Ma),f(s,Td,p),f(s,vn,p),e(vn,CE),f(s,Rd,p),f(s,xt,p),e(xt,Ls),e(Ls,Iu),e(xt,qE),f(s,Dd,p),ke&&ke.m(s,p),f(s,Sd,p),Ad=!0},p(s,p){Q0&&ke.p(s,p)},i(s){Ad||(pt(h.$$.fragment,s),pt(A.$$.fragment,s),pt(la.$$.fragment,s),pt(oa.$$.fragment,s),pt(za.$$.fragment,s),pt(ke),Ad=!0)},o(s){ht(h.$$.fragment,s),ht(A.$$.fragment,s),ht(la.$$.fragment,s),ht(oa.$$.fragment,s),ht(za.$$.fragment,s),ht(ke),Ad=!1},d(s){s&&t(d),s&&t(g),js(h,s),s&&t(v),s&&t(k),s&&t(x),s&&t(b),s&&t(I),s&&t(O),s&&t(D),js(A,s),s&&t(S),s&&t(P),s&&t(Q),s&&t(W),s&&t(B),s&&t(C),s&&t(H),s&&t(X),s&&t(Gu),s&&t(sl),s&&t(Hu),s&&t(al),s&&t(Uu),s&&t(Fs),s&&t(Mu),s&&t(Ys),s&&t(Bu),s&&t(Xs),s&&t(ju),s&&t(Zs),s&&t(Wu),s&&t(Ks),s&&t(Fu),s&&t(wt),s&&t(Yu),s&&t(Vs),s&&t(Xu),s&&t(Te),s&&t(Zu),s&&t(Re),s&&t(Ku),s&&t(Dt),s&&t(Vu),s&&t(nl),s&&t(Qu),s&&t(De),s&&t(Ju),s&&t(At),s&&t($u),s&&t(gt),s&&t(ef),s&&t(Lt),s&&t(tf),s&&t(mt),s&&t(sf),s&&t(Hl),s&&t(af),s&&t(Gt),s&&t(lf),s&&t(Qs),s&&t(rf),s&&t(Js),s&&t(of),s&&t(Ut),s&&t(nf),s&&t(vt),s&&t(cf),s&&t(Bt),s&&t(uf),s&&t(le),s&&t(ff),s&&t(Wt),s&&t(df),s&&t(Yt),s&&t(pf),s&&t(pe),s&&t(hf),s&&t(ea),s&&t(gf),s&&t(cr),s&&t(mf),s&&t(Xt),s&&t(vf),s&&t(Ge),s&&t(_f),js(la,s),s&&t(kf),s&&t(Kt),s&&t(bf),s&&t(Qt),s&&t(Ef),s&&t(He),s&&t(xf),s&&t(J),s&&t(yf),s&&t(Ue),s&&t(wf),js(oa,s),s&&t(Tf),s&&t($t),s&&t(Rf),s&&t(Wr),s&&t(Df),s&&t(he),s&&t(Sf),s&&t(ts),s&&t(Af),s&&t(as),s&&t(Of),s&&t(da),s&&t(Lf),s&&t(Me),s&&t(If),s&&t(pa),s&&t(zf),s&&t(ls),s&&t(Pf),s&&t(rs),s&&t(Nf),s&&t(os),s&&t(Cf),s&&t(ga),s&&t(qf),s&&t(cs),s&&t(Gf),s&&t(fs),s&&t(Hf),s&&t(va),s&&t(Uf),s&&t(ti),s&&t(Mf),s&&t(_a),s&&t(Bf),s&&t(Be),s&&t(jf),s&&t(je),s&&t(Wf),s&&t(ii),s&&t(Ff),s&&t(ds),s&&t(Yf),s&&t(ci),s&&t(Xf),s&&t(ka),s&&t(Zf),s&&t(ps),s&&t(Kf),s&&t(_t),s&&t(Vf),s&&t(kt),s&&t(Qf),s&&t(wi),s&&t(Jf),s&&t(Ea),s&&t($f),s&&t(M),s&&t(ed),s&&t(gs),s&&t(td),s&&t(Xi),s&&t(sd),js(za,s),s&&t(ad),s&&t(vs),s&&t(ld),s&&t(ks),s&&t(rd),s&&t(bs),s&&t(id),s&&t(oe),s&&t(nd),s&&t(Fe),s&&t(cd),s&&t(ge),s&&t(ud),s&&t(ys),s&&t(fd),s&&t(me),s&&t(dd),s&&t(po),s&&t(pd),s&&t(Ca),s&&t(hd),s&&t(Ts),s&&t(gd),s&&t(ho),s&&t(md),s&&t(Ye),s&&t(vd),s&&t(bt),s&&t(_d),s&&t(Ds),s&&t(kd),s&&t(zo),s&&t(bd),s&&t(Et),s&&t(Ed),s&&t(As),s&&t(xd),s&&t(gn),s&&t(yd),s&&t(mn),s&&t(wd),s&&t(Ua),s&&t(Td),s&&t(vn),s&&t(Rd),s&&t(xt),s&&t(Dd),ke&&ke.d(s),s&&t(Sd)}}}function Y6(_){let d,m;const g=[_[0],Kx];let h={$$slots:{default:[F6]},$$scope:{ctx:_}};for(let v=0;v<g.length;v+=1)h=Zx(h,g[v]);return d=new v6({props:h}),{c(){Us(d.$$.fragment)},l(v){Ms(d.$$.fragment,v)},m(v,k){Bs(d,v,k),m=!0},p(v,[k]){const E=k&1?m6(g,[k&1&&W0(v[0]),k&0&&W0(Kx)]):{};k&2&&(E.$$scope={dirty:k,ctx:v}),d.$set(E)},i(v){m||(pt(d.$$.fragment,v),m=!0)},o(v){ht(d.$$.fragment,v),m=!1},d(v){js(d,v)}}}const Kx={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:rT,date:iT,modifiedDate:oT,categories:nT,svg:cT,seoImage:uT,shortDescription:fT,author:dT,spacelab:Q0,id:X6,spacelabDefaultTitle:Z6,spacelabDefaultContent:K6,menu:pT,keywords:hT}=Kx;function V6(_,d,m){return _.$$set=g=>{m(0,d=Zx(Zx({},d),F0(g)))},d=F0(d),[d]}class gT extends vp{constructor(d){super(),_p(this,d,V6,Y6,kp,{})}}export{gT as default,Kx as metadata};
