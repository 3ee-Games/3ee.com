import{S as G2,i as U2,s as H2,l as Zf,g as d,E as lS,d as t,v as nN,e as s,t as o,c as l,a as i,h as n,b as r,G as e,j as ce,k as c,m as u,F as ee,H as Ie,N as zx,Y as cN,J as ta,f as ea,Z as uN,_ as dN,$ as fN,q as aa,o as sa,O as pN,w as Ui,x as Hi,y as qi,B as Mi,C as iS,z as hN,A as xx,a1 as Nx}from"../../chunks/index-2a82a4a8.js";import{P as vN}from"../../chunks/_post-913f18eb.js";import{g as tS}from"../../chunks/config-201c2df4.js";import{a as aS}from"../../chunks/accountStore-3492c591.js";/* empty css                                                                   */import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function gN(_){let p,g,v,h,m,E,y,T,R,k,b,w,O,P,N,G,A,L;function D(I,U){return typeof I[2].title!="undefined"?EN:_N}let z=D(_),x=z(_);function Q(I,U){return typeof I[2].description!="undefined"?yN:bN}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&Cx(_),C=typeof _[2].footer_description!="undefined"&&Gx(_);return{c(){p=s("hr"),g=c(),v=s("div"),x.c(),h=c(),m=s("p"),E=s("ion-icon"),y=o("SpaceLab Content"),T=c(),F.c(),R=c(),B&&B.c(),k=c(),C&&C.c(),b=c(),w=s("button"),O=s("ion-icon"),P=c(),N=s("span"),G=o("SpaceLab"),this.h()},l(I){p=l(I,"HR",{}),g=u(I),v=l(I,"DIV",{class:!0});var U=i(v);x.l(U),h=u(U),m=l(U,"P",{class:!0});var Z=i(m);E=l(Z,"ION-ICON",{class:!0,name:!0}),i(E).forEach(t),y=n(Z,"SpaceLab Content"),Z.forEach(t),T=u(U),F.l(U),R=u(U),B&&B.l(U),k=u(U),C&&C.l(U),b=u(U),w=l(U,"BUTTON",{class:!0});var H=i(w);O=l(H,"ION-ICON",{class:!0,name:!0}),i(O).forEach(t),P=u(H),N=l(H,"SPAN",{});var S=i(N);G=n(S,"SpaceLab"),S.forEach(t),H.forEach(t),U.forEach(t),this.h()},h(){ee(E,"class","icon svelte-s12rf8"),ee(E,"name","lock-closed"),r(m,"class","highlight large svelte-s12rf8"),ee(O,"class","icon svelte-s12rf8"),ee(O,"name","planet"),r(w,"class","button subscribe svelte-s12rf8"),r(v,"class","subscribe svelte-s12rf8")},m(I,U){d(I,p,U),d(I,g,U),d(I,v,U),x.m(v,null),e(v,h),e(v,m),e(m,E),e(m,y),e(v,T),F.m(v,null),e(v,R),B&&B.m(v,null),e(v,k),C&&C.m(v,null),e(v,b),e(v,w),e(w,O),e(w,P),e(w,N),e(N,G),A||(L=Ie(w,"click",_[15]),A=!0)},p(I,U){z===(z=D(I))&&x?x.p(I,U):(x.d(1),x=z(I),x&&(x.c(),x.m(v,h))),j===(j=Q(I))&&F?F.p(I,U):(F.d(1),F=j(I),F&&(F.c(),F.m(v,R))),typeof I[2].list_description!="undefined"?B?B.p(I,U):(B=Cx(I),B.c(),B.m(v,k)):B&&(B.d(1),B=null),typeof I[2].footer_description!="undefined"?C?C.p(I,U):(C=Gx(I),C.c(),C.m(v,b)):C&&(C.d(1),C=null)},d(I){I&&t(p),I&&t(g),I&&t(v),x.d(),F.d(),B&&B.d(),C&&C.d(),A=!1,L()}}}function mN(_){let p,g,v,h=_[2].title+"",m,E,y,T,R,k,b,w=_[2].description+"",O,P,N,G,A,L,D,z,x,Q,j,F,B,C=typeof _[2].list_description!="undefined"&&Ux(_),I=typeof _[2].footer_description!="undefined"&&Hx(_);function U(S,q){if(S[2].github_private_repo&&S[2].github_state==="LOG_EXISTS")return TN;if(S[2].github_private_repo&&S[2].github_state==="NO_LOGS")return wN;if(S[2].github_private_repo&&S[2].github_state==="NO_GITHUB_USERNAME")return kN}let Z=U(_),H=Z&&Z(_);return{c(){p=s("hr"),g=c(),v=s("h2"),m=o(h),E=c(),y=s("p"),T=s("ion-icon"),R=o("SpaceLab Content"),k=c(),b=s("p"),O=o(w),P=c(),C&&C.c(),N=c(),I&&I.c(),G=c(),A=s("button"),L=s("ion-icon"),D=c(),z=s("span"),x=o("Download"),Q=c(),H&&H.c(),j=Zf(),this.h()},l(S){p=l(S,"HR",{}),g=u(S),v=l(S,"H2",{class:!0});var q=i(v);m=n(q,h),q.forEach(t),E=u(S),y=l(S,"P",{class:!0});var la=i(y);T=l(la,"ION-ICON",{class:!0,name:!0}),i(T).forEach(t),R=n(la,"SpaceLab Content"),la.forEach(t),k=u(S),b=l(S,"P",{class:!0});var Oe=i(b);O=n(Oe,w),Oe.forEach(t),P=u(S),C&&C.l(S),N=u(S),I&&I.l(S),G=u(S),A=l(S,"BUTTON",{class:!0});var de=i(A);L=l(de,"ION-ICON",{class:!0,name:!0}),i(L).forEach(t),D=u(de),z=l(de,"SPAN",{});var Qf=i(z);x=n(Qf,"Download"),Qf.forEach(t),de.forEach(t),Q=u(S),H&&H.l(S),j=Zf(),this.h()},h(){r(v,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","planet-sharp"),r(y,"class","highlight large svelte-s12rf8"),r(b,"class","svelte-s12rf8"),ee(L,"class","icon svelte-s12rf8"),ee(L,"name","cloud-download"),r(A,"class","button svelte-s12rf8")},m(S,q){d(S,p,q),d(S,g,q),d(S,v,q),e(v,m),d(S,E,q),d(S,y,q),e(y,T),e(y,R),d(S,k,q),d(S,b,q),e(b,O),d(S,P,q),C&&C.m(S,q),d(S,N,q),I&&I.m(S,q),d(S,G,q),d(S,A,q),e(A,L),e(A,D),e(A,z),e(z,x),d(S,Q,q),H&&H.m(S,q),d(S,j,q),F||(B=Ie(A,"click",_[10]),F=!0)},p(S,q){q&4&&h!==(h=S[2].title+"")&&ce(m,h),q&4&&w!==(w=S[2].description+"")&&ce(O,w),typeof S[2].list_description!="undefined"?C?C.p(S,q):(C=Ux(S),C.c(),C.m(N.parentNode,N)):C&&(C.d(1),C=null),typeof S[2].footer_description!="undefined"?I?I.p(S,q):(I=Hx(S),I.c(),I.m(G.parentNode,G)):I&&(I.d(1),I=null),Z===(Z=U(S))&&H?H.p(S,q):(H&&H.d(1),H=Z&&Z(S),H&&(H.c(),H.m(j.parentNode,j)))},d(S){S&&t(p),S&&t(g),S&&t(v),S&&t(E),S&&t(y),S&&t(k),S&&t(b),S&&t(P),C&&C.d(S),S&&t(N),I&&I.d(S),S&&t(G),S&&t(A),S&&t(Q),H&&H.d(S),S&&t(j),F=!1,B()}}}function _N(_){let p,g;return{c(){p=s("h2"),g=o(_[0]),this.h()},l(v){p=l(v,"H2",{class:!0});var h=i(p);g=n(h,_[0]),h.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(v,h){d(v,p,h),e(p,g)},p(v,h){h&1&&ce(g,v[0])},d(v){v&&t(p)}}}function EN(_){let p,g=_[2].title+"",v;return{c(){p=s("h2"),v=o(g),this.h()},l(h){p=l(h,"H2",{class:!0});var m=i(p);v=n(m,g),m.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(h,m){d(h,p,m),e(p,v)},p(h,m){m&4&&g!==(g=h[2].title+"")&&ce(v,g)},d(h){h&&t(p)}}}function bN(_){let p,g;return{c(){p=s("p"),g=o(_[1]),this.h()},l(v){p=l(v,"P",{class:!0});var h=i(p);g=n(h,_[1]),h.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(v,h){d(v,p,h),e(p,g)},p(v,h){h&2&&ce(g,v[1])},d(v){v&&t(p)}}}function yN(_){let p,g=_[2].description+"",v;return{c(){p=s("p"),v=o(g),this.h()},l(h){p=l(h,"P",{class:!0});var m=i(p);v=n(m,g),m.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(h,m){d(h,p,m),e(p,v)},p(h,m){m&4&&g!==(g=h[2].description+"")&&ce(v,g)},d(h){h&&t(p)}}}function Cx(_){let p,g,v=_[2].list_description+"",h;return{c(){p=s("div"),g=s("p"),h=o(v),this.h()},l(m){p=l(m,"DIV",{class:!0});var E=i(p);g=l(E,"P",{class:!0});var y=i(g);h=n(y,v),y.forEach(t),E.forEach(t),this.h()},h(){r(g,"class","svelte-s12rf8"),r(p,"class","list-description svelte-s12rf8")},m(m,E){d(m,p,E),e(p,g),e(g,h)},p(m,E){E&4&&v!==(v=m[2].list_description+"")&&ce(h,v)},d(m){m&&t(p)}}}function Gx(_){let p,g=_[2].footer_description+"",v;return{c(){p=s("p"),v=o(g),this.h()},l(h){p=l(h,"P",{class:!0});var m=i(p);v=n(m,g),m.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(h,m){d(h,p,m),e(p,v)},p(h,m){m&4&&g!==(g=h[2].footer_description+"")&&ce(v,g)},d(h){h&&t(p)}}}function Ux(_){let p,g,v=_[2].list_description+"",h;return{c(){p=s("div"),g=s("p"),h=o(v),this.h()},l(m){p=l(m,"DIV",{class:!0});var E=i(p);g=l(E,"P",{class:!0});var y=i(g);h=n(y,v),y.forEach(t),E.forEach(t),this.h()},h(){r(g,"class","svelte-s12rf8"),r(p,"class","list-description svelte-s12rf8")},m(m,E){d(m,p,E),e(p,g),e(g,h)},p(m,E){E&4&&v!==(v=m[2].list_description+"")&&ce(h,v)},d(m){m&&t(p)}}}function Hx(_){let p,g=_[2].footer_description+"",v;return{c(){p=s("p"),v=o(g),this.h()},l(h){p=l(h,"P",{class:!0});var m=i(p);v=n(m,g),m.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(h,m){d(h,p,m),e(p,v)},p(h,m){m&4&&g!==(g=h[2].footer_description+"")&&ce(v,g)},d(h){h&&t(p)}}}function kN(_){let p,g,v,h,m,E;function y(k,b){return k[5]?SN:RN}let T=y(_),R=T(_);return{c(){p=s("h2"),g=o("Private GitHub Access"),v=c(),h=s("form"),R.c(),this.h()},l(k){p=l(k,"H2",{class:!0});var b=i(p);g=n(b,"Private GitHub Access"),b.forEach(t),v=u(k),h=l(k,"FORM",{class:!0});var w=i(h);R.l(w),w.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8"),r(h,"class","request-permission svelte-s12rf8")},m(k,b){d(k,p,b),e(p,g),d(k,v,b),d(k,h,b),R.m(h,null),m||(E=Ie(h,"submit",_[8]),m=!0)},p(k,b){T===(T=y(k))&&R?R.p(k,b):(R.d(1),R=T(k),R&&(R.c(),R.m(h,null)))},d(k){k&&t(p),k&&t(v),k&&t(h),R.d(),m=!1,E()}}}function wN(_){let p,g,v,h,m,E;function y(k,b){return k[5]?AN:DN}let T=y(_),R=T(_);return{c(){p=s("h2"),g=o("Private GitHub Access"),v=c(),h=s("form"),R.c(),this.h()},l(k){p=l(k,"H2",{class:!0});var b=i(p);g=n(b,"Private GitHub Access"),b.forEach(t),v=u(k),h=l(k,"FORM",{});var w=i(h);R.l(w),w.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8")},m(k,b){d(k,p,b),e(p,g),d(k,v,b),d(k,h,b),R.m(h,null),m||(E=Ie(h,"submit",_[7]),m=!0)},p(k,b){T===(T=y(k))&&R?R.p(k,b):(R.d(1),R=T(k),R&&(R.c(),R.m(h,null)))},d(k){k&&t(p),k&&t(v),k&&t(h),R.d(),m=!1,E()}}}function TN(_){var L;let p,g,v,h,m,E,y=((L=_[6].profile)==null?void 0:L.githubUsername)+"",T,R,k,b,w,O,P,N,G,A;return{c(){p=s("h2"),g=o("Private GitHub Access"),v=c(),h=s("p"),m=o("Your GitHub account "),E=s("span"),T=o(y),R=o(` is
			linked to this content.`),k=c(),b=s("button"),w=s("ion-icon"),O=c(),P=s("span"),N=o("Open Repository"),this.h()},l(D){p=l(D,"H2",{class:!0});var z=i(p);g=n(z,"Private GitHub Access"),z.forEach(t),v=u(D),h=l(D,"P",{class:!0});var x=i(h);m=n(x,"Your GitHub account "),E=l(x,"SPAN",{class:!0});var Q=i(E);T=n(Q,y),Q.forEach(t),R=n(x,` is
			linked to this content.`),x.forEach(t),k=u(D),b=l(D,"BUTTON",{class:!0});var j=i(b);w=l(j,"ION-ICON",{class:!0,name:!0}),i(w).forEach(t),O=u(j),P=l(j,"SPAN",{});var F=i(P);N=n(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8"),r(E,"class","highlight svelte-s12rf8"),r(h,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","rocket-sharp"),r(b,"class","svelte-s12rf8")},m(D,z){d(D,p,z),e(p,g),d(D,v,z),d(D,h,z),e(h,m),e(h,E),e(E,T),e(h,R),d(D,k,z),d(D,b,z),e(b,w),e(b,O),e(b,P),e(P,N),G||(A=Ie(b,"click",_[11]),G=!0)},p(D,z){var x;z&64&&y!==(y=((x=D[6].profile)==null?void 0:x.githubUsername)+"")&&ce(T,y)},d(D){D&&t(p),D&&t(v),D&&t(h),D&&t(k),D&&t(b),G=!1,A()}}}function RN(_){let p,g,v,h,m,E,y,T,R,k,b,w,O,P,N,G;return{c(){p=s("p"),g=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),v=c(),h=s("label"),m=o("Github username:"),E=c(),y=s("input"),R=c(),k=s("button"),b=s("ion-icon"),w=c(),O=s("span"),P=o("Request Permission"),this.h()},l(A){p=l(A,"P",{class:!0});var L=i(p);g=n(L,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),L.forEach(t),v=u(A),h=l(A,"LABEL",{for:!0});var D=i(h);m=n(D,"Github username:"),D.forEach(t),E=u(A),y=l(A,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),R=u(A),k=l(A,"BUTTON",{class:!0});var z=i(k);b=l(z,"ION-ICON",{class:!0,name:!0}),i(b).forEach(t),w=u(z),O=l(z,"SPAN",{});var x=i(O);P=n(x,"Request Permission"),x.forEach(t),z.forEach(t),this.h()},h(){r(p,"class","svelte-s12rf8"),r(h,"for","username"),r(y,"name","username"),r(y,"id","username"),r(y,"placeholder","enter a username"),r(y,"type","text"),y.required="true",r(y,"class",T=_[4]?"validation-error":""),ee(b,"class","icon svelte-s12rf8"),ee(b,"name","rocket-sharp"),r(k,"class","svelte-s12rf8")},m(A,L){d(A,p,L),e(p,g),d(A,v,L),d(A,h,L),e(h,m),d(A,E,L),d(A,y,L),zx(y,_[3]),d(A,R,L),d(A,k,L),e(k,b),e(k,w),e(k,O),e(O,P),N||(G=Ie(y,"input",_[14]),N=!0)},p(A,L){L&16&&T!==(T=A[4]?"validation-error":"")&&r(y,"class",T),L&8&&y.value!==A[3]&&zx(y,A[3])},d(A){A&&t(p),A&&t(v),A&&t(h),A&&t(E),A&&t(y),A&&t(R),A&&t(k),N=!1,G()}}}function SN(_){let p,g,v,h,m,E,y,T,R,k;return{c(){p=s("p"),g=o(_[5]),v=c(),h=s("button"),m=s("ion-icon"),E=c(),y=s("span"),T=o("Open Repository"),this.h()},l(b){p=l(b,"P",{class:!0});var w=i(p);g=n(w,_[5]),w.forEach(t),v=u(b),h=l(b,"BUTTON",{class:!0});var O=i(h);m=l(O,"ION-ICON",{class:!0,name:!0}),i(m).forEach(t),E=u(O),y=l(O,"SPAN",{});var P=i(y);T=n(P,"Open Repository"),P.forEach(t),O.forEach(t),this.h()},h(){r(p,"class","feedback svelte-s12rf8"),ee(m,"class","icon svelte-s12rf8"),ee(m,"name","rocket-sharp"),r(h,"class","svelte-s12rf8")},m(b,w){d(b,p,w),e(p,g),d(b,v,w),d(b,h,w),e(h,m),e(h,E),e(h,y),e(y,T),R||(k=Ie(h,"click",_[13]),R=!0)},p(b,w){w&32&&ce(g,b[5])},d(b){b&&t(p),b&&t(v),b&&t(h),R=!1,k()}}}function DN(_){var O;let p,g,v,h=((O=_[6].profile)==null?void 0:O.githubUsername)+"",m,E,y,T,R,k,b,w;return{c(){p=s("p"),g=o("This content can grant access to a private GitHub repository. Allow "),v=s("span"),m=o(h),E=o(" access to this repo?"),y=c(),T=s("button"),R=s("ion-icon"),k=c(),b=s("span"),w=o("Request Permission"),this.h()},l(P){p=l(P,"P",{class:!0});var N=i(p);g=n(N,"This content can grant access to a private GitHub repository. Allow "),v=l(N,"SPAN",{class:!0});var G=i(v);m=n(G,h),G.forEach(t),E=n(N," access to this repo?"),N.forEach(t),y=u(P),T=l(P,"BUTTON",{class:!0});var A=i(T);R=l(A,"ION-ICON",{class:!0,name:!0}),i(R).forEach(t),k=u(A),b=l(A,"SPAN",{});var L=i(b);w=n(L,"Request Permission"),L.forEach(t),A.forEach(t),this.h()},h(){r(v,"class","highlight svelte-s12rf8"),r(p,"class","svelte-s12rf8"),ee(R,"class","icon svelte-s12rf8"),ee(R,"name","rocket-sharp"),r(T,"class","svelte-s12rf8")},m(P,N){d(P,p,N),e(p,g),e(p,v),e(v,m),e(p,E),d(P,y,N),d(P,T,N),e(T,R),e(T,k),e(T,b),e(b,w)},p(P,N){var G;N&64&&h!==(h=((G=P[6].profile)==null?void 0:G.githubUsername)+"")&&ce(m,h)},d(P){P&&t(p),P&&t(y),P&&t(T)}}}function AN(_){let p,g,v,h,m,E,y,T,R,k;return{c(){p=s("p"),g=o(_[5]),v=c(),h=s("button"),m=s("ion-icon"),E=c(),y=s("span"),T=o("Open Repository"),this.h()},l(b){p=l(b,"P",{class:!0});var w=i(p);g=n(w,_[5]),w.forEach(t),v=u(b),h=l(b,"BUTTON",{class:!0});var O=i(h);m=l(O,"ION-ICON",{class:!0,name:!0}),i(m).forEach(t),E=u(O),y=l(O,"SPAN",{});var P=i(y);T=n(P,"Open Repository"),P.forEach(t),O.forEach(t),this.h()},h(){r(p,"class","feedback svelte-s12rf8"),ee(m,"class","icon svelte-s12rf8"),ee(m,"name","rocket-sharp"),r(h,"class","svelte-s12rf8")},m(b,w){d(b,p,w),e(p,g),d(b,v,w),d(b,h,w),e(h,m),e(h,E),e(h,y),e(y,T),R||(k=Ie(h,"click",_[12]),R=!0)},p(b,w){w&32&&ce(g,b[5])},d(b){b&&t(p),b&&t(v),b&&t(h),R=!1,k()}}}function LN(_){let p;function g(m,E){return typeof m[2]!="undefined"&&typeof m[2].pk!="undefined"?mN:gN}let v=g(_),h=v(_);return{c(){h.c(),p=Zf()},l(m){h.l(m),p=Zf()},m(m,E){h.m(m,E),d(m,p,E)},p(m,[E]){v===(v=g(m))&&h?h.p(m,E):(h.d(1),h=v(m),h&&(h.c(),h.m(p.parentNode,p)))},i:lS,o:lS,d(m){h.d(m),m&&t(p)}}}function sS(_){window.open(_,"_blank")||window.location.replace(_)}function IN(_,p,g){let{id:v}=p,{spacelabDefaultTitle:h="Spacelab Content"}=p,{spacelabDefaultContent:m="To access this content, you need a SpaceLab subscription."}=p,E={},y="",T=!1,R="",k;aS.subscribe(D=>{g(6,k=D)}),nN(async()=>{if(typeof(k==null?void 0:k.token)!="undefined"){const D=await fetch(`${tS().serviceUrl}/education/spacelab/${v}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors"});if(D.status===401){aS.set({}),aS.deleteLocalStorage();return}let z=await D.json();g(2,E=z)}else g(2,E.success=!1,E)});async function b(D){D.preventDefault();const z={};try{const x=await fetch(`${tS().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(z)});if(x.ok)g(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await x.json();g(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(x){console.error("Error while sending GitHub access request:",x),g(5,R="An unexpected error occurred. Please try again later.")}}async function w(D){if(D.preventDefault(),!y.trim()){g(4,T=!0),g(5,R="Please enter a valid GitHub username.");return}g(4,T=!1);const z={github_username:y};try{const x=await fetch(`${tS().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(z)});if(x.ok)g(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await x.json();g(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(x){console.error("Error while sending GitHub access request:",x),g(5,R="An unexpected error occurred. Please try again later.")}}const O=()=>window.open(E.url,"_blank"),P=()=>sS(`https://github.com/${E.github_repo_name}`),N=()=>sS(`https://github.com/${E.github_repo_name}`),G=()=>sS(`https://github.com/${E.github_repo_name}`);function A(){y=this.value,g(3,y)}const L=()=>window.open("/spacelab/","_blank");return _.$$set=D=>{"id"in D&&g(9,v=D.id),"spacelabDefaultTitle"in D&&g(0,h=D.spacelabDefaultTitle),"spacelabDefaultContent"in D&&g(1,m=D.spacelabDefaultContent)},[h,m,E,y,T,R,k,b,w,v,O,P,N,G,A,L]}class ON extends G2{constructor(p){super(),U2(this,p,IN,LN,H2,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const PN=_=>({}),qx=_=>({});function zN(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(g){p=n(g,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(g,v){d(g,p,v)},d(g){g&&t(p)}}}function xN(_){let p,g,v,h,m,E,y,T,R,k,b,w,O,P;const N=_[7]["slider-label"],G=cN(N,_,_[6],qx),A=G||zN();return{c(){p=s("div"),g=s("img"),h=c(),m=s("img"),y=c(),T=s("label"),R=s("span"),A&&A.c(),k=c(),b=s("input"),this.h()},l(L){p=l(L,"DIV",{class:!0,style:!0,"data-testid":!0});var D=i(p);g=l(D,"IMG",{src:!0,alt:!0,class:!0}),h=u(D),m=l(D,"IMG",{src:!0,alt:!0,class:!0}),y=u(D),T=l(D,"LABEL",{class:!0});var z=i(T);R=l(z,"SPAN",{class:!0});var x=i(R);A&&A.l(x),x.forEach(t),k=u(z),b=l(z,"INPUT",{type:!0,min:!0,max:!0,class:!0}),z.forEach(t),D.forEach(t),this.h()},h(){ta(g.src,v=_[0])||r(g,"src",v),r(g,"alt",_[1]),r(g,"class","left-img svelte-1po6qlg"),ta(m.src,E=_[2])||r(m,"src",E),r(m,"alt",_[3]),r(m,"class","right-img svelte-1po6qlg"),r(R,"class","visually-hidden svelte-1po6qlg"),r(b,"type","range"),r(b,"min","0"),r(b,"max","100"),b.value=_[4],r(b,"class","svelte-1po6qlg"),r(T,"class","svelte-1po6qlg"),r(p,"class","svelte-compare-image-container svelte-1po6qlg"),ea(p,"--slider-position",_[4]+"%"),r(p,"data-testid","svelte-compare-image")},m(L,D){d(L,p,D),e(p,g),e(p,h),e(p,m),e(p,y),e(p,T),e(T,R),A&&A.m(R,null),e(T,k),e(T,b),w=!0,O||(P=[Ie(b,"input",_[5]),Ie(b,"change",_[5]),Ie(b,"click",NN)],O=!0)},p(L,[D]){(!w||D&1&&!ta(g.src,v=L[0]))&&r(g,"src",v),(!w||D&2)&&r(g,"alt",L[1]),(!w||D&4&&!ta(m.src,E=L[2]))&&r(m,"src",E),(!w||D&8)&&r(m,"alt",L[3]),G&&G.p&&(!w||D&64)&&uN(G,N,L,L[6],w?fN(N,L[6],D,PN):dN(L[6]),qx),(!w||D&16)&&(b.value=L[4]),(!w||D&16)&&ea(p,"--slider-position",L[4]+"%")},i(L){w||(aa(A,L),w=!0)},o(L){sa(A,L),w=!1},d(L){L&&t(p),A&&A.d(L),O=!1,pN(P)}}}function NN(_){_.target.focus()}function CN(_,p,g){let{$$slots:v={},$$scope:h}=p,{imageLeftSrc:m=""}=p,{imageLeftAlt:E=""}=p,{imageRightSrc:y=""}=p,{imageRightAlt:T=""}=p,R=50,k=null;function b(w){k&&cancelAnimationFrame(k),k=requestAnimationFrame(()=>{g(4,R=w.target.valueAsNumber)})}return _.$$set=w=>{"imageLeftSrc"in w&&g(0,m=w.imageLeftSrc),"imageLeftAlt"in w&&g(1,E=w.imageLeftAlt),"imageRightSrc"in w&&g(2,y=w.imageRightSrc),"imageRightAlt"in w&&g(3,T=w.imageRightAlt),"$$scope"in w&&g(6,h=w.$$scope)},[m,E,y,T,R,b,h,v]}class GN extends G2{constructor(p){super(),U2(this,p,CN,xN,H2,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function UN(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(g){p=n(g,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(g,v){d(g,p,v)},d(g){g&&t(p)}}}function HN(_){let p,g,v,h;return g=new GN({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[UN]},$$scope:{ctx:_}}}),{c(){p=s("div"),v=s("div"),Ui(g.$$.fragment),this.h()},l(m){p=l(m,"DIV",{class:!0});var E=i(p);v=l(E,"DIV",{style:!0});var y=i(v);Hi(g.$$.fragment,y),E.forEach(t),this.h()},h(){ea(v,"display","contents"),ea(v,"--handle-size","2.5rem"),ea(v,"--handle-background-color","rgba(0, 0, 0, 0.6)"),ea(v,"--handle-background-image",_[4]),ea(v,"--handle-border-width","0.125rem"),ea(v,"--slider-color","#ffffff"),ea(v,"--slider-width","0.125rem"),r(p,"class","image-compare-container svelte-s79nww")},m(m,E){d(m,p,E),e(p,v),qi(g,v,null),h=!0},p(m,[E]){const y={};E&1&&(y.imageLeftSrc=m[0]),E&2&&(y.imageLeftAlt=m[1]),E&4&&(y.imageRightSrc=m[2]),E&8&&(y.imageRightAlt=m[3]),E&32&&(y.$$scope={dirty:E,ctx:m}),g.$set(y)},i(m){h||(aa(g.$$.fragment,m),h=!0)},o(m){sa(g.$$.fragment,m),h=!1},d(m){m&&t(p),Mi(g)}}}function qN(_,p,g){const v=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=p,{imageLeftAlt:m="left"}=p,{imageRightSrc:E="https://via.placeholder.com/512x512/00aaff/ffffff/"}=p,{imageRightAlt:y="right"}=p;return _.$$set=T=>{"imageLeftSrc"in T&&g(0,h=T.imageLeftSrc),"imageLeftAlt"in T&&g(1,m=T.imageLeftAlt),"imageRightSrc"in T&&g(2,E=T.imageRightSrc),"imageRightAlt"in T&&g(3,y=T.imageRightAlt)},[h,m,E,y,v]}class C2 extends G2{constructor(p){super(),U2(this,p,qN,HN,H2,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function MN(_){let p,g;return p=new ON({props:{id:jN,spacelabDefaultTitle:FN,spacelabDefaultContent:VN}}),{c(){Ui(p.$$.fragment)},l(v){Hi(p.$$.fragment,v)},m(v,h){qi(p,v,h),g=!0},p:lS,i(v){g||(aa(p.$$.fragment,v),g=!0)},o(v){sa(p.$$.fragment,v),g=!1},d(v){Mi(p,v)}}}function BN(_){let p,g,v,h,m,E,y,T,R,k,b,w,O,P,N,G,A,L,D,z,x,Q,j,F,B,C,I,U,Z,H,S,q,la,Oe,de,Qf,Lv,Bi,q2,Iv,ia,ra,Jf,M2,Ov,Wi,B2,Pv,pl,ji,W2,zv,hl,xv,Fi,j2,Nv,Vi,F2,Cv,Ki,V2,Gv,qt,Yi,Pe,Xi,K2,Y2,Zi,X2,Z2,Qi,Q2,J2,ze,xe,Ji,$f,$2,e_,$i,t_,a_,er,s_,l_,Ne,tr,ep,i_,r_,ar,o_,n_,sr,c_,u_,Ce,lr,tp,d_,f_,ir,p_,h_,rr,v_,Uv,or,g_,Hv,nr,m_,qv,vl,cr,__,Mv,oa,na,ap,E_,Bv,gl,sp,b_,y_,Wv,ml,lp,k_,w_,jv,_l,ip,T_,R_,Fv,ca,ua,rp,S_,Vv,El,op,D_,A_,Kv,bl,np,L_,I_,Yv,yl,cp,O_,P_,Xv,da,fa,up,z_,Zv,kl,dp,x_,N_,Qv,Ge,C_,fp,G_,U_,pp,H_,q_,Jv,Ue,ur,hp,M_,B_,W_,dr,vp,j_,F_,V_,pa,gp,K_,Y_,fr,X_,Z_,$v,wl,pr,Q_,eg,ha,va,mp,_p,J_,tg,hr,$_,ag,He,vr,Ep,e0,t0,a0,gr,bp,s0,l0,i0,mr,yp,r0,o0,sg,ga,ma,kp,wp,n0,lg,Mt,_r,qe,Er,Tp,c0,u0,br,Rp,d0,f0,yr,Sp,p0,h0,fe,Me,kr,Dp,v0,g0,wr,m0,_0,Tr,E0,b0,Be,Rr,Ap,y0,k0,Sr,w0,T0,Dr,R0,S0,We,Ar,Lp,D0,A0,Lr,L0,I0,Ir,O0,P0,je,Or,Ip,z0,x0,Pr,N0,C0,zr,G0,ig,_a,Ea,Op,U0,rg,Bt,xr,ba,Nr,H0,q0,Cr,M0,B0,pe,ya,Gr,Pp,W0,j0,Ur,F0,V0,ka,Hr,zp,K0,Y0,qr,X0,Z0,wa,Mr,xp,Q0,J0,Br,$0,eE,Ta,Wr,Np,tE,aE,jr,sE,og,Fr,lE,ng,Ra,Sa,Cp,iE,cg,he,rE,Gp,oE,nE,Vr,cE,uE,Kr,dE,fE,ug,ve,pE,Yr,hE,vE,Xr,gE,mE,Zr,_E,EE,dg,Tl,Bx=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,fg,Rl,Wx=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,pg,Da,Aa,Up,bE,hg,Wt,Qr,Fe,Jr,yE,kE,$r,wE,TE,eo,RE,SE,ge,Ve,to,DE,AE,ao,LE,IE,so,OE,PE,Ke,lo,zE,xE,io,NE,CE,ro,GE,UE,Ye,oo,HE,qE,no,ME,BE,co,WE,jE,Xe,uo,FE,VE,fo,KE,YE,po,XE,vg,ho,ZE,gg,vo,QE,mg,go,JE,_g,Eg,bg,La,Ia,Hp,$E,yg,Oa,eb,Sl,tb,ab,kg,Pa,za,qp,sb,wg,xa,lb,Dl,ib,rb,Tg,Al,jx=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,Rg,Na,Ca,Mp,ob,Sg,Ze,Bp,nb,cb,Wp,ub,db,jp,fb,Dg,Ga,Ua,Fp,pb,Ag,Qe,Vp,hb,vb,Kp,gb,mb,Yp,_b,Lg,Ha,qa,Xp,Eb,Ig,Ll,Zp,bb,yb,Og,Il,Fx=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,Pg,Ma,Ba,Qp,kb,zg,Je,Jp,wb,Tb,$p,Rb,Sb,eh,Db,xg,Ol,mo,Ab,Ng,Wa,ja,th,Lb,Cg,Pl,ah,Ib,Ob,Gg,_o,Pb,Ug,$e,zl,zb,Eo,xb,Nb,Cb,sh,Gb,Ub,lh,Hb,Hg,xl,bo,qb,qg,Fa,Va,ih,Mb,Mg,Nl,rh,Bb,Wb,Bg,Cl,Vx=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Wg,yo,jb,jg,et,oh,Fb,Vb,nh,Kb,Yb,ch,Xb,Fg,Gl,ko,Zb,Vg,Ka,Ya,uh,Qb,Kg,Xa,Jb,dh,$b,ey,Yg,Ul,Kx=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,Xg,jt,wo,tt,To,ty,ay,Ro,sy,ly,So,iy,ry,at,st,Do,Ao,oy,ny,Lo,cy,uy,Io,dy,fy,lt,Oo,Po,py,hy,zo,vy,gy,xo,my,_y,it,No,Co,Ey,by,Go,yy,ky,Uo,wy,Zg,Za,Qa,fh,Ty,Qg,rt,Hl,Ry,Ho,Sy,Dy,Ay,De,Ly,qo,Iy,Oy,Mo,Py,zy,Bo,xy,Ny,Cy,Ft,Gy,Wo,Uy,Hy,jo,qy,My,Jg,Ja,$a,ph,By,$g,Fo,Wy,em,Vo,es,hh,jy,Fy,Ko,Vy,Ky,tm,ts,as,vh,Yy,am,ot,gh,Xy,Zy,mh,Qy,Jy,_h,$y,sm,Yo,e4,lm,ss,ls,Eh,t4,im,Xo,a4,rm,is,Zo,bh,s4,l4,i4,ql,yh,r4,o4,Vt,Qo,kh,n4,c4,u4,Jo,wh,d4,f4,p4,$o,Th,h4,v4,om,en,g4,nm,rs,tn,Rh,m4,_4,E4,an,Sh,b4,y4,cm,sn,k4,um,Ml,Dh,w4,T4,dm,nt,Ah,R4,S4,Lh,D4,A4,Ih,L4,fm,Kt,ln,me,rn,I4,O4,on,P4,z4,nn,x4,N4,cn,C4,G4,le,_e,un,U4,H4,dn,q4,M4,fn,B4,W4,pn,j4,F4,Ee,hn,V4,K4,vn,Y4,X4,gn,Z4,Q4,mn,J4,$4,be,_n,ek,tk,En,ak,sk,os,lk,Oh,ik,rk,ok,ct,nk,bn,ck,uk,yn,dk,fk,pk,ye,kn,hk,vk,wn,gk,mk,Tn,_k,Ek,Rn,bk,yk,ke,Sn,kk,wk,Dn,Tk,Rk,An,Sk,Dk,Ln,Ak,pm,hm,vm,ns,cs,Ph,Lk,gm,us,Ik,In,Ok,Pk,mm,ue,zk,On,xk,Nk,Pn,Ck,Gk,zn,Uk,Hk,xn,qk,_m,Nn,Mk,Em,ds,fs,zh,Bk,bm,ut,xh,Bl,Nh,Wk,jk,Fk,Vk,Ch,Wl,Gh,Kk,Yk,Xk,Zk,Uh,jl,Hh,Qk,Jk,$k,ym,Fl,km,ps,hs,qh,e3,wm,vs,t3,Vl,a3,s3,Tm,dt,l3,Cn,i3,r3,Gn,o3,n3,Rm,J,Mh,Un,c3,Hn,u3,d3,Bh,Kl,f3,qn,p3,h3,v3,Wh,K,g3,Mn,m3,_3,Bn,E3,b3,Wn,y3,k3,jn,w3,T3,Fn,R3,S3,Vn,D3,A3,Kn,L3,I3,Yn,O3,P3,jh,$,z3,Xn,x3,N3,Zn,C3,G3,Qn,U3,H3,Jn,q3,M3,$n,B3,W3,ec,j3,F3,tc,V3,K3,Fh,Y,Y3,ac,X3,Z3,sc,Q3,J3,lc,$3,e5,ic,t5,a5,rc,s5,l5,oc,i5,r5,nc,o5,n5,cc,c5,u5,Vh,uc,d5,dc,f5,p5,Kh,gs,h5,fc,v5,g5,pc,m5,Sm,ft,_5,hc,E5,b5,vc,y5,k5,Dm,Yl,Am,ms,_s,Yh,w5,Lm,gc,T5,Im,we,mc,Xl,R5,S5,D5,_c,Zl,A5,L5,I5,Ec,Ql,O5,P5,z5,bc,Jl,x5,N5,Om,Es,bs,Xh,C5,Pm,yc,G5,zm,kc,U5,xm,pt,wc,Zh,H5,q5,M5,ht,Qh,B5,W5,Tc,j5,F5,Rc,V5,K5,Y5,Sc,Jh,X5,Z5,Nm,$l,Yx=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,Cm,ys,ei,Q5,Dc,J5,$5,ew,ti,tw,Ac,aw,sw,Gm,ks,$h,lw,iw,Lc,rw,Um,ws,Ts,ev,ow,Hm,vt,nw,ai,cw,uw,si,dw,fw,qm,li,Rs,pw,ii,hw,vw,Mm,ri,Ae,gw,oi,mw,_w,ni,Ew,bw,ci,yw,Bm,Ss,Ds,tv,kw,Wm,As,ww,Ic,Tw,Rw,jm,ui,Xx=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Fm,Oc,Sw,Vm,di,Zx='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Km,Ls,Dw,Pc,Aw,Lw,Ym,fi,Is,Iw,zc,Ow,Pw,Xm,gt,zw,xc,xw,Nw,Nc,Cw,Gw,Zm,Cc,Uw,Qm,Os,Gc,Hw,av,sv,qw,Mw,Uc,Bw,lv,iv,Ww,Jm,Hc,jw,$m,pi,hi,oS,e1,Ps,zs,rv,Fw,t1,Yt,Vw,qc,Kw,Yw,Mc,Xw,a1,Xt,Bc,ie,Wc,Zw,Qw,jc,Jw,$w,Fc,e6,t6,Vc,a6,s6,Kc,l6,i6,Yc,re,Xc,r6,o6,Zc,n6,c6,Qc,u6,d6,Jc,f6,p6,$c,h6,s1,eu,v6,l1,vi,Qx=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,i1,M,tu,gi,g6,au,m6,_6,E6,b6,su,mi,y6,lu,k6,w6,T6,R6,iu,_i,S6,ru,D6,A6,L6,I6,ou,Ei,O6,nu,P6,z6,x6,N6,cu,ov,C6,G6,U6,uu,bi,H6,du,q6,M6,B6,W6,fu,yi,j6,pu,F6,V6,K6,Y6,hu,ki,X6,vu,Z6,Q6,J6,$6,gu,wi,e8,mu,t8,a8,s8,l8,_u,Ti,i8,Eu,r8,o8,n8,c8,bu,Ri,u8,yu,d8,f8,p8,r1,xs,Ns,nv,h8,o1,ku,v8,n1,Si,c1,Cs,Gs,cv,g8,u1,Us,m8,Di,_8,E8,d1,Hs,b8,wu,y8,k8,f1,oe,Tu,w8,p1,T8,uv,R8,S8,mt,D8,Ru,A8,L8,Su,I8,O8,Du,P8,z8,Au,x8,Lu,N8,C8,qs,G8,Iu,U8,H8,Ou,q8,h1,_t,M8,Pu,B8,W8,zu,j8,F8,v1,Te,Ms,V8,xu,K8,Y8,Nu,X8,Z8,Ai,Q8,Cu,J8,$8,e7,dv,t7,a7,fv,s7,g1,Bs,Ws,pv,l7,m1,Re,Gu,hv,i7,r7,o7,Uu,vv,n7,c7,u7,Hu,gv,d7,f7,p7,qu,mv,h7,v7,_1,Mu,g7,E1,Li,Ii,nS,b1,js,Fs,_v,m7,y1,Bu,_7,k1,Et,Oi,E7,Wu,b7,y7,k7,Pi,w7,ju,T7,R7,S7,Ev,D7,w1,Zt,Fu,bt,Vu,A7,L7,Ku,I7,O7,Yu,P7,z7,Se,yt,Xu,x7,N7,Zu,C7,G7,Qu,U7,H7,kt,Ju,q7,M7,$u,B7,W7,ed,j7,F7,wt,td,V7,K7,ad,Y7,X7,sd,Z7,Q7,Tt,ld,J7,$7,id,eT,tT,rd,aT,T1,Vs,Ks,bv,sT,R1,od,lT,S1,Qt,nd,Rt,cd,iT,rT,ud,oT,nT,dd,cT,uT,W,St,fd,dT,fT,pd,pT,hT,hd,vT,gT,Dt,vd,mT,_T,gd,ET,bT,md,yT,kT,At,_d,wT,TT,Ed,RT,ST,bd,DT,AT,Lt,yd,LT,IT,kd,OT,PT,wd,zT,xT,It,Td,NT,CT,Rd,GT,UT,Sd,HT,qT,Ot,Dd,MT,BT,Ad,WT,jT,Ld,FT,VT,Pt,Id,KT,YT,Od,XT,ZT,Pd,QT,JT,zt,zd,$T,e9,xd,t9,a9,Nd,s9,l9,xt,Cd,i9,r9,Gd,o9,n9,Ud,c9,u9,Nt,Hd,d9,f9,qd,p9,h9,Md,v9,D1,Ys,Xs,yv,g9,A1,Bd,m9,L1,Wd,_9,I1,zi,xi,cS,O1,jd,E9,P1,Jt,Zs,kv,b9,z1,x1,N1;hl=new C2({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),Fl=new C2({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),Yl=new C2({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Si=new C2({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let Le=Mx&&MN();return{c(){p=s("p"),g=o("Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),v=c(),h=s("p"),m=o("I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),E=c(),y=s("h4"),T=s("a"),R=s("span"),k=o("Experiment 1: Anime-Inspired Heroism"),b=c(),w=s("p"),O=s("img"),N=c(),G=s("p"),A=o("I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),L=c(),D=s("ul"),z=s("li"),x=o("My action figure photos (for costume accuracy)."),Q=c(),j=s("li"),F=o("Stylized anime references (for anatomy and texture)."),B=c(),C=s("p"),I=o("The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),U=c(),Z=s("h4"),H=s("a"),S=s("span"),q=o("Experiment 2: Retro Cartoon Resurrection"),la=c(),Oe=s("p"),de=s("img"),Lv=c(),Bi=s("p"),q2=o("Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),Iv=c(),ia=s("h2"),ra=s("a"),Jf=s("span"),M2=o("What are Regularization Images?"),Ov=c(),Wi=s("p"),B2=o("Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),Pv=c(),pl=s("blockquote"),ji=s("p"),W2=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),zv=c(),Ui(hl.$$.fragment),xv=c(),Fi=s("p"),j2=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Nv=c(),Vi=s("p"),F2=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),Cv=c(),Ki=s("p"),V2=o("Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),Gv=c(),qt=s("table"),Yi=s("thead"),Pe=s("tr"),Xi=s("th"),K2=o("Aspect"),Y2=c(),Zi=s("th"),X2=o("Regularization"),Z2=c(),Qi=s("th"),Q2=o("No Regularization"),J2=c(),ze=s("tbody"),xe=s("tr"),Ji=s("td"),$f=s("strong"),$2=o("Class Definition"),e_=c(),$i=s("td"),t_=o("Explicit anchoring"),a_=c(),er=s("td"),s_=o("Implicit learning"),l_=c(),Ne=s("tr"),tr=s("td"),ep=s("strong"),i_=o("Failure Modes"),r_=c(),ar=s("td"),o_=o("Underfitting if overdone"),n_=c(),sr=s("td"),c_=o("Overfitting/drift"),u_=c(),Ce=s("tr"),lr=s("td"),tp=s("strong"),d_=o("Data Efficiency"),f_=c(),ir=s("td"),p_=o("Better generalization"),h_=c(),rr=s("td"),v_=o("Requires more data"),Uv=c(),or=s("p"),g_=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Hv=c(),nr=s("p"),m_=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),qv=c(),vl=s("blockquote"),cr=s("p"),__=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Mv=c(),oa=s("h4"),na=s("a"),ap=s("span"),E_=o("Scenario 1: Limited Training Data"),Bv=c(),gl=s("p"),sp=s("strong"),b_=o("Situation"),y_=o(": You only have a few images of your cat and no other cat images."),Wv=c(),ml=s("p"),lp=s("strong"),k_=o("Problem"),w_=o(": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),jv=c(),_l=s("p"),ip=s("strong"),T_=o("Solution"),R_=o(": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Fv=c(),ca=s("h4"),ua=s("a"),rp=s("span"),S_=o("Scenario 2: Imbalanced Training Data"),Vv=c(),El=s("p"),op=s("strong"),D_=o("Situation"),A_=o(": You have many images of other cats but only a few of your cat."),Kv=c(),bl=s("p"),np=s("strong"),L_=o("Problem"),I_=o(": The model may focus too much on the other cats, failing to learn the unique features of your cat."),Yv=c(),yl=s("p"),cp=s("strong"),O_=o("Solution"),P_=o(": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Xv=c(),da=s("h2"),fa=s("a"),up=s("span"),z_=o("Divergence"),Zv=c(),kl=s("p"),dp=s("strong"),x_=o("Divergence"),N_=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Qv=c(),Ge=s("p"),C_=o("Preventing divergence starts with "),fp=s("strong"),G_=o("careful dataset curation"),U_=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),pp=s("strong"),H_=o("regularization techniques"),q_=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Jv=c(),Ue=s("ul"),ur=s("li"),hp=s("strong"),M_=o("Chaotic outputs"),B_=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),W_=c(),dr=s("li"),vp=s("strong"),j_=o("Exploding gradients"),F_=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),V_=c(),pa=s("li"),gp=s("strong"),K_=o("Loss value instability (NaN/infinity values)"),Y_=o(" The training loss fluctuates wildly, sometimes becoming "),fr=s("code"),X_=o("NaN"),Z_=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),$v=c(),wl=s("blockquote"),pr=s("p"),Q_=o("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),eg=c(),ha=s("h2"),va=s("a"),mp=s("span"),_p=s("strong"),J_=o("Overfitting"),tg=c(),hr=s("p"),$_=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),ag=c(),He=s("ul"),vr=s("li"),Ep=s("strong"),e0=o("Perfectly replicates training samples"),t0=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),a0=c(),gr=s("li"),bp=s("strong"),s0=o("Fails to generalize to new inputs"),l0=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),i0=c(),mr=s("li"),yp=s("strong"),r0=o("Shows excellent training loss but poor validation loss"),o0=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),sg=c(),ga=s("h3"),ma=s("a"),kp=s("span"),wp=s("strong"),n0=o("Key Differences"),lg=c(),Mt=s("table"),_r=s("thead"),qe=s("tr"),Er=s("th"),Tp=s("strong"),c0=o("Aspect"),u0=c(),br=s("th"),Rp=s("strong"),d0=o("Divergence"),f0=c(),yr=s("th"),Sp=s("strong"),p0=o("Overfitting"),h0=c(),fe=s("tbody"),Me=s("tr"),kr=s("td"),Dp=s("strong"),v0=o("Cause"),g0=c(),wr=s("td"),m0=o("Excessive learning rate"),_0=c(),Tr=s("td"),E0=o("Insufficient regularization"),b0=c(),Be=s("tr"),Rr=s("td"),Ap=s("strong"),y0=o("Loss Behavior"),k0=c(),Sr=s("td"),w0=o("Sudden spikes/NaN values"),T0=c(),Dr=s("td"),R0=o("Steady decrease then rise"),S0=c(),We=s("tr"),Ar=s("td"),Lp=s("strong"),D0=o("Output Quality"),A0=c(),Lr=s("td"),L0=o("Random noise/artifacts"),I0=c(),Ir=s("td"),O0=o("Overly detailed replicas"),P0=c(),je=s("tr"),Or=s("td"),Ip=s("strong"),z0=o("Recovery"),x0=c(),Pr=s("td"),N0=o("Requires restart"),C0=c(),zr=s("td"),G0=o("Early stopping works"),ig=c(),_a=s("h3"),Ea=s("a"),Op=s("span"),U0=o("Preventing Divergence"),rg=c(),Bt=s("table"),xr=s("thead"),ba=s("tr"),Nr=s("th"),H0=o("Situation"),q0=c(),Cr=s("th"),M0=o("Outcome"),B0=c(),pe=s("tbody"),ya=s("tr"),Gr=s("td"),Pp=s("strong"),W0=o("Excessive/inconsistent data"),j0=c(),Ur=s("td"),F0=o("Model struggles to learn and produces unreliable predictions."),V0=c(),ka=s("tr"),Hr=s("td"),zp=s("strong"),K0=o("Lack of unique features"),Y0=c(),qr=s("td"),X0=o("Poor generalization leading to inaccurate outputs."),Z0=c(),wa=s("tr"),Mr=s("td"),xp=s("strong"),Q0=o("Carefully curated datasets"),J0=c(),Br=s("td"),$0=o("Improved learning by ensuring the model sees only relevant, high-quality data."),eE=c(),Ta=s("tr"),Wr=s("td"),Np=s("strong"),tE=o("Regularization techniques"),aE=c(),jr=s("td"),sE=o("Helps maintain focus on essential features and prevents instability."),og=c(),Fr=s("p"),lE=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),ng=c(),Ra=s("h3"),Sa=s("a"),Cp=s("span"),iE=o("Implement these Strategies"),cg=c(),he=s("p"),rE=o("To prevent divergence and overfitting during training, carefully configure your training parameters and regularization techniques. Start with a "),Gp=s("strong"),oE=o("conservative learning rate"),nE=o(" (e.g., "),Vr=s("code"),cE=o("1e-5"),uE=o(") to avoid sudden spikes or NaN values in the loss, which are signs of divergence. Use gradient clipping ("),Kr=s("code"),dE=o("max_grad_norm: 1.0"),fE=o(") to stabilize training by preventing excessively large updates to the model weights. A cosine learning rate scheduler ensures a smooth and stable adjustment of the learning rate over time, reducing the risk of instability."),ug=c(),ve=s("p"),pE=o("For regularization, incorporate techniques like dropout ("),Yr=s("code"),hE=o("dropout_prob: 0.1"),vE=o(") to prevent the model from over-relying on specific features, improving generalization. Use a small batch size ("),Xr=s("code"),gE=o("train_batch_size: 2"),mE=o(") to introduce noise into the training process, which can help avoid overfitting. Additionally, limit the number of training steps ("),Zr=s("code"),_E=o("max_train_steps: 1500"),EE=o(") to prevent the model from memorizing the dataset.  By combining these strategies, you can train a robust model that generalizes well and avoids divergence / overfitting."),dg=c(),Tl=s("pre"),fg=c(),Rl=s("pre"),pg=c(),Da=s("h4"),Aa=s("a"),Up=s("span"),bE=o("Data Considerations"),hg=c(),Wt=s("table"),Qr=s("thead"),Fe=s("tr"),Jr=s("th"),yE=o("Situation"),kE=c(),$r=s("th"),wE=o("Actual Risk"),TE=c(),eo=s("th"),RE=o("Solution"),SE=c(),ge=s("tbody"),Ve=s("tr"),to=s("td"),DE=o("High LR + small batch size"),AE=c(),ao=s("td"),LE=o("Divergence"),IE=c(),so=s("td"),OE=o("Lower LR, increase batch size"),PE=c(),Ke=s("tr"),lo=s("td"),zE=o("Inconsistent features"),xE=c(),io=s("td"),NE=o("Overfitting"),CE=c(),ro=s("td"),GE=o("Improve dataset consistency"),UE=c(),Ye=s("tr"),oo=s("td"),HE=o("Insufficient reg images"),qE=c(),no=s("td"),ME=o("Class leakage"),BE=c(),co=s("td"),WE=o("Add 100-300 class images"),jE=c(),Xe=s("tr"),uo=s("td"),FE=o("High variance in training data"),VE=c(),fo=s("td"),KE=o("Mode collapse"),YE=c(),po=s("td"),XE=o("Curate focused dataset"),vg=c(),ho=s("p"),ZE=o("This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs\u2014fix this by lowering the learning rate and increasing the batch size."),gg=c(),vo=s("p"),QE=o("Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects\u2014adding 100-300 images helps."),mg=c(),go=s("p"),JE=o("High variance in training data can result in mode collapse, producing repetitive outputs\u2014keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),_g=c(),Eg=s("hr"),bg=c(),La=s("h2"),Ia=s("a"),Hp=s("span"),$E=o("Monitoring Tips"),yg=c(),Oa=s("p"),eb=o("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Sl=s("a"),tb=o("kohya-ss/sd-scripts"),ab=o(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),kg=c(),Pa=s("h3"),za=s("a"),qp=s("span"),sb=o("Track loss curves"),wg=c(),xa=s("p"),lb=o("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Dl=s("a"),ib=o("TensorBoard"),rb=o(" to create these graphs."),Tg=c(),Al=s("pre"),Rg=c(),Na=s("h4"),Ca=s("a"),Mp=s("span"),ob=o("What to Monitor:"),Sg=c(),Ze=s("ul"),Bp=s("li"),nb=o("Training Loss: Should decrease steadily but not too quickly."),cb=c(),Wp=s("li"),ub=o("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),db=c(),jp=s("li"),fb=o("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),Dg=c(),Ga=s("h4"),Ua=s("a"),Fp=s("span"),pb=o("Warning Signs:"),Ag=c(),Qe=s("ul"),Vp=s("li"),hb=o("Sudden spikes in loss \u2192 Likely divergence."),vb=c(),Kp=s("li"),gb=o("Loss plateauing too early \u2192 Learning rate may be too low."),mb=c(),Yp=s("li"),_b=o("Validation loss increasing while training loss decreases \u2192 Overfitting."),Lg=c(),Ha=s("h4"),qa=s("a"),Xp=s("span"),Eb=o("Generate validation images every 100 steps"),Ig=c(),Ll=s("p"),Zp=s("strong"),bb=o("Why It Matters"),yb=o(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),Og=c(),Il=s("pre"),Pg=c(),Ma=s("h4"),Ba=s("a"),Qp=s("span"),kb=o("What to Look For:"),zg=c(),Je=s("ul"),Jp=s("li"),wb=o("Consistency: Outputs should align with the training data style."),Tb=c(),$p=s("li"),Rb=o("Artifacts: Check for distortions, noise, or unnatural features."),Sb=c(),eh=s("li"),Db=o("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),xg=c(),Ol=s("blockquote"),mo=s("p"),Ab=o("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),Ng=c(),Wa=s("h4"),ja=s("a"),th=s("span"),Lb=o("Use Gradient Clipping"),Cg=c(),Pl=s("p"),ah=s("strong"),Ib=o("Why It Matters"),Ob=o(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),Gg=c(),_o=s("p"),Pb=o("Key Insights:"),Ug=c(),$e=s("ul"),zl=s("li"),zb=o("Gradient Norm "),Eo=s("code"),xb=o("<"),Nb=o(" than 0.1: Training may stall due to tiny updates."),Cb=c(),sh=s("li"),Gb=o("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),Ub=c(),lh=s("li"),Hb=o("Ideal Range: 0.1 to 2.0 for stable training."),Hg=c(),xl=s("blockquote"),bo=s("p"),qb=o("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),qg=c(),Fa=s("h4"),Va=s("a"),ih=s("span"),Mb=o("Enable Mixed Precision Training"),Mg=c(),Nl=s("p"),rh=s("strong"),Bb=o("Why It Matters"),Wb=o(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),Bg=c(),Cl=s("pre"),Wg=c(),yo=s("p"),jb=o("Benefits:"),jg=c(),et=s("ul"),oh=s("li"),Fb=o("2-3x Faster Training: Leverages GPU tensor cores."),Vb=c(),nh=s("li"),Kb=o("50% Less VRAM Usage: Allows larger batch sizes or models."),Yb=c(),ch=s("li"),Xb=o("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),Fg=c(),Gl=s("blockquote"),ko=s("p"),Zb=o("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),Vg=c(),Ka=s("h4"),Ya=s("a"),uh=s("span"),Qb=o("Start with Conservative Learning Rates"),Kg=c(),Xa=s("p"),Jb=o("Start off with 1e-5 to 1e-6.  "),dh=s("strong"),$b=o("Why It Matters"),ey=o(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Yg=c(),Ul=s("pre"),Xg=c(),jt=s("table"),wo=s("thead"),tt=s("tr"),To=s("th"),ty=o("Option"),ay=c(),Ro=s("th"),sy=o("Values"),ly=c(),So=s("th"),iy=o("Effect"),ry=c(),at=s("tbody"),st=s("tr"),Do=s("td"),Ao=s("code"),oy=o("learning_rate"),ny=c(),Lo=s("td"),cy=o("0.005 - 0.0001"),uy=c(),Io=s("td"),dy=o("Main control for learning rate. Sets defaults for the other two."),fy=c(),lt=s("tr"),Oo=s("td"),Po=s("code"),py=o("unet_lr"),hy=c(),zo=s("td"),vy=o("0.0001 - 0.005"),gy=c(),xo=s("td"),my=o("Sets Unet\u2019s learning rate. Most sensitive part; avoid setting too high."),_y=c(),it=s("tr"),No=s("td"),Co=s("code"),Ey=o("text_encoder_lr"),by=c(),Go=s("td"),yy=o("0.00001 - 0.00005"),ky=c(),Uo=s("td"),wy=o("Sets text encoder\u2019s learning rate. Keep much lower than Unet\u2019s."),Zg=c(),Za=s("h4"),Qa=s("a"),fh=s("span"),Ty=o("What does this mean?"),Qg=c(),rt=s("ul"),Hl=s("li"),Ry=o("If you don\u2019t want to fine-tune, just use "),Ho=s("code"),Sy=o("--learning_rate"),Dy=o(" to set the other two automatically."),Ay=c(),De=s("li"),Ly=o("If you want more control, set "),qo=s("code"),Iy=o("--unet_lr"),Oy=o(" and "),Mo=s("code"),Py=o("--text_encoder_lr"),zy=o(" individually. Setting "),Bo=s("code"),xy=o("--learning_rate"),Ny=o(" becomes redundant in this case."),Cy=c(),Ft=s("li"),Gy=o("A common approach is to set "),Wo=s("code"),Uy=o("--learning_rate"),Hy=o(" the same as "),jo=s("code"),qy=o("--unet_lr"),My=o(" for simplicity."),Jg=c(),Ja=s("h4"),$a=s("a"),ph=s("span"),By=o("Text Encoder Learning Rate"),$g=c(),Fo=s("p"),Wy=o("The text encoder interprets text prompts and links tags/tokens to data in the Unet during training."),em=c(),Vo=s("ul"),es=s("li"),hh=s("strong"),jy=o("Default Value"),Fy=o(": 5e-5 (or uses "),Ko=s("code"),Vy=o("--learning_rate"),Ky=o(" if not specified)."),tm=c(),ts=s("h4"),as=s("a"),vh=s("span"),Yy=o("Effects:"),am=c(),ot=s("ul"),gh=s("li"),Xy=o("Lowering it helps separate objects better in generations."),Zy=c(),mh=s("li"),Qy=o("If unwanted objects appear, try lowering it."),Jy=c(),_h=s("li"),$y=o("If prompts require heavy weighting to make things appear, it\u2019s set too low."),sm=c(),Yo=s("p"),e4=o("A well-trained text encoder improves prompt control and feature granularity."),lm=c(),ss=s("h4"),ls=s("a"),Eh=s("span"),t4=o("Unet Learning Rate"),im=c(),Xo=s("p"),a4=o("The Unet acts as the model\u2019s \u201Cvisual memory,\u201D handling image structure, detail, and relationships between elements."),rm=c(),is=s("ul"),Zo=s("li"),bh=s("strong"),s4=o("Default Value"),l4=o(": 1e-4 (avoid changing unless necessary)."),i4=c(),ql=s("li"),yh=s("strong"),r4=o("Issues & Fixes"),o4=o(":"),Vt=s("ul"),Qo=s("li"),kh=s("strong"),n4=o("Overfitting"),c4=o(": Reduce learning rate, steps, or use dampeners."),u4=c(),Jo=s("li"),wh=s("strong"),d4=o("Visual Noise (blobs)"),f4=o(": Learning rate is too high\u2014divide by at least 8."),p4=c(),$o=s("li"),Th=s("strong"),h4=o("Weak Details"),v4=o(": Increase learning rate or train for more steps."),om=c(),en=s("p"),g4=o("The Unet works progressively, starting with broad shapes and adding finer details. Overcooking it can lead to misplaced or excessive features (e.g., eyes everywhere)."),nm=c(),rs=s("ul"),tn=s("li"),Rh=s("strong"),m4=o("Visualization"),_4=o(": Think of it as zooming in from a blurry silhouette to pixel-level detail."),E4=c(),an=s("li"),Sh=s("strong"),b4=o("Structure"),y4=o(": IN blocks handle planning, OUT blocks manage fine details like texture."),cm=c(),sn=s("p"),k4=o("Burning the Unet results in chaotic outputs."),um=c(),Ml=s("p"),Dh=s("strong"),w4=o("Warning Signs"),T4=o(":"),dm=c(),nt=s("ul"),Ah=s("li"),R4=o("Loss Spikes: Learning rate is too high."),S4=c(),Lh=s("li"),D4=o("Slow Convergence: Learning rate is too low."),A4=c(),Ih=s("li"),L4=o("Oscillating Loss: Poor scheduling or unstable gradients."),fm=c(),Kt=s("table"),ln=s("thead"),me=s("tr"),rn=s("th"),I4=o("Practice"),O4=c(),on=s("th"),P4=o("Key Benefit"),z4=c(),nn=s("th"),x4=o("Tool/Setting"),N4=c(),cn=s("th"),C4=o("Warning Signs"),G4=c(),le=s("tbody"),_e=s("tr"),un=s("td"),U4=o("Track Loss Curves"),H4=c(),dn=s("td"),q4=o("Detect overfitting/divergence early"),M4=c(),fn=s("td"),B4=o("TensorBoard, Weights & Biases"),W4=c(),pn=s("td"),j4=o("Spikes, plateaus, growing gaps"),F4=c(),Ee=s("tr"),hn=s("td"),V4=o("Generate Validation Images"),K4=c(),vn=s("td"),Y4=o("Visualize model progress"),X4=c(),gn=s("td"),Z4=o("Fixed prompts/seeds"),Q4=c(),mn=s("td"),J4=o("Artifacts, mode collapse"),$4=c(),be=s("tr"),_n=s("td"),ek=o("Gradient Clipping"),tk=c(),En=s("td"),ak=o("Prevent exploding gradients"),sk=c(),os=s("td"),lk=o("clip"),Oh=s("em"),ik=o("grad_norm"),rk=o(" (1.0-2.0)"),ok=c(),ct=s("td"),nk=o("Norm "),bn=s("code"),ck=o(">"),uk=o(" 10.0 or "),yn=s("code"),dk=o("<"),fk=o(" 0.1"),pk=c(),ye=s("tr"),kn=s("td"),hk=o("Mixed Precision Training"),vk=c(),wn=s("td"),gk=o("Faster training, lower VRAM usage"),mk=c(),Tn=s("td"),_k=o("PyTorch AMP (torch.cuda.amp)"),Ek=c(),Rn=s("td"),bk=o("NaN values (disable if unstable)"),yk=c(),ke=s("tr"),Sn=s("td"),kk=o("Conservative Learning Rates"),wk=c(),Dn=s("td"),Tk=o("Stable training, avoid divergence"),Rk=c(),An=s("td"),Sk=o("Start at 1e-5 to 1e-6, use scheduler"),Dk=c(),Ln=s("td"),Ak=o("Spikes, slow convergence"),pm=c(),hm=s("hr"),vm=c(),ns=s("h2"),cs=s("a"),Ph=s("span"),Lk=o("Generating Regularization images"),gm=c(),us=s("p"),Ik=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),In=s("code"),Ok=o("1boy"),Pk=o(")."),mm=c(),ue=s("p"),zk=o("According to the Dreambooth technique, "),On=s("code"),xk=o("200"),Nk=o(" regularization images per training image.  For example, if you have "),Pn=s("code"),Ck=o("16"),Gk=o(" images: "),zn=s("code"),Uk=o("200 * 16 = 3200"),Hk=o(" total regularization images.  When training, the math involved for calculating total steps is: "),xn=s("code"),qk=o("repeats * training images >= repeats * regularization images"),_m=c(),Nn=s("p"),Mk=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),Em=c(),ds=s("h4"),fs=s("a"),zh=s("span"),Bk=o("Important considerations"),bm=c(),ut=s("ol"),xh=s("li"),Bl=s("p"),Nh=s("strong"),Wk=o("Use the same base model for regularization images and training"),jk=s("br"),Fk=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Vk=c(),Ch=s("li"),Wl=s("p"),Gh=s("strong"),Kk=o("Maintain consistent class representation"),Yk=s("br"),Xk=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Zk=c(),Uh=s("li"),jl=s("p"),Hh=s("strong"),Qk=o("Match output resolution to training data"),Jk=s("br"),$k=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),ym=c(),Ui(Fl.$$.fragment),km=c(),ps=s("h4"),hs=s("a"),qh=s("span"),e3=o("Generate using Stable Diffusion web UI"),wm=c(),vs=s("p"),t3=o("We\u2019re going to use "),Vl=s("a"),a3=o("Stable Diffusion web UI"),s3=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Tm=c(),dt=s("p"),l3=o("We\u2019re going to use the "),Cn=s("code"),i3=o("X/Y/Z plot"),r3=o(" script to use "),Gn=s("code"),o3=o("Prompt Search & Replace"),n3=o(" to dynamically build a prompt that will generate hundreds of regularization images."),Rm=c(),J=s("ol"),Mh=s("li"),Un=s("p"),c3=o("Select the text 2 image tab.  Enter a generic prompt "),Hn=s("code"),u3=o("princeadam, portrait, looking_at_viewer, forest"),d3=c(),Bh=s("li"),Kl=s("p"),f3=o("In generation parameters and select the "),qn=s("code"),p3=o("X/Y/Z plot"),h3=o(" script."),v3=c(),Wh=s("li"),K=s("p"),g3=o("Select the "),Mn=s("code"),m3=o("X"),_3=o(" parameter and "),Bn=s("code"),E3=o("Prompt SR"),b3=o(" for Prompt Replace.  We\u2019re going to replace "),Wn=s("code"),y3=o("portrait"),k3=o(" with different camera angle tags: "),jn=s("code"),w3=o("close-up"),T3=o(", "),Fn=s("code"),R3=o("upper_body"),S3=o(", "),Vn=s("code"),D3=o("from_below"),A3=o(", "),Kn=s("code"),L3=o("from_above"),I3=o(", "),Yn=s("code"),O3=o("dutch_angle"),P3=c(),jh=s("li"),$=s("p"),z3=o("Select the "),Xn=s("code"),x3=o("Y"),N3=o(" parameter and "),Zn=s("code"),C3=o("Prompt SR"),G3=o(" for Prompt Replace.  Replace "),Qn=s("code"),U3=o("looking_at_viewer"),H3=o(": "),Jn=s("code"),q3=o("looking_away"),M3=o(", "),$n=s("code"),B3=o("looking_to_the_side"),W3=o(", "),ec=s("code"),j3=o("looking_ahead"),F3=o(", "),tc=s("code"),V3=o("looking_down"),K3=c(),Fh=s("li"),Y=s("p"),Y3=o("Select the "),ac=s("code"),X3=o("Z"),Z3=o(" parameter and "),sc=s("code"),Q3=o("Prompt SR"),J3=o(" for Prompt Replace. Replace "),lc=s("code"),$3=o("forest"),e5=o(" with a vareity of locatinos: "),ic=s("code"),t5=o("castle"),a5=o(", "),rc=s("code"),s5=o("mountain"),l5=o(", "),oc=s("code"),i5=o("cave"),r5=o(", "),nc=s("code"),o5=o("farm"),n5=o(", "),cc=s("code"),c5=o("ocean"),u5=c(),Vh=s("li"),uc=s("p"),d5=o("Select a fast sampler like "),dc=s("code"),f5=o("DPM2 KARRAS"),p5=c(),Kh=s("li"),gs=s("p"),h5=o("CFG Scale set to "),fc=s("code"),v5=o("7"),g5=o(" and Steps to "),pc=s("code"),m5=o("20"),Sm=c(),ft=s("p"),_5=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),hc=s("code"),E5=o("150"),b5=o(" - "),vc=s("code"),y5=o("200"),k5=o(" and keep in mind we can add and remove as we try different training settings with different output."),Dm=c(),Ui(Yl.$$.fragment),Am=c(),ms=s("h4"),_s=s("a"),Yh=s("span"),w5=o("Download images"),Lm=c(),gc=s("p"),T5=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Im=c(),we=s("ul"),mc=s("li"),Xl=s("a"),R5=o("3ee Games regularization images"),S5=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),D5=c(),_c=s("li"),Zl=s("a"),A5=o("Pre-Rendered Regularization Images"),L5=o(": Includes 1500 regularization images."),I5=c(),Ec=s("li"),Ql=s("a"),O5=o("Stable Diffusion 1.5 Regularization Images"),P5=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),z5=c(),bc=s("li"),Jl=s("a"),x5=o("Aitrepreneur SDXL image set"),N5=o(": a large image set generated with Stable Diffusion SDXL."),Om=c(),Es=s("h4"),bs=s("a"),Xh=s("span"),C5=o("Captioning Regularization images"),Pm=c(),yc=s("p"),G5=o("While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),zm=c(),kc=s("p"),U5=o("Here\u2019s the workflow I used:"),xm=c(),pt=s("ul"),wc=s("li"),Zh=s("strong"),H5=o("Structured Filenames"),q5=o(": Stable Diffusion Web UI automatically embeds prompts in filenames"),M5=c(),ht=s("li"),Qh=s("strong"),B5=o("Automated Extraction"),W5=o(": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),Tc=s("code"),j5=o("1boy"),F5=o(" or "),Rc=s("code"),V5=o("purple_vest"),K5=o("."),Y5=c(),Sc=s("li"),Jh=s("strong"),X5=o("Manual Verification"),Z5=o(": Spot-checked captions to ensure accuracy."),Nm=c(),$l=s("pre"),Cm=c(),ys=s("ol"),ei=s("li"),Q5=o("Save this file as "),Dc=s("code"),J5=o("filename2txt.bat"),$5=o(" and place it into the regularization images directory"),ew=c(),ti=s("li"),tw=o("Run: "),Ac=s("code"),aw=o(".\\filename2txt.bat"),sw=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Gm=c(),ks=s("p"),$h=s("strong"),lw=o("Example filename"),iw=o(": "),Lc=s("code"),rw=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),Um=c(),ws=s("h2"),Ts=s("a"),ev=s("span"),ow=o("Training a LoRA"),Hm=c(),vt=s("p"),nw=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),ai=s("a"),cw=o("Kohya\u2019s Stable Diffusion trainers"),uw=o(".  If you want to use a GUI, use "),si=s("a"),dw=o("Kohya\u2019s GUI"),fw=o(".  In this article, you can will able to use either since the settings config can be modified in json and reloaded in the GUI."),qm=c(),li=s("blockquote"),Rs=s("p"),pw=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ii=s("a"),hw=o("Kohya SD script documentation"),vw=o("."),Mm=c(),ri=s("blockquote"),Ae=s("p"),gw=o("\u{1F4C4} Recommended reading: "),oi=s("a"),mw=o("https://rentry.org/59xed3"),_w=o(", "),ni=s("a"),Ew=o("https://rentry.org/ezlora"),bw=o(", "),ci=s("a"),yw=o("https://rentry.org/lora_train"),Bm=c(),Ss=s("h3"),Ds=s("a"),tv=s("span"),kw=o("Directory setup"),Wm=c(),As=s("p"),ww=o("In your configuration json, use "),Ic=s("code"),Tw=o("reg_data_dir"),Rw=o(" to point to the directory with your regularization images:"),jm=c(),ui=s("pre"),Fm=c(),Oc=s("p"),Sw=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Vm=c(),di=s("pre"),Km=c(),Ls=s("p"),Dw=o("Set the "),Pc=s("code"),Aw=o("number of iterations"),Lw=o(" so that training images are used as often as or more often than regularization images."),Ym=c(),fi=s("blockquote"),Is=s("p"),Iw=o("In one epoch, the total data is "),zc=s("code"),Ow=o("training images \xD7 iterations"),Pw=o(". If there are more regularization images than this, the extras won\u2019t be used."),Xm=c(),gt=s("p"),zw=o("Create folders in the training image folder with the format "),xc=s("code"),xw=o("<repetition count>_<class>"),Nw=o(" multiple times, and similarly create folders in the regularization image folder with the format "),Nc=s("code"),Cw=o("<repetition count>_<class>"),Gw=o("."),Zm=c(),Cc=s("p"),Uw=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Qm=c(),Os=s("ul"),Gc=s("li"),Hw=o("train_data_dir"),av=s("ul"),sv=s("li"),qw=o("10_princeadam"),Mw=c(),Uc=s("li"),Bw=o("reg_dir"),lv=s("ul"),iv=s("li"),Ww=o("1_1boy"),Jm=c(),Hc=s("p"),jw=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),$m=c(),pi=s("p"),hi=s("img"),e1=c(),Ps=s("h3"),zs=s("a"),rv=s("span"),Fw=o("Training Settings"),t1=c(),Yt=s("p"),Vw=o("The training setup we\u2019re going to use is:  "),qc=s("code"),Kw=o("Number of images * repeats * epoch / batch size = total steps"),Yw=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Mc=s("code"),Xw=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),a1=c(),Xt=s("table"),Bc=s("thead"),ie=s("tr"),Wc=s("th"),Zw=o("Number of Images"),Qw=c(),jc=s("th"),Jw=o("Repeats"),$w=c(),Fc=s("th"),e6=o("Epochs"),t6=c(),Vc=s("th"),a6=o("Batch Size"),s6=c(),Kc=s("th"),l6=o("Total Steps"),i6=c(),Yc=s("tbody"),re=s("tr"),Xc=s("td"),r6=o("45"),o6=c(),Zc=s("td"),n6=o("10"),c6=c(),Qc=s("td"),u6=o("20"),d6=c(),Jc=s("td"),f6=o("2"),p6=c(),$c=s("td"),h6=o("4500"),s1=c(),eu=s("p"),v6=o("Now let\u2019s focus on these training settings:"),l1=c(),vi=s("pre"),i1=c(),M=s("ul"),tu=s("li"),gi=s("strong"),g6=o("Learning Rate ("),au=s("code"),m6=o("learning_rate"),_6=o(")"),E6=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),b6=c(),su=s("li"),mi=s("strong"),y6=o("Text Encoder Learning Rate ("),lu=s("code"),k6=o("text_encoder_lr"),w6=o(")"),T6=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),R6=c(),iu=s("li"),_i=s("strong"),S6=o("UNet Learning Rate ("),ru=s("code"),D6=o("unet_lr"),A6=o(")"),L6=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),I6=c(),ou=s("li"),Ei=s("strong"),O6=o("Learning Rate Scheduler ("),nu=s("code"),P6=o("lr_scheduler"),z6=o(")"),x6=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),N6=c(),cu=s("li"),ov=s("strong"),C6=o("Number of Cycles"),G6=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),U6=c(),uu=s("li"),bi=s("strong"),H6=o("Network Dimension ("),du=s("code"),q6=o("network_dim"),M6=o(")"),B6=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),W6=c(),fu=s("li"),yi=s("strong"),j6=o("Network Alpha ("),pu=s("code"),F6=o("network_alpha"),V6=o(")"),K6=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Y6=c(),hu=s("li"),ki=s("strong"),X6=o("Clip Skip ("),vu=s("code"),Z6=o("clip_skip"),Q6=o(")"),J6=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),$6=c(),gu=s("li"),wi=s("strong"),e8=o("Max Token Length ("),mu=s("code"),t8=o("max_token_length"),a8=o(")"),s8=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),l8=c(),_u=s("li"),Ti=s("strong"),i8=o("Noise Offset ("),Eu=s("code"),r8=o("noise_offset"),o8=o(")"),n8=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),c8=c(),bu=s("li"),Ri=s("strong"),u8=o("Regularization Data Directory ("),yu=s("code"),d8=o("reg_data_dir"),f8=o(")"),p8=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),r1=c(),xs=s("h3"),Ns=s("a"),nv=s("span"),h8=o("Fine Tuning"),o1=c(),ku=s("p"),v8=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),n1=c(),Ui(Si.$$.fragment),c1=c(),Cs=s("h4"),Gs=s("a"),cv=s("span"),g8=o("Workflow with Auto1111 WebUI"),u1=c(),Us=s("p"),m8=o("We\u2019re going to use "),Di=s("a"),_8=o("Stable Diffusion web UI"),E8=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),d1=c(),Hs=s("p"),b8=o("We\u2019re going to use the "),wu=s("code"),y8=o("X/Y/Z plot"),k8=o(" script to compare different epochs."),f1=c(),oe=s("ul"),Tu=s("li"),w8=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),p1=s("princeadam0001:0.7"),T8=c(),uv=s("li"),R8=o("In generation parameters and select the X/Y/Z plot script."),S8=c(),mt=s("li"),D8=o("Select "),Ru=s("code"),A8=o("Prompt SR"),L8=o(" for Prompt Replace.  We\u2019re going to replace "),Su=s("code"),I8=o("<princeadam0001:0.7>"),O8=o(" with different epoch: "),Du=s("code"),P8=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),z8=c(),Au=s("li"),x8=o("Select a fast sampler like "),Lu=s("code"),N8=o("DPM2 KARRAS"),C8=c(),qs=s("li"),G8=o("CFG Scale set to "),Iu=s("code"),U8=o("7"),H8=o(" and Steps to "),Ou=s("code"),q8=o("20"),h1=c(),_t=s("p"),M8=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Pu=s("code"),B8=o("network_dim"),W8=o(" and "),zu=s("code"),j8=o("network_alpha"),F8=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),v1=c(),Te=s("ul"),Ms=s("li"),V8=o("Select "),xu=s("code"),K8=o("Prompt SR"),Y8=o(" for Prompt Replace.  We\u2019re going to replace the weights "),Nu=s("code"),X8=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),Z8=c(),Ai=s("li"),Q8=o("Use Prompt SR to generate a variety of angles: Select "),Cu=s("code"),J8=o("Prompt SR"),$8=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),e7=c(),dv=s("li"),t7=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),a7=c(),fv=s("li"),s7=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),g1=c(),Bs=s("h4"),Ws=s("a"),pv=s("span"),l7=o("Issues to look for"),m1=c(),Re=s("ul"),Gu=s("li"),hv=s("strong"),i7=o("Undercooked:"),r7=o(" Lacks output, adjust unet learning rate or extend training duration."),o7=c(),Uu=s("li"),vv=s("strong"),n7=o("Overcooked:"),c7=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),u7=c(),Hu=s("li"),gv=s("strong"),d7=o("Overfit:"),f7=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),p7=c(),qu=s("li"),mv=s("strong"),h7=o("Mismatched:"),v7=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),_1=c(),Mu=s("p"),g7=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),E1=c(),Li=s("p"),Ii=s("img"),b1=c(),js=s("h3"),Fs=s("a"),_v=s("span"),m7=o("Troubleshooting"),y1=c(),Bu=s("p"),_7=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),k1=c(),Et=s("ul"),Oi=s("li"),E7=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Wu=s("code"),b7=o("200"),y7=o(" regularization images per training image."),k7=c(),Pi=s("li"),w7=o("Repeats of regularization images, but may overfit more.  Increasing the "),ju=s("code"),T7=o("repetition_count"),R7=o(" will cycle through the images more but the results may have results that overfit the model."),S7=c(),Ev=s("li"),D7=o("Create more regularization images without increasing repeats will help with the overfitting."),w1=c(),Zt=s("table"),Fu=s("thead"),bt=s("tr"),Vu=s("th"),A7=o("Issue"),L7=c(),Ku=s("th"),I7=o("Situation"),O7=c(),Yu=s("th"),P7=o("Recommendation"),z7=c(),Se=s("tbody"),yt=s("tr"),Xu=s("td"),x7=o("Varying quality"),N7=c(),Zu=s("td"),C7=o("Results differ from expectations"),G7=c(),Qu=s("td"),U7=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),H7=c(),kt=s("tr"),Ju=s("td"),q7=o("Inadequate regularization for input data"),M7=c(),$u=s("td"),B7=o("Lower input images, less regularization needed"),W7=c(),ed=s("td"),j7=o("Reduce the number of input images or increasing the quantity of reg images."),F7=c(),wt=s("tr"),td=s("td"),V7=o("Overfitting due to repetition"),K7=c(),ad=s("td"),Y7=o("Repeats of reg images, risk of overfitting"),X7=c(),sd=s("td"),Z7=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),Q7=c(),Tt=s("tr"),ld=s("td"),J7=o("Mitigate overfitting while increasing diversity"),$7=c(),id=s("td"),eT=o("Create more reg images without repeats"),tT=c(),rd=s("td"),aT=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),T1=c(),Vs=s("h4"),Ks=s("a"),bv=s("span"),sT=o("More Solutions"),R1=c(),od=s("p"),lT=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),S1=c(),Qt=s("table"),nd=s("thead"),Rt=s("tr"),cd=s("th"),iT=o("Symptom"),rT=c(),ud=s("th"),oT=o("Likely Cause"),nT=c(),dd=s("th"),cT=o("Solution"),uT=c(),W=s("tbody"),St=s("tr"),fd=s("td"),dT=o("Plastic texture persists"),fT=c(),pd=s("td"),pT=o("Insufficient human reg images"),hT=c(),hd=s("td"),vT=o("Add real photos to reg set"),gT=c(),Dt=s("tr"),vd=s("td"),mT=o("Loss plateaus early"),_T=c(),gd=s("td"),ET=o("Learning rate too low"),bT=c(),md=s("td"),yT=o("Increase LR by 10x"),kT=c(),At=s("tr"),_d=s("td"),wT=o("Features blurry"),TT=c(),Ed=s("td"),RT=o("Network dimension too small"),ST=c(),bd=s("td"),DT=o("Increase network_dim to 64+"),AT=c(),Lt=s("tr"),yd=s("td"),LT=o("Color distortion"),IT=c(),kd=s("td"),OT=o("Noise offset conflict"),PT=c(),wd=s("td"),zT=o("Try noise_offset 0.05-0.1"),xT=c(),It=s("tr"),Td=s("td"),NT=o("Overly stylized outputs"),CT=c(),Rd=s("td"),GT=o("Reg image style mismatch"),UT=c(),Sd=s("td"),HT=o("Regenerate reg images with base model"),qT=c(),Ot=s("tr"),Dd=s("td"),MT=o("Training instability"),BT=c(),Ad=s("td"),WT=o("Batch size too large"),jT=c(),Ld=s("td"),FT=o("Reduce batch_size to 1-2"),VT=c(),Pt=s("tr"),Id=s("td"),KT=o("Slow convergence"),YT=c(),Od=s("td"),XT=o("Network_alpha too high"),ZT=c(),Pd=s("td"),QT=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),JT=c(),zt=s("tr"),zd=s("td"),$T=o("Loss divergence"),e9=c(),xd=s("td"),t9=o("Text encoder LR too high"),a9=c(),Nd=s("td"),s9=o("Reduce text_encoder_lr by 10x"),l9=c(),xt=s("tr"),Cd=s("td"),i9=o("Poor prompt adherence"),r9=c(),Gd=s("td"),o9=o("Clip skip too high"),n9=c(),Ud=s("td"),c9=o("Reduce clip_skip to 1-2"),u9=c(),Nt=s("tr"),Hd=s("td"),d9=o("Memory errors"),f9=c(),qd=s("td"),p9=o("Resolution too high"),h9=c(),Md=s("td"),v9=o("Reduce to 512-768px, enable gradient checkpointing"),D1=c(),Ys=s("h2"),Xs=s("a"),yv=s("span"),g9=o("Results"),A1=c(),Bd=s("p"),m9=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),L1=c(),Wd=s("p"),_9=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),I1=c(),zi=s("p"),xi=s("img"),O1=c(),jd=s("p"),E9=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),P1=c(),Jt=s("h2"),Zs=s("a"),kv=s("span"),b9=o("spacelab"),z1=c(),Le&&Le.c(),x1=Zf(),this.h()},l(a){p=l(a,"P",{});var f=i(p);g=n(f,"Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),f.forEach(t),v=u(a),h=l(a,"P",{});var uS=i(h);m=n(uS,"I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),uS.forEach(t),E=u(a),y=l(a,"H4",{id:!0});var y9=i(y);T=l(y9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var dS=i(T);R=l(dS,"SPAN",{class:!0}),i(R).forEach(t),dS.forEach(t),k=n(y9,"Experiment 1: Anime-Inspired Heroism"),y9.forEach(t),b=u(a),w=l(a,"P",{class:!0});var fS=i(w);O=l(fS,"IMG",{src:!0,alt:!0,class:!0}),fS.forEach(t),N=u(a),G=l(a,"P",{});var pS=i(G);A=n(pS,"I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),pS.forEach(t),L=u(a),D=l(a,"UL",{});var C1=i(D);z=l(C1,"LI",{});var hS=i(z);x=n(hS,"My action figure photos (for costume accuracy)."),hS.forEach(t),Q=u(C1),j=l(C1,"LI",{});var vS=i(j);F=n(vS,"Stylized anime references (for anatomy and texture)."),vS.forEach(t),C1.forEach(t),B=u(a),C=l(a,"P",{});var gS=i(C);I=n(gS,"The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),gS.forEach(t),U=u(a),Z=l(a,"H4",{id:!0});var k9=i(Z);H=l(k9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mS=i(H);S=l(mS,"SPAN",{class:!0}),i(S).forEach(t),mS.forEach(t),q=n(k9,"Experiment 2: Retro Cartoon Resurrection"),k9.forEach(t),la=u(a),Oe=l(a,"P",{class:!0});var _S=i(Oe);de=l(_S,"IMG",{src:!0,alt:!0,class:!0}),_S.forEach(t),Lv=u(a),Bi=l(a,"P",{});var ES=i(Bi);q2=n(ES,"Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),ES.forEach(t),Iv=u(a),ia=l(a,"H2",{id:!0});var w9=i(ia);ra=l(w9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var bS=i(ra);Jf=l(bS,"SPAN",{class:!0}),i(Jf).forEach(t),bS.forEach(t),M2=n(w9,"What are Regularization Images?"),w9.forEach(t),Ov=u(a),Wi=l(a,"P",{});var yS=i(Wi);B2=n(yS,"Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),yS.forEach(t),Pv=u(a),pl=l(a,"BLOCKQUOTE",{class:!0});var kS=i(pl);ji=l(kS,"P",{class:!0});var wS=i(ji);W2=n(wS,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),wS.forEach(t),kS.forEach(t),zv=u(a),Hi(hl.$$.fragment,a),xv=u(a),Fi=l(a,"P",{});var TS=i(Fi);j2=n(TS,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),TS.forEach(t),Nv=u(a),Vi=l(a,"P",{});var RS=i(Vi);F2=n(RS,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),RS.forEach(t),Cv=u(a),Ki=l(a,"P",{});var SS=i(Ki);V2=n(SS,"Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),SS.forEach(t),Gv=u(a),qt=l(a,"TABLE",{class:!0});var G1=i(qt);Yi=l(G1,"THEAD",{class:!0});var DS=i(Yi);Pe=l(DS,"TR",{class:!0});var Fd=i(Pe);Xi=l(Fd,"TH",{class:!0});var AS=i(Xi);K2=n(AS,"Aspect"),AS.forEach(t),Y2=u(Fd),Zi=l(Fd,"TH",{class:!0});var LS=i(Zi);X2=n(LS,"Regularization"),LS.forEach(t),Z2=u(Fd),Qi=l(Fd,"TH",{class:!0});var IS=i(Qi);Q2=n(IS,"No Regularization"),IS.forEach(t),Fd.forEach(t),DS.forEach(t),J2=u(G1),ze=l(G1,"TBODY",{class:!0});var Vd=i(ze);xe=l(Vd,"TR",{class:!0});var Kd=i(xe);Ji=l(Kd,"TD",{class:!0});var OS=i(Ji);$f=l(OS,"STRONG",{});var PS=i($f);$2=n(PS,"Class Definition"),PS.forEach(t),OS.forEach(t),e_=u(Kd),$i=l(Kd,"TD",{class:!0});var zS=i($i);t_=n(zS,"Explicit anchoring"),zS.forEach(t),a_=u(Kd),er=l(Kd,"TD",{class:!0});var xS=i(er);s_=n(xS,"Implicit learning"),xS.forEach(t),Kd.forEach(t),l_=u(Vd),Ne=l(Vd,"TR",{class:!0});var Yd=i(Ne);tr=l(Yd,"TD",{class:!0});var NS=i(tr);ep=l(NS,"STRONG",{});var CS=i(ep);i_=n(CS,"Failure Modes"),CS.forEach(t),NS.forEach(t),r_=u(Yd),ar=l(Yd,"TD",{class:!0});var GS=i(ar);o_=n(GS,"Underfitting if overdone"),GS.forEach(t),n_=u(Yd),sr=l(Yd,"TD",{class:!0});var US=i(sr);c_=n(US,"Overfitting/drift"),US.forEach(t),Yd.forEach(t),u_=u(Vd),Ce=l(Vd,"TR",{class:!0});var Xd=i(Ce);lr=l(Xd,"TD",{class:!0});var HS=i(lr);tp=l(HS,"STRONG",{});var qS=i(tp);d_=n(qS,"Data Efficiency"),qS.forEach(t),HS.forEach(t),f_=u(Xd),ir=l(Xd,"TD",{class:!0});var MS=i(ir);p_=n(MS,"Better generalization"),MS.forEach(t),h_=u(Xd),rr=l(Xd,"TD",{class:!0});var BS=i(rr);v_=n(BS,"Requires more data"),BS.forEach(t),Xd.forEach(t),Vd.forEach(t),G1.forEach(t),Uv=u(a),or=l(a,"P",{});var WS=i(or);g_=n(WS,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),WS.forEach(t),Hv=u(a),nr=l(a,"P",{});var jS=i(nr);m_=n(jS,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),jS.forEach(t),qv=u(a),vl=l(a,"BLOCKQUOTE",{class:!0});var FS=i(vl);cr=l(FS,"P",{class:!0});var VS=i(cr);__=n(VS,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),VS.forEach(t),FS.forEach(t),Mv=u(a),oa=l(a,"H4",{id:!0});var T9=i(oa);na=l(T9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var KS=i(na);ap=l(KS,"SPAN",{class:!0}),i(ap).forEach(t),KS.forEach(t),E_=n(T9,"Scenario 1: Limited Training Data"),T9.forEach(t),Bv=u(a),gl=l(a,"P",{});var R9=i(gl);sp=l(R9,"STRONG",{});var YS=i(sp);b_=n(YS,"Situation"),YS.forEach(t),y_=n(R9,": You only have a few images of your cat and no other cat images."),R9.forEach(t),Wv=u(a),ml=l(a,"P",{});var S9=i(ml);lp=l(S9,"STRONG",{});var XS=i(lp);k_=n(XS,"Problem"),XS.forEach(t),w_=n(S9,": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),S9.forEach(t),jv=u(a),_l=l(a,"P",{});var D9=i(_l);ip=l(D9,"STRONG",{});var ZS=i(ip);T_=n(ZS,"Solution"),ZS.forEach(t),R_=n(D9,": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),D9.forEach(t),Fv=u(a),ca=l(a,"H4",{id:!0});var A9=i(ca);ua=l(A9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var QS=i(ua);rp=l(QS,"SPAN",{class:!0}),i(rp).forEach(t),QS.forEach(t),S_=n(A9,"Scenario 2: Imbalanced Training Data"),A9.forEach(t),Vv=u(a),El=l(a,"P",{});var L9=i(El);op=l(L9,"STRONG",{});var JS=i(op);D_=n(JS,"Situation"),JS.forEach(t),A_=n(L9,": You have many images of other cats but only a few of your cat."),L9.forEach(t),Kv=u(a),bl=l(a,"P",{});var I9=i(bl);np=l(I9,"STRONG",{});var $S=i(np);L_=n($S,"Problem"),$S.forEach(t),I_=n(I9,": The model may focus too much on the other cats, failing to learn the unique features of your cat."),I9.forEach(t),Yv=u(a),yl=l(a,"P",{});var O9=i(yl);cp=l(O9,"STRONG",{});var eD=i(cp);O_=n(eD,"Solution"),eD.forEach(t),P_=n(O9,": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),O9.forEach(t),Xv=u(a),da=l(a,"H2",{id:!0});var P9=i(da);fa=l(P9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var tD=i(fa);up=l(tD,"SPAN",{class:!0}),i(up).forEach(t),tD.forEach(t),z_=n(P9,"Divergence"),P9.forEach(t),Zv=u(a),kl=l(a,"P",{});var z9=i(kl);dp=l(z9,"STRONG",{});var aD=i(dp);x_=n(aD,"Divergence"),aD.forEach(t),N_=n(z9," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),z9.forEach(t),Qv=u(a),Ge=l(a,"P",{});var Zd=i(Ge);C_=n(Zd,"Preventing divergence starts with "),fp=l(Zd,"STRONG",{});var sD=i(fp);G_=n(sD,"careful dataset curation"),sD.forEach(t),U_=n(Zd,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),pp=l(Zd,"STRONG",{});var lD=i(pp);H_=n(lD,"regularization techniques"),lD.forEach(t),q_=n(Zd," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Zd.forEach(t),Jv=u(a),Ue=l(a,"UL",{});var Qd=i(Ue);ur=l(Qd,"LI",{});var x9=i(ur);hp=l(x9,"STRONG",{});var iD=i(hp);M_=n(iD,"Chaotic outputs"),iD.forEach(t),B_=n(x9," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),x9.forEach(t),W_=u(Qd),dr=l(Qd,"LI",{});var N9=i(dr);vp=l(N9,"STRONG",{});var rD=i(vp);j_=n(rD,"Exploding gradients"),rD.forEach(t),F_=n(N9," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),N9.forEach(t),V_=u(Qd),pa=l(Qd,"LI",{});var wv=i(pa);gp=l(wv,"STRONG",{});var oD=i(gp);K_=n(oD,"Loss value instability (NaN/infinity values)"),oD.forEach(t),Y_=n(wv," The training loss fluctuates wildly, sometimes becoming "),fr=l(wv,"CODE",{class:!0});var nD=i(fr);X_=n(nD,"NaN"),nD.forEach(t),Z_=n(wv," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),wv.forEach(t),Qd.forEach(t),$v=u(a),wl=l(a,"BLOCKQUOTE",{class:!0});var cD=i(wl);pr=l(cD,"P",{class:!0});var uD=i(pr);Q_=n(uD,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),uD.forEach(t),cD.forEach(t),eg=u(a),ha=l(a,"H2",{id:!0});var C9=i(ha);va=l(C9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var dD=i(va);mp=l(dD,"SPAN",{class:!0}),i(mp).forEach(t),dD.forEach(t),_p=l(C9,"STRONG",{});var fD=i(_p);J_=n(fD,"Overfitting"),fD.forEach(t),C9.forEach(t),tg=u(a),hr=l(a,"P",{});var pD=i(hr);$_=n(pD,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),pD.forEach(t),ag=u(a),He=l(a,"UL",{});var Jd=i(He);vr=l(Jd,"LI",{});var G9=i(vr);Ep=l(G9,"STRONG",{});var hD=i(Ep);e0=n(hD,"Perfectly replicates training samples"),hD.forEach(t),t0=n(G9," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),G9.forEach(t),a0=u(Jd),gr=l(Jd,"LI",{});var U9=i(gr);bp=l(U9,"STRONG",{});var vD=i(bp);s0=n(vD,"Fails to generalize to new inputs"),vD.forEach(t),l0=n(U9," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),U9.forEach(t),i0=u(Jd),mr=l(Jd,"LI",{});var H9=i(mr);yp=l(H9,"STRONG",{});var gD=i(yp);r0=n(gD,"Shows excellent training loss but poor validation loss"),gD.forEach(t),o0=n(H9," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),H9.forEach(t),Jd.forEach(t),sg=u(a),ga=l(a,"H3",{id:!0});var q9=i(ga);ma=l(q9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mD=i(ma);kp=l(mD,"SPAN",{class:!0}),i(kp).forEach(t),mD.forEach(t),wp=l(q9,"STRONG",{});var _D=i(wp);n0=n(_D,"Key Differences"),_D.forEach(t),q9.forEach(t),lg=u(a),Mt=l(a,"TABLE",{class:!0});var U1=i(Mt);_r=l(U1,"THEAD",{class:!0});var ED=i(_r);qe=l(ED,"TR",{class:!0});var $d=i(qe);Er=l($d,"TH",{class:!0});var bD=i(Er);Tp=l(bD,"STRONG",{});var yD=i(Tp);c0=n(yD,"Aspect"),yD.forEach(t),bD.forEach(t),u0=u($d),br=l($d,"TH",{class:!0});var kD=i(br);Rp=l(kD,"STRONG",{});var wD=i(Rp);d0=n(wD,"Divergence"),wD.forEach(t),kD.forEach(t),f0=u($d),yr=l($d,"TH",{class:!0});var TD=i(yr);Sp=l(TD,"STRONG",{});var RD=i(Sp);p0=n(RD,"Overfitting"),RD.forEach(t),TD.forEach(t),$d.forEach(t),ED.forEach(t),h0=u(U1),fe=l(U1,"TBODY",{class:!0});var Qs=i(fe);Me=l(Qs,"TR",{class:!0});var ef=i(Me);kr=l(ef,"TD",{class:!0});var SD=i(kr);Dp=l(SD,"STRONG",{});var DD=i(Dp);v0=n(DD,"Cause"),DD.forEach(t),SD.forEach(t),g0=u(ef),wr=l(ef,"TD",{class:!0});var AD=i(wr);m0=n(AD,"Excessive learning rate"),AD.forEach(t),_0=u(ef),Tr=l(ef,"TD",{class:!0});var LD=i(Tr);E0=n(LD,"Insufficient regularization"),LD.forEach(t),ef.forEach(t),b0=u(Qs),Be=l(Qs,"TR",{class:!0});var tf=i(Be);Rr=l(tf,"TD",{class:!0});var ID=i(Rr);Ap=l(ID,"STRONG",{});var OD=i(Ap);y0=n(OD,"Loss Behavior"),OD.forEach(t),ID.forEach(t),k0=u(tf),Sr=l(tf,"TD",{class:!0});var PD=i(Sr);w0=n(PD,"Sudden spikes/NaN values"),PD.forEach(t),T0=u(tf),Dr=l(tf,"TD",{class:!0});var zD=i(Dr);R0=n(zD,"Steady decrease then rise"),zD.forEach(t),tf.forEach(t),S0=u(Qs),We=l(Qs,"TR",{class:!0});var af=i(We);Ar=l(af,"TD",{class:!0});var xD=i(Ar);Lp=l(xD,"STRONG",{});var ND=i(Lp);D0=n(ND,"Output Quality"),ND.forEach(t),xD.forEach(t),A0=u(af),Lr=l(af,"TD",{class:!0});var CD=i(Lr);L0=n(CD,"Random noise/artifacts"),CD.forEach(t),I0=u(af),Ir=l(af,"TD",{class:!0});var GD=i(Ir);O0=n(GD,"Overly detailed replicas"),GD.forEach(t),af.forEach(t),P0=u(Qs),je=l(Qs,"TR",{class:!0});var sf=i(je);Or=l(sf,"TD",{class:!0});var UD=i(Or);Ip=l(UD,"STRONG",{});var HD=i(Ip);z0=n(HD,"Recovery"),HD.forEach(t),UD.forEach(t),x0=u(sf),Pr=l(sf,"TD",{class:!0});var qD=i(Pr);N0=n(qD,"Requires restart"),qD.forEach(t),C0=u(sf),zr=l(sf,"TD",{class:!0});var MD=i(zr);G0=n(MD,"Early stopping works"),MD.forEach(t),sf.forEach(t),Qs.forEach(t),U1.forEach(t),ig=u(a),_a=l(a,"H3",{id:!0});var M9=i(_a);Ea=l(M9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var BD=i(Ea);Op=l(BD,"SPAN",{class:!0}),i(Op).forEach(t),BD.forEach(t),U0=n(M9,"Preventing Divergence"),M9.forEach(t),rg=u(a),Bt=l(a,"TABLE",{class:!0});var H1=i(Bt);xr=l(H1,"THEAD",{class:!0});var WD=i(xr);ba=l(WD,"TR",{class:!0});var q1=i(ba);Nr=l(q1,"TH",{class:!0});var jD=i(Nr);H0=n(jD,"Situation"),jD.forEach(t),q0=u(q1),Cr=l(q1,"TH",{class:!0});var FD=i(Cr);M0=n(FD,"Outcome"),FD.forEach(t),q1.forEach(t),WD.forEach(t),B0=u(H1),pe=l(H1,"TBODY",{class:!0});var Js=i(pe);ya=l(Js,"TR",{class:!0});var M1=i(ya);Gr=l(M1,"TD",{class:!0});var VD=i(Gr);Pp=l(VD,"STRONG",{});var KD=i(Pp);W0=n(KD,"Excessive/inconsistent data"),KD.forEach(t),VD.forEach(t),j0=u(M1),Ur=l(M1,"TD",{class:!0});var YD=i(Ur);F0=n(YD,"Model struggles to learn and produces unreliable predictions."),YD.forEach(t),M1.forEach(t),V0=u(Js),ka=l(Js,"TR",{class:!0});var B1=i(ka);Hr=l(B1,"TD",{class:!0});var XD=i(Hr);zp=l(XD,"STRONG",{});var ZD=i(zp);K0=n(ZD,"Lack of unique features"),ZD.forEach(t),XD.forEach(t),Y0=u(B1),qr=l(B1,"TD",{class:!0});var QD=i(qr);X0=n(QD,"Poor generalization leading to inaccurate outputs."),QD.forEach(t),B1.forEach(t),Z0=u(Js),wa=l(Js,"TR",{class:!0});var W1=i(wa);Mr=l(W1,"TD",{class:!0});var JD=i(Mr);xp=l(JD,"STRONG",{});var $D=i(xp);Q0=n($D,"Carefully curated datasets"),$D.forEach(t),JD.forEach(t),J0=u(W1),Br=l(W1,"TD",{class:!0});var eA=i(Br);$0=n(eA,"Improved learning by ensuring the model sees only relevant, high-quality data."),eA.forEach(t),W1.forEach(t),eE=u(Js),Ta=l(Js,"TR",{class:!0});var j1=i(Ta);Wr=l(j1,"TD",{class:!0});var tA=i(Wr);Np=l(tA,"STRONG",{});var aA=i(Np);tE=n(aA,"Regularization techniques"),aA.forEach(t),tA.forEach(t),aE=u(j1),jr=l(j1,"TD",{class:!0});var sA=i(jr);sE=n(sA,"Helps maintain focus on essential features and prevents instability."),sA.forEach(t),j1.forEach(t),Js.forEach(t),H1.forEach(t),og=u(a),Fr=l(a,"P",{});var lA=i(Fr);lE=n(lA,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),lA.forEach(t),ng=u(a),Ra=l(a,"H3",{id:!0});var B9=i(Ra);Sa=l(B9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var iA=i(Sa);Cp=l(iA,"SPAN",{class:!0}),i(Cp).forEach(t),iA.forEach(t),iE=n(B9,"Implement these Strategies"),B9.forEach(t),cg=u(a),he=l(a,"P",{});var $s=i(he);rE=n($s,"To prevent divergence and overfitting during training, carefully configure your training parameters and regularization techniques. Start with a "),Gp=l($s,"STRONG",{});var rA=i(Gp);oE=n(rA,"conservative learning rate"),rA.forEach(t),nE=n($s," (e.g., "),Vr=l($s,"CODE",{class:!0});var oA=i(Vr);cE=n(oA,"1e-5"),oA.forEach(t),uE=n($s,") to avoid sudden spikes or NaN values in the loss, which are signs of divergence. Use gradient clipping ("),Kr=l($s,"CODE",{class:!0});var nA=i(Kr);dE=n(nA,"max_grad_norm: 1.0"),nA.forEach(t),fE=n($s,") to stabilize training by preventing excessively large updates to the model weights. A cosine learning rate scheduler ensures a smooth and stable adjustment of the learning rate over time, reducing the risk of instability."),$s.forEach(t),ug=u(a),ve=l(a,"P",{});var el=i(ve);pE=n(el,"For regularization, incorporate techniques like dropout ("),Yr=l(el,"CODE",{class:!0});var cA=i(Yr);hE=n(cA,"dropout_prob: 0.1"),cA.forEach(t),vE=n(el,") to prevent the model from over-relying on specific features, improving generalization. Use a small batch size ("),Xr=l(el,"CODE",{class:!0});var uA=i(Xr);gE=n(uA,"train_batch_size: 2"),uA.forEach(t),mE=n(el,") to introduce noise into the training process, which can help avoid overfitting. Additionally, limit the number of training steps ("),Zr=l(el,"CODE",{class:!0});var dA=i(Zr);_E=n(dA,"max_train_steps: 1500"),dA.forEach(t),EE=n(el,") to prevent the model from memorizing the dataset.  By combining these strategies, you can train a robust model that generalizes well and avoids divergence / overfitting."),el.forEach(t),dg=u(a),Tl=l(a,"PRE",{class:!0});var Jx=i(Tl);Jx.forEach(t),fg=u(a),Rl=l(a,"PRE",{class:!0});var $x=i(Rl);$x.forEach(t),pg=u(a),Da=l(a,"H4",{id:!0});var W9=i(Da);Aa=l(W9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var fA=i(Aa);Up=l(fA,"SPAN",{class:!0}),i(Up).forEach(t),fA.forEach(t),bE=n(W9,"Data Considerations"),W9.forEach(t),hg=u(a),Wt=l(a,"TABLE",{class:!0});var F1=i(Wt);Qr=l(F1,"THEAD",{class:!0});var pA=i(Qr);Fe=l(pA,"TR",{class:!0});var lf=i(Fe);Jr=l(lf,"TH",{class:!0});var hA=i(Jr);yE=n(hA,"Situation"),hA.forEach(t),kE=u(lf),$r=l(lf,"TH",{class:!0});var vA=i($r);wE=n(vA,"Actual Risk"),vA.forEach(t),TE=u(lf),eo=l(lf,"TH",{class:!0});var gA=i(eo);RE=n(gA,"Solution"),gA.forEach(t),lf.forEach(t),pA.forEach(t),SE=u(F1),ge=l(F1,"TBODY",{class:!0});var tl=i(ge);Ve=l(tl,"TR",{class:!0});var rf=i(Ve);to=l(rf,"TD",{class:!0});var mA=i(to);DE=n(mA,"High LR + small batch size"),mA.forEach(t),AE=u(rf),ao=l(rf,"TD",{class:!0});var _A=i(ao);LE=n(_A,"Divergence"),_A.forEach(t),IE=u(rf),so=l(rf,"TD",{class:!0});var EA=i(so);OE=n(EA,"Lower LR, increase batch size"),EA.forEach(t),rf.forEach(t),PE=u(tl),Ke=l(tl,"TR",{class:!0});var of=i(Ke);lo=l(of,"TD",{class:!0});var bA=i(lo);zE=n(bA,"Inconsistent features"),bA.forEach(t),xE=u(of),io=l(of,"TD",{class:!0});var yA=i(io);NE=n(yA,"Overfitting"),yA.forEach(t),CE=u(of),ro=l(of,"TD",{class:!0});var kA=i(ro);GE=n(kA,"Improve dataset consistency"),kA.forEach(t),of.forEach(t),UE=u(tl),Ye=l(tl,"TR",{class:!0});var nf=i(Ye);oo=l(nf,"TD",{class:!0});var wA=i(oo);HE=n(wA,"Insufficient reg images"),wA.forEach(t),qE=u(nf),no=l(nf,"TD",{class:!0});var TA=i(no);ME=n(TA,"Class leakage"),TA.forEach(t),BE=u(nf),co=l(nf,"TD",{class:!0});var RA=i(co);WE=n(RA,"Add 100-300 class images"),RA.forEach(t),nf.forEach(t),jE=u(tl),Xe=l(tl,"TR",{class:!0});var cf=i(Xe);uo=l(cf,"TD",{class:!0});var SA=i(uo);FE=n(SA,"High variance in training data"),SA.forEach(t),VE=u(cf),fo=l(cf,"TD",{class:!0});var DA=i(fo);KE=n(DA,"Mode collapse"),DA.forEach(t),YE=u(cf),po=l(cf,"TD",{class:!0});var AA=i(po);XE=n(AA,"Curate focused dataset"),AA.forEach(t),cf.forEach(t),tl.forEach(t),F1.forEach(t),vg=u(a),ho=l(a,"P",{});var LA=i(ho);ZE=n(LA,"This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs\u2014fix this by lowering the learning rate and increasing the batch size."),LA.forEach(t),gg=u(a),vo=l(a,"P",{});var IA=i(vo);QE=n(IA,"Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects\u2014adding 100-300 images helps."),IA.forEach(t),mg=u(a),go=l(a,"P",{});var OA=i(go);JE=n(OA,"High variance in training data can result in mode collapse, producing repetitive outputs\u2014keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),OA.forEach(t),_g=u(a),Eg=l(a,"HR",{}),bg=u(a),La=l(a,"H2",{id:!0});var j9=i(La);Ia=l(j9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var PA=i(Ia);Hp=l(PA,"SPAN",{class:!0}),i(Hp).forEach(t),PA.forEach(t),$E=n(j9,"Monitoring Tips"),j9.forEach(t),yg=u(a),Oa=l(a,"P",{});var V1=i(Oa);eb=n(V1,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Sl=l(V1,"A",{href:!0,rel:!0});var zA=i(Sl);tb=n(zA,"kohya-ss/sd-scripts"),zA.forEach(t),ab=n(V1,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),V1.forEach(t),kg=u(a),Pa=l(a,"H3",{id:!0});var F9=i(Pa);za=l(F9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xA=i(za);qp=l(xA,"SPAN",{class:!0}),i(qp).forEach(t),xA.forEach(t),sb=n(F9,"Track loss curves"),F9.forEach(t),wg=u(a),xa=l(a,"P",{});var K1=i(xa);lb=n(K1,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Dl=l(K1,"A",{href:!0,rel:!0});var NA=i(Dl);ib=n(NA,"TensorBoard"),NA.forEach(t),rb=n(K1," to create these graphs."),K1.forEach(t),Tg=u(a),Al=l(a,"PRE",{class:!0});var eN=i(Al);eN.forEach(t),Rg=u(a),Na=l(a,"H4",{id:!0});var V9=i(Na);Ca=l(V9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var CA=i(Ca);Mp=l(CA,"SPAN",{class:!0}),i(Mp).forEach(t),CA.forEach(t),ob=n(V9,"What to Monitor:"),V9.forEach(t),Sg=u(a),Ze=l(a,"UL",{});var uf=i(Ze);Bp=l(uf,"LI",{});var GA=i(Bp);nb=n(GA,"Training Loss: Should decrease steadily but not too quickly."),GA.forEach(t),cb=u(uf),Wp=l(uf,"LI",{});var UA=i(Wp);ub=n(UA,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),UA.forEach(t),db=u(uf),jp=l(uf,"LI",{});var HA=i(jp);fb=n(HA,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),HA.forEach(t),uf.forEach(t),Dg=u(a),Ga=l(a,"H4",{id:!0});var K9=i(Ga);Ua=l(K9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var qA=i(Ua);Fp=l(qA,"SPAN",{class:!0}),i(Fp).forEach(t),qA.forEach(t),pb=n(K9,"Warning Signs:"),K9.forEach(t),Ag=u(a),Qe=l(a,"UL",{});var df=i(Qe);Vp=l(df,"LI",{});var MA=i(Vp);hb=n(MA,"Sudden spikes in loss \u2192 Likely divergence."),MA.forEach(t),vb=u(df),Kp=l(df,"LI",{});var BA=i(Kp);gb=n(BA,"Loss plateauing too early \u2192 Learning rate may be too low."),BA.forEach(t),mb=u(df),Yp=l(df,"LI",{});var WA=i(Yp);_b=n(WA,"Validation loss increasing while training loss decreases \u2192 Overfitting."),WA.forEach(t),df.forEach(t),Lg=u(a),Ha=l(a,"H4",{id:!0});var Y9=i(Ha);qa=l(Y9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jA=i(qa);Xp=l(jA,"SPAN",{class:!0}),i(Xp).forEach(t),jA.forEach(t),Eb=n(Y9,"Generate validation images every 100 steps"),Y9.forEach(t),Ig=u(a),Ll=l(a,"P",{});var X9=i(Ll);Zp=l(X9,"STRONG",{});var FA=i(Zp);bb=n(FA,"Why It Matters"),FA.forEach(t),yb=n(X9," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),X9.forEach(t),Og=u(a),Il=l(a,"PRE",{class:!0});var tN=i(Il);tN.forEach(t),Pg=u(a),Ma=l(a,"H4",{id:!0});var Z9=i(Ma);Ba=l(Z9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var VA=i(Ba);Qp=l(VA,"SPAN",{class:!0}),i(Qp).forEach(t),VA.forEach(t),kb=n(Z9,"What to Look For:"),Z9.forEach(t),zg=u(a),Je=l(a,"UL",{});var ff=i(Je);Jp=l(ff,"LI",{});var KA=i(Jp);wb=n(KA,"Consistency: Outputs should align with the training data style."),KA.forEach(t),Tb=u(ff),$p=l(ff,"LI",{});var YA=i($p);Rb=n(YA,"Artifacts: Check for distortions, noise, or unnatural features."),YA.forEach(t),Sb=u(ff),eh=l(ff,"LI",{});var XA=i(eh);Db=n(XA,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),XA.forEach(t),ff.forEach(t),xg=u(a),Ol=l(a,"BLOCKQUOTE",{class:!0});var ZA=i(Ol);mo=l(ZA,"P",{class:!0});var QA=i(mo);Ab=n(QA,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),QA.forEach(t),ZA.forEach(t),Ng=u(a),Wa=l(a,"H4",{id:!0});var Q9=i(Wa);ja=l(Q9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var JA=i(ja);th=l(JA,"SPAN",{class:!0}),i(th).forEach(t),JA.forEach(t),Lb=n(Q9,"Use Gradient Clipping"),Q9.forEach(t),Cg=u(a),Pl=l(a,"P",{});var J9=i(Pl);ah=l(J9,"STRONG",{});var $A=i(ah);Ib=n($A,"Why It Matters"),$A.forEach(t),Ob=n(J9,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),J9.forEach(t),Gg=u(a),_o=l(a,"P",{});var eL=i(_o);Pb=n(eL,"Key Insights:"),eL.forEach(t),Ug=u(a),$e=l(a,"UL",{});var pf=i($e);zl=l(pf,"LI",{});var Y1=i(zl);zb=n(Y1,"Gradient Norm "),Eo=l(Y1,"CODE",{class:!0});var tL=i(Eo);xb=n(tL,"<"),tL.forEach(t),Nb=n(Y1," than 0.1: Training may stall due to tiny updates."),Y1.forEach(t),Cb=u(pf),sh=l(pf,"LI",{});var aL=i(sh);Gb=n(aL,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),aL.forEach(t),Ub=u(pf),lh=l(pf,"LI",{});var sL=i(lh);Hb=n(sL,"Ideal Range: 0.1 to 2.0 for stable training."),sL.forEach(t),pf.forEach(t),Hg=u(a),xl=l(a,"BLOCKQUOTE",{class:!0});var lL=i(xl);bo=l(lL,"P",{class:!0});var iL=i(bo);qb=n(iL,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),iL.forEach(t),lL.forEach(t),qg=u(a),Fa=l(a,"H4",{id:!0});var $9=i(Fa);Va=l($9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var rL=i(Va);ih=l(rL,"SPAN",{class:!0}),i(ih).forEach(t),rL.forEach(t),Mb=n($9,"Enable Mixed Precision Training"),$9.forEach(t),Mg=u(a),Nl=l(a,"P",{});var eR=i(Nl);rh=l(eR,"STRONG",{});var oL=i(rh);Bb=n(oL,"Why It Matters"),oL.forEach(t),Wb=n(eR,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),eR.forEach(t),Bg=u(a),Cl=l(a,"PRE",{class:!0});var aN=i(Cl);aN.forEach(t),Wg=u(a),yo=l(a,"P",{});var nL=i(yo);jb=n(nL,"Benefits:"),nL.forEach(t),jg=u(a),et=l(a,"UL",{});var hf=i(et);oh=l(hf,"LI",{});var cL=i(oh);Fb=n(cL,"2-3x Faster Training: Leverages GPU tensor cores."),cL.forEach(t),Vb=u(hf),nh=l(hf,"LI",{});var uL=i(nh);Kb=n(uL,"50% Less VRAM Usage: Allows larger batch sizes or models."),uL.forEach(t),Yb=u(hf),ch=l(hf,"LI",{});var dL=i(ch);Xb=n(dL,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),dL.forEach(t),hf.forEach(t),Fg=u(a),Gl=l(a,"BLOCKQUOTE",{class:!0});var fL=i(Gl);ko=l(fL,"P",{class:!0});var pL=i(ko);Zb=n(pL,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),pL.forEach(t),fL.forEach(t),Vg=u(a),Ka=l(a,"H4",{id:!0});var tR=i(Ka);Ya=l(tR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var hL=i(Ya);uh=l(hL,"SPAN",{class:!0}),i(uh).forEach(t),hL.forEach(t),Qb=n(tR,"Start with Conservative Learning Rates"),tR.forEach(t),Kg=u(a),Xa=l(a,"P",{});var X1=i(Xa);Jb=n(X1,"Start off with 1e-5 to 1e-6.  "),dh=l(X1,"STRONG",{});var vL=i(dh);$b=n(vL,"Why It Matters"),vL.forEach(t),ey=n(X1,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),X1.forEach(t),Yg=u(a),Ul=l(a,"PRE",{class:!0});var sN=i(Ul);sN.forEach(t),Xg=u(a),jt=l(a,"TABLE",{class:!0});var Z1=i(jt);wo=l(Z1,"THEAD",{class:!0});var gL=i(wo);tt=l(gL,"TR",{class:!0});var vf=i(tt);To=l(vf,"TH",{class:!0});var mL=i(To);ty=n(mL,"Option"),mL.forEach(t),ay=u(vf),Ro=l(vf,"TH",{class:!0});var _L=i(Ro);sy=n(_L,"Values"),_L.forEach(t),ly=u(vf),So=l(vf,"TH",{class:!0});var EL=i(So);iy=n(EL,"Effect"),EL.forEach(t),vf.forEach(t),gL.forEach(t),ry=u(Z1),at=l(Z1,"TBODY",{class:!0});var gf=i(at);st=l(gf,"TR",{class:!0});var mf=i(st);Do=l(mf,"TD",{class:!0});var bL=i(Do);Ao=l(bL,"CODE",{class:!0});var yL=i(Ao);oy=n(yL,"learning_rate"),yL.forEach(t),bL.forEach(t),ny=u(mf),Lo=l(mf,"TD",{class:!0});var kL=i(Lo);cy=n(kL,"0.005 - 0.0001"),kL.forEach(t),uy=u(mf),Io=l(mf,"TD",{class:!0});var wL=i(Io);dy=n(wL,"Main control for learning rate. Sets defaults for the other two."),wL.forEach(t),mf.forEach(t),fy=u(gf),lt=l(gf,"TR",{class:!0});var _f=i(lt);Oo=l(_f,"TD",{class:!0});var TL=i(Oo);Po=l(TL,"CODE",{class:!0});var RL=i(Po);py=n(RL,"unet_lr"),RL.forEach(t),TL.forEach(t),hy=u(_f),zo=l(_f,"TD",{class:!0});var SL=i(zo);vy=n(SL,"0.0001 - 0.005"),SL.forEach(t),gy=u(_f),xo=l(_f,"TD",{class:!0});var DL=i(xo);my=n(DL,"Sets Unet\u2019s learning rate. Most sensitive part; avoid setting too high."),DL.forEach(t),_f.forEach(t),_y=u(gf),it=l(gf,"TR",{class:!0});var Ef=i(it);No=l(Ef,"TD",{class:!0});var AL=i(No);Co=l(AL,"CODE",{class:!0});var LL=i(Co);Ey=n(LL,"text_encoder_lr"),LL.forEach(t),AL.forEach(t),by=u(Ef),Go=l(Ef,"TD",{class:!0});var IL=i(Go);yy=n(IL,"0.00001 - 0.00005"),IL.forEach(t),ky=u(Ef),Uo=l(Ef,"TD",{class:!0});var OL=i(Uo);wy=n(OL,"Sets text encoder\u2019s learning rate. Keep much lower than Unet\u2019s."),OL.forEach(t),Ef.forEach(t),gf.forEach(t),Z1.forEach(t),Zg=u(a),Za=l(a,"H4",{id:!0});var aR=i(Za);Qa=l(aR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var PL=i(Qa);fh=l(PL,"SPAN",{class:!0}),i(fh).forEach(t),PL.forEach(t),Ty=n(aR,"What does this mean?"),aR.forEach(t),Qg=u(a),rt=l(a,"UL",{});var bf=i(rt);Hl=l(bf,"LI",{});var Q1=i(Hl);Ry=n(Q1,"If you don\u2019t want to fine-tune, just use "),Ho=l(Q1,"CODE",{class:!0});var zL=i(Ho);Sy=n(zL,"--learning_rate"),zL.forEach(t),Dy=n(Q1," to set the other two automatically."),Q1.forEach(t),Ay=u(bf),De=l(bf,"LI",{});var al=i(De);Ly=n(al,"If you want more control, set "),qo=l(al,"CODE",{class:!0});var xL=i(qo);Iy=n(xL,"--unet_lr"),xL.forEach(t),Oy=n(al," and "),Mo=l(al,"CODE",{class:!0});var NL=i(Mo);Py=n(NL,"--text_encoder_lr"),NL.forEach(t),zy=n(al," individually. Setting "),Bo=l(al,"CODE",{class:!0});var CL=i(Bo);xy=n(CL,"--learning_rate"),CL.forEach(t),Ny=n(al," becomes redundant in this case."),al.forEach(t),Cy=u(bf),Ft=l(bf,"LI",{});var yf=i(Ft);Gy=n(yf,"A common approach is to set "),Wo=l(yf,"CODE",{class:!0});var GL=i(Wo);Uy=n(GL,"--learning_rate"),GL.forEach(t),Hy=n(yf," the same as "),jo=l(yf,"CODE",{class:!0});var UL=i(jo);qy=n(UL,"--unet_lr"),UL.forEach(t),My=n(yf," for simplicity."),yf.forEach(t),bf.forEach(t),Jg=u(a),Ja=l(a,"H4",{id:!0});var sR=i(Ja);$a=l(sR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var HL=i($a);ph=l(HL,"SPAN",{class:!0}),i(ph).forEach(t),HL.forEach(t),By=n(sR,"Text Encoder Learning Rate"),sR.forEach(t),$g=u(a),Fo=l(a,"P",{});var qL=i(Fo);Wy=n(qL,"The text encoder interprets text prompts and links tags/tokens to data in the Unet during training."),qL.forEach(t),em=u(a),Vo=l(a,"UL",{});var ML=i(Vo);es=l(ML,"LI",{});var Tv=i(es);hh=l(Tv,"STRONG",{});var BL=i(hh);jy=n(BL,"Default Value"),BL.forEach(t),Fy=n(Tv,": 5e-5 (or uses "),Ko=l(Tv,"CODE",{class:!0});var WL=i(Ko);Vy=n(WL,"--learning_rate"),WL.forEach(t),Ky=n(Tv," if not specified)."),Tv.forEach(t),ML.forEach(t),tm=u(a),ts=l(a,"H4",{id:!0});var lR=i(ts);as=l(lR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jL=i(as);vh=l(jL,"SPAN",{class:!0}),i(vh).forEach(t),jL.forEach(t),Yy=n(lR,"Effects:"),lR.forEach(t),am=u(a),ot=l(a,"UL",{});var kf=i(ot);gh=l(kf,"LI",{});var FL=i(gh);Xy=n(FL,"Lowering it helps separate objects better in generations."),FL.forEach(t),Zy=u(kf),mh=l(kf,"LI",{});var VL=i(mh);Qy=n(VL,"If unwanted objects appear, try lowering it."),VL.forEach(t),Jy=u(kf),_h=l(kf,"LI",{});var KL=i(_h);$y=n(KL,"If prompts require heavy weighting to make things appear, it\u2019s set too low."),KL.forEach(t),kf.forEach(t),sm=u(a),Yo=l(a,"P",{});var YL=i(Yo);e4=n(YL,"A well-trained text encoder improves prompt control and feature granularity."),YL.forEach(t),lm=u(a),ss=l(a,"H4",{id:!0});var iR=i(ss);ls=l(iR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var XL=i(ls);Eh=l(XL,"SPAN",{class:!0}),i(Eh).forEach(t),XL.forEach(t),t4=n(iR,"Unet Learning Rate"),iR.forEach(t),im=u(a),Xo=l(a,"P",{});var ZL=i(Xo);a4=n(ZL,"The Unet acts as the model\u2019s \u201Cvisual memory,\u201D handling image structure, detail, and relationships between elements."),ZL.forEach(t),rm=u(a),is=l(a,"UL",{});var J1=i(is);Zo=l(J1,"LI",{});var rR=i(Zo);bh=l(rR,"STRONG",{});var QL=i(bh);s4=n(QL,"Default Value"),QL.forEach(t),l4=n(rR,": 1e-4 (avoid changing unless necessary)."),rR.forEach(t),i4=u(J1),ql=l(J1,"LI",{});var $1=i(ql);yh=l($1,"STRONG",{});var JL=i(yh);r4=n(JL,"Issues & Fixes"),JL.forEach(t),o4=n($1,":"),Vt=l($1,"UL",{});var wf=i(Vt);Qo=l(wf,"LI",{});var oR=i(Qo);kh=l(oR,"STRONG",{});var $L=i(kh);n4=n($L,"Overfitting"),$L.forEach(t),c4=n(oR,": Reduce learning rate, steps, or use dampeners."),oR.forEach(t),u4=u(wf),Jo=l(wf,"LI",{});var nR=i(Jo);wh=l(nR,"STRONG",{});var eI=i(wh);d4=n(eI,"Visual Noise (blobs)"),eI.forEach(t),f4=n(nR,": Learning rate is too high\u2014divide by at least 8."),nR.forEach(t),p4=u(wf),$o=l(wf,"LI",{});var cR=i($o);Th=l(cR,"STRONG",{});var tI=i(Th);h4=n(tI,"Weak Details"),tI.forEach(t),v4=n(cR,": Increase learning rate or train for more steps."),cR.forEach(t),wf.forEach(t),$1.forEach(t),J1.forEach(t),om=u(a),en=l(a,"P",{});var aI=i(en);g4=n(aI,"The Unet works progressively, starting with broad shapes and adding finer details. Overcooking it can lead to misplaced or excessive features (e.g., eyes everywhere)."),aI.forEach(t),nm=u(a),rs=l(a,"UL",{});var e2=i(rs);tn=l(e2,"LI",{});var uR=i(tn);Rh=l(uR,"STRONG",{});var sI=i(Rh);m4=n(sI,"Visualization"),sI.forEach(t),_4=n(uR,": Think of it as zooming in from a blurry silhouette to pixel-level detail."),uR.forEach(t),E4=u(e2),an=l(e2,"LI",{});var dR=i(an);Sh=l(dR,"STRONG",{});var lI=i(Sh);b4=n(lI,"Structure"),lI.forEach(t),y4=n(dR,": IN blocks handle planning, OUT blocks manage fine details like texture."),dR.forEach(t),e2.forEach(t),cm=u(a),sn=l(a,"P",{});var iI=i(sn);k4=n(iI,"Burning the Unet results in chaotic outputs."),iI.forEach(t),um=u(a),Ml=l(a,"P",{});var fR=i(Ml);Dh=l(fR,"STRONG",{});var rI=i(Dh);w4=n(rI,"Warning Signs"),rI.forEach(t),T4=n(fR,":"),fR.forEach(t),dm=u(a),nt=l(a,"UL",{});var Tf=i(nt);Ah=l(Tf,"LI",{});var oI=i(Ah);R4=n(oI,"Loss Spikes: Learning rate is too high."),oI.forEach(t),S4=u(Tf),Lh=l(Tf,"LI",{});var nI=i(Lh);D4=n(nI,"Slow Convergence: Learning rate is too low."),nI.forEach(t),A4=u(Tf),Ih=l(Tf,"LI",{});var cI=i(Ih);L4=n(cI,"Oscillating Loss: Poor scheduling or unstable gradients."),cI.forEach(t),Tf.forEach(t),fm=u(a),Kt=l(a,"TABLE",{class:!0});var t2=i(Kt);ln=l(t2,"THEAD",{class:!0});var uI=i(ln);me=l(uI,"TR",{class:!0});var sl=i(me);rn=l(sl,"TH",{class:!0});var dI=i(rn);I4=n(dI,"Practice"),dI.forEach(t),O4=u(sl),on=l(sl,"TH",{class:!0});var fI=i(on);P4=n(fI,"Key Benefit"),fI.forEach(t),z4=u(sl),nn=l(sl,"TH",{class:!0});var pI=i(nn);x4=n(pI,"Tool/Setting"),pI.forEach(t),N4=u(sl),cn=l(sl,"TH",{class:!0});var hI=i(cn);C4=n(hI,"Warning Signs"),hI.forEach(t),sl.forEach(t),uI.forEach(t),G4=u(t2),le=l(t2,"TBODY",{class:!0});var Ct=i(le);_e=l(Ct,"TR",{class:!0});var ll=i(_e);un=l(ll,"TD",{class:!0});var vI=i(un);U4=n(vI,"Track Loss Curves"),vI.forEach(t),H4=u(ll),dn=l(ll,"TD",{class:!0});var gI=i(dn);q4=n(gI,"Detect overfitting/divergence early"),gI.forEach(t),M4=u(ll),fn=l(ll,"TD",{class:!0});var mI=i(fn);B4=n(mI,"TensorBoard, Weights & Biases"),mI.forEach(t),W4=u(ll),pn=l(ll,"TD",{class:!0});var _I=i(pn);j4=n(_I,"Spikes, plateaus, growing gaps"),_I.forEach(t),ll.forEach(t),F4=u(Ct),Ee=l(Ct,"TR",{class:!0});var il=i(Ee);hn=l(il,"TD",{class:!0});var EI=i(hn);V4=n(EI,"Generate Validation Images"),EI.forEach(t),K4=u(il),vn=l(il,"TD",{class:!0});var bI=i(vn);Y4=n(bI,"Visualize model progress"),bI.forEach(t),X4=u(il),gn=l(il,"TD",{class:!0});var yI=i(gn);Z4=n(yI,"Fixed prompts/seeds"),yI.forEach(t),Q4=u(il),mn=l(il,"TD",{class:!0});var kI=i(mn);J4=n(kI,"Artifacts, mode collapse"),kI.forEach(t),il.forEach(t),$4=u(Ct),be=l(Ct,"TR",{class:!0});var rl=i(be);_n=l(rl,"TD",{class:!0});var wI=i(_n);ek=n(wI,"Gradient Clipping"),wI.forEach(t),tk=u(rl),En=l(rl,"TD",{class:!0});var TI=i(En);ak=n(TI,"Prevent exploding gradients"),TI.forEach(t),sk=u(rl),os=l(rl,"TD",{class:!0});var a2=i(os);lk=n(a2,"clip"),Oh=l(a2,"EM",{});var RI=i(Oh);ik=n(RI,"grad_norm"),RI.forEach(t),rk=n(a2," (1.0-2.0)"),a2.forEach(t),ok=u(rl),ct=l(rl,"TD",{class:!0});var Rf=i(ct);nk=n(Rf,"Norm "),bn=l(Rf,"CODE",{class:!0});var SI=i(bn);ck=n(SI,">"),SI.forEach(t),uk=n(Rf," 10.0 or "),yn=l(Rf,"CODE",{class:!0});var DI=i(yn);dk=n(DI,"<"),DI.forEach(t),fk=n(Rf," 0.1"),Rf.forEach(t),rl.forEach(t),pk=u(Ct),ye=l(Ct,"TR",{class:!0});var ol=i(ye);kn=l(ol,"TD",{class:!0});var AI=i(kn);hk=n(AI,"Mixed Precision Training"),AI.forEach(t),vk=u(ol),wn=l(ol,"TD",{class:!0});var LI=i(wn);gk=n(LI,"Faster training, lower VRAM usage"),LI.forEach(t),mk=u(ol),Tn=l(ol,"TD",{class:!0});var II=i(Tn);_k=n(II,"PyTorch AMP (torch.cuda.amp)"),II.forEach(t),Ek=u(ol),Rn=l(ol,"TD",{class:!0});var OI=i(Rn);bk=n(OI,"NaN values (disable if unstable)"),OI.forEach(t),ol.forEach(t),yk=u(Ct),ke=l(Ct,"TR",{class:!0});var nl=i(ke);Sn=l(nl,"TD",{class:!0});var PI=i(Sn);kk=n(PI,"Conservative Learning Rates"),PI.forEach(t),wk=u(nl),Dn=l(nl,"TD",{class:!0});var zI=i(Dn);Tk=n(zI,"Stable training, avoid divergence"),zI.forEach(t),Rk=u(nl),An=l(nl,"TD",{class:!0});var xI=i(An);Sk=n(xI,"Start at 1e-5 to 1e-6, use scheduler"),xI.forEach(t),Dk=u(nl),Ln=l(nl,"TD",{class:!0});var NI=i(Ln);Ak=n(NI,"Spikes, slow convergence"),NI.forEach(t),nl.forEach(t),Ct.forEach(t),t2.forEach(t),pm=u(a),hm=l(a,"HR",{}),vm=u(a),ns=l(a,"H2",{id:!0});var pR=i(ns);cs=l(pR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var CI=i(cs);Ph=l(CI,"SPAN",{class:!0}),i(Ph).forEach(t),CI.forEach(t),Lk=n(pR,"Generating Regularization images"),pR.forEach(t),gm=u(a),us=l(a,"P",{});var s2=i(us);Ik=n(s2,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),In=l(s2,"CODE",{class:!0});var GI=i(In);Ok=n(GI,"1boy"),GI.forEach(t),Pk=n(s2,")."),s2.forEach(t),mm=u(a),ue=l(a,"P",{});var $t=i(ue);zk=n($t,"According to the Dreambooth technique, "),On=l($t,"CODE",{class:!0});var UI=i(On);xk=n(UI,"200"),UI.forEach(t),Nk=n($t," regularization images per training image.  For example, if you have "),Pn=l($t,"CODE",{class:!0});var HI=i(Pn);Ck=n(HI,"16"),HI.forEach(t),Gk=n($t," images: "),zn=l($t,"CODE",{class:!0});var qI=i(zn);Uk=n(qI,"200 * 16 = 3200"),qI.forEach(t),Hk=n($t," total regularization images.  When training, the math involved for calculating total steps is: "),xn=l($t,"CODE",{class:!0});var MI=i(xn);qk=n(MI,"repeats * training images >= repeats * regularization images"),MI.forEach(t),$t.forEach(t),_m=u(a),Nn=l(a,"P",{});var BI=i(Nn);Mk=n(BI,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),BI.forEach(t),Em=u(a),ds=l(a,"H4",{id:!0});var hR=i(ds);fs=l(hR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var WI=i(fs);zh=l(WI,"SPAN",{class:!0}),i(zh).forEach(t),WI.forEach(t),Bk=n(hR,"Important considerations"),hR.forEach(t),bm=u(a),ut=l(a,"OL",{});var Sf=i(ut);xh=l(Sf,"LI",{});var jI=i(xh);Bl=l(jI,"P",{});var l2=i(Bl);Nh=l(l2,"STRONG",{});var FI=i(Nh);Wk=n(FI,"Use the same base model for regularization images and training"),FI.forEach(t),jk=l(l2,"BR",{}),Fk=n(l2,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),l2.forEach(t),jI.forEach(t),Vk=u(Sf),Ch=l(Sf,"LI",{});var VI=i(Ch);Wl=l(VI,"P",{});var i2=i(Wl);Gh=l(i2,"STRONG",{});var KI=i(Gh);Kk=n(KI,"Maintain consistent class representation"),KI.forEach(t),Yk=l(i2,"BR",{}),Xk=n(i2,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),i2.forEach(t),VI.forEach(t),Zk=u(Sf),Uh=l(Sf,"LI",{});var YI=i(Uh);jl=l(YI,"P",{});var r2=i(jl);Hh=l(r2,"STRONG",{});var XI=i(Hh);Qk=n(XI,"Match output resolution to training data"),XI.forEach(t),Jk=l(r2,"BR",{}),$k=n(r2,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),r2.forEach(t),YI.forEach(t),Sf.forEach(t),ym=u(a),Hi(Fl.$$.fragment,a),km=u(a),ps=l(a,"H4",{id:!0});var vR=i(ps);hs=l(vR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ZI=i(hs);qh=l(ZI,"SPAN",{class:!0}),i(qh).forEach(t),ZI.forEach(t),e3=n(vR,"Generate using Stable Diffusion web UI"),vR.forEach(t),wm=u(a),vs=l(a,"P",{});var o2=i(vs);t3=n(o2,"We\u2019re going to use "),Vl=l(o2,"A",{href:!0,rel:!0});var QI=i(Vl);a3=n(QI,"Stable Diffusion web UI"),QI.forEach(t),s3=n(o2," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),o2.forEach(t),Tm=u(a),dt=l(a,"P",{});var Df=i(dt);l3=n(Df,"We\u2019re going to use the "),Cn=l(Df,"CODE",{class:!0});var JI=i(Cn);i3=n(JI,"X/Y/Z plot"),JI.forEach(t),r3=n(Df," script to use "),Gn=l(Df,"CODE",{class:!0});var $I=i(Gn);o3=n($I,"Prompt Search & Replace"),$I.forEach(t),n3=n(Df," to dynamically build a prompt that will generate hundreds of regularization images."),Df.forEach(t),Rm=u(a),J=l(a,"OL",{});var ne=i(J);Mh=l(ne,"LI",{});var eO=i(Mh);Un=l(eO,"P",{});var gR=i(Un);c3=n(gR,"Select the text 2 image tab.  Enter a generic prompt "),Hn=l(gR,"CODE",{class:!0});var tO=i(Hn);u3=n(tO,"princeadam, portrait, looking_at_viewer, forest"),tO.forEach(t),gR.forEach(t),eO.forEach(t),d3=u(ne),Bh=l(ne,"LI",{});var aO=i(Bh);Kl=l(aO,"P",{});var n2=i(Kl);f3=n(n2,"In generation parameters and select the "),qn=l(n2,"CODE",{class:!0});var sO=i(qn);p3=n(sO,"X/Y/Z plot"),sO.forEach(t),h3=n(n2," script."),n2.forEach(t),aO.forEach(t),v3=u(ne),Wh=l(ne,"LI",{});var lO=i(Wh);K=l(lO,"P",{});var te=i(K);g3=n(te,"Select the "),Mn=l(te,"CODE",{class:!0});var iO=i(Mn);m3=n(iO,"X"),iO.forEach(t),_3=n(te," parameter and "),Bn=l(te,"CODE",{class:!0});var rO=i(Bn);E3=n(rO,"Prompt SR"),rO.forEach(t),b3=n(te," for Prompt Replace.  We\u2019re going to replace "),Wn=l(te,"CODE",{class:!0});var oO=i(Wn);y3=n(oO,"portrait"),oO.forEach(t),k3=n(te," with different camera angle tags: "),jn=l(te,"CODE",{class:!0});var nO=i(jn);w3=n(nO,"close-up"),nO.forEach(t),T3=n(te,", "),Fn=l(te,"CODE",{class:!0});var cO=i(Fn);R3=n(cO,"upper_body"),cO.forEach(t),S3=n(te,", "),Vn=l(te,"CODE",{class:!0});var uO=i(Vn);D3=n(uO,"from_below"),uO.forEach(t),A3=n(te,", "),Kn=l(te,"CODE",{class:!0});var dO=i(Kn);L3=n(dO,"from_above"),dO.forEach(t),I3=n(te,", "),Yn=l(te,"CODE",{class:!0});var fO=i(Yn);O3=n(fO,"dutch_angle"),fO.forEach(t),te.forEach(t),lO.forEach(t),P3=u(ne),jh=l(ne,"LI",{});var pO=i(jh);$=l(pO,"P",{});var se=i($);z3=n(se,"Select the "),Xn=l(se,"CODE",{class:!0});var hO=i(Xn);x3=n(hO,"Y"),hO.forEach(t),N3=n(se," parameter and "),Zn=l(se,"CODE",{class:!0});var vO=i(Zn);C3=n(vO,"Prompt SR"),vO.forEach(t),G3=n(se," for Prompt Replace.  Replace "),Qn=l(se,"CODE",{class:!0});var gO=i(Qn);U3=n(gO,"looking_at_viewer"),gO.forEach(t),H3=n(se,": "),Jn=l(se,"CODE",{class:!0});var mO=i(Jn);q3=n(mO,"looking_away"),mO.forEach(t),M3=n(se,", "),$n=l(se,"CODE",{class:!0});var _O=i($n);B3=n(_O,"looking_to_the_side"),_O.forEach(t),W3=n(se,", "),ec=l(se,"CODE",{class:!0});var EO=i(ec);j3=n(EO,"looking_ahead"),EO.forEach(t),F3=n(se,", "),tc=l(se,"CODE",{class:!0});var bO=i(tc);V3=n(bO,"looking_down"),bO.forEach(t),se.forEach(t),pO.forEach(t),K3=u(ne),Fh=l(ne,"LI",{});var yO=i(Fh);Y=l(yO,"P",{});var ae=i(Y);Y3=n(ae,"Select the "),ac=l(ae,"CODE",{class:!0});var kO=i(ac);X3=n(kO,"Z"),kO.forEach(t),Z3=n(ae," parameter and "),sc=l(ae,"CODE",{class:!0});var wO=i(sc);Q3=n(wO,"Prompt SR"),wO.forEach(t),J3=n(ae," for Prompt Replace. Replace "),lc=l(ae,"CODE",{class:!0});var TO=i(lc);$3=n(TO,"forest"),TO.forEach(t),e5=n(ae," with a vareity of locatinos: "),ic=l(ae,"CODE",{class:!0});var RO=i(ic);t5=n(RO,"castle"),RO.forEach(t),a5=n(ae,", "),rc=l(ae,"CODE",{class:!0});var SO=i(rc);s5=n(SO,"mountain"),SO.forEach(t),l5=n(ae,", "),oc=l(ae,"CODE",{class:!0});var DO=i(oc);i5=n(DO,"cave"),DO.forEach(t),r5=n(ae,", "),nc=l(ae,"CODE",{class:!0});var AO=i(nc);o5=n(AO,"farm"),AO.forEach(t),n5=n(ae,", "),cc=l(ae,"CODE",{class:!0});var LO=i(cc);c5=n(LO,"ocean"),LO.forEach(t),ae.forEach(t),yO.forEach(t),u5=u(ne),Vh=l(ne,"LI",{});var IO=i(Vh);uc=l(IO,"P",{});var mR=i(uc);d5=n(mR,"Select a fast sampler like "),dc=l(mR,"CODE",{class:!0});var OO=i(dc);f5=n(OO,"DPM2 KARRAS"),OO.forEach(t),mR.forEach(t),IO.forEach(t),p5=u(ne),Kh=l(ne,"LI",{});var PO=i(Kh);gs=l(PO,"P",{});var Rv=i(gs);h5=n(Rv,"CFG Scale set to "),fc=l(Rv,"CODE",{class:!0});var zO=i(fc);v5=n(zO,"7"),zO.forEach(t),g5=n(Rv," and Steps to "),pc=l(Rv,"CODE",{class:!0});var xO=i(pc);m5=n(xO,"20"),xO.forEach(t),Rv.forEach(t),PO.forEach(t),ne.forEach(t),Sm=u(a),ft=l(a,"P",{});var Af=i(ft);_5=n(Af,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),hc=l(Af,"CODE",{class:!0});var NO=i(hc);E5=n(NO,"150"),NO.forEach(t),b5=n(Af," - "),vc=l(Af,"CODE",{class:!0});var CO=i(vc);y5=n(CO,"200"),CO.forEach(t),k5=n(Af," and keep in mind we can add and remove as we try different training settings with different output."),Af.forEach(t),Dm=u(a),Hi(Yl.$$.fragment,a),Am=u(a),ms=l(a,"H4",{id:!0});var _R=i(ms);_s=l(_R,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var GO=i(_s);Yh=l(GO,"SPAN",{class:!0}),i(Yh).forEach(t),GO.forEach(t),w5=n(_R,"Download images"),_R.forEach(t),Lm=u(a),gc=l(a,"P",{});var UO=i(gc);T5=n(UO,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),UO.forEach(t),Im=u(a),we=l(a,"UL",{});var cl=i(we);mc=l(cl,"LI",{});var ER=i(mc);Xl=l(ER,"A",{href:!0,rel:!0});var HO=i(Xl);R5=n(HO,"3ee Games regularization images"),HO.forEach(t),S5=n(ER,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),ER.forEach(t),D5=u(cl),_c=l(cl,"LI",{});var bR=i(_c);Zl=l(bR,"A",{href:!0,rel:!0});var qO=i(Zl);A5=n(qO,"Pre-Rendered Regularization Images"),qO.forEach(t),L5=n(bR,": Includes 1500 regularization images."),bR.forEach(t),I5=u(cl),Ec=l(cl,"LI",{});var yR=i(Ec);Ql=l(yR,"A",{href:!0,rel:!0});var MO=i(Ql);O5=n(MO,"Stable Diffusion 1.5 Regularization Images"),MO.forEach(t),P5=n(yR,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),yR.forEach(t),z5=u(cl),bc=l(cl,"LI",{});var kR=i(bc);Jl=l(kR,"A",{href:!0,rel:!0});var BO=i(Jl);x5=n(BO,"Aitrepreneur SDXL image set"),BO.forEach(t),N5=n(kR,": a large image set generated with Stable Diffusion SDXL."),kR.forEach(t),cl.forEach(t),Om=u(a),Es=l(a,"H4",{id:!0});var wR=i(Es);bs=l(wR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var WO=i(bs);Xh=l(WO,"SPAN",{class:!0}),i(Xh).forEach(t),WO.forEach(t),C5=n(wR,"Captioning Regularization images"),wR.forEach(t),Pm=u(a),yc=l(a,"P",{});var jO=i(yc);G5=n(jO,"While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts\u2014critical for maintaining style consistency."),jO.forEach(t),zm=u(a),kc=l(a,"P",{});var FO=i(kc);U5=n(FO,"Here\u2019s the workflow I used:"),FO.forEach(t),xm=u(a),pt=l(a,"UL",{});var Lf=i(pt);wc=l(Lf,"LI",{});var TR=i(wc);Zh=l(TR,"STRONG",{});var VO=i(Zh);H5=n(VO,"Structured Filenames"),VO.forEach(t),q5=n(TR,": Stable Diffusion Web UI automatically embeds prompts in filenames"),TR.forEach(t),M5=u(Lf),ht=l(Lf,"LI",{});var Ni=i(ht);Qh=l(Ni,"STRONG",{});var KO=i(Qh);B5=n(KO,"Automated Extraction"),KO.forEach(t),W5=n(Ni,": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),Tc=l(Ni,"CODE",{class:!0});var YO=i(Tc);j5=n(YO,"1boy"),YO.forEach(t),F5=n(Ni," or "),Rc=l(Ni,"CODE",{class:!0});var XO=i(Rc);V5=n(XO,"purple_vest"),XO.forEach(t),K5=n(Ni,"."),Ni.forEach(t),Y5=u(Lf),Sc=l(Lf,"LI",{});var RR=i(Sc);Jh=l(RR,"STRONG",{});var ZO=i(Jh);X5=n(ZO,"Manual Verification"),ZO.forEach(t),Z5=n(RR,": Spot-checked captions to ensure accuracy."),RR.forEach(t),Lf.forEach(t),Nm=u(a),$l=l(a,"PRE",{class:!0});var lN=i($l);lN.forEach(t),Cm=u(a),ys=l(a,"OL",{});var c2=i(ys);ei=l(c2,"LI",{});var u2=i(ei);Q5=n(u2,"Save this file as "),Dc=l(u2,"CODE",{class:!0});var QO=i(Dc);J5=n(QO,"filename2txt.bat"),QO.forEach(t),$5=n(u2," and place it into the regularization images directory"),u2.forEach(t),ew=u(c2),ti=l(c2,"LI",{});var d2=i(ti);tw=n(d2,"Run: "),Ac=l(d2,"CODE",{class:!0});var JO=i(Ac);aw=n(JO,".\\filename2txt.bat"),JO.forEach(t),sw=n(d2,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),d2.forEach(t),c2.forEach(t),Gm=u(a),ks=l(a,"P",{});var f2=i(ks);$h=l(f2,"STRONG",{});var $O=i($h);lw=n($O,"Example filename"),$O.forEach(t),iw=n(f2,": "),Lc=l(f2,"CODE",{class:!0});var eP=i(Lc);rw=n(eP,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),eP.forEach(t),f2.forEach(t),Um=u(a),ws=l(a,"H2",{id:!0});var SR=i(ws);Ts=l(SR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var tP=i(Ts);ev=l(tP,"SPAN",{class:!0}),i(ev).forEach(t),tP.forEach(t),ow=n(SR,"Training a LoRA"),SR.forEach(t),Hm=u(a),vt=l(a,"P",{});var If=i(vt);nw=n(If,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),ai=l(If,"A",{href:!0,rel:!0});var aP=i(ai);cw=n(aP,"Kohya\u2019s Stable Diffusion trainers"),aP.forEach(t),uw=n(If,".  If you want to use a GUI, use "),si=l(If,"A",{href:!0,rel:!0});var sP=i(si);dw=n(sP,"Kohya\u2019s GUI"),sP.forEach(t),fw=n(If,".  In this article, you can will able to use either since the settings config can be modified in json and reloaded in the GUI."),If.forEach(t),qm=u(a),li=l(a,"BLOCKQUOTE",{class:!0});var lP=i(li);Rs=l(lP,"P",{class:!0});var p2=i(Rs);pw=n(p2,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ii=l(p2,"A",{href:!0,rel:!0});var iP=i(ii);hw=n(iP,"Kohya SD script documentation"),iP.forEach(t),vw=n(p2,"."),p2.forEach(t),lP.forEach(t),Mm=u(a),ri=l(a,"BLOCKQUOTE",{class:!0});var rP=i(ri);Ae=l(rP,"P",{class:!0});var Ci=i(Ae);gw=n(Ci,"\u{1F4C4} Recommended reading: "),oi=l(Ci,"A",{href:!0,rel:!0});var oP=i(oi);mw=n(oP,"https://rentry.org/59xed3"),oP.forEach(t),_w=n(Ci,", "),ni=l(Ci,"A",{href:!0,rel:!0});var nP=i(ni);Ew=n(nP,"https://rentry.org/ezlora"),nP.forEach(t),bw=n(Ci,", "),ci=l(Ci,"A",{href:!0,rel:!0});var cP=i(ci);yw=n(cP,"https://rentry.org/lora_train"),cP.forEach(t),Ci.forEach(t),rP.forEach(t),Bm=u(a),Ss=l(a,"H3",{id:!0});var DR=i(Ss);Ds=l(DR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uP=i(Ds);tv=l(uP,"SPAN",{class:!0}),i(tv).forEach(t),uP.forEach(t),kw=n(DR,"Directory setup"),DR.forEach(t),Wm=u(a),As=l(a,"P",{});var h2=i(As);ww=n(h2,"In your configuration json, use "),Ic=l(h2,"CODE",{class:!0});var dP=i(Ic);Tw=n(dP,"reg_data_dir"),dP.forEach(t),Rw=n(h2," to point to the directory with your regularization images:"),h2.forEach(t),jm=u(a),ui=l(a,"PRE",{class:!0});var iN=i(ui);iN.forEach(t),Fm=u(a),Oc=l(a,"P",{});var fP=i(Oc);Sw=n(fP,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),fP.forEach(t),Vm=u(a),di=l(a,"PRE",{class:!0});var rN=i(di);rN.forEach(t),Km=u(a),Ls=l(a,"P",{});var v2=i(Ls);Dw=n(v2,"Set the "),Pc=l(v2,"CODE",{class:!0});var pP=i(Pc);Aw=n(pP,"number of iterations"),pP.forEach(t),Lw=n(v2," so that training images are used as often as or more often than regularization images."),v2.forEach(t),Ym=u(a),fi=l(a,"BLOCKQUOTE",{class:!0});var hP=i(fi);Is=l(hP,"P",{class:!0});var g2=i(Is);Iw=n(g2,"In one epoch, the total data is "),zc=l(g2,"CODE",{class:!0});var vP=i(zc);Ow=n(vP,"training images \xD7 iterations"),vP.forEach(t),Pw=n(g2,". If there are more regularization images than this, the extras won\u2019t be used."),g2.forEach(t),hP.forEach(t),Xm=u(a),gt=l(a,"P",{});var Of=i(gt);zw=n(Of,"Create folders in the training image folder with the format "),xc=l(Of,"CODE",{class:!0});var gP=i(xc);xw=n(gP,"<repetition count>_<class>"),gP.forEach(t),Nw=n(Of," multiple times, and similarly create folders in the regularization image folder with the format "),Nc=l(Of,"CODE",{class:!0});var mP=i(Nc);Cw=n(mP,"<repetition count>_<class>"),mP.forEach(t),Gw=n(Of,"."),Of.forEach(t),Zm=u(a),Cc=l(a,"P",{});var _P=i(Cc);Uw=n(_P,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),_P.forEach(t),Qm=u(a),Os=l(a,"UL",{});var m2=i(Os);Gc=l(m2,"LI",{});var AR=i(Gc);Hw=n(AR,"train_data_dir"),av=l(AR,"UL",{});var EP=i(av);sv=l(EP,"LI",{});var bP=i(sv);qw=n(bP,"10_princeadam"),bP.forEach(t),EP.forEach(t),AR.forEach(t),Mw=u(m2),Uc=l(m2,"LI",{});var LR=i(Uc);Bw=n(LR,"reg_dir"),lv=l(LR,"UL",{});var yP=i(lv);iv=l(yP,"LI",{});var kP=i(iv);Ww=n(kP,"1_1boy"),kP.forEach(t),yP.forEach(t),LR.forEach(t),m2.forEach(t),Jm=u(a),Hc=l(a,"P",{});var wP=i(Hc);jw=n(wP,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),wP.forEach(t),$m=u(a),pi=l(a,"P",{class:!0});var TP=i(pi);hi=l(TP,"IMG",{src:!0,alt:!0,class:!0}),TP.forEach(t),e1=u(a),Ps=l(a,"H3",{id:!0});var IR=i(Ps);zs=l(IR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var RP=i(zs);rv=l(RP,"SPAN",{class:!0}),i(rv).forEach(t),RP.forEach(t),Fw=n(IR,"Training Settings"),IR.forEach(t),t1=u(a),Yt=l(a,"P",{});var Sv=i(Yt);Vw=n(Sv,"The training setup we\u2019re going to use is:  "),qc=l(Sv,"CODE",{class:!0});var SP=i(qc);Kw=n(SP,"Number of images * repeats * epoch / batch size = total steps"),SP.forEach(t),Yw=n(Sv,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Mc=l(Sv,"CODE",{class:!0});var DP=i(Mc);Xw=n(DP,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),DP.forEach(t),Sv.forEach(t),a1=u(a),Xt=l(a,"TABLE",{class:!0});var _2=i(Xt);Bc=l(_2,"THEAD",{class:!0});var AP=i(Bc);ie=l(AP,"TR",{class:!0});var Gt=i(ie);Wc=l(Gt,"TH",{class:!0});var LP=i(Wc);Zw=n(LP,"Number of Images"),LP.forEach(t),Qw=u(Gt),jc=l(Gt,"TH",{class:!0});var IP=i(jc);Jw=n(IP,"Repeats"),IP.forEach(t),$w=u(Gt),Fc=l(Gt,"TH",{class:!0});var OP=i(Fc);e6=n(OP,"Epochs"),OP.forEach(t),t6=u(Gt),Vc=l(Gt,"TH",{class:!0});var PP=i(Vc);a6=n(PP,"Batch Size"),PP.forEach(t),s6=u(Gt),Kc=l(Gt,"TH",{class:!0});var zP=i(Kc);l6=n(zP,"Total Steps"),zP.forEach(t),Gt.forEach(t),AP.forEach(t),i6=u(_2),Yc=l(_2,"TBODY",{class:!0});var xP=i(Yc);re=l(xP,"TR",{class:!0});var Ut=i(re);Xc=l(Ut,"TD",{class:!0});var NP=i(Xc);r6=n(NP,"45"),NP.forEach(t),o6=u(Ut),Zc=l(Ut,"TD",{class:!0});var CP=i(Zc);n6=n(CP,"10"),CP.forEach(t),c6=u(Ut),Qc=l(Ut,"TD",{class:!0});var GP=i(Qc);u6=n(GP,"20"),GP.forEach(t),d6=u(Ut),Jc=l(Ut,"TD",{class:!0});var UP=i(Jc);f6=n(UP,"2"),UP.forEach(t),p6=u(Ut),$c=l(Ut,"TD",{class:!0});var HP=i($c);h6=n(HP,"4500"),HP.forEach(t),Ut.forEach(t),xP.forEach(t),_2.forEach(t),s1=u(a),eu=l(a,"P",{});var qP=i(eu);v6=n(qP,"Now let\u2019s focus on these training settings:"),qP.forEach(t),l1=u(a),vi=l(a,"PRE",{class:!0});var oN=i(vi);oN.forEach(t),i1=u(a),M=l(a,"UL",{});var V=i(M);tu=l(V,"LI",{});var OR=i(tu);gi=l(OR,"STRONG",{});var E2=i(gi);g6=n(E2,"Learning Rate ("),au=l(E2,"CODE",{class:!0});var MP=i(au);m6=n(MP,"learning_rate"),MP.forEach(t),_6=n(E2,")"),E2.forEach(t),E6=n(OR,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),OR.forEach(t),b6=u(V),su=l(V,"LI",{});var PR=i(su);mi=l(PR,"STRONG",{});var b2=i(mi);y6=n(b2,"Text Encoder Learning Rate ("),lu=l(b2,"CODE",{class:!0});var BP=i(lu);k6=n(BP,"text_encoder_lr"),BP.forEach(t),w6=n(b2,")"),b2.forEach(t),T6=n(PR,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),PR.forEach(t),R6=u(V),iu=l(V,"LI",{});var zR=i(iu);_i=l(zR,"STRONG",{});var y2=i(_i);S6=n(y2,"UNet Learning Rate ("),ru=l(y2,"CODE",{class:!0});var WP=i(ru);D6=n(WP,"unet_lr"),WP.forEach(t),A6=n(y2,")"),y2.forEach(t),L6=n(zR,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),zR.forEach(t),I6=u(V),ou=l(V,"LI",{});var xR=i(ou);Ei=l(xR,"STRONG",{});var k2=i(Ei);O6=n(k2,"Learning Rate Scheduler ("),nu=l(k2,"CODE",{class:!0});var jP=i(nu);P6=n(jP,"lr_scheduler"),jP.forEach(t),z6=n(k2,")"),k2.forEach(t),x6=n(xR,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),xR.forEach(t),N6=u(V),cu=l(V,"LI",{});var NR=i(cu);ov=l(NR,"STRONG",{});var FP=i(ov);C6=n(FP,"Number of Cycles"),FP.forEach(t),G6=n(NR,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),NR.forEach(t),U6=u(V),uu=l(V,"LI",{});var CR=i(uu);bi=l(CR,"STRONG",{});var w2=i(bi);H6=n(w2,"Network Dimension ("),du=l(w2,"CODE",{class:!0});var VP=i(du);q6=n(VP,"network_dim"),VP.forEach(t),M6=n(w2,")"),w2.forEach(t),B6=n(CR,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),CR.forEach(t),W6=u(V),fu=l(V,"LI",{});var GR=i(fu);yi=l(GR,"STRONG",{});var T2=i(yi);j6=n(T2,"Network Alpha ("),pu=l(T2,"CODE",{class:!0});var KP=i(pu);F6=n(KP,"network_alpha"),KP.forEach(t),V6=n(T2,")"),T2.forEach(t),K6=n(GR,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),GR.forEach(t),Y6=u(V),hu=l(V,"LI",{});var UR=i(hu);ki=l(UR,"STRONG",{});var R2=i(ki);X6=n(R2,"Clip Skip ("),vu=l(R2,"CODE",{class:!0});var YP=i(vu);Z6=n(YP,"clip_skip"),YP.forEach(t),Q6=n(R2,")"),R2.forEach(t),J6=n(UR,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),UR.forEach(t),$6=u(V),gu=l(V,"LI",{});var HR=i(gu);wi=l(HR,"STRONG",{});var S2=i(wi);e8=n(S2,"Max Token Length ("),mu=l(S2,"CODE",{class:!0});var XP=i(mu);t8=n(XP,"max_token_length"),XP.forEach(t),a8=n(S2,")"),S2.forEach(t),s8=n(HR,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),HR.forEach(t),l8=u(V),_u=l(V,"LI",{});var qR=i(_u);Ti=l(qR,"STRONG",{});var D2=i(Ti);i8=n(D2,"Noise Offset ("),Eu=l(D2,"CODE",{class:!0});var ZP=i(Eu);r8=n(ZP,"noise_offset"),ZP.forEach(t),o8=n(D2,")"),D2.forEach(t),n8=n(qR,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),qR.forEach(t),c8=u(V),bu=l(V,"LI",{});var MR=i(bu);Ri=l(MR,"STRONG",{});var A2=i(Ri);u8=n(A2,"Regularization Data Directory ("),yu=l(A2,"CODE",{class:!0});var QP=i(yu);d8=n(QP,"reg_data_dir"),QP.forEach(t),f8=n(A2,")"),A2.forEach(t),p8=n(MR,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),MR.forEach(t),V.forEach(t),r1=u(a),xs=l(a,"H3",{id:!0});var BR=i(xs);Ns=l(BR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var JP=i(Ns);nv=l(JP,"SPAN",{class:!0}),i(nv).forEach(t),JP.forEach(t),h8=n(BR,"Fine Tuning"),BR.forEach(t),o1=u(a),ku=l(a,"P",{});var $P=i(ku);v8=n($P,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),$P.forEach(t),n1=u(a),Hi(Si.$$.fragment,a),c1=u(a),Cs=l(a,"H4",{id:!0});var WR=i(Cs);Gs=l(WR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ez=i(Gs);cv=l(ez,"SPAN",{class:!0}),i(cv).forEach(t),ez.forEach(t),g8=n(WR,"Workflow with Auto1111 WebUI"),WR.forEach(t),u1=u(a),Us=l(a,"P",{});var L2=i(Us);m8=n(L2,"We\u2019re going to use "),Di=l(L2,"A",{href:!0,rel:!0});var tz=i(Di);_8=n(tz,"Stable Diffusion web UI"),tz.forEach(t),E8=n(L2," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),L2.forEach(t),d1=u(a),Hs=l(a,"P",{});var I2=i(Hs);b8=n(I2,"We\u2019re going to use the "),wu=l(I2,"CODE",{class:!0});var az=i(wu);y8=n(az,"X/Y/Z plot"),az.forEach(t),k8=n(I2," script to compare different epochs."),I2.forEach(t),f1=u(a),oe=l(a,"UL",{});var Ht=i(oe);Tu=l(Ht,"LI",{});var jR=i(Tu);w8=n(jR,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),p1=l(jR,"PRINCEADAM0001:0.7",{}),i(p1).forEach(t),jR.forEach(t),T8=u(Ht),uv=l(Ht,"LI",{});var sz=i(uv);R8=n(sz,"In generation parameters and select the X/Y/Z plot script."),sz.forEach(t),S8=u(Ht),mt=l(Ht,"LI",{});var Gi=i(mt);D8=n(Gi,"Select "),Ru=l(Gi,"CODE",{class:!0});var lz=i(Ru);A8=n(lz,"Prompt SR"),lz.forEach(t),L8=n(Gi," for Prompt Replace.  We\u2019re going to replace "),Su=l(Gi,"CODE",{class:!0});var iz=i(Su);I8=n(iz,"<princeadam0001:0.7>"),iz.forEach(t),O8=n(Gi," with different epoch: "),Du=l(Gi,"CODE",{class:!0});var rz=i(Du);P8=n(rz,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),rz.forEach(t),Gi.forEach(t),z8=u(Ht),Au=l(Ht,"LI",{});var FR=i(Au);x8=n(FR,"Select a fast sampler like "),Lu=l(FR,"CODE",{class:!0});var oz=i(Lu);N8=n(oz,"DPM2 KARRAS"),oz.forEach(t),FR.forEach(t),C8=u(Ht),qs=l(Ht,"LI",{});var Dv=i(qs);G8=n(Dv,"CFG Scale set to "),Iu=l(Dv,"CODE",{class:!0});var nz=i(Iu);U8=n(nz,"7"),nz.forEach(t),H8=n(Dv," and Steps to "),Ou=l(Dv,"CODE",{class:!0});var cz=i(Ou);q8=n(cz,"20"),cz.forEach(t),Dv.forEach(t),Ht.forEach(t),h1=u(a),_t=l(a,"P",{});var Pf=i(_t);M8=n(Pf,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Pu=l(Pf,"CODE",{class:!0});var uz=i(Pu);B8=n(uz,"network_dim"),uz.forEach(t),W8=n(Pf," and "),zu=l(Pf,"CODE",{class:!0});var dz=i(zu);j8=n(dz,"network_alpha"),dz.forEach(t),F8=n(Pf,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Pf.forEach(t),v1=u(a),Te=l(a,"UL",{});var ul=i(Te);Ms=l(ul,"LI",{});var Av=i(Ms);V8=n(Av,"Select "),xu=l(Av,"CODE",{class:!0});var fz=i(xu);K8=n(fz,"Prompt SR"),fz.forEach(t),Y8=n(Av," for Prompt Replace.  We\u2019re going to replace the weights "),Nu=l(Av,"CODE",{class:!0});var pz=i(Nu);X8=n(pz,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),pz.forEach(t),Av.forEach(t),Z8=u(ul),Ai=l(ul,"LI",{});var O2=i(Ai);Q8=n(O2,"Use Prompt SR to generate a variety of angles: Select "),Cu=l(O2,"CODE",{class:!0});var hz=i(Cu);J8=n(hz,"Prompt SR"),hz.forEach(t),$8=n(O2," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),O2.forEach(t),e7=u(ul),dv=l(ul,"LI",{});var vz=i(dv);t7=n(vz,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),vz.forEach(t),a7=u(ul),fv=l(ul,"LI",{});var gz=i(fv);s7=n(gz,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),gz.forEach(t),ul.forEach(t),g1=u(a),Bs=l(a,"H4",{id:!0});var VR=i(Bs);Ws=l(VR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mz=i(Ws);pv=l(mz,"SPAN",{class:!0}),i(pv).forEach(t),mz.forEach(t),l7=n(VR,"Issues to look for"),VR.forEach(t),m1=u(a),Re=l(a,"UL",{});var dl=i(Re);Gu=l(dl,"LI",{});var KR=i(Gu);hv=l(KR,"STRONG",{});var _z=i(hv);i7=n(_z,"Undercooked:"),_z.forEach(t),r7=n(KR," Lacks output, adjust unet learning rate or extend training duration."),KR.forEach(t),o7=u(dl),Uu=l(dl,"LI",{});var YR=i(Uu);vv=l(YR,"STRONG",{});var Ez=i(vv);n7=n(Ez,"Overcooked:"),Ez.forEach(t),c7=n(YR," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),YR.forEach(t),u7=u(dl),Hu=l(dl,"LI",{});var XR=i(Hu);gv=l(XR,"STRONG",{});var bz=i(gv);d7=n(bz,"Overfit:"),bz.forEach(t),f7=n(XR," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),XR.forEach(t),p7=u(dl),qu=l(dl,"LI",{});var ZR=i(qu);mv=l(ZR,"STRONG",{});var yz=i(mv);h7=n(yz,"Mismatched:"),yz.forEach(t),v7=n(ZR," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),ZR.forEach(t),dl.forEach(t),_1=u(a),Mu=l(a,"P",{});var kz=i(Mu);g7=n(kz,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),kz.forEach(t),E1=u(a),Li=l(a,"P",{class:!0});var wz=i(Li);Ii=l(wz,"IMG",{src:!0,alt:!0,class:!0}),wz.forEach(t),b1=u(a),js=l(a,"H3",{id:!0});var QR=i(js);Fs=l(QR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Tz=i(Fs);_v=l(Tz,"SPAN",{class:!0}),i(_v).forEach(t),Tz.forEach(t),m7=n(QR,"Troubleshooting"),QR.forEach(t),y1=u(a),Bu=l(a,"P",{});var Rz=i(Bu);_7=n(Rz,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),Rz.forEach(t),k1=u(a),Et=l(a,"UL",{});var zf=i(Et);Oi=l(zf,"LI",{});var P2=i(Oi);E7=n(P2,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Wu=l(P2,"CODE",{class:!0});var Sz=i(Wu);b7=n(Sz,"200"),Sz.forEach(t),y7=n(P2," regularization images per training image."),P2.forEach(t),k7=u(zf),Pi=l(zf,"LI",{});var z2=i(Pi);w7=n(z2,"Repeats of regularization images, but may overfit more.  Increasing the "),ju=l(z2,"CODE",{class:!0});var Dz=i(ju);T7=n(Dz,"repetition_count"),Dz.forEach(t),R7=n(z2," will cycle through the images more but the results may have results that overfit the model."),z2.forEach(t),S7=u(zf),Ev=l(zf,"LI",{});var Az=i(Ev);D7=n(Az,"Create more regularization images without increasing repeats will help with the overfitting."),Az.forEach(t),zf.forEach(t),w1=u(a),Zt=l(a,"TABLE",{class:!0});var x2=i(Zt);Fu=l(x2,"THEAD",{class:!0});var Lz=i(Fu);bt=l(Lz,"TR",{class:!0});var xf=i(bt);Vu=l(xf,"TH",{class:!0});var Iz=i(Vu);A7=n(Iz,"Issue"),Iz.forEach(t),L7=u(xf),Ku=l(xf,"TH",{class:!0});var Oz=i(Ku);I7=n(Oz,"Situation"),Oz.forEach(t),O7=u(xf),Yu=l(xf,"TH",{class:!0});var Pz=i(Yu);P7=n(Pz,"Recommendation"),Pz.forEach(t),xf.forEach(t),Lz.forEach(t),z7=u(x2),Se=l(x2,"TBODY",{class:!0});var fl=i(Se);yt=l(fl,"TR",{class:!0});var Nf=i(yt);Xu=l(Nf,"TD",{class:!0});var zz=i(Xu);x7=n(zz,"Varying quality"),zz.forEach(t),N7=u(Nf),Zu=l(Nf,"TD",{class:!0});var xz=i(Zu);C7=n(xz,"Results differ from expectations"),xz.forEach(t),G7=u(Nf),Qu=l(Nf,"TD",{class:!0});var Nz=i(Qu);U7=n(Nz,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),Nz.forEach(t),Nf.forEach(t),H7=u(fl),kt=l(fl,"TR",{class:!0});var Cf=i(kt);Ju=l(Cf,"TD",{class:!0});var Cz=i(Ju);q7=n(Cz,"Inadequate regularization for input data"),Cz.forEach(t),M7=u(Cf),$u=l(Cf,"TD",{class:!0});var Gz=i($u);B7=n(Gz,"Lower input images, less regularization needed"),Gz.forEach(t),W7=u(Cf),ed=l(Cf,"TD",{class:!0});var Uz=i(ed);j7=n(Uz,"Reduce the number of input images or increasing the quantity of reg images."),Uz.forEach(t),Cf.forEach(t),F7=u(fl),wt=l(fl,"TR",{class:!0});var Gf=i(wt);td=l(Gf,"TD",{class:!0});var Hz=i(td);V7=n(Hz,"Overfitting due to repetition"),Hz.forEach(t),K7=u(Gf),ad=l(Gf,"TD",{class:!0});var qz=i(ad);Y7=n(qz,"Repeats of reg images, risk of overfitting"),qz.forEach(t),X7=u(Gf),sd=l(Gf,"TD",{class:!0});var Mz=i(sd);Z7=n(Mz,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),Mz.forEach(t),Gf.forEach(t),Q7=u(fl),Tt=l(fl,"TR",{class:!0});var Uf=i(Tt);ld=l(Uf,"TD",{class:!0});var Bz=i(ld);J7=n(Bz,"Mitigate overfitting while increasing diversity"),Bz.forEach(t),$7=u(Uf),id=l(Uf,"TD",{class:!0});var Wz=i(id);eT=n(Wz,"Create more reg images without repeats"),Wz.forEach(t),tT=u(Uf),rd=l(Uf,"TD",{class:!0});var jz=i(rd);aT=n(jz,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),jz.forEach(t),Uf.forEach(t),fl.forEach(t),x2.forEach(t),T1=u(a),Vs=l(a,"H4",{id:!0});var JR=i(Vs);Ks=l(JR,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Fz=i(Ks);bv=l(Fz,"SPAN",{class:!0}),i(bv).forEach(t),Fz.forEach(t),sT=n(JR,"More Solutions"),JR.forEach(t),R1=u(a),od=l(a,"P",{});var Vz=i(od);lT=n(Vz,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),Vz.forEach(t),S1=u(a),Qt=l(a,"TABLE",{class:!0});var N2=i(Qt);nd=l(N2,"THEAD",{class:!0});var Kz=i(nd);Rt=l(Kz,"TR",{class:!0});var Hf=i(Rt);cd=l(Hf,"TH",{class:!0});var Yz=i(cd);iT=n(Yz,"Symptom"),Yz.forEach(t),rT=u(Hf),ud=l(Hf,"TH",{class:!0});var Xz=i(ud);oT=n(Xz,"Likely Cause"),Xz.forEach(t),nT=u(Hf),dd=l(Hf,"TH",{class:!0});var Zz=i(dd);cT=n(Zz,"Solution"),Zz.forEach(t),Hf.forEach(t),Kz.forEach(t),uT=u(N2),W=l(N2,"TBODY",{class:!0});var X=i(W);St=l(X,"TR",{class:!0});var qf=i(St);fd=l(qf,"TD",{class:!0});var Qz=i(fd);dT=n(Qz,"Plastic texture persists"),Qz.forEach(t),fT=u(qf),pd=l(qf,"TD",{class:!0});var Jz=i(pd);pT=n(Jz,"Insufficient human reg images"),Jz.forEach(t),hT=u(qf),hd=l(qf,"TD",{class:!0});var $z=i(hd);vT=n($z,"Add real photos to reg set"),$z.forEach(t),qf.forEach(t),gT=u(X),Dt=l(X,"TR",{class:!0});var Mf=i(Dt);vd=l(Mf,"TD",{class:!0});var ex=i(vd);mT=n(ex,"Loss plateaus early"),ex.forEach(t),_T=u(Mf),gd=l(Mf,"TD",{class:!0});var tx=i(gd);ET=n(tx,"Learning rate too low"),tx.forEach(t),bT=u(Mf),md=l(Mf,"TD",{class:!0});var ax=i(md);yT=n(ax,"Increase LR by 10x"),ax.forEach(t),Mf.forEach(t),kT=u(X),At=l(X,"TR",{class:!0});var Bf=i(At);_d=l(Bf,"TD",{class:!0});var sx=i(_d);wT=n(sx,"Features blurry"),sx.forEach(t),TT=u(Bf),Ed=l(Bf,"TD",{class:!0});var lx=i(Ed);RT=n(lx,"Network dimension too small"),lx.forEach(t),ST=u(Bf),bd=l(Bf,"TD",{class:!0});var ix=i(bd);DT=n(ix,"Increase network_dim to 64+"),ix.forEach(t),Bf.forEach(t),AT=u(X),Lt=l(X,"TR",{class:!0});var Wf=i(Lt);yd=l(Wf,"TD",{class:!0});var rx=i(yd);LT=n(rx,"Color distortion"),rx.forEach(t),IT=u(Wf),kd=l(Wf,"TD",{class:!0});var ox=i(kd);OT=n(ox,"Noise offset conflict"),ox.forEach(t),PT=u(Wf),wd=l(Wf,"TD",{class:!0});var nx=i(wd);zT=n(nx,"Try noise_offset 0.05-0.1"),nx.forEach(t),Wf.forEach(t),xT=u(X),It=l(X,"TR",{class:!0});var jf=i(It);Td=l(jf,"TD",{class:!0});var cx=i(Td);NT=n(cx,"Overly stylized outputs"),cx.forEach(t),CT=u(jf),Rd=l(jf,"TD",{class:!0});var ux=i(Rd);GT=n(ux,"Reg image style mismatch"),ux.forEach(t),UT=u(jf),Sd=l(jf,"TD",{class:!0});var dx=i(Sd);HT=n(dx,"Regenerate reg images with base model"),dx.forEach(t),jf.forEach(t),qT=u(X),Ot=l(X,"TR",{class:!0});var Ff=i(Ot);Dd=l(Ff,"TD",{class:!0});var fx=i(Dd);MT=n(fx,"Training instability"),fx.forEach(t),BT=u(Ff),Ad=l(Ff,"TD",{class:!0});var px=i(Ad);WT=n(px,"Batch size too large"),px.forEach(t),jT=u(Ff),Ld=l(Ff,"TD",{class:!0});var hx=i(Ld);FT=n(hx,"Reduce batch_size to 1-2"),hx.forEach(t),Ff.forEach(t),VT=u(X),Pt=l(X,"TR",{class:!0});var Vf=i(Pt);Id=l(Vf,"TD",{class:!0});var vx=i(Id);KT=n(vx,"Slow convergence"),vx.forEach(t),YT=u(Vf),Od=l(Vf,"TD",{class:!0});var gx=i(Od);XT=n(gx,"Network_alpha too high"),gx.forEach(t),ZT=u(Vf),Pd=l(Vf,"TD",{class:!0});var mx=i(Pd);QT=n(mx,"Set alpha = dim/2 (e.g., 64/2 = 32)"),mx.forEach(t),Vf.forEach(t),JT=u(X),zt=l(X,"TR",{class:!0});var Kf=i(zt);zd=l(Kf,"TD",{class:!0});var _x=i(zd);$T=n(_x,"Loss divergence"),_x.forEach(t),e9=u(Kf),xd=l(Kf,"TD",{class:!0});var Ex=i(xd);t9=n(Ex,"Text encoder LR too high"),Ex.forEach(t),a9=u(Kf),Nd=l(Kf,"TD",{class:!0});var bx=i(Nd);s9=n(bx,"Reduce text_encoder_lr by 10x"),bx.forEach(t),Kf.forEach(t),l9=u(X),xt=l(X,"TR",{class:!0});var Yf=i(xt);Cd=l(Yf,"TD",{class:!0});var yx=i(Cd);i9=n(yx,"Poor prompt adherence"),yx.forEach(t),r9=u(Yf),Gd=l(Yf,"TD",{class:!0});var kx=i(Gd);o9=n(kx,"Clip skip too high"),kx.forEach(t),n9=u(Yf),Ud=l(Yf,"TD",{class:!0});var wx=i(Ud);c9=n(wx,"Reduce clip_skip to 1-2"),wx.forEach(t),Yf.forEach(t),u9=u(X),Nt=l(X,"TR",{class:!0});var Xf=i(Nt);Hd=l(Xf,"TD",{class:!0});var Tx=i(Hd);d9=n(Tx,"Memory errors"),Tx.forEach(t),f9=u(Xf),qd=l(Xf,"TD",{class:!0});var Rx=i(qd);p9=n(Rx,"Resolution too high"),Rx.forEach(t),h9=u(Xf),Md=l(Xf,"TD",{class:!0});var Sx=i(Md);v9=n(Sx,"Reduce to 512-768px, enable gradient checkpointing"),Sx.forEach(t),Xf.forEach(t),X.forEach(t),N2.forEach(t),D1=u(a),Ys=l(a,"H2",{id:!0});var $R=i(Ys);Xs=l($R,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Dx=i(Xs);yv=l(Dx,"SPAN",{class:!0}),i(yv).forEach(t),Dx.forEach(t),g9=n($R,"Results"),$R.forEach(t),A1=u(a),Bd=l(a,"P",{});var Ax=i(Bd);m9=n(Ax,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),Ax.forEach(t),L1=u(a),Wd=l(a,"P",{});var Lx=i(Wd);_9=n(Lx,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),Lx.forEach(t),I1=u(a),zi=l(a,"P",{class:!0});var Ix=i(zi);xi=l(Ix,"IMG",{src:!0,alt:!0,class:!0}),Ix.forEach(t),O1=u(a),jd=l(a,"P",{});var Ox=i(jd);E9=n(Ox,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),Ox.forEach(t),P1=u(a),Jt=l(a,"H2",{id:!0,class:!0});var eS=i(Jt);Zs=l(eS,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Px=i(Zs);kv=l(Px,"SPAN",{class:!0}),i(kv).forEach(t),Px.forEach(t),b9=n(eS,"spacelab"),eS.forEach(t),z1=u(a),Le&&Le.l(a),x1=Zf(),this.h()},h(){r(R,"class","icon icon-link"),r(T,"aria-hidden","true"),r(T,"tabindex","-1"),r(T,"href","#experiment-1-anime-inspired-heroism"),r(y,"id","experiment-1-anime-inspired-heroism"),ta(O.src,P="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png")||r(O,"src",P),r(O,"alt","image"),r(O,"class","svelte-10uiha2"),r(w,"class","svelte-10uiha2"),r(S,"class","icon icon-link"),r(H,"aria-hidden","true"),r(H,"tabindex","-1"),r(H,"href","#experiment-2-retro-cartoon-resurrection"),r(Z,"id","experiment-2-retro-cartoon-resurrection"),ta(de.src,Qf="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1738190889/blog/fiz3ariex9rpsoovdccl.png")||r(de,"src",Qf),r(de,"alt","image"),r(de,"class","svelte-10uiha2"),r(Oe,"class","svelte-10uiha2"),r(Jf,"class","icon icon-link"),r(ra,"aria-hidden","true"),r(ra,"tabindex","-1"),r(ra,"href","#what-are-regularization-images"),r(ia,"id","what-are-regularization-images"),r(ji,"class","svelte-10uiha2"),r(pl,"class","svelte-10uiha2"),r(Xi,"class","svelte-10uiha2"),r(Zi,"class","svelte-10uiha2"),r(Qi,"class","svelte-10uiha2"),r(Pe,"class","svelte-10uiha2"),r(Yi,"class","svelte-10uiha2"),r(Ji,"class","svelte-10uiha2"),r($i,"class","svelte-10uiha2"),r(er,"class","svelte-10uiha2"),r(xe,"class","svelte-10uiha2"),r(tr,"class","svelte-10uiha2"),r(ar,"class","svelte-10uiha2"),r(sr,"class","svelte-10uiha2"),r(Ne,"class","svelte-10uiha2"),r(lr,"class","svelte-10uiha2"),r(ir,"class","svelte-10uiha2"),r(rr,"class","svelte-10uiha2"),r(Ce,"class","svelte-10uiha2"),r(ze,"class","svelte-10uiha2"),r(qt,"class","svelte-10uiha2"),r(cr,"class","svelte-10uiha2"),r(vl,"class","svelte-10uiha2"),r(ap,"class","icon icon-link"),r(na,"aria-hidden","true"),r(na,"tabindex","-1"),r(na,"href","#scenario-1-limited-training-data"),r(oa,"id","scenario-1-limited-training-data"),r(rp,"class","icon icon-link"),r(ua,"aria-hidden","true"),r(ua,"tabindex","-1"),r(ua,"href","#scenario-2-imbalanced-training-data"),r(ca,"id","scenario-2-imbalanced-training-data"),r(up,"class","icon icon-link"),r(fa,"aria-hidden","true"),r(fa,"tabindex","-1"),r(fa,"href","#divergence"),r(da,"id","divergence"),r(fr,"class","svelte-10uiha2"),r(pr,"class","svelte-10uiha2"),r(wl,"class","svelte-10uiha2"),r(mp,"class","icon icon-link"),r(va,"aria-hidden","true"),r(va,"tabindex","-1"),r(va,"href","#overfitting"),r(ha,"id","overfitting"),r(kp,"class","icon icon-link"),r(ma,"aria-hidden","true"),r(ma,"tabindex","-1"),r(ma,"href","#key-differences"),r(ga,"id","key-differences"),r(Er,"class","svelte-10uiha2"),r(br,"class","svelte-10uiha2"),r(yr,"class","svelte-10uiha2"),r(qe,"class","svelte-10uiha2"),r(_r,"class","svelte-10uiha2"),r(kr,"class","svelte-10uiha2"),r(wr,"class","svelte-10uiha2"),r(Tr,"class","svelte-10uiha2"),r(Me,"class","svelte-10uiha2"),r(Rr,"class","svelte-10uiha2"),r(Sr,"class","svelte-10uiha2"),r(Dr,"class","svelte-10uiha2"),r(Be,"class","svelte-10uiha2"),r(Ar,"class","svelte-10uiha2"),r(Lr,"class","svelte-10uiha2"),r(Ir,"class","svelte-10uiha2"),r(We,"class","svelte-10uiha2"),r(Or,"class","svelte-10uiha2"),r(Pr,"class","svelte-10uiha2"),r(zr,"class","svelte-10uiha2"),r(je,"class","svelte-10uiha2"),r(fe,"class","svelte-10uiha2"),r(Mt,"class","svelte-10uiha2"),r(Op,"class","icon icon-link"),r(Ea,"aria-hidden","true"),r(Ea,"tabindex","-1"),r(Ea,"href","#preventing-divergence"),r(_a,"id","preventing-divergence"),r(Nr,"class","svelte-10uiha2"),r(Cr,"class","svelte-10uiha2"),r(ba,"class","svelte-10uiha2"),r(xr,"class","svelte-10uiha2"),r(Gr,"class","svelte-10uiha2"),r(Ur,"class","svelte-10uiha2"),r(ya,"class","svelte-10uiha2"),r(Hr,"class","svelte-10uiha2"),r(qr,"class","svelte-10uiha2"),r(ka,"class","svelte-10uiha2"),r(Mr,"class","svelte-10uiha2"),r(Br,"class","svelte-10uiha2"),r(wa,"class","svelte-10uiha2"),r(Wr,"class","svelte-10uiha2"),r(jr,"class","svelte-10uiha2"),r(Ta,"class","svelte-10uiha2"),r(pe,"class","svelte-10uiha2"),r(Bt,"class","svelte-10uiha2"),r(Cp,"class","icon icon-link"),r(Sa,"aria-hidden","true"),r(Sa,"tabindex","-1"),r(Sa,"href","#implement-these-strategies"),r(Ra,"id","implement-these-strategies"),r(Vr,"class","svelte-10uiha2"),r(Kr,"class","svelte-10uiha2"),r(Yr,"class","svelte-10uiha2"),r(Xr,"class","svelte-10uiha2"),r(Zr,"class","svelte-10uiha2"),r(Tl,"class","language-python"),r(Rl,"class","language-python"),r(Up,"class","icon icon-link"),r(Aa,"aria-hidden","true"),r(Aa,"tabindex","-1"),r(Aa,"href","#data-considerations"),r(Da,"id","data-considerations"),r(Jr,"class","svelte-10uiha2"),r($r,"class","svelte-10uiha2"),r(eo,"class","svelte-10uiha2"),r(Fe,"class","svelte-10uiha2"),r(Qr,"class","svelte-10uiha2"),r(to,"class","svelte-10uiha2"),r(ao,"class","svelte-10uiha2"),r(so,"class","svelte-10uiha2"),r(Ve,"class","svelte-10uiha2"),r(lo,"class","svelte-10uiha2"),r(io,"class","svelte-10uiha2"),r(ro,"class","svelte-10uiha2"),r(Ke,"class","svelte-10uiha2"),r(oo,"class","svelte-10uiha2"),r(no,"class","svelte-10uiha2"),r(co,"class","svelte-10uiha2"),r(Ye,"class","svelte-10uiha2"),r(uo,"class","svelte-10uiha2"),r(fo,"class","svelte-10uiha2"),r(po,"class","svelte-10uiha2"),r(Xe,"class","svelte-10uiha2"),r(ge,"class","svelte-10uiha2"),r(Wt,"class","svelte-10uiha2"),r(Hp,"class","icon icon-link"),r(Ia,"aria-hidden","true"),r(Ia,"tabindex","-1"),r(Ia,"href","#monitoring-tips"),r(La,"id","monitoring-tips"),r(Sl,"href","https://github.com/kohya-ss/sd-scripts"),r(Sl,"rel","nofollow"),r(qp,"class","icon icon-link"),r(za,"aria-hidden","true"),r(za,"tabindex","-1"),r(za,"href","#track-loss-curves"),r(Pa,"id","track-loss-curves"),r(Dl,"href","https://www.tensorflow.org/tensorboard"),r(Dl,"rel","nofollow"),r(Al,"class","language-bash"),r(Mp,"class","icon icon-link"),r(Ca,"aria-hidden","true"),r(Ca,"tabindex","-1"),r(Ca,"href","#what-to-monitor"),r(Na,"id","what-to-monitor"),r(Fp,"class","icon icon-link"),r(Ua,"aria-hidden","true"),r(Ua,"tabindex","-1"),r(Ua,"href","#warning-signs"),r(Ga,"id","warning-signs"),r(Xp,"class","icon icon-link"),r(qa,"aria-hidden","true"),r(qa,"tabindex","-1"),r(qa,"href","#generate-validation-images-every-100-steps"),r(Ha,"id","generate-validation-images-every-100-steps"),r(Il,"class","language-json"),r(Qp,"class","icon icon-link"),r(Ba,"aria-hidden","true"),r(Ba,"tabindex","-1"),r(Ba,"href","#what-to-look-for"),r(Ma,"id","what-to-look-for"),r(mo,"class","svelte-10uiha2"),r(Ol,"class","svelte-10uiha2"),r(th,"class","icon icon-link"),r(ja,"aria-hidden","true"),r(ja,"tabindex","-1"),r(ja,"href","#use-gradient-clipping"),r(Wa,"id","use-gradient-clipping"),r(Eo,"class","svelte-10uiha2"),r(bo,"class","svelte-10uiha2"),r(xl,"class","svelte-10uiha2"),r(ih,"class","icon icon-link"),r(Va,"aria-hidden","true"),r(Va,"tabindex","-1"),r(Va,"href","#enable-mixed-precision-training"),r(Fa,"id","enable-mixed-precision-training"),r(Cl,"class","language-python"),r(ko,"class","svelte-10uiha2"),r(Gl,"class","svelte-10uiha2"),r(uh,"class","icon icon-link"),r(Ya,"aria-hidden","true"),r(Ya,"tabindex","-1"),r(Ya,"href","#start-with-conservative-learning-rates"),r(Ka,"id","start-with-conservative-learning-rates"),r(Ul,"class","language-yml"),r(To,"class","svelte-10uiha2"),r(Ro,"class","svelte-10uiha2"),r(So,"class","svelte-10uiha2"),r(tt,"class","svelte-10uiha2"),r(wo,"class","svelte-10uiha2"),r(Ao,"class","svelte-10uiha2"),r(Do,"class","svelte-10uiha2"),r(Lo,"class","svelte-10uiha2"),r(Io,"class","svelte-10uiha2"),r(st,"class","svelte-10uiha2"),r(Po,"class","svelte-10uiha2"),r(Oo,"class","svelte-10uiha2"),r(zo,"class","svelte-10uiha2"),r(xo,"class","svelte-10uiha2"),r(lt,"class","svelte-10uiha2"),r(Co,"class","svelte-10uiha2"),r(No,"class","svelte-10uiha2"),r(Go,"class","svelte-10uiha2"),r(Uo,"class","svelte-10uiha2"),r(it,"class","svelte-10uiha2"),r(at,"class","svelte-10uiha2"),r(jt,"class","svelte-10uiha2"),r(fh,"class","icon icon-link"),r(Qa,"aria-hidden","true"),r(Qa,"tabindex","-1"),r(Qa,"href","#what-does-this-mean"),r(Za,"id","what-does-this-mean"),r(Ho,"class","svelte-10uiha2"),r(qo,"class","svelte-10uiha2"),r(Mo,"class","svelte-10uiha2"),r(Bo,"class","svelte-10uiha2"),r(Wo,"class","svelte-10uiha2"),r(jo,"class","svelte-10uiha2"),r(ph,"class","icon icon-link"),r($a,"aria-hidden","true"),r($a,"tabindex","-1"),r($a,"href","#text-encoder-learning-rate"),r(Ja,"id","text-encoder-learning-rate"),r(Ko,"class","svelte-10uiha2"),r(vh,"class","icon icon-link"),r(as,"aria-hidden","true"),r(as,"tabindex","-1"),r(as,"href","#effects"),r(ts,"id","effects"),r(Eh,"class","icon icon-link"),r(ls,"aria-hidden","true"),r(ls,"tabindex","-1"),r(ls,"href","#unet-learning-rate"),r(ss,"id","unet-learning-rate"),r(rn,"class","svelte-10uiha2"),r(on,"class","svelte-10uiha2"),r(nn,"class","svelte-10uiha2"),r(cn,"class","svelte-10uiha2"),r(me,"class","svelte-10uiha2"),r(ln,"class","svelte-10uiha2"),r(un,"class","svelte-10uiha2"),r(dn,"class","svelte-10uiha2"),r(fn,"class","svelte-10uiha2"),r(pn,"class","svelte-10uiha2"),r(_e,"class","svelte-10uiha2"),r(hn,"class","svelte-10uiha2"),r(vn,"class","svelte-10uiha2"),r(gn,"class","svelte-10uiha2"),r(mn,"class","svelte-10uiha2"),r(Ee,"class","svelte-10uiha2"),r(_n,"class","svelte-10uiha2"),r(En,"class","svelte-10uiha2"),r(os,"class","svelte-10uiha2"),r(bn,"class","svelte-10uiha2"),r(yn,"class","svelte-10uiha2"),r(ct,"class","svelte-10uiha2"),r(be,"class","svelte-10uiha2"),r(kn,"class","svelte-10uiha2"),r(wn,"class","svelte-10uiha2"),r(Tn,"class","svelte-10uiha2"),r(Rn,"class","svelte-10uiha2"),r(ye,"class","svelte-10uiha2"),r(Sn,"class","svelte-10uiha2"),r(Dn,"class","svelte-10uiha2"),r(An,"class","svelte-10uiha2"),r(Ln,"class","svelte-10uiha2"),r(ke,"class","svelte-10uiha2"),r(le,"class","svelte-10uiha2"),r(Kt,"class","svelte-10uiha2"),r(Ph,"class","icon icon-link"),r(cs,"aria-hidden","true"),r(cs,"tabindex","-1"),r(cs,"href","#generating-regularization-images"),r(ns,"id","generating-regularization-images"),r(In,"class","svelte-10uiha2"),r(On,"class","svelte-10uiha2"),r(Pn,"class","svelte-10uiha2"),r(zn,"class","svelte-10uiha2"),r(xn,"class","svelte-10uiha2"),r(zh,"class","icon icon-link"),r(fs,"aria-hidden","true"),r(fs,"tabindex","-1"),r(fs,"href","#important-considerations"),r(ds,"id","important-considerations"),r(qh,"class","icon icon-link"),r(hs,"aria-hidden","true"),r(hs,"tabindex","-1"),r(hs,"href","#generate-using-stable-diffusion-web-ui"),r(ps,"id","generate-using-stable-diffusion-web-ui"),r(Vl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),r(Vl,"rel","nofollow"),r(Cn,"class","svelte-10uiha2"),r(Gn,"class","svelte-10uiha2"),r(Hn,"class","svelte-10uiha2"),r(qn,"class","svelte-10uiha2"),r(Mn,"class","svelte-10uiha2"),r(Bn,"class","svelte-10uiha2"),r(Wn,"class","svelte-10uiha2"),r(jn,"class","svelte-10uiha2"),r(Fn,"class","svelte-10uiha2"),r(Vn,"class","svelte-10uiha2"),r(Kn,"class","svelte-10uiha2"),r(Yn,"class","svelte-10uiha2"),r(Xn,"class","svelte-10uiha2"),r(Zn,"class","svelte-10uiha2"),r(Qn,"class","svelte-10uiha2"),r(Jn,"class","svelte-10uiha2"),r($n,"class","svelte-10uiha2"),r(ec,"class","svelte-10uiha2"),r(tc,"class","svelte-10uiha2"),r(ac,"class","svelte-10uiha2"),r(sc,"class","svelte-10uiha2"),r(lc,"class","svelte-10uiha2"),r(ic,"class","svelte-10uiha2"),r(rc,"class","svelte-10uiha2"),r(oc,"class","svelte-10uiha2"),r(nc,"class","svelte-10uiha2"),r(cc,"class","svelte-10uiha2"),r(dc,"class","svelte-10uiha2"),r(fc,"class","svelte-10uiha2"),r(pc,"class","svelte-10uiha2"),r(hc,"class","svelte-10uiha2"),r(vc,"class","svelte-10uiha2"),r(Yh,"class","icon icon-link"),r(_s,"aria-hidden","true"),r(_s,"tabindex","-1"),r(_s,"href","#download-images"),r(ms,"id","download-images"),r(Xl,"href","https://huggingface.co/3ee"),r(Xl,"rel","nofollow"),r(Zl,"href","https://github.com/Luehrsen/sd_regularization_images"),r(Zl,"rel","nofollow"),r(Ql,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),r(Ql,"rel","nofollow"),r(Jl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),r(Jl,"rel","nofollow"),r(Xh,"class","icon icon-link"),r(bs,"aria-hidden","true"),r(bs,"tabindex","-1"),r(bs,"href","#captioning-regularization-images"),r(Es,"id","captioning-regularization-images"),r(Tc,"class","svelte-10uiha2"),r(Rc,"class","svelte-10uiha2"),r($l,"class","language-shell"),r(Dc,"class","svelte-10uiha2"),r(Ac,"class","svelte-10uiha2"),r(Lc,"class","svelte-10uiha2"),r(ev,"class","icon icon-link"),r(Ts,"aria-hidden","true"),r(Ts,"tabindex","-1"),r(Ts,"href","#training-a-lora"),r(ws,"id","training-a-lora"),r(ai,"href","https://github.com/kohya-ss/sd-scripts"),r(ai,"rel","nofollow"),r(si,"href","https://github.com/bmaltais/kohya_ss"),r(si,"rel","nofollow"),r(ii,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),r(ii,"rel","nofollow"),r(Rs,"class","svelte-10uiha2"),r(li,"class","svelte-10uiha2"),r(oi,"href","https://rentry.org/59xed3"),r(oi,"rel","nofollow"),r(ni,"href","https://rentry.org/ezlora"),r(ni,"rel","nofollow"),r(ci,"href","https://rentry.org/lora_train"),r(ci,"rel","nofollow"),r(Ae,"class","svelte-10uiha2"),r(ri,"class","svelte-10uiha2"),r(tv,"class","icon icon-link"),r(Ds,"aria-hidden","true"),r(Ds,"tabindex","-1"),r(Ds,"href","#directory-setup"),r(Ss,"id","directory-setup"),r(Ic,"class","svelte-10uiha2"),r(ui,"class","language-json"),r(di,"class","language-xml"),r(Pc,"class","svelte-10uiha2"),r(zc,"class","svelte-10uiha2"),r(Is,"class","svelte-10uiha2"),r(fi,"class","svelte-10uiha2"),r(xc,"class","svelte-10uiha2"),r(Nc,"class","svelte-10uiha2"),ta(hi.src,oS="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||r(hi,"src",oS),r(hi,"alt","image"),r(hi,"class","svelte-10uiha2"),r(pi,"class","svelte-10uiha2"),r(rv,"class","icon icon-link"),r(zs,"aria-hidden","true"),r(zs,"tabindex","-1"),r(zs,"href","#training-settings"),r(Ps,"id","training-settings"),r(qc,"class","svelte-10uiha2"),r(Mc,"class","svelte-10uiha2"),r(Wc,"class","svelte-10uiha2"),r(jc,"class","svelte-10uiha2"),r(Fc,"class","svelte-10uiha2"),r(Vc,"class","svelte-10uiha2"),r(Kc,"class","svelte-10uiha2"),r(ie,"class","svelte-10uiha2"),r(Bc,"class","svelte-10uiha2"),r(Xc,"class","svelte-10uiha2"),r(Zc,"class","svelte-10uiha2"),r(Qc,"class","svelte-10uiha2"),r(Jc,"class","svelte-10uiha2"),r($c,"class","svelte-10uiha2"),r(re,"class","svelte-10uiha2"),r(Yc,"class","svelte-10uiha2"),r(Xt,"class","svelte-10uiha2"),r(vi,"class","language-json"),r(au,"class","svelte-10uiha2"),r(lu,"class","svelte-10uiha2"),r(ru,"class","svelte-10uiha2"),r(nu,"class","svelte-10uiha2"),r(du,"class","svelte-10uiha2"),r(pu,"class","svelte-10uiha2"),r(vu,"class","svelte-10uiha2"),r(mu,"class","svelte-10uiha2"),r(Eu,"class","svelte-10uiha2"),r(yu,"class","svelte-10uiha2"),r(nv,"class","icon icon-link"),r(Ns,"aria-hidden","true"),r(Ns,"tabindex","-1"),r(Ns,"href","#fine-tuning"),r(xs,"id","fine-tuning"),r(cv,"class","icon icon-link"),r(Gs,"aria-hidden","true"),r(Gs,"tabindex","-1"),r(Gs,"href","#workflow-with-auto1111-webui"),r(Cs,"id","workflow-with-auto1111-webui"),r(Di,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),r(Di,"rel","nofollow"),r(wu,"class","svelte-10uiha2"),r(Ru,"class","svelte-10uiha2"),r(Su,"class","svelte-10uiha2"),r(Du,"class","svelte-10uiha2"),r(Lu,"class","svelte-10uiha2"),r(Iu,"class","svelte-10uiha2"),r(Ou,"class","svelte-10uiha2"),r(Pu,"class","svelte-10uiha2"),r(zu,"class","svelte-10uiha2"),r(xu,"class","svelte-10uiha2"),r(Nu,"class","svelte-10uiha2"),r(Cu,"class","svelte-10uiha2"),r(pv,"class","icon icon-link"),r(Ws,"aria-hidden","true"),r(Ws,"tabindex","-1"),r(Ws,"href","#issues-to-look-for"),r(Bs,"id","issues-to-look-for"),ta(Ii.src,nS="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||r(Ii,"src",nS),r(Ii,"alt","image"),r(Ii,"class","svelte-10uiha2"),r(Li,"class","svelte-10uiha2"),r(_v,"class","icon icon-link"),r(Fs,"aria-hidden","true"),r(Fs,"tabindex","-1"),r(Fs,"href","#troubleshooting"),r(js,"id","troubleshooting"),r(Wu,"class","svelte-10uiha2"),r(ju,"class","svelte-10uiha2"),r(Vu,"class","svelte-10uiha2"),r(Ku,"class","svelte-10uiha2"),r(Yu,"class","svelte-10uiha2"),r(bt,"class","svelte-10uiha2"),r(Fu,"class","svelte-10uiha2"),r(Xu,"class","svelte-10uiha2"),r(Zu,"class","svelte-10uiha2"),r(Qu,"class","svelte-10uiha2"),r(yt,"class","svelte-10uiha2"),r(Ju,"class","svelte-10uiha2"),r($u,"class","svelte-10uiha2"),r(ed,"class","svelte-10uiha2"),r(kt,"class","svelte-10uiha2"),r(td,"class","svelte-10uiha2"),r(ad,"class","svelte-10uiha2"),r(sd,"class","svelte-10uiha2"),r(wt,"class","svelte-10uiha2"),r(ld,"class","svelte-10uiha2"),r(id,"class","svelte-10uiha2"),r(rd,"class","svelte-10uiha2"),r(Tt,"class","svelte-10uiha2"),r(Se,"class","svelte-10uiha2"),r(Zt,"class","svelte-10uiha2"),r(bv,"class","icon icon-link"),r(Ks,"aria-hidden","true"),r(Ks,"tabindex","-1"),r(Ks,"href","#more-solutions"),r(Vs,"id","more-solutions"),r(cd,"class","svelte-10uiha2"),r(ud,"class","svelte-10uiha2"),r(dd,"class","svelte-10uiha2"),r(Rt,"class","svelte-10uiha2"),r(nd,"class","svelte-10uiha2"),r(fd,"class","svelte-10uiha2"),r(pd,"class","svelte-10uiha2"),r(hd,"class","svelte-10uiha2"),r(St,"class","svelte-10uiha2"),r(vd,"class","svelte-10uiha2"),r(gd,"class","svelte-10uiha2"),r(md,"class","svelte-10uiha2"),r(Dt,"class","svelte-10uiha2"),r(_d,"class","svelte-10uiha2"),r(Ed,"class","svelte-10uiha2"),r(bd,"class","svelte-10uiha2"),r(At,"class","svelte-10uiha2"),r(yd,"class","svelte-10uiha2"),r(kd,"class","svelte-10uiha2"),r(wd,"class","svelte-10uiha2"),r(Lt,"class","svelte-10uiha2"),r(Td,"class","svelte-10uiha2"),r(Rd,"class","svelte-10uiha2"),r(Sd,"class","svelte-10uiha2"),r(It,"class","svelte-10uiha2"),r(Dd,"class","svelte-10uiha2"),r(Ad,"class","svelte-10uiha2"),r(Ld,"class","svelte-10uiha2"),r(Ot,"class","svelte-10uiha2"),r(Id,"class","svelte-10uiha2"),r(Od,"class","svelte-10uiha2"),r(Pd,"class","svelte-10uiha2"),r(Pt,"class","svelte-10uiha2"),r(zd,"class","svelte-10uiha2"),r(xd,"class","svelte-10uiha2"),r(Nd,"class","svelte-10uiha2"),r(zt,"class","svelte-10uiha2"),r(Cd,"class","svelte-10uiha2"),r(Gd,"class","svelte-10uiha2"),r(Ud,"class","svelte-10uiha2"),r(xt,"class","svelte-10uiha2"),r(Hd,"class","svelte-10uiha2"),r(qd,"class","svelte-10uiha2"),r(Md,"class","svelte-10uiha2"),r(Nt,"class","svelte-10uiha2"),r(W,"class","svelte-10uiha2"),r(Qt,"class","svelte-10uiha2"),r(yv,"class","icon icon-link"),r(Xs,"aria-hidden","true"),r(Xs,"tabindex","-1"),r(Xs,"href","#results"),r(Ys,"id","results"),ta(xi.src,cS="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||r(xi,"src",cS),r(xi,"alt","image"),r(xi,"class","svelte-10uiha2"),r(zi,"class","svelte-10uiha2"),r(kv,"class","icon icon-link"),r(Zs,"aria-hidden","true"),r(Zs,"tabindex","-1"),r(Zs,"href","#spacelab"),r(Jt,"id","spacelab"),r(Jt,"class","svelte-10uiha2")},m(a,f){d(a,p,f),e(p,g),d(a,v,f),d(a,h,f),e(h,m),d(a,E,f),d(a,y,f),e(y,T),e(T,R),e(y,k),d(a,b,f),d(a,w,f),e(w,O),d(a,N,f),d(a,G,f),e(G,A),d(a,L,f),d(a,D,f),e(D,z),e(z,x),e(D,Q),e(D,j),e(j,F),d(a,B,f),d(a,C,f),e(C,I),d(a,U,f),d(a,Z,f),e(Z,H),e(H,S),e(Z,q),d(a,la,f),d(a,Oe,f),e(Oe,de),d(a,Lv,f),d(a,Bi,f),e(Bi,q2),d(a,Iv,f),d(a,ia,f),e(ia,ra),e(ra,Jf),e(ia,M2),d(a,Ov,f),d(a,Wi,f),e(Wi,B2),d(a,Pv,f),d(a,pl,f),e(pl,ji),e(ji,W2),d(a,zv,f),qi(hl,a,f),d(a,xv,f),d(a,Fi,f),e(Fi,j2),d(a,Nv,f),d(a,Vi,f),e(Vi,F2),d(a,Cv,f),d(a,Ki,f),e(Ki,V2),d(a,Gv,f),d(a,qt,f),e(qt,Yi),e(Yi,Pe),e(Pe,Xi),e(Xi,K2),e(Pe,Y2),e(Pe,Zi),e(Zi,X2),e(Pe,Z2),e(Pe,Qi),e(Qi,Q2),e(qt,J2),e(qt,ze),e(ze,xe),e(xe,Ji),e(Ji,$f),e($f,$2),e(xe,e_),e(xe,$i),e($i,t_),e(xe,a_),e(xe,er),e(er,s_),e(ze,l_),e(ze,Ne),e(Ne,tr),e(tr,ep),e(ep,i_),e(Ne,r_),e(Ne,ar),e(ar,o_),e(Ne,n_),e(Ne,sr),e(sr,c_),e(ze,u_),e(ze,Ce),e(Ce,lr),e(lr,tp),e(tp,d_),e(Ce,f_),e(Ce,ir),e(ir,p_),e(Ce,h_),e(Ce,rr),e(rr,v_),d(a,Uv,f),d(a,or,f),e(or,g_),d(a,Hv,f),d(a,nr,f),e(nr,m_),d(a,qv,f),d(a,vl,f),e(vl,cr),e(cr,__),d(a,Mv,f),d(a,oa,f),e(oa,na),e(na,ap),e(oa,E_),d(a,Bv,f),d(a,gl,f),e(gl,sp),e(sp,b_),e(gl,y_),d(a,Wv,f),d(a,ml,f),e(ml,lp),e(lp,k_),e(ml,w_),d(a,jv,f),d(a,_l,f),e(_l,ip),e(ip,T_),e(_l,R_),d(a,Fv,f),d(a,ca,f),e(ca,ua),e(ua,rp),e(ca,S_),d(a,Vv,f),d(a,El,f),e(El,op),e(op,D_),e(El,A_),d(a,Kv,f),d(a,bl,f),e(bl,np),e(np,L_),e(bl,I_),d(a,Yv,f),d(a,yl,f),e(yl,cp),e(cp,O_),e(yl,P_),d(a,Xv,f),d(a,da,f),e(da,fa),e(fa,up),e(da,z_),d(a,Zv,f),d(a,kl,f),e(kl,dp),e(dp,x_),e(kl,N_),d(a,Qv,f),d(a,Ge,f),e(Ge,C_),e(Ge,fp),e(fp,G_),e(Ge,U_),e(Ge,pp),e(pp,H_),e(Ge,q_),d(a,Jv,f),d(a,Ue,f),e(Ue,ur),e(ur,hp),e(hp,M_),e(ur,B_),e(Ue,W_),e(Ue,dr),e(dr,vp),e(vp,j_),e(dr,F_),e(Ue,V_),e(Ue,pa),e(pa,gp),e(gp,K_),e(pa,Y_),e(pa,fr),e(fr,X_),e(pa,Z_),d(a,$v,f),d(a,wl,f),e(wl,pr),e(pr,Q_),d(a,eg,f),d(a,ha,f),e(ha,va),e(va,mp),e(ha,_p),e(_p,J_),d(a,tg,f),d(a,hr,f),e(hr,$_),d(a,ag,f),d(a,He,f),e(He,vr),e(vr,Ep),e(Ep,e0),e(vr,t0),e(He,a0),e(He,gr),e(gr,bp),e(bp,s0),e(gr,l0),e(He,i0),e(He,mr),e(mr,yp),e(yp,r0),e(mr,o0),d(a,sg,f),d(a,ga,f),e(ga,ma),e(ma,kp),e(ga,wp),e(wp,n0),d(a,lg,f),d(a,Mt,f),e(Mt,_r),e(_r,qe),e(qe,Er),e(Er,Tp),e(Tp,c0),e(qe,u0),e(qe,br),e(br,Rp),e(Rp,d0),e(qe,f0),e(qe,yr),e(yr,Sp),e(Sp,p0),e(Mt,h0),e(Mt,fe),e(fe,Me),e(Me,kr),e(kr,Dp),e(Dp,v0),e(Me,g0),e(Me,wr),e(wr,m0),e(Me,_0),e(Me,Tr),e(Tr,E0),e(fe,b0),e(fe,Be),e(Be,Rr),e(Rr,Ap),e(Ap,y0),e(Be,k0),e(Be,Sr),e(Sr,w0),e(Be,T0),e(Be,Dr),e(Dr,R0),e(fe,S0),e(fe,We),e(We,Ar),e(Ar,Lp),e(Lp,D0),e(We,A0),e(We,Lr),e(Lr,L0),e(We,I0),e(We,Ir),e(Ir,O0),e(fe,P0),e(fe,je),e(je,Or),e(Or,Ip),e(Ip,z0),e(je,x0),e(je,Pr),e(Pr,N0),e(je,C0),e(je,zr),e(zr,G0),d(a,ig,f),d(a,_a,f),e(_a,Ea),e(Ea,Op),e(_a,U0),d(a,rg,f),d(a,Bt,f),e(Bt,xr),e(xr,ba),e(ba,Nr),e(Nr,H0),e(ba,q0),e(ba,Cr),e(Cr,M0),e(Bt,B0),e(Bt,pe),e(pe,ya),e(ya,Gr),e(Gr,Pp),e(Pp,W0),e(ya,j0),e(ya,Ur),e(Ur,F0),e(pe,V0),e(pe,ka),e(ka,Hr),e(Hr,zp),e(zp,K0),e(ka,Y0),e(ka,qr),e(qr,X0),e(pe,Z0),e(pe,wa),e(wa,Mr),e(Mr,xp),e(xp,Q0),e(wa,J0),e(wa,Br),e(Br,$0),e(pe,eE),e(pe,Ta),e(Ta,Wr),e(Wr,Np),e(Np,tE),e(Ta,aE),e(Ta,jr),e(jr,sE),d(a,og,f),d(a,Fr,f),e(Fr,lE),d(a,ng,f),d(a,Ra,f),e(Ra,Sa),e(Sa,Cp),e(Ra,iE),d(a,cg,f),d(a,he,f),e(he,rE),e(he,Gp),e(Gp,oE),e(he,nE),e(he,Vr),e(Vr,cE),e(he,uE),e(he,Kr),e(Kr,dE),e(he,fE),d(a,ug,f),d(a,ve,f),e(ve,pE),e(ve,Yr),e(Yr,hE),e(ve,vE),e(ve,Xr),e(Xr,gE),e(ve,mE),e(ve,Zr),e(Zr,_E),e(ve,EE),d(a,dg,f),d(a,Tl,f),Tl.innerHTML=Bx,d(a,fg,f),d(a,Rl,f),Rl.innerHTML=Wx,d(a,pg,f),d(a,Da,f),e(Da,Aa),e(Aa,Up),e(Da,bE),d(a,hg,f),d(a,Wt,f),e(Wt,Qr),e(Qr,Fe),e(Fe,Jr),e(Jr,yE),e(Fe,kE),e(Fe,$r),e($r,wE),e(Fe,TE),e(Fe,eo),e(eo,RE),e(Wt,SE),e(Wt,ge),e(ge,Ve),e(Ve,to),e(to,DE),e(Ve,AE),e(Ve,ao),e(ao,LE),e(Ve,IE),e(Ve,so),e(so,OE),e(ge,PE),e(ge,Ke),e(Ke,lo),e(lo,zE),e(Ke,xE),e(Ke,io),e(io,NE),e(Ke,CE),e(Ke,ro),e(ro,GE),e(ge,UE),e(ge,Ye),e(Ye,oo),e(oo,HE),e(Ye,qE),e(Ye,no),e(no,ME),e(Ye,BE),e(Ye,co),e(co,WE),e(ge,jE),e(ge,Xe),e(Xe,uo),e(uo,FE),e(Xe,VE),e(Xe,fo),e(fo,KE),e(Xe,YE),e(Xe,po),e(po,XE),d(a,vg,f),d(a,ho,f),e(ho,ZE),d(a,gg,f),d(a,vo,f),e(vo,QE),d(a,mg,f),d(a,go,f),e(go,JE),d(a,_g,f),d(a,Eg,f),d(a,bg,f),d(a,La,f),e(La,Ia),e(Ia,Hp),e(La,$E),d(a,yg,f),d(a,Oa,f),e(Oa,eb),e(Oa,Sl),e(Sl,tb),e(Oa,ab),d(a,kg,f),d(a,Pa,f),e(Pa,za),e(za,qp),e(Pa,sb),d(a,wg,f),d(a,xa,f),e(xa,lb),e(xa,Dl),e(Dl,ib),e(xa,rb),d(a,Tg,f),d(a,Al,f),Al.innerHTML=jx,d(a,Rg,f),d(a,Na,f),e(Na,Ca),e(Ca,Mp),e(Na,ob),d(a,Sg,f),d(a,Ze,f),e(Ze,Bp),e(Bp,nb),e(Ze,cb),e(Ze,Wp),e(Wp,ub),e(Ze,db),e(Ze,jp),e(jp,fb),d(a,Dg,f),d(a,Ga,f),e(Ga,Ua),e(Ua,Fp),e(Ga,pb),d(a,Ag,f),d(a,Qe,f),e(Qe,Vp),e(Vp,hb),e(Qe,vb),e(Qe,Kp),e(Kp,gb),e(Qe,mb),e(Qe,Yp),e(Yp,_b),d(a,Lg,f),d(a,Ha,f),e(Ha,qa),e(qa,Xp),e(Ha,Eb),d(a,Ig,f),d(a,Ll,f),e(Ll,Zp),e(Zp,bb),e(Ll,yb),d(a,Og,f),d(a,Il,f),Il.innerHTML=Fx,d(a,Pg,f),d(a,Ma,f),e(Ma,Ba),e(Ba,Qp),e(Ma,kb),d(a,zg,f),d(a,Je,f),e(Je,Jp),e(Jp,wb),e(Je,Tb),e(Je,$p),e($p,Rb),e(Je,Sb),e(Je,eh),e(eh,Db),d(a,xg,f),d(a,Ol,f),e(Ol,mo),e(mo,Ab),d(a,Ng,f),d(a,Wa,f),e(Wa,ja),e(ja,th),e(Wa,Lb),d(a,Cg,f),d(a,Pl,f),e(Pl,ah),e(ah,Ib),e(Pl,Ob),d(a,Gg,f),d(a,_o,f),e(_o,Pb),d(a,Ug,f),d(a,$e,f),e($e,zl),e(zl,zb),e(zl,Eo),e(Eo,xb),e(zl,Nb),e($e,Cb),e($e,sh),e(sh,Gb),e($e,Ub),e($e,lh),e(lh,Hb),d(a,Hg,f),d(a,xl,f),e(xl,bo),e(bo,qb),d(a,qg,f),d(a,Fa,f),e(Fa,Va),e(Va,ih),e(Fa,Mb),d(a,Mg,f),d(a,Nl,f),e(Nl,rh),e(rh,Bb),e(Nl,Wb),d(a,Bg,f),d(a,Cl,f),Cl.innerHTML=Vx,d(a,Wg,f),d(a,yo,f),e(yo,jb),d(a,jg,f),d(a,et,f),e(et,oh),e(oh,Fb),e(et,Vb),e(et,nh),e(nh,Kb),e(et,Yb),e(et,ch),e(ch,Xb),d(a,Fg,f),d(a,Gl,f),e(Gl,ko),e(ko,Zb),d(a,Vg,f),d(a,Ka,f),e(Ka,Ya),e(Ya,uh),e(Ka,Qb),d(a,Kg,f),d(a,Xa,f),e(Xa,Jb),e(Xa,dh),e(dh,$b),e(Xa,ey),d(a,Yg,f),d(a,Ul,f),Ul.innerHTML=Kx,d(a,Xg,f),d(a,jt,f),e(jt,wo),e(wo,tt),e(tt,To),e(To,ty),e(tt,ay),e(tt,Ro),e(Ro,sy),e(tt,ly),e(tt,So),e(So,iy),e(jt,ry),e(jt,at),e(at,st),e(st,Do),e(Do,Ao),e(Ao,oy),e(st,ny),e(st,Lo),e(Lo,cy),e(st,uy),e(st,Io),e(Io,dy),e(at,fy),e(at,lt),e(lt,Oo),e(Oo,Po),e(Po,py),e(lt,hy),e(lt,zo),e(zo,vy),e(lt,gy),e(lt,xo),e(xo,my),e(at,_y),e(at,it),e(it,No),e(No,Co),e(Co,Ey),e(it,by),e(it,Go),e(Go,yy),e(it,ky),e(it,Uo),e(Uo,wy),d(a,Zg,f),d(a,Za,f),e(Za,Qa),e(Qa,fh),e(Za,Ty),d(a,Qg,f),d(a,rt,f),e(rt,Hl),e(Hl,Ry),e(Hl,Ho),e(Ho,Sy),e(Hl,Dy),e(rt,Ay),e(rt,De),e(De,Ly),e(De,qo),e(qo,Iy),e(De,Oy),e(De,Mo),e(Mo,Py),e(De,zy),e(De,Bo),e(Bo,xy),e(De,Ny),e(rt,Cy),e(rt,Ft),e(Ft,Gy),e(Ft,Wo),e(Wo,Uy),e(Ft,Hy),e(Ft,jo),e(jo,qy),e(Ft,My),d(a,Jg,f),d(a,Ja,f),e(Ja,$a),e($a,ph),e(Ja,By),d(a,$g,f),d(a,Fo,f),e(Fo,Wy),d(a,em,f),d(a,Vo,f),e(Vo,es),e(es,hh),e(hh,jy),e(es,Fy),e(es,Ko),e(Ko,Vy),e(es,Ky),d(a,tm,f),d(a,ts,f),e(ts,as),e(as,vh),e(ts,Yy),d(a,am,f),d(a,ot,f),e(ot,gh),e(gh,Xy),e(ot,Zy),e(ot,mh),e(mh,Qy),e(ot,Jy),e(ot,_h),e(_h,$y),d(a,sm,f),d(a,Yo,f),e(Yo,e4),d(a,lm,f),d(a,ss,f),e(ss,ls),e(ls,Eh),e(ss,t4),d(a,im,f),d(a,Xo,f),e(Xo,a4),d(a,rm,f),d(a,is,f),e(is,Zo),e(Zo,bh),e(bh,s4),e(Zo,l4),e(is,i4),e(is,ql),e(ql,yh),e(yh,r4),e(ql,o4),e(ql,Vt),e(Vt,Qo),e(Qo,kh),e(kh,n4),e(Qo,c4),e(Vt,u4),e(Vt,Jo),e(Jo,wh),e(wh,d4),e(Jo,f4),e(Vt,p4),e(Vt,$o),e($o,Th),e(Th,h4),e($o,v4),d(a,om,f),d(a,en,f),e(en,g4),d(a,nm,f),d(a,rs,f),e(rs,tn),e(tn,Rh),e(Rh,m4),e(tn,_4),e(rs,E4),e(rs,an),e(an,Sh),e(Sh,b4),e(an,y4),d(a,cm,f),d(a,sn,f),e(sn,k4),d(a,um,f),d(a,Ml,f),e(Ml,Dh),e(Dh,w4),e(Ml,T4),d(a,dm,f),d(a,nt,f),e(nt,Ah),e(Ah,R4),e(nt,S4),e(nt,Lh),e(Lh,D4),e(nt,A4),e(nt,Ih),e(Ih,L4),d(a,fm,f),d(a,Kt,f),e(Kt,ln),e(ln,me),e(me,rn),e(rn,I4),e(me,O4),e(me,on),e(on,P4),e(me,z4),e(me,nn),e(nn,x4),e(me,N4),e(me,cn),e(cn,C4),e(Kt,G4),e(Kt,le),e(le,_e),e(_e,un),e(un,U4),e(_e,H4),e(_e,dn),e(dn,q4),e(_e,M4),e(_e,fn),e(fn,B4),e(_e,W4),e(_e,pn),e(pn,j4),e(le,F4),e(le,Ee),e(Ee,hn),e(hn,V4),e(Ee,K4),e(Ee,vn),e(vn,Y4),e(Ee,X4),e(Ee,gn),e(gn,Z4),e(Ee,Q4),e(Ee,mn),e(mn,J4),e(le,$4),e(le,be),e(be,_n),e(_n,ek),e(be,tk),e(be,En),e(En,ak),e(be,sk),e(be,os),e(os,lk),e(os,Oh),e(Oh,ik),e(os,rk),e(be,ok),e(be,ct),e(ct,nk),e(ct,bn),e(bn,ck),e(ct,uk),e(ct,yn),e(yn,dk),e(ct,fk),e(le,pk),e(le,ye),e(ye,kn),e(kn,hk),e(ye,vk),e(ye,wn),e(wn,gk),e(ye,mk),e(ye,Tn),e(Tn,_k),e(ye,Ek),e(ye,Rn),e(Rn,bk),e(le,yk),e(le,ke),e(ke,Sn),e(Sn,kk),e(ke,wk),e(ke,Dn),e(Dn,Tk),e(ke,Rk),e(ke,An),e(An,Sk),e(ke,Dk),e(ke,Ln),e(Ln,Ak),d(a,pm,f),d(a,hm,f),d(a,vm,f),d(a,ns,f),e(ns,cs),e(cs,Ph),e(ns,Lk),d(a,gm,f),d(a,us,f),e(us,Ik),e(us,In),e(In,Ok),e(us,Pk),d(a,mm,f),d(a,ue,f),e(ue,zk),e(ue,On),e(On,xk),e(ue,Nk),e(ue,Pn),e(Pn,Ck),e(ue,Gk),e(ue,zn),e(zn,Uk),e(ue,Hk),e(ue,xn),e(xn,qk),d(a,_m,f),d(a,Nn,f),e(Nn,Mk),d(a,Em,f),d(a,ds,f),e(ds,fs),e(fs,zh),e(ds,Bk),d(a,bm,f),d(a,ut,f),e(ut,xh),e(xh,Bl),e(Bl,Nh),e(Nh,Wk),e(Bl,jk),e(Bl,Fk),e(ut,Vk),e(ut,Ch),e(Ch,Wl),e(Wl,Gh),e(Gh,Kk),e(Wl,Yk),e(Wl,Xk),e(ut,Zk),e(ut,Uh),e(Uh,jl),e(jl,Hh),e(Hh,Qk),e(jl,Jk),e(jl,$k),d(a,ym,f),qi(Fl,a,f),d(a,km,f),d(a,ps,f),e(ps,hs),e(hs,qh),e(ps,e3),d(a,wm,f),d(a,vs,f),e(vs,t3),e(vs,Vl),e(Vl,a3),e(vs,s3),d(a,Tm,f),d(a,dt,f),e(dt,l3),e(dt,Cn),e(Cn,i3),e(dt,r3),e(dt,Gn),e(Gn,o3),e(dt,n3),d(a,Rm,f),d(a,J,f),e(J,Mh),e(Mh,Un),e(Un,c3),e(Un,Hn),e(Hn,u3),e(J,d3),e(J,Bh),e(Bh,Kl),e(Kl,f3),e(Kl,qn),e(qn,p3),e(Kl,h3),e(J,v3),e(J,Wh),e(Wh,K),e(K,g3),e(K,Mn),e(Mn,m3),e(K,_3),e(K,Bn),e(Bn,E3),e(K,b3),e(K,Wn),e(Wn,y3),e(K,k3),e(K,jn),e(jn,w3),e(K,T3),e(K,Fn),e(Fn,R3),e(K,S3),e(K,Vn),e(Vn,D3),e(K,A3),e(K,Kn),e(Kn,L3),e(K,I3),e(K,Yn),e(Yn,O3),e(J,P3),e(J,jh),e(jh,$),e($,z3),e($,Xn),e(Xn,x3),e($,N3),e($,Zn),e(Zn,C3),e($,G3),e($,Qn),e(Qn,U3),e($,H3),e($,Jn),e(Jn,q3),e($,M3),e($,$n),e($n,B3),e($,W3),e($,ec),e(ec,j3),e($,F3),e($,tc),e(tc,V3),e(J,K3),e(J,Fh),e(Fh,Y),e(Y,Y3),e(Y,ac),e(ac,X3),e(Y,Z3),e(Y,sc),e(sc,Q3),e(Y,J3),e(Y,lc),e(lc,$3),e(Y,e5),e(Y,ic),e(ic,t5),e(Y,a5),e(Y,rc),e(rc,s5),e(Y,l5),e(Y,oc),e(oc,i5),e(Y,r5),e(Y,nc),e(nc,o5),e(Y,n5),e(Y,cc),e(cc,c5),e(J,u5),e(J,Vh),e(Vh,uc),e(uc,d5),e(uc,dc),e(dc,f5),e(J,p5),e(J,Kh),e(Kh,gs),e(gs,h5),e(gs,fc),e(fc,v5),e(gs,g5),e(gs,pc),e(pc,m5),d(a,Sm,f),d(a,ft,f),e(ft,_5),e(ft,hc),e(hc,E5),e(ft,b5),e(ft,vc),e(vc,y5),e(ft,k5),d(a,Dm,f),qi(Yl,a,f),d(a,Am,f),d(a,ms,f),e(ms,_s),e(_s,Yh),e(ms,w5),d(a,Lm,f),d(a,gc,f),e(gc,T5),d(a,Im,f),d(a,we,f),e(we,mc),e(mc,Xl),e(Xl,R5),e(mc,S5),e(we,D5),e(we,_c),e(_c,Zl),e(Zl,A5),e(_c,L5),e(we,I5),e(we,Ec),e(Ec,Ql),e(Ql,O5),e(Ec,P5),e(we,z5),e(we,bc),e(bc,Jl),e(Jl,x5),e(bc,N5),d(a,Om,f),d(a,Es,f),e(Es,bs),e(bs,Xh),e(Es,C5),d(a,Pm,f),d(a,yc,f),e(yc,G5),d(a,zm,f),d(a,kc,f),e(kc,U5),d(a,xm,f),d(a,pt,f),e(pt,wc),e(wc,Zh),e(Zh,H5),e(wc,q5),e(pt,M5),e(pt,ht),e(ht,Qh),e(Qh,B5),e(ht,W5),e(ht,Tc),e(Tc,j5),e(ht,F5),e(ht,Rc),e(Rc,V5),e(ht,K5),e(pt,Y5),e(pt,Sc),e(Sc,Jh),e(Jh,X5),e(Sc,Z5),d(a,Nm,f),d(a,$l,f),$l.innerHTML=Yx,d(a,Cm,f),d(a,ys,f),e(ys,ei),e(ei,Q5),e(ei,Dc),e(Dc,J5),e(ei,$5),e(ys,ew),e(ys,ti),e(ti,tw),e(ti,Ac),e(Ac,aw),e(ti,sw),d(a,Gm,f),d(a,ks,f),e(ks,$h),e($h,lw),e(ks,iw),e(ks,Lc),e(Lc,rw),d(a,Um,f),d(a,ws,f),e(ws,Ts),e(Ts,ev),e(ws,ow),d(a,Hm,f),d(a,vt,f),e(vt,nw),e(vt,ai),e(ai,cw),e(vt,uw),e(vt,si),e(si,dw),e(vt,fw),d(a,qm,f),d(a,li,f),e(li,Rs),e(Rs,pw),e(Rs,ii),e(ii,hw),e(Rs,vw),d(a,Mm,f),d(a,ri,f),e(ri,Ae),e(Ae,gw),e(Ae,oi),e(oi,mw),e(Ae,_w),e(Ae,ni),e(ni,Ew),e(Ae,bw),e(Ae,ci),e(ci,yw),d(a,Bm,f),d(a,Ss,f),e(Ss,Ds),e(Ds,tv),e(Ss,kw),d(a,Wm,f),d(a,As,f),e(As,ww),e(As,Ic),e(Ic,Tw),e(As,Rw),d(a,jm,f),d(a,ui,f),ui.innerHTML=Xx,d(a,Fm,f),d(a,Oc,f),e(Oc,Sw),d(a,Vm,f),d(a,di,f),di.innerHTML=Zx,d(a,Km,f),d(a,Ls,f),e(Ls,Dw),e(Ls,Pc),e(Pc,Aw),e(Ls,Lw),d(a,Ym,f),d(a,fi,f),e(fi,Is),e(Is,Iw),e(Is,zc),e(zc,Ow),e(Is,Pw),d(a,Xm,f),d(a,gt,f),e(gt,zw),e(gt,xc),e(xc,xw),e(gt,Nw),e(gt,Nc),e(Nc,Cw),e(gt,Gw),d(a,Zm,f),d(a,Cc,f),e(Cc,Uw),d(a,Qm,f),d(a,Os,f),e(Os,Gc),e(Gc,Hw),e(Gc,av),e(av,sv),e(sv,qw),e(Os,Mw),e(Os,Uc),e(Uc,Bw),e(Uc,lv),e(lv,iv),e(iv,Ww),d(a,Jm,f),d(a,Hc,f),e(Hc,jw),d(a,$m,f),d(a,pi,f),e(pi,hi),d(a,e1,f),d(a,Ps,f),e(Ps,zs),e(zs,rv),e(Ps,Fw),d(a,t1,f),d(a,Yt,f),e(Yt,Vw),e(Yt,qc),e(qc,Kw),e(Yt,Yw),e(Yt,Mc),e(Mc,Xw),d(a,a1,f),d(a,Xt,f),e(Xt,Bc),e(Bc,ie),e(ie,Wc),e(Wc,Zw),e(ie,Qw),e(ie,jc),e(jc,Jw),e(ie,$w),e(ie,Fc),e(Fc,e6),e(ie,t6),e(ie,Vc),e(Vc,a6),e(ie,s6),e(ie,Kc),e(Kc,l6),e(Xt,i6),e(Xt,Yc),e(Yc,re),e(re,Xc),e(Xc,r6),e(re,o6),e(re,Zc),e(Zc,n6),e(re,c6),e(re,Qc),e(Qc,u6),e(re,d6),e(re,Jc),e(Jc,f6),e(re,p6),e(re,$c),e($c,h6),d(a,s1,f),d(a,eu,f),e(eu,v6),d(a,l1,f),d(a,vi,f),vi.innerHTML=Qx,d(a,i1,f),d(a,M,f),e(M,tu),e(tu,gi),e(gi,g6),e(gi,au),e(au,m6),e(gi,_6),e(tu,E6),e(M,b6),e(M,su),e(su,mi),e(mi,y6),e(mi,lu),e(lu,k6),e(mi,w6),e(su,T6),e(M,R6),e(M,iu),e(iu,_i),e(_i,S6),e(_i,ru),e(ru,D6),e(_i,A6),e(iu,L6),e(M,I6),e(M,ou),e(ou,Ei),e(Ei,O6),e(Ei,nu),e(nu,P6),e(Ei,z6),e(ou,x6),e(M,N6),e(M,cu),e(cu,ov),e(ov,C6),e(cu,G6),e(M,U6),e(M,uu),e(uu,bi),e(bi,H6),e(bi,du),e(du,q6),e(bi,M6),e(uu,B6),e(M,W6),e(M,fu),e(fu,yi),e(yi,j6),e(yi,pu),e(pu,F6),e(yi,V6),e(fu,K6),e(M,Y6),e(M,hu),e(hu,ki),e(ki,X6),e(ki,vu),e(vu,Z6),e(ki,Q6),e(hu,J6),e(M,$6),e(M,gu),e(gu,wi),e(wi,e8),e(wi,mu),e(mu,t8),e(wi,a8),e(gu,s8),e(M,l8),e(M,_u),e(_u,Ti),e(Ti,i8),e(Ti,Eu),e(Eu,r8),e(Ti,o8),e(_u,n8),e(M,c8),e(M,bu),e(bu,Ri),e(Ri,u8),e(Ri,yu),e(yu,d8),e(Ri,f8),e(bu,p8),d(a,r1,f),d(a,xs,f),e(xs,Ns),e(Ns,nv),e(xs,h8),d(a,o1,f),d(a,ku,f),e(ku,v8),d(a,n1,f),qi(Si,a,f),d(a,c1,f),d(a,Cs,f),e(Cs,Gs),e(Gs,cv),e(Cs,g8),d(a,u1,f),d(a,Us,f),e(Us,m8),e(Us,Di),e(Di,_8),e(Us,E8),d(a,d1,f),d(a,Hs,f),e(Hs,b8),e(Hs,wu),e(wu,y8),e(Hs,k8),d(a,f1,f),d(a,oe,f),e(oe,Tu),e(Tu,w8),e(Tu,p1),e(oe,T8),e(oe,uv),e(uv,R8),e(oe,S8),e(oe,mt),e(mt,D8),e(mt,Ru),e(Ru,A8),e(mt,L8),e(mt,Su),e(Su,I8),e(mt,O8),e(mt,Du),e(Du,P8),e(oe,z8),e(oe,Au),e(Au,x8),e(Au,Lu),e(Lu,N8),e(oe,C8),e(oe,qs),e(qs,G8),e(qs,Iu),e(Iu,U8),e(qs,H8),e(qs,Ou),e(Ou,q8),d(a,h1,f),d(a,_t,f),e(_t,M8),e(_t,Pu),e(Pu,B8),e(_t,W8),e(_t,zu),e(zu,j8),e(_t,F8),d(a,v1,f),d(a,Te,f),e(Te,Ms),e(Ms,V8),e(Ms,xu),e(xu,K8),e(Ms,Y8),e(Ms,Nu),e(Nu,X8),e(Te,Z8),e(Te,Ai),e(Ai,Q8),e(Ai,Cu),e(Cu,J8),e(Ai,$8),e(Te,e7),e(Te,dv),e(dv,t7),e(Te,a7),e(Te,fv),e(fv,s7),d(a,g1,f),d(a,Bs,f),e(Bs,Ws),e(Ws,pv),e(Bs,l7),d(a,m1,f),d(a,Re,f),e(Re,Gu),e(Gu,hv),e(hv,i7),e(Gu,r7),e(Re,o7),e(Re,Uu),e(Uu,vv),e(vv,n7),e(Uu,c7),e(Re,u7),e(Re,Hu),e(Hu,gv),e(gv,d7),e(Hu,f7),e(Re,p7),e(Re,qu),e(qu,mv),e(mv,h7),e(qu,v7),d(a,_1,f),d(a,Mu,f),e(Mu,g7),d(a,E1,f),d(a,Li,f),e(Li,Ii),d(a,b1,f),d(a,js,f),e(js,Fs),e(Fs,_v),e(js,m7),d(a,y1,f),d(a,Bu,f),e(Bu,_7),d(a,k1,f),d(a,Et,f),e(Et,Oi),e(Oi,E7),e(Oi,Wu),e(Wu,b7),e(Oi,y7),e(Et,k7),e(Et,Pi),e(Pi,w7),e(Pi,ju),e(ju,T7),e(Pi,R7),e(Et,S7),e(Et,Ev),e(Ev,D7),d(a,w1,f),d(a,Zt,f),e(Zt,Fu),e(Fu,bt),e(bt,Vu),e(Vu,A7),e(bt,L7),e(bt,Ku),e(Ku,I7),e(bt,O7),e(bt,Yu),e(Yu,P7),e(Zt,z7),e(Zt,Se),e(Se,yt),e(yt,Xu),e(Xu,x7),e(yt,N7),e(yt,Zu),e(Zu,C7),e(yt,G7),e(yt,Qu),e(Qu,U7),e(Se,H7),e(Se,kt),e(kt,Ju),e(Ju,q7),e(kt,M7),e(kt,$u),e($u,B7),e(kt,W7),e(kt,ed),e(ed,j7),e(Se,F7),e(Se,wt),e(wt,td),e(td,V7),e(wt,K7),e(wt,ad),e(ad,Y7),e(wt,X7),e(wt,sd),e(sd,Z7),e(Se,Q7),e(Se,Tt),e(Tt,ld),e(ld,J7),e(Tt,$7),e(Tt,id),e(id,eT),e(Tt,tT),e(Tt,rd),e(rd,aT),d(a,T1,f),d(a,Vs,f),e(Vs,Ks),e(Ks,bv),e(Vs,sT),d(a,R1,f),d(a,od,f),e(od,lT),d(a,S1,f),d(a,Qt,f),e(Qt,nd),e(nd,Rt),e(Rt,cd),e(cd,iT),e(Rt,rT),e(Rt,ud),e(ud,oT),e(Rt,nT),e(Rt,dd),e(dd,cT),e(Qt,uT),e(Qt,W),e(W,St),e(St,fd),e(fd,dT),e(St,fT),e(St,pd),e(pd,pT),e(St,hT),e(St,hd),e(hd,vT),e(W,gT),e(W,Dt),e(Dt,vd),e(vd,mT),e(Dt,_T),e(Dt,gd),e(gd,ET),e(Dt,bT),e(Dt,md),e(md,yT),e(W,kT),e(W,At),e(At,_d),e(_d,wT),e(At,TT),e(At,Ed),e(Ed,RT),e(At,ST),e(At,bd),e(bd,DT),e(W,AT),e(W,Lt),e(Lt,yd),e(yd,LT),e(Lt,IT),e(Lt,kd),e(kd,OT),e(Lt,PT),e(Lt,wd),e(wd,zT),e(W,xT),e(W,It),e(It,Td),e(Td,NT),e(It,CT),e(It,Rd),e(Rd,GT),e(It,UT),e(It,Sd),e(Sd,HT),e(W,qT),e(W,Ot),e(Ot,Dd),e(Dd,MT),e(Ot,BT),e(Ot,Ad),e(Ad,WT),e(Ot,jT),e(Ot,Ld),e(Ld,FT),e(W,VT),e(W,Pt),e(Pt,Id),e(Id,KT),e(Pt,YT),e(Pt,Od),e(Od,XT),e(Pt,ZT),e(Pt,Pd),e(Pd,QT),e(W,JT),e(W,zt),e(zt,zd),e(zd,$T),e(zt,e9),e(zt,xd),e(xd,t9),e(zt,a9),e(zt,Nd),e(Nd,s9),e(W,l9),e(W,xt),e(xt,Cd),e(Cd,i9),e(xt,r9),e(xt,Gd),e(Gd,o9),e(xt,n9),e(xt,Ud),e(Ud,c9),e(W,u9),e(W,Nt),e(Nt,Hd),e(Hd,d9),e(Nt,f9),e(Nt,qd),e(qd,p9),e(Nt,h9),e(Nt,Md),e(Md,v9),d(a,D1,f),d(a,Ys,f),e(Ys,Xs),e(Xs,yv),e(Ys,g9),d(a,A1,f),d(a,Bd,f),e(Bd,m9),d(a,L1,f),d(a,Wd,f),e(Wd,_9),d(a,I1,f),d(a,zi,f),e(zi,xi),d(a,O1,f),d(a,jd,f),e(jd,E9),d(a,P1,f),d(a,Jt,f),e(Jt,Zs),e(Zs,kv),e(Jt,b9),d(a,z1,f),Le&&Le.m(a,f),d(a,x1,f),N1=!0},p(a,f){Mx&&Le.p(a,f)},i(a){N1||(aa(hl.$$.fragment,a),aa(Fl.$$.fragment,a),aa(Yl.$$.fragment,a),aa(Si.$$.fragment,a),aa(Le),N1=!0)},o(a){sa(hl.$$.fragment,a),sa(Fl.$$.fragment,a),sa(Yl.$$.fragment,a),sa(Si.$$.fragment,a),sa(Le),N1=!1},d(a){a&&t(p),a&&t(v),a&&t(h),a&&t(E),a&&t(y),a&&t(b),a&&t(w),a&&t(N),a&&t(G),a&&t(L),a&&t(D),a&&t(B),a&&t(C),a&&t(U),a&&t(Z),a&&t(la),a&&t(Oe),a&&t(Lv),a&&t(Bi),a&&t(Iv),a&&t(ia),a&&t(Ov),a&&t(Wi),a&&t(Pv),a&&t(pl),a&&t(zv),Mi(hl,a),a&&t(xv),a&&t(Fi),a&&t(Nv),a&&t(Vi),a&&t(Cv),a&&t(Ki),a&&t(Gv),a&&t(qt),a&&t(Uv),a&&t(or),a&&t(Hv),a&&t(nr),a&&t(qv),a&&t(vl),a&&t(Mv),a&&t(oa),a&&t(Bv),a&&t(gl),a&&t(Wv),a&&t(ml),a&&t(jv),a&&t(_l),a&&t(Fv),a&&t(ca),a&&t(Vv),a&&t(El),a&&t(Kv),a&&t(bl),a&&t(Yv),a&&t(yl),a&&t(Xv),a&&t(da),a&&t(Zv),a&&t(kl),a&&t(Qv),a&&t(Ge),a&&t(Jv),a&&t(Ue),a&&t($v),a&&t(wl),a&&t(eg),a&&t(ha),a&&t(tg),a&&t(hr),a&&t(ag),a&&t(He),a&&t(sg),a&&t(ga),a&&t(lg),a&&t(Mt),a&&t(ig),a&&t(_a),a&&t(rg),a&&t(Bt),a&&t(og),a&&t(Fr),a&&t(ng),a&&t(Ra),a&&t(cg),a&&t(he),a&&t(ug),a&&t(ve),a&&t(dg),a&&t(Tl),a&&t(fg),a&&t(Rl),a&&t(pg),a&&t(Da),a&&t(hg),a&&t(Wt),a&&t(vg),a&&t(ho),a&&t(gg),a&&t(vo),a&&t(mg),a&&t(go),a&&t(_g),a&&t(Eg),a&&t(bg),a&&t(La),a&&t(yg),a&&t(Oa),a&&t(kg),a&&t(Pa),a&&t(wg),a&&t(xa),a&&t(Tg),a&&t(Al),a&&t(Rg),a&&t(Na),a&&t(Sg),a&&t(Ze),a&&t(Dg),a&&t(Ga),a&&t(Ag),a&&t(Qe),a&&t(Lg),a&&t(Ha),a&&t(Ig),a&&t(Ll),a&&t(Og),a&&t(Il),a&&t(Pg),a&&t(Ma),a&&t(zg),a&&t(Je),a&&t(xg),a&&t(Ol),a&&t(Ng),a&&t(Wa),a&&t(Cg),a&&t(Pl),a&&t(Gg),a&&t(_o),a&&t(Ug),a&&t($e),a&&t(Hg),a&&t(xl),a&&t(qg),a&&t(Fa),a&&t(Mg),a&&t(Nl),a&&t(Bg),a&&t(Cl),a&&t(Wg),a&&t(yo),a&&t(jg),a&&t(et),a&&t(Fg),a&&t(Gl),a&&t(Vg),a&&t(Ka),a&&t(Kg),a&&t(Xa),a&&t(Yg),a&&t(Ul),a&&t(Xg),a&&t(jt),a&&t(Zg),a&&t(Za),a&&t(Qg),a&&t(rt),a&&t(Jg),a&&t(Ja),a&&t($g),a&&t(Fo),a&&t(em),a&&t(Vo),a&&t(tm),a&&t(ts),a&&t(am),a&&t(ot),a&&t(sm),a&&t(Yo),a&&t(lm),a&&t(ss),a&&t(im),a&&t(Xo),a&&t(rm),a&&t(is),a&&t(om),a&&t(en),a&&t(nm),a&&t(rs),a&&t(cm),a&&t(sn),a&&t(um),a&&t(Ml),a&&t(dm),a&&t(nt),a&&t(fm),a&&t(Kt),a&&t(pm),a&&t(hm),a&&t(vm),a&&t(ns),a&&t(gm),a&&t(us),a&&t(mm),a&&t(ue),a&&t(_m),a&&t(Nn),a&&t(Em),a&&t(ds),a&&t(bm),a&&t(ut),a&&t(ym),Mi(Fl,a),a&&t(km),a&&t(ps),a&&t(wm),a&&t(vs),a&&t(Tm),a&&t(dt),a&&t(Rm),a&&t(J),a&&t(Sm),a&&t(ft),a&&t(Dm),Mi(Yl,a),a&&t(Am),a&&t(ms),a&&t(Lm),a&&t(gc),a&&t(Im),a&&t(we),a&&t(Om),a&&t(Es),a&&t(Pm),a&&t(yc),a&&t(zm),a&&t(kc),a&&t(xm),a&&t(pt),a&&t(Nm),a&&t($l),a&&t(Cm),a&&t(ys),a&&t(Gm),a&&t(ks),a&&t(Um),a&&t(ws),a&&t(Hm),a&&t(vt),a&&t(qm),a&&t(li),a&&t(Mm),a&&t(ri),a&&t(Bm),a&&t(Ss),a&&t(Wm),a&&t(As),a&&t(jm),a&&t(ui),a&&t(Fm),a&&t(Oc),a&&t(Vm),a&&t(di),a&&t(Km),a&&t(Ls),a&&t(Ym),a&&t(fi),a&&t(Xm),a&&t(gt),a&&t(Zm),a&&t(Cc),a&&t(Qm),a&&t(Os),a&&t(Jm),a&&t(Hc),a&&t($m),a&&t(pi),a&&t(e1),a&&t(Ps),a&&t(t1),a&&t(Yt),a&&t(a1),a&&t(Xt),a&&t(s1),a&&t(eu),a&&t(l1),a&&t(vi),a&&t(i1),a&&t(M),a&&t(r1),a&&t(xs),a&&t(o1),a&&t(ku),a&&t(n1),Mi(Si,a),a&&t(c1),a&&t(Cs),a&&t(u1),a&&t(Us),a&&t(d1),a&&t(Hs),a&&t(f1),a&&t(oe),a&&t(h1),a&&t(_t),a&&t(v1),a&&t(Te),a&&t(g1),a&&t(Bs),a&&t(m1),a&&t(Re),a&&t(_1),a&&t(Mu),a&&t(E1),a&&t(Li),a&&t(b1),a&&t(js),a&&t(y1),a&&t(Bu),a&&t(k1),a&&t(Et),a&&t(w1),a&&t(Zt),a&&t(T1),a&&t(Vs),a&&t(R1),a&&t(od),a&&t(S1),a&&t(Qt),a&&t(D1),a&&t(Ys),a&&t(A1),a&&t(Bd),a&&t(L1),a&&t(Wd),a&&t(I1),a&&t(zi),a&&t(O1),a&&t(jd),a&&t(P1),a&&t(Jt),a&&t(z1),Le&&Le.d(a),a&&t(x1)}}}function WN(_){let p,g;const v=[_[0],rS];let h={$$slots:{default:[BN]},$$scope:{ctx:_}};for(let m=0;m<v.length;m+=1)h=iS(h,v[m]);return p=new vN({props:h}),{c(){Ui(p.$$.fragment)},l(m){Hi(p.$$.fragment,m)},m(m,E){qi(p,m,E),g=!0},p(m,[E]){const y=E&1?hN(v,[E&1&&xx(m[0]),E&0&&xx(rS)]):{};E&2&&(y.$$scope={dirty:E,ctx:m}),p.$set(y)},i(m){g||(aa(p.$$.fragment,m),g=!0)},o(m){sa(p.$$.fragment,m),g=!1},d(m){Mi(p,m)}}}const rS={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-31 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Monitoring",icon:"\u{1F4C9}",url:"/blog/action-figure-art/#monitoring-tips"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:aC,date:sC,modifiedDate:lC,categories:iC,svg:rC,seoImage:oC,shortDescription:nC,author:cC,spacelab:Mx,id:jN,spacelabDefaultTitle:FN,spacelabDefaultContent:VN,menu:uC,keywords:dC}=rS;function KN(_,p,g){return _.$$set=v=>{g(0,p=iS(iS({},p),Nx(v)))},p=Nx(p),[p]}class fC extends G2{constructor(p){super(),U2(this,p,KN,WN,H2,{})}}export{fC as default,rS as metadata};
