import{S as ev,i as tv,s as sv,l as uf,g as f,E as o6,d as t,v as sA,e as a,t as o,c as l,a as r,h as n,b as i,G as e,j as ce,k as c,m as u,F as ee,H as Re,N as T9,Y as aA,J as Mt,f as qt,Z as lA,_ as rA,$ as iA,q as Ut,o as Bt,O as oA,w as $l,x as er,y as tr,B as sr,C as n6,z as nA,A as R9,a1 as S9}from"../../chunks/index-2a82a4a8.js";import{P as cA}from"../../chunks/_post-913f18eb.js";import{g as l6}from"../../chunks/config-201c2df4.js";import{a as r6}from"../../chunks/accountStore-3492c591.js";/* empty css                                                                   */import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function uA(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A;function S(L,H){return typeof L[2].title!="undefined"?pA:dA}let O=S(_),z=O(_);function Q(L,H){return typeof L[2].description!="undefined"?gA:hA}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&D9(_),C=typeof _[2].footer_description!="undefined"&&A9(_);return{c(){p=a("hr"),m=c(),g=a("div"),z.c(),h=c(),v=a("p"),k=a("ion-icon"),b=o("SpaceLab Content"),w=c(),F.c(),T=c(),B&&B.c(),x=c(),C&&C.c(),E=c(),y=a("button"),I=a("ion-icon"),P=c(),N=a("span"),G=o("SpaceLab"),this.h()},l(L){p=l(L,"HR",{}),m=u(L),g=l(L,"DIV",{class:!0});var H=r(g);z.l(H),h=u(H),v=l(H,"P",{class:!0});var Z=r(v);k=l(Z,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),b=n(Z,"SpaceLab Content"),Z.forEach(t),w=u(H),F.l(H),T=u(H),B&&B.l(H),x=u(H),C&&C.l(H),E=u(H),y=l(H,"BUTTON",{class:!0});var q=r(y);I=l(q,"ION-ICON",{class:!0,name:!0}),r(I).forEach(t),P=u(q),N=l(q,"SPAN",{});var R=r(N);G=n(R,"SpaceLab"),R.forEach(t),q.forEach(t),H.forEach(t),this.h()},h(){ee(k,"class","icon svelte-s12rf8"),ee(k,"name","lock-closed"),i(v,"class","highlight large svelte-s12rf8"),ee(I,"class","icon svelte-s12rf8"),ee(I,"name","planet"),i(y,"class","button subscribe svelte-s12rf8"),i(g,"class","subscribe svelte-s12rf8")},m(L,H){f(L,p,H),f(L,m,H),f(L,g,H),z.m(g,null),e(g,h),e(g,v),e(v,k),e(v,b),e(g,w),F.m(g,null),e(g,T),B&&B.m(g,null),e(g,x),C&&C.m(g,null),e(g,E),e(g,y),e(y,I),e(y,P),e(y,N),e(N,G),D||(A=Re(y,"click",_[15]),D=!0)},p(L,H){O===(O=S(L))&&z?z.p(L,H):(z.d(1),z=O(L),z&&(z.c(),z.m(g,h))),j===(j=Q(L))&&F?F.p(L,H):(F.d(1),F=j(L),F&&(F.c(),F.m(g,T))),typeof L[2].list_description!="undefined"?B?B.p(L,H):(B=D9(L),B.c(),B.m(g,x)):B&&(B.d(1),B=null),typeof L[2].footer_description!="undefined"?C?C.p(L,H):(C=A9(L),C.c(),C.m(g,E)):C&&(C.d(1),C=null)},d(L){L&&t(p),L&&t(m),L&&t(g),z.d(),F.d(),B&&B.d(),C&&C.d(),D=!1,A()}}}function fA(_){let p,m,g,h=_[2].title+"",v,k,b,w,T,x,E,y=_[2].description+"",I,P,N,G,D,A,S,O,z,Q,j,F,B,C=typeof _[2].list_description!="undefined"&&L9(_),L=typeof _[2].footer_description!="undefined"&&I9(_);function H(R,M){if(R[2].github_private_repo&&R[2].github_state==="LOG_EXISTS")return _A;if(R[2].github_private_repo&&R[2].github_state==="NO_LOGS")return vA;if(R[2].github_private_repo&&R[2].github_state==="NO_GITHUB_USERNAME")return mA}let Z=H(_),q=Z&&Z(_);return{c(){p=a("hr"),m=c(),g=a("h2"),v=o(h),k=c(),b=a("p"),w=a("ion-icon"),T=o("SpaceLab Content"),x=c(),E=a("p"),I=o(y),P=c(),C&&C.c(),N=c(),L&&L.c(),G=c(),D=a("button"),A=a("ion-icon"),S=c(),O=a("span"),z=o("Download"),Q=c(),q&&q.c(),j=uf(),this.h()},l(R){p=l(R,"HR",{}),m=u(R),g=l(R,"H2",{class:!0});var M=r(g);v=n(M,h),M.forEach(t),k=u(R),b=l(R,"P",{class:!0});var Wt=r(b);w=l(Wt,"ION-ICON",{class:!0,name:!0}),r(w).forEach(t),T=n(Wt,"SpaceLab Content"),Wt.forEach(t),x=u(R),E=l(R,"P",{class:!0});var Se=r(E);I=n(Se,y),Se.forEach(t),P=u(R),C&&C.l(R),N=u(R),L&&L.l(R),G=u(R),D=l(R,"BUTTON",{class:!0});var fe=r(D);A=l(fe,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),S=u(fe),O=l(fe,"SPAN",{});var ff=r(O);z=n(ff,"Download"),ff.forEach(t),fe.forEach(t),Q=u(R),q&&q.l(R),j=uf(),this.h()},h(){i(g,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","planet-sharp"),i(b,"class","highlight large svelte-s12rf8"),i(E,"class","svelte-s12rf8"),ee(A,"class","icon svelte-s12rf8"),ee(A,"name","cloud-download"),i(D,"class","button svelte-s12rf8")},m(R,M){f(R,p,M),f(R,m,M),f(R,g,M),e(g,v),f(R,k,M),f(R,b,M),e(b,w),e(b,T),f(R,x,M),f(R,E,M),e(E,I),f(R,P,M),C&&C.m(R,M),f(R,N,M),L&&L.m(R,M),f(R,G,M),f(R,D,M),e(D,A),e(D,S),e(D,O),e(O,z),f(R,Q,M),q&&q.m(R,M),f(R,j,M),F||(B=Re(D,"click",_[10]),F=!0)},p(R,M){M&4&&h!==(h=R[2].title+"")&&ce(v,h),M&4&&y!==(y=R[2].description+"")&&ce(I,y),typeof R[2].list_description!="undefined"?C?C.p(R,M):(C=L9(R),C.c(),C.m(N.parentNode,N)):C&&(C.d(1),C=null),typeof R[2].footer_description!="undefined"?L?L.p(R,M):(L=I9(R),L.c(),L.m(G.parentNode,G)):L&&(L.d(1),L=null),Z===(Z=H(R))&&q?q.p(R,M):(q&&q.d(1),q=Z&&Z(R),q&&(q.c(),q.m(j.parentNode,j)))},d(R){R&&t(p),R&&t(m),R&&t(g),R&&t(k),R&&t(b),R&&t(x),R&&t(E),R&&t(P),C&&C.d(R),R&&t(N),L&&L.d(R),R&&t(G),R&&t(D),R&&t(Q),q&&q.d(R),R&&t(j),F=!1,B()}}}function dA(_){let p,m;return{c(){p=a("h2"),m=o(_[0]),this.h()},l(g){p=l(g,"H2",{class:!0});var h=r(p);m=n(h,_[0]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&1&&ce(m,g[0])},d(g){g&&t(p)}}}function pA(_){let p,m=_[2].title+"",g;return{c(){p=a("h2"),g=o(m),this.h()},l(h){p=l(h,"H2",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].title+"")&&ce(g,m)},d(h){h&&t(p)}}}function hA(_){let p,m;return{c(){p=a("p"),m=o(_[1]),this.h()},l(g){p=l(g,"P",{class:!0});var h=r(p);m=n(h,_[1]),h.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(g,h){f(g,p,h),e(p,m)},p(g,h){h&2&&ce(m,g[1])},d(g){g&&t(p)}}}function gA(_){let p,m=_[2].description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].description+"")&&ce(g,m)},d(h){h&&t(p)}}}function D9(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function A9(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function L9(_){let p,m,g=_[2].list_description+"",h;return{c(){p=a("div"),m=a("p"),h=o(g),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(p,"class","list-description svelte-s12rf8")},m(v,k){f(v,p,k),e(p,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(p)}}}function I9(_){let p,m=_[2].footer_description+"",g;return{c(){p=a("p"),g=o(m),this.h()},l(h){p=l(h,"P",{class:!0});var v=r(p);g=n(v,m),v.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(h,v){f(h,p,v),e(p,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(p)}}}function mA(_){let p,m,g,h,v,k;function b(x,E){return x[5]?EA:kA}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{class:!0});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[8]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function vA(_){let p,m,g,h,v,k;function b(x,E){return x[5]?xA:bA}let w=b(_),T=w(_);return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),T.c(),this.h()},l(x){p=l(x,"H2",{class:!0});var E=r(p);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{});var y=r(h);T.l(y),y.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8")},m(x,E){f(x,p,E),e(p,m),f(x,g,E),f(x,h,E),T.m(h,null),v||(k=Re(h,"submit",_[7]),v=!0)},p(x,E){w===(w=b(x))&&T?T.p(x,E):(T.d(1),T=w(x),T&&(T.c(),T.m(h,null)))},d(x){x&&t(p),x&&t(g),x&&t(h),T.d(),v=!1,k()}}}function _A(_){var A;let p,m,g,h,v,k,b=((A=_[6].profile)==null?void 0:A.githubUsername)+"",w,T,x,E,y,I,P,N,G,D;return{c(){p=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("p"),v=o("Your GitHub account "),k=a("span"),w=o(b),T=o(` is
			linked to this content.`),x=c(),E=a("button"),y=a("ion-icon"),I=c(),P=a("span"),N=o("Open Repository"),this.h()},l(S){p=l(S,"H2",{class:!0});var O=r(p);m=n(O,"Private GitHub Access"),O.forEach(t),g=u(S),h=l(S,"P",{class:!0});var z=r(h);v=n(z,"Your GitHub account "),k=l(z,"SPAN",{class:!0});var Q=r(k);w=n(Q,b),Q.forEach(t),T=n(z,` is
			linked to this content.`),z.forEach(t),x=u(S),E=l(S,"BUTTON",{class:!0});var j=r(E);y=l(j,"ION-ICON",{class:!0,name:!0}),r(y).forEach(t),I=u(j),P=l(j,"SPAN",{});var F=r(P);N=n(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(k,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(y,"class","icon svelte-s12rf8"),ee(y,"name","rocket-sharp"),i(E,"class","svelte-s12rf8")},m(S,O){f(S,p,O),e(p,m),f(S,g,O),f(S,h,O),e(h,v),e(h,k),e(k,w),e(h,T),f(S,x,O),f(S,E,O),e(E,y),e(E,I),e(E,P),e(P,N),G||(D=Re(E,"click",_[11]),G=!0)},p(S,O){var z;O&64&&b!==(b=((z=S[6].profile)==null?void 0:z.githubUsername)+"")&&ce(w,b)},d(S){S&&t(p),S&&t(g),S&&t(h),S&&t(x),S&&t(E),G=!1,D()}}}function kA(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G;return{c(){p=a("p"),m=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),g=c(),h=a("label"),v=o("Github username:"),k=c(),b=a("input"),T=c(),x=a("button"),E=a("ion-icon"),y=c(),I=a("span"),P=o("Request Permission"),this.h()},l(D){p=l(D,"P",{class:!0});var A=r(p);m=n(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),g=u(D),h=l(D,"LABEL",{for:!0});var S=r(h);v=n(S,"Github username:"),S.forEach(t),k=u(D),b=l(D,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),T=u(D),x=l(D,"BUTTON",{class:!0});var O=r(x);E=l(O,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=u(O),I=l(O,"SPAN",{});var z=r(I);P=n(z,"Request Permission"),z.forEach(t),O.forEach(t),this.h()},h(){i(p,"class","svelte-s12rf8"),i(h,"for","username"),i(b,"name","username"),i(b,"id","username"),i(b,"placeholder","enter a username"),i(b,"type","text"),b.required="true",i(b,"class",w=_[4]?"validation-error":""),ee(E,"class","icon svelte-s12rf8"),ee(E,"name","rocket-sharp"),i(x,"class","svelte-s12rf8")},m(D,A){f(D,p,A),e(p,m),f(D,g,A),f(D,h,A),e(h,v),f(D,k,A),f(D,b,A),T9(b,_[3]),f(D,T,A),f(D,x,A),e(x,E),e(x,y),e(x,I),e(I,P),N||(G=Re(b,"input",_[14]),N=!0)},p(D,A){A&16&&w!==(w=D[4]?"validation-error":"")&&i(b,"class",w),A&8&&b.value!==D[3]&&T9(b,D[3])},d(D){D&&t(p),D&&t(g),D&&t(h),D&&t(k),D&&t(b),D&&t(T),D&&t(x),N=!1,G()}}}function EA(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[13]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function bA(_){var I;let p,m,g,h=((I=_[6].profile)==null?void 0:I.githubUsername)+"",v,k,b,w,T,x,E,y;return{c(){p=a("p"),m=o("This content can grant access to a private GitHub repository. Allow "),g=a("span"),v=o(h),k=o(" access to this repo?"),b=c(),w=a("button"),T=a("ion-icon"),x=c(),E=a("span"),y=o("Request Permission"),this.h()},l(P){p=l(P,"P",{class:!0});var N=r(p);m=n(N,"This content can grant access to a private GitHub repository. Allow "),g=l(N,"SPAN",{class:!0});var G=r(g);v=n(G,h),G.forEach(t),k=n(N," access to this repo?"),N.forEach(t),b=u(P),w=l(P,"BUTTON",{class:!0});var D=r(w);T=l(D,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),x=u(D),E=l(D,"SPAN",{});var A=r(E);y=n(A,"Request Permission"),A.forEach(t),D.forEach(t),this.h()},h(){i(g,"class","highlight svelte-s12rf8"),i(p,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","rocket-sharp"),i(w,"class","svelte-s12rf8")},m(P,N){f(P,p,N),e(p,m),e(p,g),e(g,v),e(p,k),f(P,b,N),f(P,w,N),e(w,T),e(w,x),e(w,E),e(E,y)},p(P,N){var G;N&64&&h!==(h=((G=P[6].profile)==null?void 0:G.githubUsername)+"")&&ce(v,h)},d(P){P&&t(p),P&&t(b),P&&t(w)}}}function xA(_){let p,m,g,h,v,k,b,w,T,x;return{c(){p=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),w=o("Open Repository"),this.h()},l(E){p=l(E,"P",{class:!0});var y=r(p);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var I=r(h);v=l(I,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(I),b=l(I,"SPAN",{});var P=r(b);w=n(P,"Open Repository"),P.forEach(t),I.forEach(t),this.h()},h(){i(p,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){f(E,p,y),e(p,m),f(E,g,y),f(E,h,y),e(h,v),e(h,k),e(h,b),e(b,w),T||(x=Re(h,"click",_[12]),T=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(p),E&&t(g),E&&t(h),T=!1,x()}}}function yA(_){let p;function m(v,k){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?fA:uA}let g=m(_),h=g(_);return{c(){h.c(),p=uf()},l(v){h.l(v),p=uf()},m(v,k){h.m(v,k),f(v,p,k)},p(v,[k]){g===(g=m(v))&&h?h.p(v,k):(h.d(1),h=g(v),h&&(h.c(),h.m(p.parentNode,p)))},i:o6,o:o6,d(v){h.d(v),v&&t(p)}}}function i6(_){window.open(_,"_blank")||window.location.replace(_)}function wA(_,p,m){let{id:g}=p,{spacelabDefaultTitle:h="Spacelab Content"}=p,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=p,k={},b="",w=!1,T="",x;r6.subscribe(S=>{m(6,x=S)}),sA(async()=>{if(typeof(x==null?void 0:x.token)!="undefined"){const S=await fetch(`${l6().serviceUrl}/education/spacelab/${g}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors"});if(S.status===401){r6.set({}),r6.deleteLocalStorage();return}let O=await S.json();m(2,k=O)}else m(2,k.success=!1,k)});async function E(S){S.preventDefault();const O={};try{const z=await fetch(`${l6().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}async function y(S){if(S.preventDefault(),!b.trim()){m(4,w=!0),m(5,T="Please enter a valid GitHub username.");return}m(4,w=!1);const O={github_username:b};try{const z=await fetch(`${l6().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(O)});if(z.ok)m(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await z.json();m(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(z){console.error("Error while sending GitHub access request:",z),m(5,T="An unexpected error occurred. Please try again later.")}}const I=()=>window.open(k.url,"_blank"),P=()=>i6(`https://github.com/${k.github_repo_name}`),N=()=>i6(`https://github.com/${k.github_repo_name}`),G=()=>i6(`https://github.com/${k.github_repo_name}`);function D(){b=this.value,m(3,b)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=S=>{"id"in S&&m(9,g=S.id),"spacelabDefaultTitle"in S&&m(0,h=S.spacelabDefaultTitle),"spacelabDefaultContent"in S&&m(1,v=S.spacelabDefaultContent)},[h,v,k,b,w,T,x,E,y,g,I,P,N,G,D,A]}class TA extends ev{constructor(p){super(),tv(this,p,wA,yA,sv,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const RA=_=>({}),P9=_=>({});function SA(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function DA(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P;const N=_[7]["slider-label"],G=aA(N,_,_[6],P9),D=G||SA();return{c(){p=a("div"),m=a("img"),h=c(),v=a("img"),b=c(),w=a("label"),T=a("span"),D&&D.c(),x=c(),E=a("input"),this.h()},l(A){p=l(A,"DIV",{class:!0,style:!0,"data-testid":!0});var S=r(p);m=l(S,"IMG",{src:!0,alt:!0,class:!0}),h=u(S),v=l(S,"IMG",{src:!0,alt:!0,class:!0}),b=u(S),w=l(S,"LABEL",{class:!0});var O=r(w);T=l(O,"SPAN",{class:!0});var z=r(T);D&&D.l(z),z.forEach(t),x=u(O),E=l(O,"INPUT",{type:!0,min:!0,max:!0,class:!0}),O.forEach(t),S.forEach(t),this.h()},h(){Mt(m.src,g=_[0])||i(m,"src",g),i(m,"alt",_[1]),i(m,"class","left-img svelte-1po6qlg"),Mt(v.src,k=_[2])||i(v,"src",k),i(v,"alt",_[3]),i(v,"class","right-img svelte-1po6qlg"),i(T,"class","visually-hidden svelte-1po6qlg"),i(E,"type","range"),i(E,"min","0"),i(E,"max","100"),E.value=_[4],i(E,"class","svelte-1po6qlg"),i(w,"class","svelte-1po6qlg"),i(p,"class","svelte-compare-image-container svelte-1po6qlg"),qt(p,"--slider-position",_[4]+"%"),i(p,"data-testid","svelte-compare-image")},m(A,S){f(A,p,S),e(p,m),e(p,h),e(p,v),e(p,b),e(p,w),e(w,T),D&&D.m(T,null),e(w,x),e(w,E),y=!0,I||(P=[Re(E,"input",_[5]),Re(E,"change",_[5]),Re(E,"click",AA)],I=!0)},p(A,[S]){(!y||S&1&&!Mt(m.src,g=A[0]))&&i(m,"src",g),(!y||S&2)&&i(m,"alt",A[1]),(!y||S&4&&!Mt(v.src,k=A[2]))&&i(v,"src",k),(!y||S&8)&&i(v,"alt",A[3]),G&&G.p&&(!y||S&64)&&lA(G,N,A,A[6],y?iA(N,A[6],S,RA):rA(A[6]),P9),(!y||S&16)&&(E.value=A[4]),(!y||S&16)&&qt(p,"--slider-position",A[4]+"%")},i(A){y||(Ut(D,A),y=!0)},o(A){Bt(D,A),y=!1},d(A){A&&t(p),D&&D.d(A),I=!1,oA(P)}}}function AA(_){_.target.focus()}function LA(_,p,m){let{$$slots:g={},$$scope:h}=p,{imageLeftSrc:v=""}=p,{imageLeftAlt:k=""}=p,{imageRightSrc:b=""}=p,{imageRightAlt:w=""}=p,T=50,x=null;function E(y){x&&cancelAnimationFrame(x),x=requestAnimationFrame(()=>{m(4,T=y.target.valueAsNumber)})}return _.$$set=y=>{"imageLeftSrc"in y&&m(0,v=y.imageLeftSrc),"imageLeftAlt"in y&&m(1,k=y.imageLeftAlt),"imageRightSrc"in y&&m(2,b=y.imageRightSrc),"imageRightAlt"in y&&m(3,w=y.imageRightAlt),"$$scope"in y&&m(6,h=y.$$scope)},[v,k,b,w,T,E,h,g]}class IA extends ev{constructor(p){super(),tv(this,p,LA,DA,sv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function PA(_){let p;return{c(){p=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(m){p=n(m,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(m,g){f(m,p,g)},d(m){m&&t(p)}}}function OA(_){let p,m,g,h;return m=new IA({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[PA]},$$scope:{ctx:_}}}),{c(){p=a("div"),g=a("div"),$l(m.$$.fragment),this.h()},l(v){p=l(v,"DIV",{class:!0});var k=r(p);g=l(k,"DIV",{style:!0});var b=r(g);er(m.$$.fragment,b),k.forEach(t),this.h()},h(){qt(g,"display","contents"),qt(g,"--handle-size","2.5rem"),qt(g,"--handle-background-color","rgba(0, 0, 0, 0.6)"),qt(g,"--handle-background-image",_[4]),qt(g,"--handle-border-width","0.125rem"),qt(g,"--slider-color","#ffffff"),qt(g,"--slider-width","0.125rem"),i(p,"class","image-compare-container svelte-s79nww")},m(v,k){f(v,p,k),e(p,g),tr(m,g,null),h=!0},p(v,[k]){const b={};k&1&&(b.imageLeftSrc=v[0]),k&2&&(b.imageLeftAlt=v[1]),k&4&&(b.imageRightSrc=v[2]),k&8&&(b.imageRightAlt=v[3]),k&32&&(b.$$scope={dirty:k,ctx:v}),m.$set(b)},i(v){h||(Ut(m.$$.fragment,v),h=!0)},o(v){Bt(m.$$.fragment,v),h=!1},d(v){v&&t(p),sr(m)}}}function zA(_,p,m){const g=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=p,{imageLeftAlt:v="left"}=p,{imageRightSrc:k="https://via.placeholder.com/512x512/00aaff/ffffff/"}=p,{imageRightAlt:b="right"}=p;return _.$$set=w=>{"imageLeftSrc"in w&&m(0,h=w.imageLeftSrc),"imageLeftAlt"in w&&m(1,v=w.imageLeftAlt),"imageRightSrc"in w&&m(2,k=w.imageRightSrc),"imageRightAlt"in w&&m(3,b=w.imageRightAlt)},[h,v,k,b,g]}class $m extends ev{constructor(p){super(),tv(this,p,zA,OA,sv,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function NA(_){let p,m;return p=new TA({props:{id:HA,spacelabDefaultTitle:qA,spacelabDefaultContent:MA}}),{c(){$l(p.$$.fragment)},l(g){er(p.$$.fragment,g)},m(g,h){tr(p,g,h),m=!0},p:o6,i(g){m||(Ut(p.$$.fragment,g),m=!0)},o(g){Bt(p.$$.fragment,g),m=!1},d(g){sr(p,g)}}}function CA(_){let p,m,g,h,v,k,b,w,T,x,E,y,I,P,N,G,D,A,S,O,z,Q,j,F,B,C,L,H,Z,q,R,M,Wt,Se,fe,ff,bp,ar,av,xp,jt,Ft,df,lv,yp,lr,rv,wp,Ga,rr,iv,Tp,Ha,Rp,ir,ov,Sp,or,nv,Dp,nr,cv,Ap,Dt,cr,De,ur,uv,fv,fr,dv,pv,dr,hv,gv,Ae,Le,pr,pf,mv,vv,hr,_v,kv,gr,Ev,bv,Ie,mr,hf,xv,yv,vr,wv,Tv,_r,Rv,Sv,Pe,kr,gf,Dv,Av,Er,Lv,Iv,br,Pv,Lp,xr,Ov,Ip,yr,zv,Pp,qa,wr,Nv,Op,Yt,Vt,mf,Cv,zp,Ma,vf,Gv,Hv,Np,Ua,_f,qv,Mv,Cp,Ba,kf,Uv,Bv,Gp,Kt,Xt,Ef,Wv,Hp,Wa,bf,jv,Fv,qp,ja,xf,Yv,Vv,Mp,Fa,yf,Kv,Xv,Up,Zt,Qt,wf,Zv,Bp,Ya,Tf,Qv,Jv,Wp,Oe,$v,Rf,e2,t2,Sf,s2,a2,jp,ze,Tr,Df,l2,r2,i2,Rr,Af,o2,n2,c2,Jt,Lf,u2,f2,Sr,d2,p2,Fp,Va,Dr,h2,Yp,$t,es,If,Pf,g2,Vp,Ar,m2,Kp,Ne,Lr,Of,v2,_2,k2,Ir,zf,E2,b2,x2,Pr,Nf,y2,w2,Xp,ts,ss,Cf,Gf,T2,Zp,At,Or,Ce,zr,Hf,R2,S2,Nr,qf,D2,A2,Cr,Mf,L2,I2,de,Ge,Gr,Uf,P2,O2,Hr,z2,N2,qr,C2,G2,He,Mr,Bf,H2,q2,Ur,M2,U2,Br,B2,W2,qe,Wr,Wf,j2,F2,jr,Y2,V2,Fr,K2,X2,Me,Yr,jf,Z2,Q2,Vr,J2,$2,Kr,e_,Qp,as,ls,Ff,t_,Jp,Lt,Xr,rs,Zr,s_,a_,Qr,l_,r_,pe,is,Jr,Yf,i_,o_,$r,n_,c_,os,ei,Vf,u_,f_,ti,d_,p_,ns,si,Kf,h_,g_,ai,m_,v_,cs,li,Xf,__,k_,ri,E_,$p,ii,b_,eh,us,fs,Zf,x_,th,Ka,z9=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,sh,Xa,N9=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,ah,ds,ps,Qf,y_,lh,It,oi,Ue,ni,w_,T_,ci,R_,S_,ui,D_,A_,he,Be,fi,L_,I_,di,P_,O_,pi,z_,N_,We,hi,C_,G_,gi,H_,q_,mi,M_,U_,je,vi,B_,W_,_i,j_,F_,ki,Y_,V_,Fe,Ei,K_,X_,bi,Z_,Q_,xi,J_,rh,ih,oh,hs,gs,Jf,$_,nh,ms,e1,Za,t1,s1,ch,vs,_s,$f,a1,uh,ks,l1,Qa,r1,i1,fh,Ja,C9=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,dh,Es,bs,ed,o1,ph,Ye,td,n1,c1,sd,u1,f1,ad,d1,hh,xs,ys,ld,p1,gh,Ve,rd,h1,g1,id,m1,v1,od,_1,mh,ws,Ts,nd,k1,vh,$a,cd,E1,b1,_h,el,G9=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,kh,Rs,Ss,ud,x1,Eh,Ke,fd,y1,w1,dd,T1,R1,pd,S1,bh,tl,yi,D1,xh,Ds,As,hd,A1,yh,sl,gd,L1,I1,wh,wi,P1,Th,Xe,al,O1,Ti,z1,N1,C1,md,G1,H1,vd,q1,Rh,ll,Ri,M1,Sh,Ls,Is,_d,U1,Dh,rl,kd,B1,W1,Ah,il,H9=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Lh,Si,j1,Ih,Ze,Ed,F1,Y1,bd,V1,K1,xd,X1,Ph,ol,Di,Z1,Oh,Ps,Os,yd,Q1,zh,zs,J1,wd,$1,ek,Nh,nl,q9=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,Ch,cl,M9=`<code class="language-python"><span class="token comment"># Cosine Annealing Example</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>
    optimizer<span class="token punctuation">,</span>
    T_max<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># Number of iterations per cycle</span>
    eta_min<span class="token operator">=</span><span class="token number">1e-7</span>  <span class="token comment"># Minimum learning rate</span>
<span class="token punctuation">)</span></code>`,Gh,ul,Td,tk,sk,Hh,Qe,Rd,ak,lk,Sd,rk,ik,Dd,ok,qh,Pt,Ai,ge,Li,nk,ck,Ii,uk,fk,Pi,dk,pk,Oi,hk,gk,le,me,zi,mk,vk,Ni,_k,kk,Ci,Ek,bk,Gi,xk,yk,ve,Hi,wk,Tk,qi,Rk,Sk,Mi,Dk,Ak,Ui,Lk,Ik,_e,Bi,Pk,Ok,Wi,zk,Nk,Ns,Ck,Ad,Gk,Hk,qk,Je,Mk,ji,Uk,Bk,Fi,Wk,jk,Fk,ke,Yi,Yk,Vk,Vi,Kk,Xk,Ki,Zk,Qk,Xi,Jk,$k,Ee,Zi,eE,tE,Qi,sE,aE,Ji,lE,rE,$i,iE,Mh,Uh,Bh,Cs,Gs,Ld,oE,Wh,Hs,nE,eo,cE,uE,jh,ue,fE,to,dE,pE,so,hE,gE,ao,mE,vE,lo,_E,Fh,ro,kE,Yh,qs,Ms,Id,EE,Vh,$e,Pd,fl,Od,bE,xE,yE,wE,zd,dl,Nd,TE,RE,SE,DE,Cd,pl,Gd,AE,LE,IE,Kh,hl,Xh,Us,Bs,Hd,PE,Zh,Ws,OE,gl,zE,NE,Qh,et,CE,io,GE,HE,oo,qE,ME,Jh,J,qd,no,UE,co,BE,WE,Md,ml,jE,uo,FE,YE,VE,Ud,V,KE,fo,XE,ZE,po,QE,JE,ho,$E,eb,go,tb,sb,mo,ab,lb,vo,rb,ib,_o,ob,nb,ko,cb,ub,Bd,$,fb,Eo,db,pb,bo,hb,gb,xo,mb,vb,yo,_b,kb,wo,Eb,bb,To,xb,yb,Ro,wb,Tb,Wd,K,Rb,So,Sb,Db,Do,Ab,Lb,Ao,Ib,Pb,Lo,Ob,zb,Io,Nb,Cb,Po,Gb,Hb,Oo,qb,Mb,zo,Ub,Bb,jd,No,Wb,Co,jb,Fb,Fd,js,Yb,Go,Vb,Kb,Ho,Xb,$h,tt,Zb,qo,Qb,Jb,Mo,$b,ex,eg,vl,tg,Fs,Ys,Yd,tx,sg,Uo,sx,ag,be,Bo,_l,ax,lx,rx,Wo,kl,ix,ox,nx,jo,El,cx,ux,fx,Fo,bl,dx,px,lg,Vs,Ks,Vd,hx,rg,Xs,gx,Yo,mx,vx,ig,xl,U9=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,og,st,_x,Vo,kx,Ex,Ko,bx,xx,ng,yl,yx,Xo,wx,cg,Zs,Tx,Zo,Rx,Sx,ug,Qs,Js,Kd,Dx,fg,$s,Ax,wl,Lx,Ix,dg,Tl,ea,Px,Rl,Ox,zx,pg,ta,sa,Xd,Nx,hg,aa,Cx,Qo,Gx,Hx,gg,Sl,B9=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,mg,Jo,qx,vg,Dl,W9='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',_g,at,Mx,$o,Ux,Bx,en,Wx,jx,kg,lt,Fx,tn,Yx,Vx,sn,Kx,Xx,Eg,an,Zx,bg,la,ln,Qx,Zd,Qd,Jx,$x,rn,ey,Jd,$d,ty,xg,on,sy,yg,Al,Ll,u6,wg,ra,ia,ep,ay,Tg,Ot,ly,nn,ry,iy,cn,oy,Rg,zt,un,re,fn,ny,cy,dn,uy,fy,pn,dy,py,hn,hy,gy,gn,my,vy,mn,ie,vn,_y,ky,_n,Ey,by,kn,xy,yy,En,wy,Ty,bn,Ry,Sg,xn,Sy,Dg,Il,j9=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Ag,U,yn,Pl,Dy,wn,Ay,Ly,Iy,Py,Tn,Ol,Oy,Rn,zy,Ny,Cy,Gy,Sn,zl,Hy,Dn,qy,My,Uy,By,An,Nl,Wy,Ln,jy,Fy,Yy,Vy,In,Cl,Ky,Pn,Xy,Zy,Qy,Jy,On,Gl,$y,zn,e3,t3,s3,a3,Nn,Hl,l3,Cn,r3,i3,o3,n3,Gn,ql,c3,Hn,u3,f3,d3,p3,qn,Ml,h3,Mn,g3,m3,v3,_3,Un,Ul,k3,Bn,E3,b3,x3,y3,Wn,Bl,w3,jn,T3,R3,S3,Lg,oa,na,tp,D3,Ig,Fn,A3,Pg,Wl,Og,ca,ua,sp,L3,zg,fa,I3,jl,P3,O3,Ng,da,z3,Yn,N3,C3,Cg,oe,Vn,G3,Gg,H3,ap,q3,M3,rt,U3,Kn,B3,W3,Xn,j3,F3,Zn,Y3,V3,Qn,K3,Jn,X3,Z3,pa,Q3,$n,J3,$3,ec,e4,Hg,it,t4,tc,s4,a4,sc,l4,r4,qg,xe,ha,i4,ac,o4,n4,lc,c4,u4,Fl,f4,rc,d4,p4,h4,lp,g4,m4,rp,v4,Mg,ga,ma,ip,_4,Ug,ye,ic,op,k4,E4,b4,oc,np,x4,y4,w4,nc,cp,T4,R4,S4,cc,up,D4,A4,Bg,uc,L4,Wg,Yl,Vl,f6,jg,va,_a,fp,I4,Fg,fc,P4,Yg,ot,Kl,O4,dc,z4,N4,C4,Xl,G4,pc,H4,q4,M4,dp,U4,Vg,Nt,hc,nt,gc,B4,W4,mc,j4,F4,vc,Y4,V4,we,ct,_c,K4,X4,kc,Z4,Q4,Ec,J4,$4,ut,bc,e0,t0,xc,s0,a0,yc,l0,r0,ft,wc,i0,o0,Tc,n0,c0,Rc,u0,f0,dt,Sc,d0,p0,Dc,h0,g0,Ac,m0,Kg,ka,Ea,pp,v0,Xg,Lc,_0,Zg,Ct,Ic,pt,Pc,k0,E0,Oc,b0,x0,zc,y0,w0,W,ht,Nc,T0,R0,Cc,S0,D0,Gc,A0,L0,gt,Hc,I0,P0,qc,O0,z0,Mc,N0,C0,mt,Uc,G0,H0,Bc,q0,M0,Wc,U0,B0,vt,jc,W0,j0,Fc,F0,Y0,Yc,V0,K0,_t,Vc,X0,Z0,Kc,Q0,J0,Xc,$0,ew,kt,Zc,tw,sw,Qc,aw,lw,Jc,rw,iw,Et,$c,ow,nw,eu,cw,uw,tu,fw,dw,bt,su,pw,hw,au,gw,mw,lu,vw,_w,xt,ru,kw,Ew,iu,bw,xw,ou,yw,ww,yt,nu,Tw,Rw,cu,Sw,Dw,uu,Aw,Qg,ba,xa,hp,Lw,Jg,fu,Iw,$g,du,Pw,em,Zl,Ql,d6,tm,pu,Ow,sm,Gt,ya,gp,zw,am,lm,rm;Ha=new $m({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),hl=new $m({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),vl=new $m({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Wl=new $m({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let Te=O9&&NA();return{c(){p=a("p"),m=o("Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),g=c(),h=a("p"),v=o("I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),k=c(),b=a("h4"),w=a("a"),T=a("span"),x=o("Experiment 1: Anime-Inspired Heroism"),E=c(),y=a("p"),I=a("img"),N=c(),G=a("p"),D=o("I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),A=c(),S=a("ul"),O=a("li"),z=o("My action figure photos (for costume accuracy)."),Q=c(),j=a("li"),F=o("Stylized anime references (for anatomy and texture)."),B=c(),C=a("p"),L=o("The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),H=c(),Z=a("h4"),q=a("a"),R=a("span"),M=o("Experiment 2: Retro Cartoon Resurrection"),Wt=c(),Se=a("p"),fe=a("img"),bp=c(),ar=a("p"),av=o("Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),xp=c(),jt=a("h2"),Ft=a("a"),df=a("span"),lv=o("What are Regularization Images?"),yp=c(),lr=a("p"),rv=o("Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),wp=c(),Ga=a("blockquote"),rr=a("p"),iv=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),Tp=c(),$l(Ha.$$.fragment),Rp=c(),ir=a("p"),ov=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Sp=c(),or=a("p"),nv=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),Dp=c(),nr=a("p"),cv=o("Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),Ap=c(),Dt=a("table"),cr=a("thead"),De=a("tr"),ur=a("th"),uv=o("Aspect"),fv=c(),fr=a("th"),dv=o("Regularization"),pv=c(),dr=a("th"),hv=o("No Regularization"),gv=c(),Ae=a("tbody"),Le=a("tr"),pr=a("td"),pf=a("strong"),mv=o("Class Definition"),vv=c(),hr=a("td"),_v=o("Explicit class anchoring"),kv=c(),gr=a("td"),Ev=o("Implicit class learning"),bv=c(),Ie=a("tr"),mr=a("td"),hf=a("strong"),xv=o("Failure Modes"),yv=c(),vr=a("td"),wv=o("Underfitting if overdone"),Tv=c(),_r=a("td"),Rv=o("Overfitting/drift"),Sv=c(),Pe=a("tr"),kr=a("td"),gf=a("strong"),Dv=o("Data Efficiency"),Av=c(),Er=a("td"),Lv=o("Better generalization"),Iv=c(),br=a("td"),Pv=o("Requires more data"),Lp=c(),xr=a("p"),Ov=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Ip=c(),yr=a("p"),zv=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Pp=c(),qa=a("blockquote"),wr=a("p"),Nv=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Op=c(),Yt=a("h4"),Vt=a("a"),mf=a("span"),Cv=o("Scenario 1: Limited Training Data"),zp=c(),Ma=a("p"),vf=a("strong"),Gv=o("Situation"),Hv=o(": You only have a few images of your cat and no other cat images."),Np=c(),Ua=a("p"),_f=a("strong"),qv=o("Problem"),Mv=o(": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),Cp=c(),Ba=a("p"),kf=a("strong"),Uv=o("Solution"),Bv=o(": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Gp=c(),Kt=a("h4"),Xt=a("a"),Ef=a("span"),Wv=o("Scenario 2: Imbalanced Training Data"),Hp=c(),Wa=a("p"),bf=a("strong"),jv=o("Situation"),Fv=o(": You have many images of other cats but only a few of your cat."),qp=c(),ja=a("p"),xf=a("strong"),Yv=o("Problem"),Vv=o(": The model may focus too much on the other cats, failing to learn the unique features of your cat."),Mp=c(),Fa=a("p"),yf=a("strong"),Kv=o("Solution"),Xv=o(": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Up=c(),Zt=a("h2"),Qt=a("a"),wf=a("span"),Zv=o("Divergence"),Bp=c(),Ya=a("p"),Tf=a("strong"),Qv=o("Divergence"),Jv=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Wp=c(),Oe=a("p"),$v=o("Preventing divergence starts with "),Rf=a("strong"),e2=o("careful dataset curation"),t2=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Sf=a("strong"),s2=o("regularization techniques"),a2=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),jp=c(),ze=a("ul"),Tr=a("li"),Df=a("strong"),l2=o("Chaotic outputs"),r2=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),i2=c(),Rr=a("li"),Af=a("strong"),o2=o("Exploding gradients"),n2=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),c2=c(),Jt=a("li"),Lf=a("strong"),u2=o("Loss value instability (NaN/infinity values)"),f2=o(" The training loss fluctuates wildly, sometimes becoming "),Sr=a("code"),d2=o("NaN"),p2=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Fp=c(),Va=a("blockquote"),Dr=a("p"),h2=o("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),Yp=c(),$t=a("h2"),es=a("a"),If=a("span"),Pf=a("strong"),g2=o("Overfitting"),Vp=c(),Ar=a("p"),m2=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),Kp=c(),Ne=a("ul"),Lr=a("li"),Of=a("strong"),v2=o("Perfectly replicates training samples"),_2=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),k2=c(),Ir=a("li"),zf=a("strong"),E2=o("Fails to generalize to new inputs"),b2=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),x2=c(),Pr=a("li"),Nf=a("strong"),y2=o("Shows excellent training loss but poor validation loss"),w2=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),Xp=c(),ts=a("h3"),ss=a("a"),Cf=a("span"),Gf=a("strong"),T2=o("Key Differences"),Zp=c(),At=a("table"),Or=a("thead"),Ce=a("tr"),zr=a("th"),Hf=a("strong"),R2=o("Aspect"),S2=c(),Nr=a("th"),qf=a("strong"),D2=o("Divergence"),A2=c(),Cr=a("th"),Mf=a("strong"),L2=o("Overfitting"),I2=c(),de=a("tbody"),Ge=a("tr"),Gr=a("td"),Uf=a("strong"),P2=o("Cause"),O2=c(),Hr=a("td"),z2=o("Excessive learning rate"),N2=c(),qr=a("td"),C2=o("Insufficient regularization"),G2=c(),He=a("tr"),Mr=a("td"),Bf=a("strong"),H2=o("Loss Behavior"),q2=c(),Ur=a("td"),M2=o("Sudden spikes/NaN values"),U2=c(),Br=a("td"),B2=o("Steady decrease then rise"),W2=c(),qe=a("tr"),Wr=a("td"),Wf=a("strong"),j2=o("Output Quality"),F2=c(),jr=a("td"),Y2=o("Random noise/artifacts"),V2=c(),Fr=a("td"),K2=o("Overly detailed replicas"),X2=c(),Me=a("tr"),Yr=a("td"),jf=a("strong"),Z2=o("Recovery"),Q2=c(),Vr=a("td"),J2=o("Requires restart"),$2=c(),Kr=a("td"),e_=o("Early stopping works"),Qp=c(),as=a("h3"),ls=a("a"),Ff=a("span"),t_=o("Preventing Divergence"),Jp=c(),Lt=a("table"),Xr=a("thead"),rs=a("tr"),Zr=a("th"),s_=o("Situation"),a_=c(),Qr=a("th"),l_=o("Outcome"),r_=c(),pe=a("tbody"),is=a("tr"),Jr=a("td"),Yf=a("strong"),i_=o("Excessive or inconsistent data"),o_=c(),$r=a("td"),n_=o("Model struggles to learn and produces unreliable predictions."),c_=c(),os=a("tr"),ei=a("td"),Vf=a("strong"),u_=o("Lack of unique and consistent features"),f_=c(),ti=a("td"),d_=o("Poor generalization, leading to inaccurate or meaningless outputs."),p_=c(),ns=a("tr"),si=a("td"),Kf=a("strong"),h_=o("Carefully curated datasets"),g_=c(),ai=a("td"),m_=o("Improved learning by ensuring the model sees only relevant, high-quality data."),v_=c(),cs=a("tr"),li=a("td"),Xf=a("strong"),__=o("Effective use of regularization techniques"),k_=c(),ri=a("td"),E_=o("Helps maintain focus on essential features and prevents instability."),$p=c(),ii=a("p"),b_=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),eh=c(),us=a("h3"),fs=a("a"),Zf=a("span"),x_=o("Implementing these Strategies"),th=c(),Ka=a("pre"),sh=c(),Xa=a("pre"),ah=c(),ds=a("h3"),ps=a("a"),Qf=a("span"),y_=o("Data Considerations"),lh=c(),It=a("table"),oi=a("thead"),Ue=a("tr"),ni=a("th"),w_=o("Situation"),T_=c(),ci=a("th"),R_=o("Actual Risk"),S_=c(),ui=a("th"),D_=o("Solution"),A_=c(),he=a("tbody"),Be=a("tr"),fi=a("td"),L_=o("High LR + small batch size"),I_=c(),di=a("td"),P_=o("Divergence"),O_=c(),pi=a("td"),z_=o("Lower LR, increase batch size"),N_=c(),We=a("tr"),hi=a("td"),C_=o("Inconsistent features"),G_=c(),gi=a("td"),H_=o("Overfitting"),q_=c(),mi=a("td"),M_=o("Improve dataset consistency"),U_=c(),je=a("tr"),vi=a("td"),B_=o("Insufficient reg images"),W_=c(),_i=a("td"),j_=o("Class leakage"),F_=c(),ki=a("td"),Y_=o("Add 100-300 class images"),V_=c(),Fe=a("tr"),Ei=a("td"),K_=o("High variance in training data"),X_=c(),bi=a("td"),Z_=o("Mode collapse"),Q_=c(),xi=a("td"),J_=o("Curate focused dataset"),rh=c(),ih=a("hr"),oh=c(),hs=a("h2"),gs=a("a"),Jf=a("span"),$_=o("Monitoring Tips"),nh=c(),ms=a("p"),e1=o("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Za=a("a"),t1=o("kohya-ss/sd-scripts"),s1=o(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),ch=c(),vs=a("h3"),_s=a("a"),$f=a("span"),a1=o("Track loss curves"),uh=c(),ks=a("p"),l1=o("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Qa=a("a"),r1=o("TensorBoard"),i1=o(" to create these graphs."),fh=c(),Ja=a("pre"),dh=c(),Es=a("h4"),bs=a("a"),ed=a("span"),o1=o("What to Monitor:"),ph=c(),Ye=a("ul"),td=a("li"),n1=o("Training Loss: Should decrease steadily but not too quickly."),c1=c(),sd=a("li"),u1=o("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),f1=c(),ad=a("li"),d1=o("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),hh=c(),xs=a("h4"),ys=a("a"),ld=a("span"),p1=o("Warning Signs:"),gh=c(),Ve=a("ul"),rd=a("li"),h1=o("Sudden spikes in loss \u2192 Likely divergence."),g1=c(),id=a("li"),m1=o("Loss plateauing too early \u2192 Learning rate may be too low."),v1=c(),od=a("li"),_1=o("Validation loss increasing while training loss decreases \u2192 Overfitting."),mh=c(),ws=a("h3"),Ts=a("a"),nd=a("span"),k1=o("Generate validation images every 100 steps"),vh=c(),$a=a("p"),cd=a("strong"),E1=o("Why It Matters"),b1=o(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),_h=c(),el=a("pre"),kh=c(),Rs=a("h4"),Ss=a("a"),ud=a("span"),x1=o("What to Look For:"),Eh=c(),Ke=a("ul"),fd=a("li"),y1=o("Consistency: Outputs should align with the training data style."),w1=c(),dd=a("li"),T1=o("Artifacts: Check for distortions, noise, or unnatural features."),R1=c(),pd=a("li"),S1=o("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),bh=c(),tl=a("blockquote"),yi=a("p"),D1=o("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),xh=c(),Ds=a("h4"),As=a("a"),hd=a("span"),A1=o("Use Gradient Clipping"),yh=c(),sl=a("p"),gd=a("strong"),L1=o("Why It Matters"),I1=o(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),wh=c(),wi=a("p"),P1=o("Key Insights:"),Th=c(),Xe=a("ul"),al=a("li"),O1=o("Gradient Norm "),Ti=a("code"),z1=o("<"),N1=o(" than 0.1: Training may stall due to tiny updates."),C1=c(),md=a("li"),G1=o("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),H1=c(),vd=a("li"),q1=o("Ideal Range: 0.1 to 2.0 for stable training."),Rh=c(),ll=a("blockquote"),Ri=a("p"),M1=o("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Sh=c(),Ls=a("h4"),Is=a("a"),_d=a("span"),U1=o("Enable Mixed Precision Training"),Dh=c(),rl=a("p"),kd=a("strong"),B1=o("Why It Matters"),W1=o(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),Ah=c(),il=a("pre"),Lh=c(),Si=a("p"),j1=o("Benefits:"),Ih=c(),Ze=a("ul"),Ed=a("li"),F1=o("2-3x Faster Training: Leverages GPU tensor cores."),Y1=c(),bd=a("li"),V1=o("50% Less VRAM Usage: Allows larger batch sizes or models."),K1=c(),xd=a("li"),X1=o("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),Ph=c(),ol=a("blockquote"),Di=a("p"),Z1=o("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),Oh=c(),Ps=a("h4"),Os=a("a"),yd=a("span"),Q1=o("Start with Conservative Learning Rates"),zh=c(),zs=a("p"),J1=o("Start off with 1e-5 to 1e-6.  "),wd=a("strong"),$1=o("Why It Matters"),ek=o(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Nh=c(),nl=a("pre"),Ch=c(),cl=a("pre"),Gh=c(),ul=a("p"),Td=a("strong"),tk=o("Warning Signs"),sk=o(":"),Hh=c(),Qe=a("ul"),Rd=a("li"),ak=o("Loss Spikes: Learning rate is too high."),lk=c(),Sd=a("li"),rk=o("Slow Convergence: Learning rate is too low."),ik=c(),Dd=a("li"),ok=o("Oscillating Loss: Poor scheduling or unstable gradients."),qh=c(),Pt=a("table"),Ai=a("thead"),ge=a("tr"),Li=a("th"),nk=o("Practice"),ck=c(),Ii=a("th"),uk=o("Key Benefit"),fk=c(),Pi=a("th"),dk=o("Tool/Setting"),pk=c(),Oi=a("th"),hk=o("Warning Signs"),gk=c(),le=a("tbody"),me=a("tr"),zi=a("td"),mk=o("Track Loss Curves"),vk=c(),Ni=a("td"),_k=o("Detect overfitting/divergence early"),kk=c(),Ci=a("td"),Ek=o("TensorBoard, Weights & Biases"),bk=c(),Gi=a("td"),xk=o("Spikes, plateaus, growing gaps"),yk=c(),ve=a("tr"),Hi=a("td"),wk=o("Generate Validation Images"),Tk=c(),qi=a("td"),Rk=o("Visualize model progress"),Sk=c(),Mi=a("td"),Dk=o("Fixed prompts/seeds"),Ak=c(),Ui=a("td"),Lk=o("Artifacts, mode collapse"),Ik=c(),_e=a("tr"),Bi=a("td"),Pk=o("Gradient Clipping"),Ok=c(),Wi=a("td"),zk=o("Prevent exploding gradients"),Nk=c(),Ns=a("td"),Ck=o("clip"),Ad=a("em"),Gk=o("grad_norm"),Hk=o(" (1.0-2.0)"),qk=c(),Je=a("td"),Mk=o("Norm "),ji=a("code"),Uk=o(">"),Bk=o(" 10.0 or "),Fi=a("code"),Wk=o("<"),jk=o(" 0.1"),Fk=c(),ke=a("tr"),Yi=a("td"),Yk=o("Mixed Precision Training"),Vk=c(),Vi=a("td"),Kk=o("Faster training, lower VRAM usage"),Xk=c(),Ki=a("td"),Zk=o("PyTorch AMP (torch.cuda.amp)"),Qk=c(),Xi=a("td"),Jk=o("NaN values (disable if unstable)"),$k=c(),Ee=a("tr"),Zi=a("td"),eE=o("Conservative Learning Rates"),tE=c(),Qi=a("td"),sE=o("Stable training, avoid divergence"),aE=c(),Ji=a("td"),lE=o("Start at 1e-5 to 1e-6, use scheduler"),rE=c(),$i=a("td"),iE=o("Spikes, slow convergence"),Mh=c(),Uh=a("hr"),Bh=c(),Cs=a("h2"),Gs=a("a"),Ld=a("span"),oE=o("Generating Regularization images"),Wh=c(),Hs=a("p"),nE=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),eo=a("code"),cE=o("1boy"),uE=o(")."),jh=c(),ue=a("p"),fE=o("According to the Dreambooth technique, "),to=a("code"),dE=o("200"),pE=o(" regularization images per training image.  For example, if you have "),so=a("code"),hE=o("16"),gE=o(" images: "),ao=a("code"),mE=o("200 * 16 = 3200"),vE=o(" total regularization images.  When training, the math involved for calculating total steps is: "),lo=a("code"),_E=o("repeats * training images >= repeats * regularization images"),Fh=c(),ro=a("p"),kE=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),Yh=c(),qs=a("h4"),Ms=a("a"),Id=a("span"),EE=o("Important considerations"),Vh=c(),$e=a("ol"),Pd=a("li"),fl=a("p"),Od=a("strong"),bE=o("Use the same base model for regularization images and training"),xE=a("br"),yE=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),wE=c(),zd=a("li"),dl=a("p"),Nd=a("strong"),TE=o("Maintain consistent class representation"),RE=a("br"),SE=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),DE=c(),Cd=a("li"),pl=a("p"),Gd=a("strong"),AE=o("Match output resolution to training data"),LE=a("br"),IE=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Kh=c(),$l(hl.$$.fragment),Xh=c(),Us=a("h4"),Bs=a("a"),Hd=a("span"),PE=o("Generate using Stable Diffusion web UI"),Zh=c(),Ws=a("p"),OE=o("We\u2019re going to use "),gl=a("a"),zE=o("Stable Diffusion web UI"),NE=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Qh=c(),et=a("p"),CE=o("We\u2019re going to use the "),io=a("code"),GE=o("X/Y/Z plot"),HE=o(" script to use "),oo=a("code"),qE=o("Prompt Search & Replace"),ME=o(" to dynamically build a prompt that will generate hundreds of regularization images."),Jh=c(),J=a("ol"),qd=a("li"),no=a("p"),UE=o("Select the text 2 image tab.  Enter a generic prompt "),co=a("code"),BE=o("princeadam, portrait, looking_at_viewer, forest"),WE=c(),Md=a("li"),ml=a("p"),jE=o("In generation parameters and select the "),uo=a("code"),FE=o("X/Y/Z plot"),YE=o(" script."),VE=c(),Ud=a("li"),V=a("p"),KE=o("Select the "),fo=a("code"),XE=o("X"),ZE=o(" parameter and "),po=a("code"),QE=o("Prompt SR"),JE=o(" for Prompt Replace.  We\u2019re going to replace "),ho=a("code"),$E=o("portrait"),eb=o(" with different camera angle tags: "),go=a("code"),tb=o("close-up"),sb=o(", "),mo=a("code"),ab=o("upper_body"),lb=o(", "),vo=a("code"),rb=o("from_below"),ib=o(", "),_o=a("code"),ob=o("from_above"),nb=o(", "),ko=a("code"),cb=o("dutch_angle"),ub=c(),Bd=a("li"),$=a("p"),fb=o("Select the "),Eo=a("code"),db=o("Y"),pb=o(" parameter and "),bo=a("code"),hb=o("Prompt SR"),gb=o(" for Prompt Replace.  Replace "),xo=a("code"),mb=o("looking_at_viewer"),vb=o(": "),yo=a("code"),_b=o("looking_away"),kb=o(", "),wo=a("code"),Eb=o("looking_to_the_side"),bb=o(", "),To=a("code"),xb=o("looking_ahead"),yb=o(", "),Ro=a("code"),wb=o("looking_down"),Tb=c(),Wd=a("li"),K=a("p"),Rb=o("Select the "),So=a("code"),Sb=o("Z"),Db=o(" parameter and "),Do=a("code"),Ab=o("Prompt SR"),Lb=o(" for Prompt Replace. Replace "),Ao=a("code"),Ib=o("forest"),Pb=o(" with a vareity of locatinos: "),Lo=a("code"),Ob=o("castle"),zb=o(", "),Io=a("code"),Nb=o("mountain"),Cb=o(", "),Po=a("code"),Gb=o("cave"),Hb=o(", "),Oo=a("code"),qb=o("farm"),Mb=o(", "),zo=a("code"),Ub=o("ocean"),Bb=c(),jd=a("li"),No=a("p"),Wb=o("Select a fast sampler like "),Co=a("code"),jb=o("DPM2 KARRAS"),Fb=c(),Fd=a("li"),js=a("p"),Yb=o("CFG Scale set to "),Go=a("code"),Vb=o("7"),Kb=o(" and Steps to "),Ho=a("code"),Xb=o("20"),$h=c(),tt=a("p"),Zb=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),qo=a("code"),Qb=o("150"),Jb=o(" - "),Mo=a("code"),$b=o("200"),ex=o(" and keep in mind we can add and remove as we try different training settings with different output."),eg=c(),$l(vl.$$.fragment),tg=c(),Fs=a("h4"),Ys=a("a"),Yd=a("span"),tx=o("Download images"),sg=c(),Uo=a("p"),sx=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),ag=c(),be=a("ul"),Bo=a("li"),_l=a("a"),ax=o("3ee Games regularization images"),lx=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),rx=c(),Wo=a("li"),kl=a("a"),ix=o("Pre-Rendered Regularization Images"),ox=o(": Includes 1500 regularization images."),nx=c(),jo=a("li"),El=a("a"),cx=o("Stable Diffusion 1.5 Regularization Images"),ux=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),fx=c(),Fo=a("li"),bl=a("a"),dx=o("Aitrepreneur SDXL image set"),px=o(": a large image set generated with Stable Diffusion SDXL."),lg=c(),Vs=a("h4"),Ks=a("a"),Vd=a("span"),hx=o("Captioning Regularization images"),rg=c(),Xs=a("p"),gx=o("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Yo=a("code"),mx=o("txt"),vx=o(" files with a shell script:"),ig=c(),xl=a("pre"),og=c(),st=a("p"),_x=o("Save this file as "),Vo=a("code"),kx=o("filename2txt.bat"),Ex=o(" and place it into the regularization images directory and run: "),Ko=a("code"),bx=o(".\\filename2txt.bat"),xx=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),ng=c(),yl=a("p"),yx=o("Example filename: "),Xo=a("code"),wx=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),cg=c(),Zs=a("p"),Tx=o("Output: "),Zo=a("code"),Rx=o("aburbres,princeadam,1boy,close-up,purple_vest"),Sx=o(" saved in a text file with the same name as image."),ug=c(),Qs=a("h2"),Js=a("a"),Kd=a("span"),Dx=o("Training a LoRA"),fg=c(),$s=a("p"),Ax=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),wl=a("a"),Lx=o("kohya-ss/sd-scripts"),Ix=o("."),dg=c(),Tl=a("blockquote"),ea=a("p"),Px=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Rl=a("a"),Ox=o("Kohya SD script documentation"),zx=o("."),pg=c(),ta=a("h3"),sa=a("a"),Xd=a("span"),Nx=o("Directory setup"),hg=c(),aa=a("p"),Cx=o("In your configuration json, use "),Qo=a("code"),Gx=o("reg_data_dir"),Hx=o(" to point to the directory with your regularization images:"),gg=c(),Sl=a("pre"),mg=c(),Jo=a("p"),qx=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),vg=c(),Dl=a("pre"),_g=c(),at=a("p"),Mx=o("Set the "),$o=a("code"),Ux=o("number of iterations"),Bx=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),en=a("code"),Wx=o("training images \xD7 iterations"),jx=o(". If there are more regularization images than this, the extras won\u2019t be used."),kg=c(),lt=a("p"),Fx=o("Create folders in the training image folder with the format "),tn=a("code"),Yx=o("<repetition count>_<class>"),Vx=o(" multiple times, and similarly create folders in the regularization image folder with the format "),sn=a("code"),Kx=o("<repetition count>_<class>"),Xx=o("."),Eg=c(),an=a("p"),Zx=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),bg=c(),la=a("ul"),ln=a("li"),Qx=o("train_data_dir"),Zd=a("ul"),Qd=a("li"),Jx=o("10_princeadam"),$x=c(),rn=a("li"),ey=o("reg_dir"),Jd=a("ul"),$d=a("li"),ty=o("1_1boy"),xg=c(),on=a("p"),sy=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),yg=c(),Al=a("p"),Ll=a("img"),wg=c(),ra=a("h3"),ia=a("a"),ep=a("span"),ay=o("Training Settings"),Tg=c(),Ot=a("p"),ly=o("The training setup we\u2019re going to use is:  "),nn=a("code"),ry=o("Number of images * repeats * epoch / batch size = total steps"),iy=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),cn=a("code"),oy=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Rg=c(),zt=a("table"),un=a("thead"),re=a("tr"),fn=a("th"),ny=o("Number of Images"),cy=c(),dn=a("th"),uy=o("Repeats"),fy=c(),pn=a("th"),dy=o("Epochs"),py=c(),hn=a("th"),hy=o("Batch Size"),gy=c(),gn=a("th"),my=o("Total Steps"),vy=c(),mn=a("tbody"),ie=a("tr"),vn=a("td"),_y=o("45"),ky=c(),_n=a("td"),Ey=o("10"),by=c(),kn=a("td"),xy=o("20"),yy=c(),En=a("td"),wy=o("2"),Ty=c(),bn=a("td"),Ry=o("4500"),Sg=c(),xn=a("p"),Sy=o("Now let\u2019s focus on these training settings:"),Dg=c(),Il=a("pre"),Ag=c(),U=a("ul"),yn=a("li"),Pl=a("strong"),Dy=o("Learning Rate ("),wn=a("code"),Ay=o("learning_rate"),Ly=o(")"),Iy=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Py=c(),Tn=a("li"),Ol=a("strong"),Oy=o("Text Encoder Learning Rate ("),Rn=a("code"),zy=o("text_encoder_lr"),Ny=o(")"),Cy=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Gy=c(),Sn=a("li"),zl=a("strong"),Hy=o("UNet Learning Rate ("),Dn=a("code"),qy=o("unet_lr"),My=o(")"),Uy=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),By=c(),An=a("li"),Nl=a("strong"),Wy=o("Learning Rate Scheduler ("),Ln=a("code"),jy=o("lr_scheduler"),Fy=o(")"),Yy=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Vy=c(),In=a("li"),Cl=a("strong"),Ky=o("Number of Cycles in Learning Rate Scheduler ("),Pn=a("code"),Xy=o("lr_scheduler_num_cycles"),Zy=o(")"),Qy=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Jy=c(),On=a("li"),Gl=a("strong"),$y=o("Network Dimension ("),zn=a("code"),e3=o("network_dim"),t3=o(")"),s3=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),a3=c(),Nn=a("li"),Hl=a("strong"),l3=o("Network Alpha ("),Cn=a("code"),r3=o("network_alpha"),i3=o(")"),o3=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),n3=c(),Gn=a("li"),ql=a("strong"),c3=o("Clip Skip ("),Hn=a("code"),u3=o("clip_skip"),f3=o(")"),d3=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),p3=c(),qn=a("li"),Ml=a("strong"),h3=o("Max Token Length ("),Mn=a("code"),g3=o("max_token_length"),m3=o(")"),v3=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),_3=c(),Un=a("li"),Ul=a("strong"),k3=o("Noise Offset ("),Bn=a("code"),E3=o("noise_offset"),b3=o(")"),x3=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),y3=c(),Wn=a("li"),Bl=a("strong"),w3=o("Regularization Data Directory ("),jn=a("code"),T3=o("reg_data_dir"),R3=o(")"),S3=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Lg=c(),oa=a("h3"),na=a("a"),tp=a("span"),D3=o("Fine Tuning"),Ig=c(),Fn=a("p"),A3=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),Pg=c(),$l(Wl.$$.fragment),Og=c(),ca=a("h4"),ua=a("a"),sp=a("span"),L3=o("Workflow with Auto1111 WebUI"),zg=c(),fa=a("p"),I3=o("We\u2019re going to use "),jl=a("a"),P3=o("Stable Diffusion web UI"),O3=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Ng=c(),da=a("p"),z3=o("We\u2019re going to use the "),Yn=a("code"),N3=o("X/Y/Z plot"),C3=o(" script to compare different epochs."),Cg=c(),oe=a("ul"),Vn=a("li"),G3=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),Gg=a("princeadam0001:0.7"),H3=c(),ap=a("li"),q3=o("In generation parameters and select the X/Y/Z plot script."),M3=c(),rt=a("li"),U3=o("Select "),Kn=a("code"),B3=o("Prompt SR"),W3=o(" for Prompt Replace.  We\u2019re going to replace "),Xn=a("code"),j3=o("<princeadam0001:0.7>"),F3=o(" with different epoch: "),Zn=a("code"),Y3=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),V3=c(),Qn=a("li"),K3=o("Select a fast sampler like "),Jn=a("code"),X3=o("DPM2 KARRAS"),Z3=c(),pa=a("li"),Q3=o("CFG Scale set to "),$n=a("code"),J3=o("7"),$3=o(" and Steps to "),ec=a("code"),e4=o("20"),Hg=c(),it=a("p"),t4=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),tc=a("code"),s4=o("network_dim"),a4=o(" and "),sc=a("code"),l4=o("network_alpha"),r4=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),qg=c(),xe=a("ul"),ha=a("li"),i4=o("Select "),ac=a("code"),o4=o("Prompt SR"),n4=o(" for Prompt Replace.  We\u2019re going to replace the weights "),lc=a("code"),c4=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),u4=c(),Fl=a("li"),f4=o("Use Prompt SR to generate a variety of angles: Select "),rc=a("code"),d4=o("Prompt SR"),p4=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),h4=c(),lp=a("li"),g4=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),m4=c(),rp=a("li"),v4=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),Mg=c(),ga=a("h4"),ma=a("a"),ip=a("span"),_4=o("Issues to look for"),Ug=c(),ye=a("ul"),ic=a("li"),op=a("strong"),k4=o("Undercooked:"),E4=o(" Lacks output, adjust unet learning rate or extend training duration."),b4=c(),oc=a("li"),np=a("strong"),x4=o("Overcooked:"),y4=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),w4=c(),nc=a("li"),cp=a("strong"),T4=o("Overfit:"),R4=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),S4=c(),cc=a("li"),up=a("strong"),D4=o("Mismatched:"),A4=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Bg=c(),uc=a("p"),L4=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),Wg=c(),Yl=a("p"),Vl=a("img"),jg=c(),va=a("h2"),_a=a("a"),fp=a("span"),I4=o("Troubleshooting"),Fg=c(),fc=a("p"),P4=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),Yg=c(),ot=a("ul"),Kl=a("li"),O4=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),dc=a("code"),z4=o("200"),N4=o(" regularization images per training image."),C4=c(),Xl=a("li"),G4=o("Repeats of regularization images, but may overfit more.  Increasing the "),pc=a("code"),H4=o("repetition_count"),q4=o(" will cycle through the images more but the results may have results that overfit the model."),M4=c(),dp=a("li"),U4=o("Create more regularization images without increasing repeats will help with the overfitting."),Vg=c(),Nt=a("table"),hc=a("thead"),nt=a("tr"),gc=a("th"),B4=o("Issue"),W4=c(),mc=a("th"),j4=o("Situation"),F4=c(),vc=a("th"),Y4=o("Recommendation"),V4=c(),we=a("tbody"),ct=a("tr"),_c=a("td"),K4=o("Varying quality"),X4=c(),kc=a("td"),Z4=o("Results differ from expectations"),Q4=c(),Ec=a("td"),J4=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),$4=c(),ut=a("tr"),bc=a("td"),e0=o("Inadequate regularization for input data"),t0=c(),xc=a("td"),s0=o("Lower input images, less regularization needed"),a0=c(),yc=a("td"),l0=o("Reduce the number of input images or increasing the quantity of reg images."),r0=c(),ft=a("tr"),wc=a("td"),i0=o("Overfitting due to repetition"),o0=c(),Tc=a("td"),n0=o("Repeats of reg images, risk of overfitting"),c0=c(),Rc=a("td"),u0=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),f0=c(),dt=a("tr"),Sc=a("td"),d0=o("Mitigate overfitting while increasing diversity"),p0=c(),Dc=a("td"),h0=o("Create more reg images without repeats"),g0=c(),Ac=a("td"),m0=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),Kg=c(),ka=a("h4"),Ea=a("a"),pp=a("span"),v0=o("More Solutions"),Xg=c(),Lc=a("p"),_0=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),Zg=c(),Ct=a("table"),Ic=a("thead"),pt=a("tr"),Pc=a("th"),k0=o("Symptom"),E0=c(),Oc=a("th"),b0=o("Likely Cause"),x0=c(),zc=a("th"),y0=o("Solution"),w0=c(),W=a("tbody"),ht=a("tr"),Nc=a("td"),T0=o("Plastic texture persists"),R0=c(),Cc=a("td"),S0=o("Insufficient human reg images"),D0=c(),Gc=a("td"),A0=o("Add real photos to reg set"),L0=c(),gt=a("tr"),Hc=a("td"),I0=o("Loss plateaus early"),P0=c(),qc=a("td"),O0=o("Learning rate too low"),z0=c(),Mc=a("td"),N0=o("Increase LR by 10x"),C0=c(),mt=a("tr"),Uc=a("td"),G0=o("Features blurry"),H0=c(),Bc=a("td"),q0=o("Network dimension too small"),M0=c(),Wc=a("td"),U0=o("Increase network_dim to 64+"),B0=c(),vt=a("tr"),jc=a("td"),W0=o("Color distortion"),j0=c(),Fc=a("td"),F0=o("Noise offset conflict"),Y0=c(),Yc=a("td"),V0=o("Try noise_offset 0.05-0.1"),K0=c(),_t=a("tr"),Vc=a("td"),X0=o("Overly stylized outputs"),Z0=c(),Kc=a("td"),Q0=o("Reg image style mismatch"),J0=c(),Xc=a("td"),$0=o("Regenerate reg images with base model"),ew=c(),kt=a("tr"),Zc=a("td"),tw=o("Training instability"),sw=c(),Qc=a("td"),aw=o("Batch size too large"),lw=c(),Jc=a("td"),rw=o("Reduce batch_size to 1-2"),iw=c(),Et=a("tr"),$c=a("td"),ow=o("Slow convergence"),nw=c(),eu=a("td"),cw=o("Network_alpha too high"),uw=c(),tu=a("td"),fw=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),dw=c(),bt=a("tr"),su=a("td"),pw=o("Loss divergence"),hw=c(),au=a("td"),gw=o("Text encoder LR too high"),mw=c(),lu=a("td"),vw=o("Reduce text_encoder_lr by 10x"),_w=c(),xt=a("tr"),ru=a("td"),kw=o("Poor prompt adherence"),Ew=c(),iu=a("td"),bw=o("Clip skip too high"),xw=c(),ou=a("td"),yw=o("Reduce clip_skip to 1-2"),ww=c(),yt=a("tr"),nu=a("td"),Tw=o("Memory errors"),Rw=c(),cu=a("td"),Sw=o("Resolution too high"),Dw=c(),uu=a("td"),Aw=o("Reduce to 512-768px, enable gradient checkpointing"),Qg=c(),ba=a("h2"),xa=a("a"),hp=a("span"),Lw=o("Results"),Jg=c(),fu=a("p"),Iw=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),$g=c(),du=a("p"),Pw=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),em=c(),Zl=a("p"),Ql=a("img"),tm=c(),pu=a("p"),Ow=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),sm=c(),Gt=a("h2"),ya=a("a"),gp=a("span"),zw=o("spacelab"),am=c(),Te&&Te.c(),lm=uf(),this.h()},l(s){p=l(s,"P",{});var d=r(p);m=n(d,"Growing up in the \u201880s, I loved vintage action figures\u2014their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),d.forEach(t),g=u(s),h=l(s,"P",{});var p6=r(h);v=n(p6,"I wanted to go further\u2014to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),p6.forEach(t),k=u(s),b=l(s,"H4",{id:!0});var Nw=r(b);w=l(Nw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var h6=r(w);T=l(h6,"SPAN",{class:!0}),r(T).forEach(t),h6.forEach(t),x=n(Nw,"Experiment 1: Anime-Inspired Heroism"),Nw.forEach(t),E=u(s),y=l(s,"P",{class:!0});var g6=r(y);I=l(g6,"IMG",{src:!0,alt:!0,class:!0}),g6.forEach(t),N=u(s),G=l(s,"P",{});var m6=r(G);D=n(m6,"I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),m6.forEach(t),A=u(s),S=l(s,"UL",{});var im=r(S);O=l(im,"LI",{});var v6=r(O);z=n(v6,"My action figure photos (for costume accuracy)."),v6.forEach(t),Q=u(im),j=l(im,"LI",{});var _6=r(j);F=n(_6,"Stylized anime references (for anatomy and texture)."),_6.forEach(t),im.forEach(t),B=u(s),C=l(s,"P",{});var k6=r(C);L=n(k6,"The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting\u2014bridging the gap between toy and anime hero."),k6.forEach(t),H=u(s),Z=l(s,"H4",{id:!0});var Cw=r(Z);q=l(Cw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var E6=r(q);R=l(E6,"SPAN",{class:!0}),r(R).forEach(t),E6.forEach(t),M=n(Cw,"Experiment 2: Retro Cartoon Resurrection"),Cw.forEach(t),Wt=u(s),Se=l(s,"P",{class:!0});var b6=r(Se);fe=l(b6,"IMG",{src:!0,alt:!0,class:!0}),b6.forEach(t),bp=u(s),ar=l(s,"P",{});var x6=r(ar);av=n(x6,"Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),x6.forEach(t),xp=u(s),jt=l(s,"H2",{id:!0});var Gw=r(jt);Ft=l(Gw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var y6=r(Ft);df=l(y6,"SPAN",{class:!0}),r(df).forEach(t),y6.forEach(t),lv=n(Gw,"What are Regularization Images?"),Gw.forEach(t),yp=u(s),lr=l(s,"P",{});var w6=r(lr);rv=n(w6,"Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),w6.forEach(t),wp=u(s),Ga=l(s,"BLOCKQUOTE",{class:!0});var T6=r(Ga);rr=l(T6,"P",{class:!0});var R6=r(rr);iv=n(R6,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),R6.forEach(t),T6.forEach(t),Tp=u(s),er(Ha.$$.fragment,s),Rp=u(s),ir=l(s,"P",{});var S6=r(ir);ov=n(S6,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),S6.forEach(t),Sp=u(s),or=l(s,"P",{});var D6=r(or);nv=n(D6,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),D6.forEach(t),Dp=u(s),nr=l(s,"P",{});var A6=r(nr);cv=n(A6,"Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),A6.forEach(t),Ap=u(s),Dt=l(s,"TABLE",{class:!0});var om=r(Dt);cr=l(om,"THEAD",{class:!0});var L6=r(cr);De=l(L6,"TR",{class:!0});var hu=r(De);ur=l(hu,"TH",{class:!0});var I6=r(ur);uv=n(I6,"Aspect"),I6.forEach(t),fv=u(hu),fr=l(hu,"TH",{class:!0});var P6=r(fr);dv=n(P6,"Regularization"),P6.forEach(t),pv=u(hu),dr=l(hu,"TH",{class:!0});var O6=r(dr);hv=n(O6,"No Regularization"),O6.forEach(t),hu.forEach(t),L6.forEach(t),gv=u(om),Ae=l(om,"TBODY",{class:!0});var gu=r(Ae);Le=l(gu,"TR",{class:!0});var mu=r(Le);pr=l(mu,"TD",{class:!0});var z6=r(pr);pf=l(z6,"STRONG",{});var N6=r(pf);mv=n(N6,"Class Definition"),N6.forEach(t),z6.forEach(t),vv=u(mu),hr=l(mu,"TD",{class:!0});var C6=r(hr);_v=n(C6,"Explicit class anchoring"),C6.forEach(t),kv=u(mu),gr=l(mu,"TD",{class:!0});var G6=r(gr);Ev=n(G6,"Implicit class learning"),G6.forEach(t),mu.forEach(t),bv=u(gu),Ie=l(gu,"TR",{class:!0});var vu=r(Ie);mr=l(vu,"TD",{class:!0});var H6=r(mr);hf=l(H6,"STRONG",{});var q6=r(hf);xv=n(q6,"Failure Modes"),q6.forEach(t),H6.forEach(t),yv=u(vu),vr=l(vu,"TD",{class:!0});var M6=r(vr);wv=n(M6,"Underfitting if overdone"),M6.forEach(t),Tv=u(vu),_r=l(vu,"TD",{class:!0});var U6=r(_r);Rv=n(U6,"Overfitting/drift"),U6.forEach(t),vu.forEach(t),Sv=u(gu),Pe=l(gu,"TR",{class:!0});var _u=r(Pe);kr=l(_u,"TD",{class:!0});var B6=r(kr);gf=l(B6,"STRONG",{});var W6=r(gf);Dv=n(W6,"Data Efficiency"),W6.forEach(t),B6.forEach(t),Av=u(_u),Er=l(_u,"TD",{class:!0});var j6=r(Er);Lv=n(j6,"Better generalization"),j6.forEach(t),Iv=u(_u),br=l(_u,"TD",{class:!0});var F6=r(br);Pv=n(F6,"Requires more data"),F6.forEach(t),_u.forEach(t),gu.forEach(t),om.forEach(t),Lp=u(s),xr=l(s,"P",{});var Y6=r(xr);Ov=n(Y6,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Y6.forEach(t),Ip=u(s),yr=l(s,"P",{});var V6=r(yr);zv=n(V6,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),V6.forEach(t),Pp=u(s),qa=l(s,"BLOCKQUOTE",{class:!0});var K6=r(qa);wr=l(K6,"P",{class:!0});var X6=r(wr);Nv=n(X6,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),X6.forEach(t),K6.forEach(t),Op=u(s),Yt=l(s,"H4",{id:!0});var Hw=r(Yt);Vt=l(Hw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Z6=r(Vt);mf=l(Z6,"SPAN",{class:!0}),r(mf).forEach(t),Z6.forEach(t),Cv=n(Hw,"Scenario 1: Limited Training Data"),Hw.forEach(t),zp=u(s),Ma=l(s,"P",{});var qw=r(Ma);vf=l(qw,"STRONG",{});var Q6=r(vf);Gv=n(Q6,"Situation"),Q6.forEach(t),Hv=n(qw,": You only have a few images of your cat and no other cat images."),qw.forEach(t),Np=u(s),Ua=l(s,"P",{});var Mw=r(Ua);_f=l(Mw,"STRONG",{});var J6=r(_f);qv=n(J6,"Problem"),J6.forEach(t),Mv=n(Mw,": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),Mw.forEach(t),Cp=u(s),Ba=l(s,"P",{});var Uw=r(Ba);kf=l(Uw,"STRONG",{});var $6=r(kf);Uv=n($6,"Solution"),$6.forEach(t),Bv=n(Uw,": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Uw.forEach(t),Gp=u(s),Kt=l(s,"H4",{id:!0});var Bw=r(Kt);Xt=l(Bw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var e7=r(Xt);Ef=l(e7,"SPAN",{class:!0}),r(Ef).forEach(t),e7.forEach(t),Wv=n(Bw,"Scenario 2: Imbalanced Training Data"),Bw.forEach(t),Hp=u(s),Wa=l(s,"P",{});var Ww=r(Wa);bf=l(Ww,"STRONG",{});var t7=r(bf);jv=n(t7,"Situation"),t7.forEach(t),Fv=n(Ww,": You have many images of other cats but only a few of your cat."),Ww.forEach(t),qp=u(s),ja=l(s,"P",{});var jw=r(ja);xf=l(jw,"STRONG",{});var s7=r(xf);Yv=n(s7,"Problem"),s7.forEach(t),Vv=n(jw,": The model may focus too much on the other cats, failing to learn the unique features of your cat."),jw.forEach(t),Mp=u(s),Fa=l(s,"P",{});var Fw=r(Fa);yf=l(Fw,"STRONG",{});var a7=r(yf);Kv=n(a7,"Solution"),a7.forEach(t),Xv=n(Fw,": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Fw.forEach(t),Up=u(s),Zt=l(s,"H2",{id:!0});var Yw=r(Zt);Qt=l(Yw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var l7=r(Qt);wf=l(l7,"SPAN",{class:!0}),r(wf).forEach(t),l7.forEach(t),Zv=n(Yw,"Divergence"),Yw.forEach(t),Bp=u(s),Ya=l(s,"P",{});var Vw=r(Ya);Tf=l(Vw,"STRONG",{});var r7=r(Tf);Qv=n(r7,"Divergence"),r7.forEach(t),Jv=n(Vw," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Vw.forEach(t),Wp=u(s),Oe=l(s,"P",{});var ku=r(Oe);$v=n(ku,"Preventing divergence starts with "),Rf=l(ku,"STRONG",{});var i7=r(Rf);e2=n(i7,"careful dataset curation"),i7.forEach(t),t2=n(ku,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),Sf=l(ku,"STRONG",{});var o7=r(Sf);s2=n(o7,"regularization techniques"),o7.forEach(t),a2=n(ku," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),ku.forEach(t),jp=u(s),ze=l(s,"UL",{});var Eu=r(ze);Tr=l(Eu,"LI",{});var Kw=r(Tr);Df=l(Kw,"STRONG",{});var n7=r(Df);l2=n(n7,"Chaotic outputs"),n7.forEach(t),r2=n(Kw," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),Kw.forEach(t),i2=u(Eu),Rr=l(Eu,"LI",{});var Xw=r(Rr);Af=l(Xw,"STRONG",{});var c7=r(Af);o2=n(c7,"Exploding gradients"),c7.forEach(t),n2=n(Xw," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),Xw.forEach(t),c2=u(Eu),Jt=l(Eu,"LI",{});var mp=r(Jt);Lf=l(mp,"STRONG",{});var u7=r(Lf);u2=n(u7,"Loss value instability (NaN/infinity values)"),u7.forEach(t),f2=n(mp," The training loss fluctuates wildly, sometimes becoming "),Sr=l(mp,"CODE",{class:!0});var f7=r(Sr);d2=n(f7,"NaN"),f7.forEach(t),p2=n(mp," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),mp.forEach(t),Eu.forEach(t),Fp=u(s),Va=l(s,"BLOCKQUOTE",{class:!0});var d7=r(Va);Dr=l(d7,"P",{class:!0});var p7=r(Dr);h2=n(p7,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),p7.forEach(t),d7.forEach(t),Yp=u(s),$t=l(s,"H2",{id:!0});var Zw=r($t);es=l(Zw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var h7=r(es);If=l(h7,"SPAN",{class:!0}),r(If).forEach(t),h7.forEach(t),Pf=l(Zw,"STRONG",{});var g7=r(Pf);g2=n(g7,"Overfitting"),g7.forEach(t),Zw.forEach(t),Vp=u(s),Ar=l(s,"P",{});var m7=r(Ar);m2=n(m7,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),m7.forEach(t),Kp=u(s),Ne=l(s,"UL",{});var bu=r(Ne);Lr=l(bu,"LI",{});var Qw=r(Lr);Of=l(Qw,"STRONG",{});var v7=r(Of);v2=n(v7,"Perfectly replicates training samples"),v7.forEach(t),_2=n(Qw," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),Qw.forEach(t),k2=u(bu),Ir=l(bu,"LI",{});var Jw=r(Ir);zf=l(Jw,"STRONG",{});var _7=r(zf);E2=n(_7,"Fails to generalize to new inputs"),_7.forEach(t),b2=n(Jw," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Jw.forEach(t),x2=u(bu),Pr=l(bu,"LI",{});var $w=r(Pr);Nf=l($w,"STRONG",{});var k7=r(Nf);y2=n(k7,"Shows excellent training loss but poor validation loss"),k7.forEach(t),w2=n($w," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),$w.forEach(t),bu.forEach(t),Xp=u(s),ts=l(s,"H3",{id:!0});var e5=r(ts);ss=l(e5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var E7=r(ss);Cf=l(E7,"SPAN",{class:!0}),r(Cf).forEach(t),E7.forEach(t),Gf=l(e5,"STRONG",{});var b7=r(Gf);T2=n(b7,"Key Differences"),b7.forEach(t),e5.forEach(t),Zp=u(s),At=l(s,"TABLE",{class:!0});var nm=r(At);Or=l(nm,"THEAD",{class:!0});var x7=r(Or);Ce=l(x7,"TR",{class:!0});var xu=r(Ce);zr=l(xu,"TH",{class:!0});var y7=r(zr);Hf=l(y7,"STRONG",{});var w7=r(Hf);R2=n(w7,"Aspect"),w7.forEach(t),y7.forEach(t),S2=u(xu),Nr=l(xu,"TH",{class:!0});var T7=r(Nr);qf=l(T7,"STRONG",{});var R7=r(qf);D2=n(R7,"Divergence"),R7.forEach(t),T7.forEach(t),A2=u(xu),Cr=l(xu,"TH",{class:!0});var S7=r(Cr);Mf=l(S7,"STRONG",{});var D7=r(Mf);L2=n(D7,"Overfitting"),D7.forEach(t),S7.forEach(t),xu.forEach(t),x7.forEach(t),I2=u(nm),de=l(nm,"TBODY",{class:!0});var wa=r(de);Ge=l(wa,"TR",{class:!0});var yu=r(Ge);Gr=l(yu,"TD",{class:!0});var A7=r(Gr);Uf=l(A7,"STRONG",{});var L7=r(Uf);P2=n(L7,"Cause"),L7.forEach(t),A7.forEach(t),O2=u(yu),Hr=l(yu,"TD",{class:!0});var I7=r(Hr);z2=n(I7,"Excessive learning rate"),I7.forEach(t),N2=u(yu),qr=l(yu,"TD",{class:!0});var P7=r(qr);C2=n(P7,"Insufficient regularization"),P7.forEach(t),yu.forEach(t),G2=u(wa),He=l(wa,"TR",{class:!0});var wu=r(He);Mr=l(wu,"TD",{class:!0});var O7=r(Mr);Bf=l(O7,"STRONG",{});var z7=r(Bf);H2=n(z7,"Loss Behavior"),z7.forEach(t),O7.forEach(t),q2=u(wu),Ur=l(wu,"TD",{class:!0});var N7=r(Ur);M2=n(N7,"Sudden spikes/NaN values"),N7.forEach(t),U2=u(wu),Br=l(wu,"TD",{class:!0});var C7=r(Br);B2=n(C7,"Steady decrease then rise"),C7.forEach(t),wu.forEach(t),W2=u(wa),qe=l(wa,"TR",{class:!0});var Tu=r(qe);Wr=l(Tu,"TD",{class:!0});var G7=r(Wr);Wf=l(G7,"STRONG",{});var H7=r(Wf);j2=n(H7,"Output Quality"),H7.forEach(t),G7.forEach(t),F2=u(Tu),jr=l(Tu,"TD",{class:!0});var q7=r(jr);Y2=n(q7,"Random noise/artifacts"),q7.forEach(t),V2=u(Tu),Fr=l(Tu,"TD",{class:!0});var M7=r(Fr);K2=n(M7,"Overly detailed replicas"),M7.forEach(t),Tu.forEach(t),X2=u(wa),Me=l(wa,"TR",{class:!0});var Ru=r(Me);Yr=l(Ru,"TD",{class:!0});var U7=r(Yr);jf=l(U7,"STRONG",{});var B7=r(jf);Z2=n(B7,"Recovery"),B7.forEach(t),U7.forEach(t),Q2=u(Ru),Vr=l(Ru,"TD",{class:!0});var W7=r(Vr);J2=n(W7,"Requires restart"),W7.forEach(t),$2=u(Ru),Kr=l(Ru,"TD",{class:!0});var j7=r(Kr);e_=n(j7,"Early stopping works"),j7.forEach(t),Ru.forEach(t),wa.forEach(t),nm.forEach(t),Qp=u(s),as=l(s,"H3",{id:!0});var t5=r(as);ls=l(t5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var F7=r(ls);Ff=l(F7,"SPAN",{class:!0}),r(Ff).forEach(t),F7.forEach(t),t_=n(t5,"Preventing Divergence"),t5.forEach(t),Jp=u(s),Lt=l(s,"TABLE",{class:!0});var cm=r(Lt);Xr=l(cm,"THEAD",{class:!0});var Y7=r(Xr);rs=l(Y7,"TR",{class:!0});var um=r(rs);Zr=l(um,"TH",{class:!0});var V7=r(Zr);s_=n(V7,"Situation"),V7.forEach(t),a_=u(um),Qr=l(um,"TH",{class:!0});var K7=r(Qr);l_=n(K7,"Outcome"),K7.forEach(t),um.forEach(t),Y7.forEach(t),r_=u(cm),pe=l(cm,"TBODY",{class:!0});var Ta=r(pe);is=l(Ta,"TR",{class:!0});var fm=r(is);Jr=l(fm,"TD",{class:!0});var X7=r(Jr);Yf=l(X7,"STRONG",{});var Z7=r(Yf);i_=n(Z7,"Excessive or inconsistent data"),Z7.forEach(t),X7.forEach(t),o_=u(fm),$r=l(fm,"TD",{class:!0});var Q7=r($r);n_=n(Q7,"Model struggles to learn and produces unreliable predictions."),Q7.forEach(t),fm.forEach(t),c_=u(Ta),os=l(Ta,"TR",{class:!0});var dm=r(os);ei=l(dm,"TD",{class:!0});var J7=r(ei);Vf=l(J7,"STRONG",{});var $7=r(Vf);u_=n($7,"Lack of unique and consistent features"),$7.forEach(t),J7.forEach(t),f_=u(dm),ti=l(dm,"TD",{class:!0});var eT=r(ti);d_=n(eT,"Poor generalization, leading to inaccurate or meaningless outputs."),eT.forEach(t),dm.forEach(t),p_=u(Ta),ns=l(Ta,"TR",{class:!0});var pm=r(ns);si=l(pm,"TD",{class:!0});var tT=r(si);Kf=l(tT,"STRONG",{});var sT=r(Kf);h_=n(sT,"Carefully curated datasets"),sT.forEach(t),tT.forEach(t),g_=u(pm),ai=l(pm,"TD",{class:!0});var aT=r(ai);m_=n(aT,"Improved learning by ensuring the model sees only relevant, high-quality data."),aT.forEach(t),pm.forEach(t),v_=u(Ta),cs=l(Ta,"TR",{class:!0});var hm=r(cs);li=l(hm,"TD",{class:!0});var lT=r(li);Xf=l(lT,"STRONG",{});var rT=r(Xf);__=n(rT,"Effective use of regularization techniques"),rT.forEach(t),lT.forEach(t),k_=u(hm),ri=l(hm,"TD",{class:!0});var iT=r(ri);E_=n(iT,"Helps maintain focus on essential features and prevents instability."),iT.forEach(t),hm.forEach(t),Ta.forEach(t),cm.forEach(t),$p=u(s),ii=l(s,"P",{});var oT=r(ii);b_=n(oT,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),oT.forEach(t),eh=u(s),us=l(s,"H3",{id:!0});var s5=r(us);fs=l(s5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var nT=r(fs);Zf=l(nT,"SPAN",{class:!0}),r(Zf).forEach(t),nT.forEach(t),x_=n(s5,"Implementing these Strategies"),s5.forEach(t),th=u(s),Ka=l(s,"PRE",{class:!0});var F9=r(Ka);F9.forEach(t),sh=u(s),Xa=l(s,"PRE",{class:!0});var Y9=r(Xa);Y9.forEach(t),ah=u(s),ds=l(s,"H3",{id:!0});var a5=r(ds);ps=l(a5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var cT=r(ps);Qf=l(cT,"SPAN",{class:!0}),r(Qf).forEach(t),cT.forEach(t),y_=n(a5,"Data Considerations"),a5.forEach(t),lh=u(s),It=l(s,"TABLE",{class:!0});var gm=r(It);oi=l(gm,"THEAD",{class:!0});var uT=r(oi);Ue=l(uT,"TR",{class:!0});var Su=r(Ue);ni=l(Su,"TH",{class:!0});var fT=r(ni);w_=n(fT,"Situation"),fT.forEach(t),T_=u(Su),ci=l(Su,"TH",{class:!0});var dT=r(ci);R_=n(dT,"Actual Risk"),dT.forEach(t),S_=u(Su),ui=l(Su,"TH",{class:!0});var pT=r(ui);D_=n(pT,"Solution"),pT.forEach(t),Su.forEach(t),uT.forEach(t),A_=u(gm),he=l(gm,"TBODY",{class:!0});var Ra=r(he);Be=l(Ra,"TR",{class:!0});var Du=r(Be);fi=l(Du,"TD",{class:!0});var hT=r(fi);L_=n(hT,"High LR + small batch size"),hT.forEach(t),I_=u(Du),di=l(Du,"TD",{class:!0});var gT=r(di);P_=n(gT,"Divergence"),gT.forEach(t),O_=u(Du),pi=l(Du,"TD",{class:!0});var mT=r(pi);z_=n(mT,"Lower LR, increase batch size"),mT.forEach(t),Du.forEach(t),N_=u(Ra),We=l(Ra,"TR",{class:!0});var Au=r(We);hi=l(Au,"TD",{class:!0});var vT=r(hi);C_=n(vT,"Inconsistent features"),vT.forEach(t),G_=u(Au),gi=l(Au,"TD",{class:!0});var _T=r(gi);H_=n(_T,"Overfitting"),_T.forEach(t),q_=u(Au),mi=l(Au,"TD",{class:!0});var kT=r(mi);M_=n(kT,"Improve dataset consistency"),kT.forEach(t),Au.forEach(t),U_=u(Ra),je=l(Ra,"TR",{class:!0});var Lu=r(je);vi=l(Lu,"TD",{class:!0});var ET=r(vi);B_=n(ET,"Insufficient reg images"),ET.forEach(t),W_=u(Lu),_i=l(Lu,"TD",{class:!0});var bT=r(_i);j_=n(bT,"Class leakage"),bT.forEach(t),F_=u(Lu),ki=l(Lu,"TD",{class:!0});var xT=r(ki);Y_=n(xT,"Add 100-300 class images"),xT.forEach(t),Lu.forEach(t),V_=u(Ra),Fe=l(Ra,"TR",{class:!0});var Iu=r(Fe);Ei=l(Iu,"TD",{class:!0});var yT=r(Ei);K_=n(yT,"High variance in training data"),yT.forEach(t),X_=u(Iu),bi=l(Iu,"TD",{class:!0});var wT=r(bi);Z_=n(wT,"Mode collapse"),wT.forEach(t),Q_=u(Iu),xi=l(Iu,"TD",{class:!0});var TT=r(xi);J_=n(TT,"Curate focused dataset"),TT.forEach(t),Iu.forEach(t),Ra.forEach(t),gm.forEach(t),rh=u(s),ih=l(s,"HR",{}),oh=u(s),hs=l(s,"H2",{id:!0});var l5=r(hs);gs=l(l5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var RT=r(gs);Jf=l(RT,"SPAN",{class:!0}),r(Jf).forEach(t),RT.forEach(t),$_=n(l5,"Monitoring Tips"),l5.forEach(t),nh=u(s),ms=l(s,"P",{});var mm=r(ms);e1=n(mm,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Za=l(mm,"A",{href:!0,rel:!0});var ST=r(Za);t1=n(ST,"kohya-ss/sd-scripts"),ST.forEach(t),s1=n(mm,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),mm.forEach(t),ch=u(s),vs=l(s,"H3",{id:!0});var r5=r(vs);_s=l(r5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var DT=r(_s);$f=l(DT,"SPAN",{class:!0}),r($f).forEach(t),DT.forEach(t),a1=n(r5,"Track loss curves"),r5.forEach(t),uh=u(s),ks=l(s,"P",{});var vm=r(ks);l1=n(vm,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Qa=l(vm,"A",{href:!0,rel:!0});var AT=r(Qa);r1=n(AT,"TensorBoard"),AT.forEach(t),i1=n(vm," to create these graphs."),vm.forEach(t),fh=u(s),Ja=l(s,"PRE",{class:!0});var V9=r(Ja);V9.forEach(t),dh=u(s),Es=l(s,"H4",{id:!0});var i5=r(Es);bs=l(i5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var LT=r(bs);ed=l(LT,"SPAN",{class:!0}),r(ed).forEach(t),LT.forEach(t),o1=n(i5,"What to Monitor:"),i5.forEach(t),ph=u(s),Ye=l(s,"UL",{});var Pu=r(Ye);td=l(Pu,"LI",{});var IT=r(td);n1=n(IT,"Training Loss: Should decrease steadily but not too quickly."),IT.forEach(t),c1=u(Pu),sd=l(Pu,"LI",{});var PT=r(sd);u1=n(PT,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),PT.forEach(t),f1=u(Pu),ad=l(Pu,"LI",{});var OT=r(ad);d1=n(OT,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),OT.forEach(t),Pu.forEach(t),hh=u(s),xs=l(s,"H4",{id:!0});var o5=r(xs);ys=l(o5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var zT=r(ys);ld=l(zT,"SPAN",{class:!0}),r(ld).forEach(t),zT.forEach(t),p1=n(o5,"Warning Signs:"),o5.forEach(t),gh=u(s),Ve=l(s,"UL",{});var Ou=r(Ve);rd=l(Ou,"LI",{});var NT=r(rd);h1=n(NT,"Sudden spikes in loss \u2192 Likely divergence."),NT.forEach(t),g1=u(Ou),id=l(Ou,"LI",{});var CT=r(id);m1=n(CT,"Loss plateauing too early \u2192 Learning rate may be too low."),CT.forEach(t),v1=u(Ou),od=l(Ou,"LI",{});var GT=r(od);_1=n(GT,"Validation loss increasing while training loss decreases \u2192 Overfitting."),GT.forEach(t),Ou.forEach(t),mh=u(s),ws=l(s,"H3",{id:!0});var n5=r(ws);Ts=l(n5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var HT=r(Ts);nd=l(HT,"SPAN",{class:!0}),r(nd).forEach(t),HT.forEach(t),k1=n(n5,"Generate validation images every 100 steps"),n5.forEach(t),vh=u(s),$a=l(s,"P",{});var c5=r($a);cd=l(c5,"STRONG",{});var qT=r(cd);E1=n(qT,"Why It Matters"),qT.forEach(t),b1=n(c5," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),c5.forEach(t),_h=u(s),el=l(s,"PRE",{class:!0});var K9=r(el);K9.forEach(t),kh=u(s),Rs=l(s,"H4",{id:!0});var u5=r(Rs);Ss=l(u5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var MT=r(Ss);ud=l(MT,"SPAN",{class:!0}),r(ud).forEach(t),MT.forEach(t),x1=n(u5,"What to Look For:"),u5.forEach(t),Eh=u(s),Ke=l(s,"UL",{});var zu=r(Ke);fd=l(zu,"LI",{});var UT=r(fd);y1=n(UT,"Consistency: Outputs should align with the training data style."),UT.forEach(t),w1=u(zu),dd=l(zu,"LI",{});var BT=r(dd);T1=n(BT,"Artifacts: Check for distortions, noise, or unnatural features."),BT.forEach(t),R1=u(zu),pd=l(zu,"LI",{});var WT=r(pd);S1=n(WT,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),WT.forEach(t),zu.forEach(t),bh=u(s),tl=l(s,"BLOCKQUOTE",{class:!0});var jT=r(tl);yi=l(jT,"P",{class:!0});var FT=r(yi);D1=n(FT,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),FT.forEach(t),jT.forEach(t),xh=u(s),Ds=l(s,"H4",{id:!0});var f5=r(Ds);As=l(f5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var YT=r(As);hd=l(YT,"SPAN",{class:!0}),r(hd).forEach(t),YT.forEach(t),A1=n(f5,"Use Gradient Clipping"),f5.forEach(t),yh=u(s),sl=l(s,"P",{});var d5=r(sl);gd=l(d5,"STRONG",{});var VT=r(gd);L1=n(VT,"Why It Matters"),VT.forEach(t),I1=n(d5,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),d5.forEach(t),wh=u(s),wi=l(s,"P",{});var KT=r(wi);P1=n(KT,"Key Insights:"),KT.forEach(t),Th=u(s),Xe=l(s,"UL",{});var Nu=r(Xe);al=l(Nu,"LI",{});var _m=r(al);O1=n(_m,"Gradient Norm "),Ti=l(_m,"CODE",{class:!0});var XT=r(Ti);z1=n(XT,"<"),XT.forEach(t),N1=n(_m," than 0.1: Training may stall due to tiny updates."),_m.forEach(t),C1=u(Nu),md=l(Nu,"LI",{});var ZT=r(md);G1=n(ZT,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),ZT.forEach(t),H1=u(Nu),vd=l(Nu,"LI",{});var QT=r(vd);q1=n(QT,"Ideal Range: 0.1 to 2.0 for stable training."),QT.forEach(t),Nu.forEach(t),Rh=u(s),ll=l(s,"BLOCKQUOTE",{class:!0});var JT=r(ll);Ri=l(JT,"P",{class:!0});var $T=r(Ri);M1=n($T,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),$T.forEach(t),JT.forEach(t),Sh=u(s),Ls=l(s,"H4",{id:!0});var p5=r(Ls);Is=l(p5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var e8=r(Is);_d=l(e8,"SPAN",{class:!0}),r(_d).forEach(t),e8.forEach(t),U1=n(p5,"Enable Mixed Precision Training"),p5.forEach(t),Dh=u(s),rl=l(s,"P",{});var h5=r(rl);kd=l(h5,"STRONG",{});var t8=r(kd);B1=n(t8,"Why It Matters"),t8.forEach(t),W1=n(h5,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),h5.forEach(t),Ah=u(s),il=l(s,"PRE",{class:!0});var X9=r(il);X9.forEach(t),Lh=u(s),Si=l(s,"P",{});var s8=r(Si);j1=n(s8,"Benefits:"),s8.forEach(t),Ih=u(s),Ze=l(s,"UL",{});var Cu=r(Ze);Ed=l(Cu,"LI",{});var a8=r(Ed);F1=n(a8,"2-3x Faster Training: Leverages GPU tensor cores."),a8.forEach(t),Y1=u(Cu),bd=l(Cu,"LI",{});var l8=r(bd);V1=n(l8,"50% Less VRAM Usage: Allows larger batch sizes or models."),l8.forEach(t),K1=u(Cu),xd=l(Cu,"LI",{});var r8=r(xd);X1=n(r8,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),r8.forEach(t),Cu.forEach(t),Ph=u(s),ol=l(s,"BLOCKQUOTE",{class:!0});var i8=r(ol);Di=l(i8,"P",{class:!0});var o8=r(Di);Z1=n(o8,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),o8.forEach(t),i8.forEach(t),Oh=u(s),Ps=l(s,"H4",{id:!0});var g5=r(Ps);Os=l(g5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var n8=r(Os);yd=l(n8,"SPAN",{class:!0}),r(yd).forEach(t),n8.forEach(t),Q1=n(g5,"Start with Conservative Learning Rates"),g5.forEach(t),zh=u(s),zs=l(s,"P",{});var km=r(zs);J1=n(km,"Start off with 1e-5 to 1e-6.  "),wd=l(km,"STRONG",{});var c8=r(wd);$1=n(c8,"Why It Matters"),c8.forEach(t),ek=n(km,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),km.forEach(t),Nh=u(s),nl=l(s,"PRE",{class:!0});var Z9=r(nl);Z9.forEach(t),Ch=u(s),cl=l(s,"PRE",{class:!0});var Q9=r(cl);Q9.forEach(t),Gh=u(s),ul=l(s,"P",{});var m5=r(ul);Td=l(m5,"STRONG",{});var u8=r(Td);tk=n(u8,"Warning Signs"),u8.forEach(t),sk=n(m5,":"),m5.forEach(t),Hh=u(s),Qe=l(s,"UL",{});var Gu=r(Qe);Rd=l(Gu,"LI",{});var f8=r(Rd);ak=n(f8,"Loss Spikes: Learning rate is too high."),f8.forEach(t),lk=u(Gu),Sd=l(Gu,"LI",{});var d8=r(Sd);rk=n(d8,"Slow Convergence: Learning rate is too low."),d8.forEach(t),ik=u(Gu),Dd=l(Gu,"LI",{});var p8=r(Dd);ok=n(p8,"Oscillating Loss: Poor scheduling or unstable gradients."),p8.forEach(t),Gu.forEach(t),qh=u(s),Pt=l(s,"TABLE",{class:!0});var Em=r(Pt);Ai=l(Em,"THEAD",{class:!0});var h8=r(Ai);ge=l(h8,"TR",{class:!0});var Sa=r(ge);Li=l(Sa,"TH",{class:!0});var g8=r(Li);nk=n(g8,"Practice"),g8.forEach(t),ck=u(Sa),Ii=l(Sa,"TH",{class:!0});var m8=r(Ii);uk=n(m8,"Key Benefit"),m8.forEach(t),fk=u(Sa),Pi=l(Sa,"TH",{class:!0});var v8=r(Pi);dk=n(v8,"Tool/Setting"),v8.forEach(t),pk=u(Sa),Oi=l(Sa,"TH",{class:!0});var _8=r(Oi);hk=n(_8,"Warning Signs"),_8.forEach(t),Sa.forEach(t),h8.forEach(t),gk=u(Em),le=l(Em,"TBODY",{class:!0});var wt=r(le);me=l(wt,"TR",{class:!0});var Da=r(me);zi=l(Da,"TD",{class:!0});var k8=r(zi);mk=n(k8,"Track Loss Curves"),k8.forEach(t),vk=u(Da),Ni=l(Da,"TD",{class:!0});var E8=r(Ni);_k=n(E8,"Detect overfitting/divergence early"),E8.forEach(t),kk=u(Da),Ci=l(Da,"TD",{class:!0});var b8=r(Ci);Ek=n(b8,"TensorBoard, Weights & Biases"),b8.forEach(t),bk=u(Da),Gi=l(Da,"TD",{class:!0});var x8=r(Gi);xk=n(x8,"Spikes, plateaus, growing gaps"),x8.forEach(t),Da.forEach(t),yk=u(wt),ve=l(wt,"TR",{class:!0});var Aa=r(ve);Hi=l(Aa,"TD",{class:!0});var y8=r(Hi);wk=n(y8,"Generate Validation Images"),y8.forEach(t),Tk=u(Aa),qi=l(Aa,"TD",{class:!0});var w8=r(qi);Rk=n(w8,"Visualize model progress"),w8.forEach(t),Sk=u(Aa),Mi=l(Aa,"TD",{class:!0});var T8=r(Mi);Dk=n(T8,"Fixed prompts/seeds"),T8.forEach(t),Ak=u(Aa),Ui=l(Aa,"TD",{class:!0});var R8=r(Ui);Lk=n(R8,"Artifacts, mode collapse"),R8.forEach(t),Aa.forEach(t),Ik=u(wt),_e=l(wt,"TR",{class:!0});var La=r(_e);Bi=l(La,"TD",{class:!0});var S8=r(Bi);Pk=n(S8,"Gradient Clipping"),S8.forEach(t),Ok=u(La),Wi=l(La,"TD",{class:!0});var D8=r(Wi);zk=n(D8,"Prevent exploding gradients"),D8.forEach(t),Nk=u(La),Ns=l(La,"TD",{class:!0});var bm=r(Ns);Ck=n(bm,"clip"),Ad=l(bm,"EM",{});var A8=r(Ad);Gk=n(A8,"grad_norm"),A8.forEach(t),Hk=n(bm," (1.0-2.0)"),bm.forEach(t),qk=u(La),Je=l(La,"TD",{class:!0});var Hu=r(Je);Mk=n(Hu,"Norm "),ji=l(Hu,"CODE",{class:!0});var L8=r(ji);Uk=n(L8,">"),L8.forEach(t),Bk=n(Hu," 10.0 or "),Fi=l(Hu,"CODE",{class:!0});var I8=r(Fi);Wk=n(I8,"<"),I8.forEach(t),jk=n(Hu," 0.1"),Hu.forEach(t),La.forEach(t),Fk=u(wt),ke=l(wt,"TR",{class:!0});var Ia=r(ke);Yi=l(Ia,"TD",{class:!0});var P8=r(Yi);Yk=n(P8,"Mixed Precision Training"),P8.forEach(t),Vk=u(Ia),Vi=l(Ia,"TD",{class:!0});var O8=r(Vi);Kk=n(O8,"Faster training, lower VRAM usage"),O8.forEach(t),Xk=u(Ia),Ki=l(Ia,"TD",{class:!0});var z8=r(Ki);Zk=n(z8,"PyTorch AMP (torch.cuda.amp)"),z8.forEach(t),Qk=u(Ia),Xi=l(Ia,"TD",{class:!0});var N8=r(Xi);Jk=n(N8,"NaN values (disable if unstable)"),N8.forEach(t),Ia.forEach(t),$k=u(wt),Ee=l(wt,"TR",{class:!0});var Pa=r(Ee);Zi=l(Pa,"TD",{class:!0});var C8=r(Zi);eE=n(C8,"Conservative Learning Rates"),C8.forEach(t),tE=u(Pa),Qi=l(Pa,"TD",{class:!0});var G8=r(Qi);sE=n(G8,"Stable training, avoid divergence"),G8.forEach(t),aE=u(Pa),Ji=l(Pa,"TD",{class:!0});var H8=r(Ji);lE=n(H8,"Start at 1e-5 to 1e-6, use scheduler"),H8.forEach(t),rE=u(Pa),$i=l(Pa,"TD",{class:!0});var q8=r($i);iE=n(q8,"Spikes, slow convergence"),q8.forEach(t),Pa.forEach(t),wt.forEach(t),Em.forEach(t),Mh=u(s),Uh=l(s,"HR",{}),Bh=u(s),Cs=l(s,"H2",{id:!0});var v5=r(Cs);Gs=l(v5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var M8=r(Gs);Ld=l(M8,"SPAN",{class:!0}),r(Ld).forEach(t),M8.forEach(t),oE=n(v5,"Generating Regularization images"),v5.forEach(t),Wh=u(s),Hs=l(s,"P",{});var xm=r(Hs);nE=n(xm,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),eo=l(xm,"CODE",{class:!0});var U8=r(eo);cE=n(U8,"1boy"),U8.forEach(t),uE=n(xm,")."),xm.forEach(t),jh=u(s),ue=l(s,"P",{});var Ht=r(ue);fE=n(Ht,"According to the Dreambooth technique, "),to=l(Ht,"CODE",{class:!0});var B8=r(to);dE=n(B8,"200"),B8.forEach(t),pE=n(Ht," regularization images per training image.  For example, if you have "),so=l(Ht,"CODE",{class:!0});var W8=r(so);hE=n(W8,"16"),W8.forEach(t),gE=n(Ht," images: "),ao=l(Ht,"CODE",{class:!0});var j8=r(ao);mE=n(j8,"200 * 16 = 3200"),j8.forEach(t),vE=n(Ht," total regularization images.  When training, the math involved for calculating total steps is: "),lo=l(Ht,"CODE",{class:!0});var F8=r(lo);_E=n(F8,"repeats * training images >= repeats * regularization images"),F8.forEach(t),Ht.forEach(t),Fh=u(s),ro=l(s,"P",{});var Y8=r(ro);kE=n(Y8,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),Y8.forEach(t),Yh=u(s),qs=l(s,"H4",{id:!0});var _5=r(qs);Ms=l(_5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var V8=r(Ms);Id=l(V8,"SPAN",{class:!0}),r(Id).forEach(t),V8.forEach(t),EE=n(_5,"Important considerations"),_5.forEach(t),Vh=u(s),$e=l(s,"OL",{});var qu=r($e);Pd=l(qu,"LI",{});var K8=r(Pd);fl=l(K8,"P",{});var ym=r(fl);Od=l(ym,"STRONG",{});var X8=r(Od);bE=n(X8,"Use the same base model for regularization images and training"),X8.forEach(t),xE=l(ym,"BR",{}),yE=n(ym,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),ym.forEach(t),K8.forEach(t),wE=u(qu),zd=l(qu,"LI",{});var Z8=r(zd);dl=l(Z8,"P",{});var wm=r(dl);Nd=l(wm,"STRONG",{});var Q8=r(Nd);TE=n(Q8,"Maintain consistent class representation"),Q8.forEach(t),RE=l(wm,"BR",{}),SE=n(wm,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),wm.forEach(t),Z8.forEach(t),DE=u(qu),Cd=l(qu,"LI",{});var J8=r(Cd);pl=l(J8,"P",{});var Tm=r(pl);Gd=l(Tm,"STRONG",{});var $8=r(Gd);AE=n($8,"Match output resolution to training data"),$8.forEach(t),LE=l(Tm,"BR",{}),IE=n(Tm,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Tm.forEach(t),J8.forEach(t),qu.forEach(t),Kh=u(s),er(hl.$$.fragment,s),Xh=u(s),Us=l(s,"H4",{id:!0});var k5=r(Us);Bs=l(k5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var eR=r(Bs);Hd=l(eR,"SPAN",{class:!0}),r(Hd).forEach(t),eR.forEach(t),PE=n(k5,"Generate using Stable Diffusion web UI"),k5.forEach(t),Zh=u(s),Ws=l(s,"P",{});var Rm=r(Ws);OE=n(Rm,"We\u2019re going to use "),gl=l(Rm,"A",{href:!0,rel:!0});var tR=r(gl);zE=n(tR,"Stable Diffusion web UI"),tR.forEach(t),NE=n(Rm," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Rm.forEach(t),Qh=u(s),et=l(s,"P",{});var Mu=r(et);CE=n(Mu,"We\u2019re going to use the "),io=l(Mu,"CODE",{class:!0});var sR=r(io);GE=n(sR,"X/Y/Z plot"),sR.forEach(t),HE=n(Mu," script to use "),oo=l(Mu,"CODE",{class:!0});var aR=r(oo);qE=n(aR,"Prompt Search & Replace"),aR.forEach(t),ME=n(Mu," to dynamically build a prompt that will generate hundreds of regularization images."),Mu.forEach(t),Jh=u(s),J=l(s,"OL",{});var ne=r(J);qd=l(ne,"LI",{});var lR=r(qd);no=l(lR,"P",{});var E5=r(no);UE=n(E5,"Select the text 2 image tab.  Enter a generic prompt "),co=l(E5,"CODE",{class:!0});var rR=r(co);BE=n(rR,"princeadam, portrait, looking_at_viewer, forest"),rR.forEach(t),E5.forEach(t),lR.forEach(t),WE=u(ne),Md=l(ne,"LI",{});var iR=r(Md);ml=l(iR,"P",{});var Sm=r(ml);jE=n(Sm,"In generation parameters and select the "),uo=l(Sm,"CODE",{class:!0});var oR=r(uo);FE=n(oR,"X/Y/Z plot"),oR.forEach(t),YE=n(Sm," script."),Sm.forEach(t),iR.forEach(t),VE=u(ne),Ud=l(ne,"LI",{});var nR=r(Ud);V=l(nR,"P",{});var te=r(V);KE=n(te,"Select the "),fo=l(te,"CODE",{class:!0});var cR=r(fo);XE=n(cR,"X"),cR.forEach(t),ZE=n(te," parameter and "),po=l(te,"CODE",{class:!0});var uR=r(po);QE=n(uR,"Prompt SR"),uR.forEach(t),JE=n(te," for Prompt Replace.  We\u2019re going to replace "),ho=l(te,"CODE",{class:!0});var fR=r(ho);$E=n(fR,"portrait"),fR.forEach(t),eb=n(te," with different camera angle tags: "),go=l(te,"CODE",{class:!0});var dR=r(go);tb=n(dR,"close-up"),dR.forEach(t),sb=n(te,", "),mo=l(te,"CODE",{class:!0});var pR=r(mo);ab=n(pR,"upper_body"),pR.forEach(t),lb=n(te,", "),vo=l(te,"CODE",{class:!0});var hR=r(vo);rb=n(hR,"from_below"),hR.forEach(t),ib=n(te,", "),_o=l(te,"CODE",{class:!0});var gR=r(_o);ob=n(gR,"from_above"),gR.forEach(t),nb=n(te,", "),ko=l(te,"CODE",{class:!0});var mR=r(ko);cb=n(mR,"dutch_angle"),mR.forEach(t),te.forEach(t),nR.forEach(t),ub=u(ne),Bd=l(ne,"LI",{});var vR=r(Bd);$=l(vR,"P",{});var ae=r($);fb=n(ae,"Select the "),Eo=l(ae,"CODE",{class:!0});var _R=r(Eo);db=n(_R,"Y"),_R.forEach(t),pb=n(ae," parameter and "),bo=l(ae,"CODE",{class:!0});var kR=r(bo);hb=n(kR,"Prompt SR"),kR.forEach(t),gb=n(ae," for Prompt Replace.  Replace "),xo=l(ae,"CODE",{class:!0});var ER=r(xo);mb=n(ER,"looking_at_viewer"),ER.forEach(t),vb=n(ae,": "),yo=l(ae,"CODE",{class:!0});var bR=r(yo);_b=n(bR,"looking_away"),bR.forEach(t),kb=n(ae,", "),wo=l(ae,"CODE",{class:!0});var xR=r(wo);Eb=n(xR,"looking_to_the_side"),xR.forEach(t),bb=n(ae,", "),To=l(ae,"CODE",{class:!0});var yR=r(To);xb=n(yR,"looking_ahead"),yR.forEach(t),yb=n(ae,", "),Ro=l(ae,"CODE",{class:!0});var wR=r(Ro);wb=n(wR,"looking_down"),wR.forEach(t),ae.forEach(t),vR.forEach(t),Tb=u(ne),Wd=l(ne,"LI",{});var TR=r(Wd);K=l(TR,"P",{});var se=r(K);Rb=n(se,"Select the "),So=l(se,"CODE",{class:!0});var RR=r(So);Sb=n(RR,"Z"),RR.forEach(t),Db=n(se," parameter and "),Do=l(se,"CODE",{class:!0});var SR=r(Do);Ab=n(SR,"Prompt SR"),SR.forEach(t),Lb=n(se," for Prompt Replace. Replace "),Ao=l(se,"CODE",{class:!0});var DR=r(Ao);Ib=n(DR,"forest"),DR.forEach(t),Pb=n(se," with a vareity of locatinos: "),Lo=l(se,"CODE",{class:!0});var AR=r(Lo);Ob=n(AR,"castle"),AR.forEach(t),zb=n(se,", "),Io=l(se,"CODE",{class:!0});var LR=r(Io);Nb=n(LR,"mountain"),LR.forEach(t),Cb=n(se,", "),Po=l(se,"CODE",{class:!0});var IR=r(Po);Gb=n(IR,"cave"),IR.forEach(t),Hb=n(se,", "),Oo=l(se,"CODE",{class:!0});var PR=r(Oo);qb=n(PR,"farm"),PR.forEach(t),Mb=n(se,", "),zo=l(se,"CODE",{class:!0});var OR=r(zo);Ub=n(OR,"ocean"),OR.forEach(t),se.forEach(t),TR.forEach(t),Bb=u(ne),jd=l(ne,"LI",{});var zR=r(jd);No=l(zR,"P",{});var b5=r(No);Wb=n(b5,"Select a fast sampler like "),Co=l(b5,"CODE",{class:!0});var NR=r(Co);jb=n(NR,"DPM2 KARRAS"),NR.forEach(t),b5.forEach(t),zR.forEach(t),Fb=u(ne),Fd=l(ne,"LI",{});var CR=r(Fd);js=l(CR,"P",{});var vp=r(js);Yb=n(vp,"CFG Scale set to "),Go=l(vp,"CODE",{class:!0});var GR=r(Go);Vb=n(GR,"7"),GR.forEach(t),Kb=n(vp," and Steps to "),Ho=l(vp,"CODE",{class:!0});var HR=r(Ho);Xb=n(HR,"20"),HR.forEach(t),vp.forEach(t),CR.forEach(t),ne.forEach(t),$h=u(s),tt=l(s,"P",{});var Uu=r(tt);Zb=n(Uu,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),qo=l(Uu,"CODE",{class:!0});var qR=r(qo);Qb=n(qR,"150"),qR.forEach(t),Jb=n(Uu," - "),Mo=l(Uu,"CODE",{class:!0});var MR=r(Mo);$b=n(MR,"200"),MR.forEach(t),ex=n(Uu," and keep in mind we can add and remove as we try different training settings with different output."),Uu.forEach(t),eg=u(s),er(vl.$$.fragment,s),tg=u(s),Fs=l(s,"H4",{id:!0});var x5=r(Fs);Ys=l(x5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var UR=r(Ys);Yd=l(UR,"SPAN",{class:!0}),r(Yd).forEach(t),UR.forEach(t),tx=n(x5,"Download images"),x5.forEach(t),sg=u(s),Uo=l(s,"P",{});var BR=r(Uo);sx=n(BR,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),BR.forEach(t),ag=u(s),be=l(s,"UL",{});var Oa=r(be);Bo=l(Oa,"LI",{});var y5=r(Bo);_l=l(y5,"A",{href:!0,rel:!0});var WR=r(_l);ax=n(WR,"3ee Games regularization images"),WR.forEach(t),lx=n(y5,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),y5.forEach(t),rx=u(Oa),Wo=l(Oa,"LI",{});var w5=r(Wo);kl=l(w5,"A",{href:!0,rel:!0});var jR=r(kl);ix=n(jR,"Pre-Rendered Regularization Images"),jR.forEach(t),ox=n(w5,": Includes 1500 regularization images."),w5.forEach(t),nx=u(Oa),jo=l(Oa,"LI",{});var T5=r(jo);El=l(T5,"A",{href:!0,rel:!0});var FR=r(El);cx=n(FR,"Stable Diffusion 1.5 Regularization Images"),FR.forEach(t),ux=n(T5,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),T5.forEach(t),fx=u(Oa),Fo=l(Oa,"LI",{});var R5=r(Fo);bl=l(R5,"A",{href:!0,rel:!0});var YR=r(bl);dx=n(YR,"Aitrepreneur SDXL image set"),YR.forEach(t),px=n(R5,": a large image set generated with Stable Diffusion SDXL."),R5.forEach(t),Oa.forEach(t),lg=u(s),Vs=l(s,"H4",{id:!0});var S5=r(Vs);Ks=l(S5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var VR=r(Ks);Vd=l(VR,"SPAN",{class:!0}),r(Vd).forEach(t),VR.forEach(t),hx=n(S5,"Captioning Regularization images"),S5.forEach(t),rg=u(s),Xs=l(s,"P",{});var Dm=r(Xs);gx=n(Dm,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Yo=l(Dm,"CODE",{class:!0});var KR=r(Yo);mx=n(KR,"txt"),KR.forEach(t),vx=n(Dm," files with a shell script:"),Dm.forEach(t),ig=u(s),xl=l(s,"PRE",{class:!0});var J9=r(xl);J9.forEach(t),og=u(s),st=l(s,"P",{});var Bu=r(st);_x=n(Bu,"Save this file as "),Vo=l(Bu,"CODE",{class:!0});var XR=r(Vo);kx=n(XR,"filename2txt.bat"),XR.forEach(t),Ex=n(Bu," and place it into the regularization images directory and run: "),Ko=l(Bu,"CODE",{class:!0});var ZR=r(Ko);bx=n(ZR,".\\filename2txt.bat"),ZR.forEach(t),xx=n(Bu,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Bu.forEach(t),ng=u(s),yl=l(s,"P",{});var D5=r(yl);yx=n(D5,"Example filename: "),Xo=l(D5,"CODE",{class:!0});var QR=r(Xo);wx=n(QR,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),QR.forEach(t),D5.forEach(t),cg=u(s),Zs=l(s,"P",{});var Am=r(Zs);Tx=n(Am,"Output: "),Zo=l(Am,"CODE",{class:!0});var JR=r(Zo);Rx=n(JR,"aburbres,princeadam,1boy,close-up,purple_vest"),JR.forEach(t),Sx=n(Am," saved in a text file with the same name as image."),Am.forEach(t),ug=u(s),Qs=l(s,"H2",{id:!0});var A5=r(Qs);Js=l(A5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var $R=r(Js);Kd=l($R,"SPAN",{class:!0}),r(Kd).forEach(t),$R.forEach(t),Dx=n(A5,"Training a LoRA"),A5.forEach(t),fg=u(s),$s=l(s,"P",{});var Lm=r($s);Ax=n(Lm,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),wl=l(Lm,"A",{href:!0,rel:!0});var eS=r(wl);Lx=n(eS,"kohya-ss/sd-scripts"),eS.forEach(t),Ix=n(Lm,"."),Lm.forEach(t),dg=u(s),Tl=l(s,"BLOCKQUOTE",{class:!0});var tS=r(Tl);ea=l(tS,"P",{class:!0});var Im=r(ea);Px=n(Im,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),Rl=l(Im,"A",{href:!0,rel:!0});var sS=r(Rl);Ox=n(sS,"Kohya SD script documentation"),sS.forEach(t),zx=n(Im,"."),Im.forEach(t),tS.forEach(t),pg=u(s),ta=l(s,"H3",{id:!0});var L5=r(ta);sa=l(L5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var aS=r(sa);Xd=l(aS,"SPAN",{class:!0}),r(Xd).forEach(t),aS.forEach(t),Nx=n(L5,"Directory setup"),L5.forEach(t),hg=u(s),aa=l(s,"P",{});var Pm=r(aa);Cx=n(Pm,"In your configuration json, use "),Qo=l(Pm,"CODE",{class:!0});var lS=r(Qo);Gx=n(lS,"reg_data_dir"),lS.forEach(t),Hx=n(Pm," to point to the directory with your regularization images:"),Pm.forEach(t),gg=u(s),Sl=l(s,"PRE",{class:!0});var $9=r(Sl);$9.forEach(t),mg=u(s),Jo=l(s,"P",{});var rS=r(Jo);qx=n(rS,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),rS.forEach(t),vg=u(s),Dl=l(s,"PRE",{class:!0});var eA=r(Dl);eA.forEach(t),_g=u(s),at=l(s,"P",{});var Wu=r(at);Mx=n(Wu,"Set the "),$o=l(Wu,"CODE",{class:!0});var iS=r($o);Ux=n(iS,"number of iterations"),iS.forEach(t),Bx=n(Wu," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),en=l(Wu,"CODE",{class:!0});var oS=r(en);Wx=n(oS,"training images \xD7 iterations"),oS.forEach(t),jx=n(Wu,". If there are more regularization images than this, the extras won\u2019t be used."),Wu.forEach(t),kg=u(s),lt=l(s,"P",{});var ju=r(lt);Fx=n(ju,"Create folders in the training image folder with the format "),tn=l(ju,"CODE",{class:!0});var nS=r(tn);Yx=n(nS,"<repetition count>_<class>"),nS.forEach(t),Vx=n(ju," multiple times, and similarly create folders in the regularization image folder with the format "),sn=l(ju,"CODE",{class:!0});var cS=r(sn);Kx=n(cS,"<repetition count>_<class>"),cS.forEach(t),Xx=n(ju,"."),ju.forEach(t),Eg=u(s),an=l(s,"P",{});var uS=r(an);Zx=n(uS,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),uS.forEach(t),bg=u(s),la=l(s,"UL",{});var Om=r(la);ln=l(Om,"LI",{});var I5=r(ln);Qx=n(I5,"train_data_dir"),Zd=l(I5,"UL",{});var fS=r(Zd);Qd=l(fS,"LI",{});var dS=r(Qd);Jx=n(dS,"10_princeadam"),dS.forEach(t),fS.forEach(t),I5.forEach(t),$x=u(Om),rn=l(Om,"LI",{});var P5=r(rn);ey=n(P5,"reg_dir"),Jd=l(P5,"UL",{});var pS=r(Jd);$d=l(pS,"LI",{});var hS=r($d);ty=n(hS,"1_1boy"),hS.forEach(t),pS.forEach(t),P5.forEach(t),Om.forEach(t),xg=u(s),on=l(s,"P",{});var gS=r(on);sy=n(gS,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),gS.forEach(t),yg=u(s),Al=l(s,"P",{class:!0});var mS=r(Al);Ll=l(mS,"IMG",{src:!0,alt:!0,class:!0}),mS.forEach(t),wg=u(s),ra=l(s,"H3",{id:!0});var O5=r(ra);ia=l(O5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var vS=r(ia);ep=l(vS,"SPAN",{class:!0}),r(ep).forEach(t),vS.forEach(t),ay=n(O5,"Training Settings"),O5.forEach(t),Tg=u(s),Ot=l(s,"P",{});var _p=r(Ot);ly=n(_p,"The training setup we\u2019re going to use is:  "),nn=l(_p,"CODE",{class:!0});var _S=r(nn);ry=n(_S,"Number of images * repeats * epoch / batch size = total steps"),_S.forEach(t),iy=n(_p,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),cn=l(_p,"CODE",{class:!0});var kS=r(cn);oy=n(kS,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),kS.forEach(t),_p.forEach(t),Rg=u(s),zt=l(s,"TABLE",{class:!0});var zm=r(zt);un=l(zm,"THEAD",{class:!0});var ES=r(un);re=l(ES,"TR",{class:!0});var Tt=r(re);fn=l(Tt,"TH",{class:!0});var bS=r(fn);ny=n(bS,"Number of Images"),bS.forEach(t),cy=u(Tt),dn=l(Tt,"TH",{class:!0});var xS=r(dn);uy=n(xS,"Repeats"),xS.forEach(t),fy=u(Tt),pn=l(Tt,"TH",{class:!0});var yS=r(pn);dy=n(yS,"Epochs"),yS.forEach(t),py=u(Tt),hn=l(Tt,"TH",{class:!0});var wS=r(hn);hy=n(wS,"Batch Size"),wS.forEach(t),gy=u(Tt),gn=l(Tt,"TH",{class:!0});var TS=r(gn);my=n(TS,"Total Steps"),TS.forEach(t),Tt.forEach(t),ES.forEach(t),vy=u(zm),mn=l(zm,"TBODY",{class:!0});var RS=r(mn);ie=l(RS,"TR",{class:!0});var Rt=r(ie);vn=l(Rt,"TD",{class:!0});var SS=r(vn);_y=n(SS,"45"),SS.forEach(t),ky=u(Rt),_n=l(Rt,"TD",{class:!0});var DS=r(_n);Ey=n(DS,"10"),DS.forEach(t),by=u(Rt),kn=l(Rt,"TD",{class:!0});var AS=r(kn);xy=n(AS,"20"),AS.forEach(t),yy=u(Rt),En=l(Rt,"TD",{class:!0});var LS=r(En);wy=n(LS,"2"),LS.forEach(t),Ty=u(Rt),bn=l(Rt,"TD",{class:!0});var IS=r(bn);Ry=n(IS,"4500"),IS.forEach(t),Rt.forEach(t),RS.forEach(t),zm.forEach(t),Sg=u(s),xn=l(s,"P",{});var PS=r(xn);Sy=n(PS,"Now let\u2019s focus on these training settings:"),PS.forEach(t),Dg=u(s),Il=l(s,"PRE",{class:!0});var tA=r(Il);tA.forEach(t),Ag=u(s),U=l(s,"UL",{});var Y=r(U);yn=l(Y,"LI",{});var z5=r(yn);Pl=l(z5,"STRONG",{});var Nm=r(Pl);Dy=n(Nm,"Learning Rate ("),wn=l(Nm,"CODE",{class:!0});var OS=r(wn);Ay=n(OS,"learning_rate"),OS.forEach(t),Ly=n(Nm,")"),Nm.forEach(t),Iy=n(z5,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),z5.forEach(t),Py=u(Y),Tn=l(Y,"LI",{});var N5=r(Tn);Ol=l(N5,"STRONG",{});var Cm=r(Ol);Oy=n(Cm,"Text Encoder Learning Rate ("),Rn=l(Cm,"CODE",{class:!0});var zS=r(Rn);zy=n(zS,"text_encoder_lr"),zS.forEach(t),Ny=n(Cm,")"),Cm.forEach(t),Cy=n(N5,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),N5.forEach(t),Gy=u(Y),Sn=l(Y,"LI",{});var C5=r(Sn);zl=l(C5,"STRONG",{});var Gm=r(zl);Hy=n(Gm,"UNet Learning Rate ("),Dn=l(Gm,"CODE",{class:!0});var NS=r(Dn);qy=n(NS,"unet_lr"),NS.forEach(t),My=n(Gm,")"),Gm.forEach(t),Uy=n(C5,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),C5.forEach(t),By=u(Y),An=l(Y,"LI",{});var G5=r(An);Nl=l(G5,"STRONG",{});var Hm=r(Nl);Wy=n(Hm,"Learning Rate Scheduler ("),Ln=l(Hm,"CODE",{class:!0});var CS=r(Ln);jy=n(CS,"lr_scheduler"),CS.forEach(t),Fy=n(Hm,")"),Hm.forEach(t),Yy=n(G5,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),G5.forEach(t),Vy=u(Y),In=l(Y,"LI",{});var H5=r(In);Cl=l(H5,"STRONG",{});var qm=r(Cl);Ky=n(qm,"Number of Cycles in Learning Rate Scheduler ("),Pn=l(qm,"CODE",{class:!0});var GS=r(Pn);Xy=n(GS,"lr_scheduler_num_cycles"),GS.forEach(t),Zy=n(qm,")"),qm.forEach(t),Qy=n(H5,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),H5.forEach(t),Jy=u(Y),On=l(Y,"LI",{});var q5=r(On);Gl=l(q5,"STRONG",{});var Mm=r(Gl);$y=n(Mm,"Network Dimension ("),zn=l(Mm,"CODE",{class:!0});var HS=r(zn);e3=n(HS,"network_dim"),HS.forEach(t),t3=n(Mm,")"),Mm.forEach(t),s3=n(q5,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),q5.forEach(t),a3=u(Y),Nn=l(Y,"LI",{});var M5=r(Nn);Hl=l(M5,"STRONG",{});var Um=r(Hl);l3=n(Um,"Network Alpha ("),Cn=l(Um,"CODE",{class:!0});var qS=r(Cn);r3=n(qS,"network_alpha"),qS.forEach(t),i3=n(Um,")"),Um.forEach(t),o3=n(M5,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),M5.forEach(t),n3=u(Y),Gn=l(Y,"LI",{});var U5=r(Gn);ql=l(U5,"STRONG",{});var Bm=r(ql);c3=n(Bm,"Clip Skip ("),Hn=l(Bm,"CODE",{class:!0});var MS=r(Hn);u3=n(MS,"clip_skip"),MS.forEach(t),f3=n(Bm,")"),Bm.forEach(t),d3=n(U5,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),U5.forEach(t),p3=u(Y),qn=l(Y,"LI",{});var B5=r(qn);Ml=l(B5,"STRONG",{});var Wm=r(Ml);h3=n(Wm,"Max Token Length ("),Mn=l(Wm,"CODE",{class:!0});var US=r(Mn);g3=n(US,"max_token_length"),US.forEach(t),m3=n(Wm,")"),Wm.forEach(t),v3=n(B5,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),B5.forEach(t),_3=u(Y),Un=l(Y,"LI",{});var W5=r(Un);Ul=l(W5,"STRONG",{});var jm=r(Ul);k3=n(jm,"Noise Offset ("),Bn=l(jm,"CODE",{class:!0});var BS=r(Bn);E3=n(BS,"noise_offset"),BS.forEach(t),b3=n(jm,")"),jm.forEach(t),x3=n(W5,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),W5.forEach(t),y3=u(Y),Wn=l(Y,"LI",{});var j5=r(Wn);Bl=l(j5,"STRONG",{});var Fm=r(Bl);w3=n(Fm,"Regularization Data Directory ("),jn=l(Fm,"CODE",{class:!0});var WS=r(jn);T3=n(WS,"reg_data_dir"),WS.forEach(t),R3=n(Fm,")"),Fm.forEach(t),S3=n(j5,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),j5.forEach(t),Y.forEach(t),Lg=u(s),oa=l(s,"H3",{id:!0});var F5=r(oa);na=l(F5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jS=r(na);tp=l(jS,"SPAN",{class:!0}),r(tp).forEach(t),jS.forEach(t),D3=n(F5,"Fine Tuning"),F5.forEach(t),Ig=u(s),Fn=l(s,"P",{});var FS=r(Fn);A3=n(FS,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),FS.forEach(t),Pg=u(s),er(Wl.$$.fragment,s),Og=u(s),ca=l(s,"H4",{id:!0});var Y5=r(ca);ua=l(Y5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var YS=r(ua);sp=l(YS,"SPAN",{class:!0}),r(sp).forEach(t),YS.forEach(t),L3=n(Y5,"Workflow with Auto1111 WebUI"),Y5.forEach(t),zg=u(s),fa=l(s,"P",{});var Ym=r(fa);I3=n(Ym,"We\u2019re going to use "),jl=l(Ym,"A",{href:!0,rel:!0});var VS=r(jl);P3=n(VS,"Stable Diffusion web UI"),VS.forEach(t),O3=n(Ym," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Ym.forEach(t),Ng=u(s),da=l(s,"P",{});var Vm=r(da);z3=n(Vm,"We\u2019re going to use the "),Yn=l(Vm,"CODE",{class:!0});var KS=r(Yn);N3=n(KS,"X/Y/Z plot"),KS.forEach(t),C3=n(Vm," script to compare different epochs."),Vm.forEach(t),Cg=u(s),oe=l(s,"UL",{});var St=r(oe);Vn=l(St,"LI",{});var V5=r(Vn);G3=n(V5,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),Gg=l(V5,"PRINCEADAM0001:0.7",{}),r(Gg).forEach(t),V5.forEach(t),H3=u(St),ap=l(St,"LI",{});var XS=r(ap);q3=n(XS,"In generation parameters and select the X/Y/Z plot script."),XS.forEach(t),M3=u(St),rt=l(St,"LI",{});var Jl=r(rt);U3=n(Jl,"Select "),Kn=l(Jl,"CODE",{class:!0});var ZS=r(Kn);B3=n(ZS,"Prompt SR"),ZS.forEach(t),W3=n(Jl," for Prompt Replace.  We\u2019re going to replace "),Xn=l(Jl,"CODE",{class:!0});var QS=r(Xn);j3=n(QS,"<princeadam0001:0.7>"),QS.forEach(t),F3=n(Jl," with different epoch: "),Zn=l(Jl,"CODE",{class:!0});var JS=r(Zn);Y3=n(JS,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),JS.forEach(t),Jl.forEach(t),V3=u(St),Qn=l(St,"LI",{});var K5=r(Qn);K3=n(K5,"Select a fast sampler like "),Jn=l(K5,"CODE",{class:!0});var $S=r(Jn);X3=n($S,"DPM2 KARRAS"),$S.forEach(t),K5.forEach(t),Z3=u(St),pa=l(St,"LI",{});var kp=r(pa);Q3=n(kp,"CFG Scale set to "),$n=l(kp,"CODE",{class:!0});var eD=r($n);J3=n(eD,"7"),eD.forEach(t),$3=n(kp," and Steps to "),ec=l(kp,"CODE",{class:!0});var tD=r(ec);e4=n(tD,"20"),tD.forEach(t),kp.forEach(t),St.forEach(t),Hg=u(s),it=l(s,"P",{});var Fu=r(it);t4=n(Fu,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),tc=l(Fu,"CODE",{class:!0});var sD=r(tc);s4=n(sD,"network_dim"),sD.forEach(t),a4=n(Fu," and "),sc=l(Fu,"CODE",{class:!0});var aD=r(sc);l4=n(aD,"network_alpha"),aD.forEach(t),r4=n(Fu,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Fu.forEach(t),qg=u(s),xe=l(s,"UL",{});var za=r(xe);ha=l(za,"LI",{});var Ep=r(ha);i4=n(Ep,"Select "),ac=l(Ep,"CODE",{class:!0});var lD=r(ac);o4=n(lD,"Prompt SR"),lD.forEach(t),n4=n(Ep," for Prompt Replace.  We\u2019re going to replace the weights "),lc=l(Ep,"CODE",{class:!0});var rD=r(lc);c4=n(rD,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),rD.forEach(t),Ep.forEach(t),u4=u(za),Fl=l(za,"LI",{});var Km=r(Fl);f4=n(Km,"Use Prompt SR to generate a variety of angles: Select "),rc=l(Km,"CODE",{class:!0});var iD=r(rc);d4=n(iD,"Prompt SR"),iD.forEach(t),p4=n(Km," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),Km.forEach(t),h4=u(za),lp=l(za,"LI",{});var oD=r(lp);g4=n(oD,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),oD.forEach(t),m4=u(za),rp=l(za,"LI",{});var nD=r(rp);v4=n(nD,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),nD.forEach(t),za.forEach(t),Mg=u(s),ga=l(s,"H4",{id:!0});var X5=r(ga);ma=l(X5,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var cD=r(ma);ip=l(cD,"SPAN",{class:!0}),r(ip).forEach(t),cD.forEach(t),_4=n(X5,"Issues to look for"),X5.forEach(t),Ug=u(s),ye=l(s,"UL",{});var Na=r(ye);ic=l(Na,"LI",{});var Z5=r(ic);op=l(Z5,"STRONG",{});var uD=r(op);k4=n(uD,"Undercooked:"),uD.forEach(t),E4=n(Z5," Lacks output, adjust unet learning rate or extend training duration."),Z5.forEach(t),b4=u(Na),oc=l(Na,"LI",{});var Q5=r(oc);np=l(Q5,"STRONG",{});var fD=r(np);x4=n(fD,"Overcooked:"),fD.forEach(t),y4=n(Q5," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Q5.forEach(t),w4=u(Na),nc=l(Na,"LI",{});var J5=r(nc);cp=l(J5,"STRONG",{});var dD=r(cp);T4=n(dD,"Overfit:"),dD.forEach(t),R4=n(J5," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),J5.forEach(t),S4=u(Na),cc=l(Na,"LI",{});var $5=r(cc);up=l($5,"STRONG",{});var pD=r(up);D4=n(pD,"Mismatched:"),pD.forEach(t),A4=n($5," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),$5.forEach(t),Na.forEach(t),Bg=u(s),uc=l(s,"P",{});var hD=r(uc);L4=n(hD,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),hD.forEach(t),Wg=u(s),Yl=l(s,"P",{class:!0});var gD=r(Yl);Vl=l(gD,"IMG",{src:!0,alt:!0,class:!0}),gD.forEach(t),jg=u(s),va=l(s,"H2",{id:!0});var e6=r(va);_a=l(e6,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mD=r(_a);fp=l(mD,"SPAN",{class:!0}),r(fp).forEach(t),mD.forEach(t),I4=n(e6,"Troubleshooting"),e6.forEach(t),Fg=u(s),fc=l(s,"P",{});var vD=r(fc);P4=n(vD,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),vD.forEach(t),Yg=u(s),ot=l(s,"UL",{});var Yu=r(ot);Kl=l(Yu,"LI",{});var Xm=r(Kl);O4=n(Xm,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),dc=l(Xm,"CODE",{class:!0});var _D=r(dc);z4=n(_D,"200"),_D.forEach(t),N4=n(Xm," regularization images per training image."),Xm.forEach(t),C4=u(Yu),Xl=l(Yu,"LI",{});var Zm=r(Xl);G4=n(Zm,"Repeats of regularization images, but may overfit more.  Increasing the "),pc=l(Zm,"CODE",{class:!0});var kD=r(pc);H4=n(kD,"repetition_count"),kD.forEach(t),q4=n(Zm," will cycle through the images more but the results may have results that overfit the model."),Zm.forEach(t),M4=u(Yu),dp=l(Yu,"LI",{});var ED=r(dp);U4=n(ED,"Create more regularization images without increasing repeats will help with the overfitting."),ED.forEach(t),Yu.forEach(t),Vg=u(s),Nt=l(s,"TABLE",{class:!0});var Qm=r(Nt);hc=l(Qm,"THEAD",{class:!0});var bD=r(hc);nt=l(bD,"TR",{class:!0});var Vu=r(nt);gc=l(Vu,"TH",{class:!0});var xD=r(gc);B4=n(xD,"Issue"),xD.forEach(t),W4=u(Vu),mc=l(Vu,"TH",{class:!0});var yD=r(mc);j4=n(yD,"Situation"),yD.forEach(t),F4=u(Vu),vc=l(Vu,"TH",{class:!0});var wD=r(vc);Y4=n(wD,"Recommendation"),wD.forEach(t),Vu.forEach(t),bD.forEach(t),V4=u(Qm),we=l(Qm,"TBODY",{class:!0});var Ca=r(we);ct=l(Ca,"TR",{class:!0});var Ku=r(ct);_c=l(Ku,"TD",{class:!0});var TD=r(_c);K4=n(TD,"Varying quality"),TD.forEach(t),X4=u(Ku),kc=l(Ku,"TD",{class:!0});var RD=r(kc);Z4=n(RD,"Results differ from expectations"),RD.forEach(t),Q4=u(Ku),Ec=l(Ku,"TD",{class:!0});var SD=r(Ec);J4=n(SD,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),SD.forEach(t),Ku.forEach(t),$4=u(Ca),ut=l(Ca,"TR",{class:!0});var Xu=r(ut);bc=l(Xu,"TD",{class:!0});var DD=r(bc);e0=n(DD,"Inadequate regularization for input data"),DD.forEach(t),t0=u(Xu),xc=l(Xu,"TD",{class:!0});var AD=r(xc);s0=n(AD,"Lower input images, less regularization needed"),AD.forEach(t),a0=u(Xu),yc=l(Xu,"TD",{class:!0});var LD=r(yc);l0=n(LD,"Reduce the number of input images or increasing the quantity of reg images."),LD.forEach(t),Xu.forEach(t),r0=u(Ca),ft=l(Ca,"TR",{class:!0});var Zu=r(ft);wc=l(Zu,"TD",{class:!0});var ID=r(wc);i0=n(ID,"Overfitting due to repetition"),ID.forEach(t),o0=u(Zu),Tc=l(Zu,"TD",{class:!0});var PD=r(Tc);n0=n(PD,"Repeats of reg images, risk of overfitting"),PD.forEach(t),c0=u(Zu),Rc=l(Zu,"TD",{class:!0});var OD=r(Rc);u0=n(OD,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),OD.forEach(t),Zu.forEach(t),f0=u(Ca),dt=l(Ca,"TR",{class:!0});var Qu=r(dt);Sc=l(Qu,"TD",{class:!0});var zD=r(Sc);d0=n(zD,"Mitigate overfitting while increasing diversity"),zD.forEach(t),p0=u(Qu),Dc=l(Qu,"TD",{class:!0});var ND=r(Dc);h0=n(ND,"Create more reg images without repeats"),ND.forEach(t),g0=u(Qu),Ac=l(Qu,"TD",{class:!0});var CD=r(Ac);m0=n(CD,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),CD.forEach(t),Qu.forEach(t),Ca.forEach(t),Qm.forEach(t),Kg=u(s),ka=l(s,"H4",{id:!0});var t6=r(ka);Ea=l(t6,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var GD=r(Ea);pp=l(GD,"SPAN",{class:!0}),r(pp).forEach(t),GD.forEach(t),v0=n(t6,"More Solutions"),t6.forEach(t),Xg=u(s),Lc=l(s,"P",{});var HD=r(Lc);_0=n(HD,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),HD.forEach(t),Zg=u(s),Ct=l(s,"TABLE",{class:!0});var Jm=r(Ct);Ic=l(Jm,"THEAD",{class:!0});var qD=r(Ic);pt=l(qD,"TR",{class:!0});var Ju=r(pt);Pc=l(Ju,"TH",{class:!0});var MD=r(Pc);k0=n(MD,"Symptom"),MD.forEach(t),E0=u(Ju),Oc=l(Ju,"TH",{class:!0});var UD=r(Oc);b0=n(UD,"Likely Cause"),UD.forEach(t),x0=u(Ju),zc=l(Ju,"TH",{class:!0});var BD=r(zc);y0=n(BD,"Solution"),BD.forEach(t),Ju.forEach(t),qD.forEach(t),w0=u(Jm),W=l(Jm,"TBODY",{class:!0});var X=r(W);ht=l(X,"TR",{class:!0});var $u=r(ht);Nc=l($u,"TD",{class:!0});var WD=r(Nc);T0=n(WD,"Plastic texture persists"),WD.forEach(t),R0=u($u),Cc=l($u,"TD",{class:!0});var jD=r(Cc);S0=n(jD,"Insufficient human reg images"),jD.forEach(t),D0=u($u),Gc=l($u,"TD",{class:!0});var FD=r(Gc);A0=n(FD,"Add real photos to reg set"),FD.forEach(t),$u.forEach(t),L0=u(X),gt=l(X,"TR",{class:!0});var ef=r(gt);Hc=l(ef,"TD",{class:!0});var YD=r(Hc);I0=n(YD,"Loss plateaus early"),YD.forEach(t),P0=u(ef),qc=l(ef,"TD",{class:!0});var VD=r(qc);O0=n(VD,"Learning rate too low"),VD.forEach(t),z0=u(ef),Mc=l(ef,"TD",{class:!0});var KD=r(Mc);N0=n(KD,"Increase LR by 10x"),KD.forEach(t),ef.forEach(t),C0=u(X),mt=l(X,"TR",{class:!0});var tf=r(mt);Uc=l(tf,"TD",{class:!0});var XD=r(Uc);G0=n(XD,"Features blurry"),XD.forEach(t),H0=u(tf),Bc=l(tf,"TD",{class:!0});var ZD=r(Bc);q0=n(ZD,"Network dimension too small"),ZD.forEach(t),M0=u(tf),Wc=l(tf,"TD",{class:!0});var QD=r(Wc);U0=n(QD,"Increase network_dim to 64+"),QD.forEach(t),tf.forEach(t),B0=u(X),vt=l(X,"TR",{class:!0});var sf=r(vt);jc=l(sf,"TD",{class:!0});var JD=r(jc);W0=n(JD,"Color distortion"),JD.forEach(t),j0=u(sf),Fc=l(sf,"TD",{class:!0});var $D=r(Fc);F0=n($D,"Noise offset conflict"),$D.forEach(t),Y0=u(sf),Yc=l(sf,"TD",{class:!0});var e9=r(Yc);V0=n(e9,"Try noise_offset 0.05-0.1"),e9.forEach(t),sf.forEach(t),K0=u(X),_t=l(X,"TR",{class:!0});var af=r(_t);Vc=l(af,"TD",{class:!0});var t9=r(Vc);X0=n(t9,"Overly stylized outputs"),t9.forEach(t),Z0=u(af),Kc=l(af,"TD",{class:!0});var s9=r(Kc);Q0=n(s9,"Reg image style mismatch"),s9.forEach(t),J0=u(af),Xc=l(af,"TD",{class:!0});var a9=r(Xc);$0=n(a9,"Regenerate reg images with base model"),a9.forEach(t),af.forEach(t),ew=u(X),kt=l(X,"TR",{class:!0});var lf=r(kt);Zc=l(lf,"TD",{class:!0});var l9=r(Zc);tw=n(l9,"Training instability"),l9.forEach(t),sw=u(lf),Qc=l(lf,"TD",{class:!0});var r9=r(Qc);aw=n(r9,"Batch size too large"),r9.forEach(t),lw=u(lf),Jc=l(lf,"TD",{class:!0});var i9=r(Jc);rw=n(i9,"Reduce batch_size to 1-2"),i9.forEach(t),lf.forEach(t),iw=u(X),Et=l(X,"TR",{class:!0});var rf=r(Et);$c=l(rf,"TD",{class:!0});var o9=r($c);ow=n(o9,"Slow convergence"),o9.forEach(t),nw=u(rf),eu=l(rf,"TD",{class:!0});var n9=r(eu);cw=n(n9,"Network_alpha too high"),n9.forEach(t),uw=u(rf),tu=l(rf,"TD",{class:!0});var c9=r(tu);fw=n(c9,"Set alpha = dim/2 (e.g., 64/2 = 32)"),c9.forEach(t),rf.forEach(t),dw=u(X),bt=l(X,"TR",{class:!0});var of=r(bt);su=l(of,"TD",{class:!0});var u9=r(su);pw=n(u9,"Loss divergence"),u9.forEach(t),hw=u(of),au=l(of,"TD",{class:!0});var f9=r(au);gw=n(f9,"Text encoder LR too high"),f9.forEach(t),mw=u(of),lu=l(of,"TD",{class:!0});var d9=r(lu);vw=n(d9,"Reduce text_encoder_lr by 10x"),d9.forEach(t),of.forEach(t),_w=u(X),xt=l(X,"TR",{class:!0});var nf=r(xt);ru=l(nf,"TD",{class:!0});var p9=r(ru);kw=n(p9,"Poor prompt adherence"),p9.forEach(t),Ew=u(nf),iu=l(nf,"TD",{class:!0});var h9=r(iu);bw=n(h9,"Clip skip too high"),h9.forEach(t),xw=u(nf),ou=l(nf,"TD",{class:!0});var g9=r(ou);yw=n(g9,"Reduce clip_skip to 1-2"),g9.forEach(t),nf.forEach(t),ww=u(X),yt=l(X,"TR",{class:!0});var cf=r(yt);nu=l(cf,"TD",{class:!0});var m9=r(nu);Tw=n(m9,"Memory errors"),m9.forEach(t),Rw=u(cf),cu=l(cf,"TD",{class:!0});var v9=r(cu);Sw=n(v9,"Resolution too high"),v9.forEach(t),Dw=u(cf),uu=l(cf,"TD",{class:!0});var _9=r(uu);Aw=n(_9,"Reduce to 512-768px, enable gradient checkpointing"),_9.forEach(t),cf.forEach(t),X.forEach(t),Jm.forEach(t),Qg=u(s),ba=l(s,"H2",{id:!0});var s6=r(ba);xa=l(s6,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var k9=r(xa);hp=l(k9,"SPAN",{class:!0}),r(hp).forEach(t),k9.forEach(t),Lw=n(s6,"Results"),s6.forEach(t),Jg=u(s),fu=l(s,"P",{});var E9=r(fu);Iw=n(E9,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),E9.forEach(t),$g=u(s),du=l(s,"P",{});var b9=r(du);Pw=n(b9,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),b9.forEach(t),em=u(s),Zl=l(s,"P",{class:!0});var x9=r(Zl);Ql=l(x9,"IMG",{src:!0,alt:!0,class:!0}),x9.forEach(t),tm=u(s),pu=l(s,"P",{});var y9=r(pu);Ow=n(y9,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),y9.forEach(t),sm=u(s),Gt=l(s,"H2",{id:!0,class:!0});var a6=r(Gt);ya=l(a6,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w9=r(ya);gp=l(w9,"SPAN",{class:!0}),r(gp).forEach(t),w9.forEach(t),zw=n(a6,"spacelab"),a6.forEach(t),am=u(s),Te&&Te.l(s),lm=uf(),this.h()},h(){i(T,"class","icon icon-link"),i(w,"aria-hidden","true"),i(w,"tabindex","-1"),i(w,"href","#experiment-1-anime-inspired-heroism"),i(b,"id","experiment-1-anime-inspired-heroism"),Mt(I.src,P="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png")||i(I,"src",P),i(I,"alt","image"),i(I,"class","svelte-x2kgxs"),i(y,"class","svelte-x2kgxs"),i(R,"class","icon icon-link"),i(q,"aria-hidden","true"),i(q,"tabindex","-1"),i(q,"href","#experiment-2-retro-cartoon-resurrection"),i(Z,"id","experiment-2-retro-cartoon-resurrection"),Mt(fe.src,ff="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1738190889/blog/fiz3ariex9rpsoovdccl.png")||i(fe,"src",ff),i(fe,"alt","image"),i(fe,"class","svelte-x2kgxs"),i(Se,"class","svelte-x2kgxs"),i(df,"class","icon icon-link"),i(Ft,"aria-hidden","true"),i(Ft,"tabindex","-1"),i(Ft,"href","#what-are-regularization-images"),i(jt,"id","what-are-regularization-images"),i(rr,"class","svelte-x2kgxs"),i(Ga,"class","svelte-x2kgxs"),i(ur,"class","svelte-x2kgxs"),i(fr,"class","svelte-x2kgxs"),i(dr,"class","svelte-x2kgxs"),i(De,"class","svelte-x2kgxs"),i(cr,"class","svelte-x2kgxs"),i(pr,"class","svelte-x2kgxs"),i(hr,"class","svelte-x2kgxs"),i(gr,"class","svelte-x2kgxs"),i(Le,"class","svelte-x2kgxs"),i(mr,"class","svelte-x2kgxs"),i(vr,"class","svelte-x2kgxs"),i(_r,"class","svelte-x2kgxs"),i(Ie,"class","svelte-x2kgxs"),i(kr,"class","svelte-x2kgxs"),i(Er,"class","svelte-x2kgxs"),i(br,"class","svelte-x2kgxs"),i(Pe,"class","svelte-x2kgxs"),i(Ae,"class","svelte-x2kgxs"),i(Dt,"class","svelte-x2kgxs"),i(wr,"class","svelte-x2kgxs"),i(qa,"class","svelte-x2kgxs"),i(mf,"class","icon icon-link"),i(Vt,"aria-hidden","true"),i(Vt,"tabindex","-1"),i(Vt,"href","#scenario-1-limited-training-data"),i(Yt,"id","scenario-1-limited-training-data"),i(Ef,"class","icon icon-link"),i(Xt,"aria-hidden","true"),i(Xt,"tabindex","-1"),i(Xt,"href","#scenario-2-imbalanced-training-data"),i(Kt,"id","scenario-2-imbalanced-training-data"),i(wf,"class","icon icon-link"),i(Qt,"aria-hidden","true"),i(Qt,"tabindex","-1"),i(Qt,"href","#divergence"),i(Zt,"id","divergence"),i(Sr,"class","svelte-x2kgxs"),i(Dr,"class","svelte-x2kgxs"),i(Va,"class","svelte-x2kgxs"),i(If,"class","icon icon-link"),i(es,"aria-hidden","true"),i(es,"tabindex","-1"),i(es,"href","#overfitting"),i($t,"id","overfitting"),i(Cf,"class","icon icon-link"),i(ss,"aria-hidden","true"),i(ss,"tabindex","-1"),i(ss,"href","#key-differences"),i(ts,"id","key-differences"),i(zr,"class","svelte-x2kgxs"),i(Nr,"class","svelte-x2kgxs"),i(Cr,"class","svelte-x2kgxs"),i(Ce,"class","svelte-x2kgxs"),i(Or,"class","svelte-x2kgxs"),i(Gr,"class","svelte-x2kgxs"),i(Hr,"class","svelte-x2kgxs"),i(qr,"class","svelte-x2kgxs"),i(Ge,"class","svelte-x2kgxs"),i(Mr,"class","svelte-x2kgxs"),i(Ur,"class","svelte-x2kgxs"),i(Br,"class","svelte-x2kgxs"),i(He,"class","svelte-x2kgxs"),i(Wr,"class","svelte-x2kgxs"),i(jr,"class","svelte-x2kgxs"),i(Fr,"class","svelte-x2kgxs"),i(qe,"class","svelte-x2kgxs"),i(Yr,"class","svelte-x2kgxs"),i(Vr,"class","svelte-x2kgxs"),i(Kr,"class","svelte-x2kgxs"),i(Me,"class","svelte-x2kgxs"),i(de,"class","svelte-x2kgxs"),i(At,"class","svelte-x2kgxs"),i(Ff,"class","icon icon-link"),i(ls,"aria-hidden","true"),i(ls,"tabindex","-1"),i(ls,"href","#preventing-divergence"),i(as,"id","preventing-divergence"),i(Zr,"class","svelte-x2kgxs"),i(Qr,"class","svelte-x2kgxs"),i(rs,"class","svelte-x2kgxs"),i(Xr,"class","svelte-x2kgxs"),i(Jr,"class","svelte-x2kgxs"),i($r,"class","svelte-x2kgxs"),i(is,"class","svelte-x2kgxs"),i(ei,"class","svelte-x2kgxs"),i(ti,"class","svelte-x2kgxs"),i(os,"class","svelte-x2kgxs"),i(si,"class","svelte-x2kgxs"),i(ai,"class","svelte-x2kgxs"),i(ns,"class","svelte-x2kgxs"),i(li,"class","svelte-x2kgxs"),i(ri,"class","svelte-x2kgxs"),i(cs,"class","svelte-x2kgxs"),i(pe,"class","svelte-x2kgxs"),i(Lt,"class","svelte-x2kgxs"),i(Zf,"class","icon icon-link"),i(fs,"aria-hidden","true"),i(fs,"tabindex","-1"),i(fs,"href","#implementing-these-strategies"),i(us,"id","implementing-these-strategies"),i(Ka,"class","language-python"),i(Xa,"class","language-python"),i(Qf,"class","icon icon-link"),i(ps,"aria-hidden","true"),i(ps,"tabindex","-1"),i(ps,"href","#data-considerations"),i(ds,"id","data-considerations"),i(ni,"class","svelte-x2kgxs"),i(ci,"class","svelte-x2kgxs"),i(ui,"class","svelte-x2kgxs"),i(Ue,"class","svelte-x2kgxs"),i(oi,"class","svelte-x2kgxs"),i(fi,"class","svelte-x2kgxs"),i(di,"class","svelte-x2kgxs"),i(pi,"class","svelte-x2kgxs"),i(Be,"class","svelte-x2kgxs"),i(hi,"class","svelte-x2kgxs"),i(gi,"class","svelte-x2kgxs"),i(mi,"class","svelte-x2kgxs"),i(We,"class","svelte-x2kgxs"),i(vi,"class","svelte-x2kgxs"),i(_i,"class","svelte-x2kgxs"),i(ki,"class","svelte-x2kgxs"),i(je,"class","svelte-x2kgxs"),i(Ei,"class","svelte-x2kgxs"),i(bi,"class","svelte-x2kgxs"),i(xi,"class","svelte-x2kgxs"),i(Fe,"class","svelte-x2kgxs"),i(he,"class","svelte-x2kgxs"),i(It,"class","svelte-x2kgxs"),i(Jf,"class","icon icon-link"),i(gs,"aria-hidden","true"),i(gs,"tabindex","-1"),i(gs,"href","#monitoring-tips"),i(hs,"id","monitoring-tips"),i(Za,"href","https://github.com/kohya-ss/sd-scripts"),i(Za,"rel","nofollow"),i($f,"class","icon icon-link"),i(_s,"aria-hidden","true"),i(_s,"tabindex","-1"),i(_s,"href","#track-loss-curves"),i(vs,"id","track-loss-curves"),i(Qa,"href","https://www.tensorflow.org/tensorboard"),i(Qa,"rel","nofollow"),i(Ja,"class","language-bash"),i(ed,"class","icon icon-link"),i(bs,"aria-hidden","true"),i(bs,"tabindex","-1"),i(bs,"href","#what-to-monitor"),i(Es,"id","what-to-monitor"),i(ld,"class","icon icon-link"),i(ys,"aria-hidden","true"),i(ys,"tabindex","-1"),i(ys,"href","#warning-signs"),i(xs,"id","warning-signs"),i(nd,"class","icon icon-link"),i(Ts,"aria-hidden","true"),i(Ts,"tabindex","-1"),i(Ts,"href","#generate-validation-images-every-100-steps"),i(ws,"id","generate-validation-images-every-100-steps"),i(el,"class","language-json"),i(ud,"class","icon icon-link"),i(Ss,"aria-hidden","true"),i(Ss,"tabindex","-1"),i(Ss,"href","#what-to-look-for"),i(Rs,"id","what-to-look-for"),i(yi,"class","svelte-x2kgxs"),i(tl,"class","svelte-x2kgxs"),i(hd,"class","icon icon-link"),i(As,"aria-hidden","true"),i(As,"tabindex","-1"),i(As,"href","#use-gradient-clipping"),i(Ds,"id","use-gradient-clipping"),i(Ti,"class","svelte-x2kgxs"),i(Ri,"class","svelte-x2kgxs"),i(ll,"class","svelte-x2kgxs"),i(_d,"class","icon icon-link"),i(Is,"aria-hidden","true"),i(Is,"tabindex","-1"),i(Is,"href","#enable-mixed-precision-training"),i(Ls,"id","enable-mixed-precision-training"),i(il,"class","language-python"),i(Di,"class","svelte-x2kgxs"),i(ol,"class","svelte-x2kgxs"),i(yd,"class","icon icon-link"),i(Os,"aria-hidden","true"),i(Os,"tabindex","-1"),i(Os,"href","#start-with-conservative-learning-rates"),i(Ps,"id","start-with-conservative-learning-rates"),i(nl,"class","language-yml"),i(cl,"class","language-python"),i(Li,"class","svelte-x2kgxs"),i(Ii,"class","svelte-x2kgxs"),i(Pi,"class","svelte-x2kgxs"),i(Oi,"class","svelte-x2kgxs"),i(ge,"class","svelte-x2kgxs"),i(Ai,"class","svelte-x2kgxs"),i(zi,"class","svelte-x2kgxs"),i(Ni,"class","svelte-x2kgxs"),i(Ci,"class","svelte-x2kgxs"),i(Gi,"class","svelte-x2kgxs"),i(me,"class","svelte-x2kgxs"),i(Hi,"class","svelte-x2kgxs"),i(qi,"class","svelte-x2kgxs"),i(Mi,"class","svelte-x2kgxs"),i(Ui,"class","svelte-x2kgxs"),i(ve,"class","svelte-x2kgxs"),i(Bi,"class","svelte-x2kgxs"),i(Wi,"class","svelte-x2kgxs"),i(Ns,"class","svelte-x2kgxs"),i(ji,"class","svelte-x2kgxs"),i(Fi,"class","svelte-x2kgxs"),i(Je,"class","svelte-x2kgxs"),i(_e,"class","svelte-x2kgxs"),i(Yi,"class","svelte-x2kgxs"),i(Vi,"class","svelte-x2kgxs"),i(Ki,"class","svelte-x2kgxs"),i(Xi,"class","svelte-x2kgxs"),i(ke,"class","svelte-x2kgxs"),i(Zi,"class","svelte-x2kgxs"),i(Qi,"class","svelte-x2kgxs"),i(Ji,"class","svelte-x2kgxs"),i($i,"class","svelte-x2kgxs"),i(Ee,"class","svelte-x2kgxs"),i(le,"class","svelte-x2kgxs"),i(Pt,"class","svelte-x2kgxs"),i(Ld,"class","icon icon-link"),i(Gs,"aria-hidden","true"),i(Gs,"tabindex","-1"),i(Gs,"href","#generating-regularization-images"),i(Cs,"id","generating-regularization-images"),i(eo,"class","svelte-x2kgxs"),i(to,"class","svelte-x2kgxs"),i(so,"class","svelte-x2kgxs"),i(ao,"class","svelte-x2kgxs"),i(lo,"class","svelte-x2kgxs"),i(Id,"class","icon icon-link"),i(Ms,"aria-hidden","true"),i(Ms,"tabindex","-1"),i(Ms,"href","#important-considerations"),i(qs,"id","important-considerations"),i(Hd,"class","icon icon-link"),i(Bs,"aria-hidden","true"),i(Bs,"tabindex","-1"),i(Bs,"href","#generate-using-stable-diffusion-web-ui"),i(Us,"id","generate-using-stable-diffusion-web-ui"),i(gl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(gl,"rel","nofollow"),i(io,"class","svelte-x2kgxs"),i(oo,"class","svelte-x2kgxs"),i(co,"class","svelte-x2kgxs"),i(uo,"class","svelte-x2kgxs"),i(fo,"class","svelte-x2kgxs"),i(po,"class","svelte-x2kgxs"),i(ho,"class","svelte-x2kgxs"),i(go,"class","svelte-x2kgxs"),i(mo,"class","svelte-x2kgxs"),i(vo,"class","svelte-x2kgxs"),i(_o,"class","svelte-x2kgxs"),i(ko,"class","svelte-x2kgxs"),i(Eo,"class","svelte-x2kgxs"),i(bo,"class","svelte-x2kgxs"),i(xo,"class","svelte-x2kgxs"),i(yo,"class","svelte-x2kgxs"),i(wo,"class","svelte-x2kgxs"),i(To,"class","svelte-x2kgxs"),i(Ro,"class","svelte-x2kgxs"),i(So,"class","svelte-x2kgxs"),i(Do,"class","svelte-x2kgxs"),i(Ao,"class","svelte-x2kgxs"),i(Lo,"class","svelte-x2kgxs"),i(Io,"class","svelte-x2kgxs"),i(Po,"class","svelte-x2kgxs"),i(Oo,"class","svelte-x2kgxs"),i(zo,"class","svelte-x2kgxs"),i(Co,"class","svelte-x2kgxs"),i(Go,"class","svelte-x2kgxs"),i(Ho,"class","svelte-x2kgxs"),i(qo,"class","svelte-x2kgxs"),i(Mo,"class","svelte-x2kgxs"),i(Yd,"class","icon icon-link"),i(Ys,"aria-hidden","true"),i(Ys,"tabindex","-1"),i(Ys,"href","#download-images"),i(Fs,"id","download-images"),i(_l,"href","https://huggingface.co/3ee"),i(_l,"rel","nofollow"),i(kl,"href","https://github.com/Luehrsen/sd_regularization_images"),i(kl,"rel","nofollow"),i(El,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(El,"rel","nofollow"),i(bl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(bl,"rel","nofollow"),i(Vd,"class","icon icon-link"),i(Ks,"aria-hidden","true"),i(Ks,"tabindex","-1"),i(Ks,"href","#captioning-regularization-images"),i(Vs,"id","captioning-regularization-images"),i(Yo,"class","svelte-x2kgxs"),i(xl,"class","language-shell"),i(Vo,"class","svelte-x2kgxs"),i(Ko,"class","svelte-x2kgxs"),i(Xo,"class","svelte-x2kgxs"),i(Zo,"class","svelte-x2kgxs"),i(Kd,"class","icon icon-link"),i(Js,"aria-hidden","true"),i(Js,"tabindex","-1"),i(Js,"href","#training-a-lora"),i(Qs,"id","training-a-lora"),i(wl,"href","https://github.com/kohya-ss/sd-scripts"),i(wl,"rel","nofollow"),i(Rl,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(Rl,"rel","nofollow"),i(ea,"class","svelte-x2kgxs"),i(Tl,"class","svelte-x2kgxs"),i(Xd,"class","icon icon-link"),i(sa,"aria-hidden","true"),i(sa,"tabindex","-1"),i(sa,"href","#directory-setup"),i(ta,"id","directory-setup"),i(Qo,"class","svelte-x2kgxs"),i(Sl,"class","language-json"),i(Dl,"class","language-xml"),i($o,"class","svelte-x2kgxs"),i(en,"class","svelte-x2kgxs"),i(tn,"class","svelte-x2kgxs"),i(sn,"class","svelte-x2kgxs"),Mt(Ll.src,u6="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(Ll,"src",u6),i(Ll,"alt","image"),i(Ll,"class","svelte-x2kgxs"),i(Al,"class","svelte-x2kgxs"),i(ep,"class","icon icon-link"),i(ia,"aria-hidden","true"),i(ia,"tabindex","-1"),i(ia,"href","#training-settings"),i(ra,"id","training-settings"),i(nn,"class","svelte-x2kgxs"),i(cn,"class","svelte-x2kgxs"),i(fn,"class","svelte-x2kgxs"),i(dn,"class","svelte-x2kgxs"),i(pn,"class","svelte-x2kgxs"),i(hn,"class","svelte-x2kgxs"),i(gn,"class","svelte-x2kgxs"),i(re,"class","svelte-x2kgxs"),i(un,"class","svelte-x2kgxs"),i(vn,"class","svelte-x2kgxs"),i(_n,"class","svelte-x2kgxs"),i(kn,"class","svelte-x2kgxs"),i(En,"class","svelte-x2kgxs"),i(bn,"class","svelte-x2kgxs"),i(ie,"class","svelte-x2kgxs"),i(mn,"class","svelte-x2kgxs"),i(zt,"class","svelte-x2kgxs"),i(Il,"class","language-json"),i(wn,"class","svelte-x2kgxs"),i(Rn,"class","svelte-x2kgxs"),i(Dn,"class","svelte-x2kgxs"),i(Ln,"class","svelte-x2kgxs"),i(Pn,"class","svelte-x2kgxs"),i(zn,"class","svelte-x2kgxs"),i(Cn,"class","svelte-x2kgxs"),i(Hn,"class","svelte-x2kgxs"),i(Mn,"class","svelte-x2kgxs"),i(Bn,"class","svelte-x2kgxs"),i(jn,"class","svelte-x2kgxs"),i(tp,"class","icon icon-link"),i(na,"aria-hidden","true"),i(na,"tabindex","-1"),i(na,"href","#fine-tuning"),i(oa,"id","fine-tuning"),i(sp,"class","icon icon-link"),i(ua,"aria-hidden","true"),i(ua,"tabindex","-1"),i(ua,"href","#workflow-with-auto1111-webui"),i(ca,"id","workflow-with-auto1111-webui"),i(jl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(jl,"rel","nofollow"),i(Yn,"class","svelte-x2kgxs"),i(Kn,"class","svelte-x2kgxs"),i(Xn,"class","svelte-x2kgxs"),i(Zn,"class","svelte-x2kgxs"),i(Jn,"class","svelte-x2kgxs"),i($n,"class","svelte-x2kgxs"),i(ec,"class","svelte-x2kgxs"),i(tc,"class","svelte-x2kgxs"),i(sc,"class","svelte-x2kgxs"),i(ac,"class","svelte-x2kgxs"),i(lc,"class","svelte-x2kgxs"),i(rc,"class","svelte-x2kgxs"),i(ip,"class","icon icon-link"),i(ma,"aria-hidden","true"),i(ma,"tabindex","-1"),i(ma,"href","#issues-to-look-for"),i(ga,"id","issues-to-look-for"),Mt(Vl.src,f6="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(Vl,"src",f6),i(Vl,"alt","image"),i(Vl,"class","svelte-x2kgxs"),i(Yl,"class","svelte-x2kgxs"),i(fp,"class","icon icon-link"),i(_a,"aria-hidden","true"),i(_a,"tabindex","-1"),i(_a,"href","#troubleshooting"),i(va,"id","troubleshooting"),i(dc,"class","svelte-x2kgxs"),i(pc,"class","svelte-x2kgxs"),i(gc,"class","svelte-x2kgxs"),i(mc,"class","svelte-x2kgxs"),i(vc,"class","svelte-x2kgxs"),i(nt,"class","svelte-x2kgxs"),i(hc,"class","svelte-x2kgxs"),i(_c,"class","svelte-x2kgxs"),i(kc,"class","svelte-x2kgxs"),i(Ec,"class","svelte-x2kgxs"),i(ct,"class","svelte-x2kgxs"),i(bc,"class","svelte-x2kgxs"),i(xc,"class","svelte-x2kgxs"),i(yc,"class","svelte-x2kgxs"),i(ut,"class","svelte-x2kgxs"),i(wc,"class","svelte-x2kgxs"),i(Tc,"class","svelte-x2kgxs"),i(Rc,"class","svelte-x2kgxs"),i(ft,"class","svelte-x2kgxs"),i(Sc,"class","svelte-x2kgxs"),i(Dc,"class","svelte-x2kgxs"),i(Ac,"class","svelte-x2kgxs"),i(dt,"class","svelte-x2kgxs"),i(we,"class","svelte-x2kgxs"),i(Nt,"class","svelte-x2kgxs"),i(pp,"class","icon icon-link"),i(Ea,"aria-hidden","true"),i(Ea,"tabindex","-1"),i(Ea,"href","#more-solutions"),i(ka,"id","more-solutions"),i(Pc,"class","svelte-x2kgxs"),i(Oc,"class","svelte-x2kgxs"),i(zc,"class","svelte-x2kgxs"),i(pt,"class","svelte-x2kgxs"),i(Ic,"class","svelte-x2kgxs"),i(Nc,"class","svelte-x2kgxs"),i(Cc,"class","svelte-x2kgxs"),i(Gc,"class","svelte-x2kgxs"),i(ht,"class","svelte-x2kgxs"),i(Hc,"class","svelte-x2kgxs"),i(qc,"class","svelte-x2kgxs"),i(Mc,"class","svelte-x2kgxs"),i(gt,"class","svelte-x2kgxs"),i(Uc,"class","svelte-x2kgxs"),i(Bc,"class","svelte-x2kgxs"),i(Wc,"class","svelte-x2kgxs"),i(mt,"class","svelte-x2kgxs"),i(jc,"class","svelte-x2kgxs"),i(Fc,"class","svelte-x2kgxs"),i(Yc,"class","svelte-x2kgxs"),i(vt,"class","svelte-x2kgxs"),i(Vc,"class","svelte-x2kgxs"),i(Kc,"class","svelte-x2kgxs"),i(Xc,"class","svelte-x2kgxs"),i(_t,"class","svelte-x2kgxs"),i(Zc,"class","svelte-x2kgxs"),i(Qc,"class","svelte-x2kgxs"),i(Jc,"class","svelte-x2kgxs"),i(kt,"class","svelte-x2kgxs"),i($c,"class","svelte-x2kgxs"),i(eu,"class","svelte-x2kgxs"),i(tu,"class","svelte-x2kgxs"),i(Et,"class","svelte-x2kgxs"),i(su,"class","svelte-x2kgxs"),i(au,"class","svelte-x2kgxs"),i(lu,"class","svelte-x2kgxs"),i(bt,"class","svelte-x2kgxs"),i(ru,"class","svelte-x2kgxs"),i(iu,"class","svelte-x2kgxs"),i(ou,"class","svelte-x2kgxs"),i(xt,"class","svelte-x2kgxs"),i(nu,"class","svelte-x2kgxs"),i(cu,"class","svelte-x2kgxs"),i(uu,"class","svelte-x2kgxs"),i(yt,"class","svelte-x2kgxs"),i(W,"class","svelte-x2kgxs"),i(Ct,"class","svelte-x2kgxs"),i(hp,"class","icon icon-link"),i(xa,"aria-hidden","true"),i(xa,"tabindex","-1"),i(xa,"href","#results"),i(ba,"id","results"),Mt(Ql.src,d6="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(Ql,"src",d6),i(Ql,"alt","image"),i(Ql,"class","svelte-x2kgxs"),i(Zl,"class","svelte-x2kgxs"),i(gp,"class","icon icon-link"),i(ya,"aria-hidden","true"),i(ya,"tabindex","-1"),i(ya,"href","#spacelab"),i(Gt,"id","spacelab"),i(Gt,"class","svelte-x2kgxs")},m(s,d){f(s,p,d),e(p,m),f(s,g,d),f(s,h,d),e(h,v),f(s,k,d),f(s,b,d),e(b,w),e(w,T),e(b,x),f(s,E,d),f(s,y,d),e(y,I),f(s,N,d),f(s,G,d),e(G,D),f(s,A,d),f(s,S,d),e(S,O),e(O,z),e(S,Q),e(S,j),e(j,F),f(s,B,d),f(s,C,d),e(C,L),f(s,H,d),f(s,Z,d),e(Z,q),e(q,R),e(Z,M),f(s,Wt,d),f(s,Se,d),e(Se,fe),f(s,bp,d),f(s,ar,d),e(ar,av),f(s,xp,d),f(s,jt,d),e(jt,Ft),e(Ft,df),e(jt,lv),f(s,yp,d),f(s,lr,d),e(lr,rv),f(s,wp,d),f(s,Ga,d),e(Ga,rr),e(rr,iv),f(s,Tp,d),tr(Ha,s,d),f(s,Rp,d),f(s,ir,d),e(ir,ov),f(s,Sp,d),f(s,or,d),e(or,nv),f(s,Dp,d),f(s,nr,d),e(nr,cv),f(s,Ap,d),f(s,Dt,d),e(Dt,cr),e(cr,De),e(De,ur),e(ur,uv),e(De,fv),e(De,fr),e(fr,dv),e(De,pv),e(De,dr),e(dr,hv),e(Dt,gv),e(Dt,Ae),e(Ae,Le),e(Le,pr),e(pr,pf),e(pf,mv),e(Le,vv),e(Le,hr),e(hr,_v),e(Le,kv),e(Le,gr),e(gr,Ev),e(Ae,bv),e(Ae,Ie),e(Ie,mr),e(mr,hf),e(hf,xv),e(Ie,yv),e(Ie,vr),e(vr,wv),e(Ie,Tv),e(Ie,_r),e(_r,Rv),e(Ae,Sv),e(Ae,Pe),e(Pe,kr),e(kr,gf),e(gf,Dv),e(Pe,Av),e(Pe,Er),e(Er,Lv),e(Pe,Iv),e(Pe,br),e(br,Pv),f(s,Lp,d),f(s,xr,d),e(xr,Ov),f(s,Ip,d),f(s,yr,d),e(yr,zv),f(s,Pp,d),f(s,qa,d),e(qa,wr),e(wr,Nv),f(s,Op,d),f(s,Yt,d),e(Yt,Vt),e(Vt,mf),e(Yt,Cv),f(s,zp,d),f(s,Ma,d),e(Ma,vf),e(vf,Gv),e(Ma,Hv),f(s,Np,d),f(s,Ua,d),e(Ua,_f),e(_f,qv),e(Ua,Mv),f(s,Cp,d),f(s,Ba,d),e(Ba,kf),e(kf,Uv),e(Ba,Bv),f(s,Gp,d),f(s,Kt,d),e(Kt,Xt),e(Xt,Ef),e(Kt,Wv),f(s,Hp,d),f(s,Wa,d),e(Wa,bf),e(bf,jv),e(Wa,Fv),f(s,qp,d),f(s,ja,d),e(ja,xf),e(xf,Yv),e(ja,Vv),f(s,Mp,d),f(s,Fa,d),e(Fa,yf),e(yf,Kv),e(Fa,Xv),f(s,Up,d),f(s,Zt,d),e(Zt,Qt),e(Qt,wf),e(Zt,Zv),f(s,Bp,d),f(s,Ya,d),e(Ya,Tf),e(Tf,Qv),e(Ya,Jv),f(s,Wp,d),f(s,Oe,d),e(Oe,$v),e(Oe,Rf),e(Rf,e2),e(Oe,t2),e(Oe,Sf),e(Sf,s2),e(Oe,a2),f(s,jp,d),f(s,ze,d),e(ze,Tr),e(Tr,Df),e(Df,l2),e(Tr,r2),e(ze,i2),e(ze,Rr),e(Rr,Af),e(Af,o2),e(Rr,n2),e(ze,c2),e(ze,Jt),e(Jt,Lf),e(Lf,u2),e(Jt,f2),e(Jt,Sr),e(Sr,d2),e(Jt,p2),f(s,Fp,d),f(s,Va,d),e(Va,Dr),e(Dr,h2),f(s,Yp,d),f(s,$t,d),e($t,es),e(es,If),e($t,Pf),e(Pf,g2),f(s,Vp,d),f(s,Ar,d),e(Ar,m2),f(s,Kp,d),f(s,Ne,d),e(Ne,Lr),e(Lr,Of),e(Of,v2),e(Lr,_2),e(Ne,k2),e(Ne,Ir),e(Ir,zf),e(zf,E2),e(Ir,b2),e(Ne,x2),e(Ne,Pr),e(Pr,Nf),e(Nf,y2),e(Pr,w2),f(s,Xp,d),f(s,ts,d),e(ts,ss),e(ss,Cf),e(ts,Gf),e(Gf,T2),f(s,Zp,d),f(s,At,d),e(At,Or),e(Or,Ce),e(Ce,zr),e(zr,Hf),e(Hf,R2),e(Ce,S2),e(Ce,Nr),e(Nr,qf),e(qf,D2),e(Ce,A2),e(Ce,Cr),e(Cr,Mf),e(Mf,L2),e(At,I2),e(At,de),e(de,Ge),e(Ge,Gr),e(Gr,Uf),e(Uf,P2),e(Ge,O2),e(Ge,Hr),e(Hr,z2),e(Ge,N2),e(Ge,qr),e(qr,C2),e(de,G2),e(de,He),e(He,Mr),e(Mr,Bf),e(Bf,H2),e(He,q2),e(He,Ur),e(Ur,M2),e(He,U2),e(He,Br),e(Br,B2),e(de,W2),e(de,qe),e(qe,Wr),e(Wr,Wf),e(Wf,j2),e(qe,F2),e(qe,jr),e(jr,Y2),e(qe,V2),e(qe,Fr),e(Fr,K2),e(de,X2),e(de,Me),e(Me,Yr),e(Yr,jf),e(jf,Z2),e(Me,Q2),e(Me,Vr),e(Vr,J2),e(Me,$2),e(Me,Kr),e(Kr,e_),f(s,Qp,d),f(s,as,d),e(as,ls),e(ls,Ff),e(as,t_),f(s,Jp,d),f(s,Lt,d),e(Lt,Xr),e(Xr,rs),e(rs,Zr),e(Zr,s_),e(rs,a_),e(rs,Qr),e(Qr,l_),e(Lt,r_),e(Lt,pe),e(pe,is),e(is,Jr),e(Jr,Yf),e(Yf,i_),e(is,o_),e(is,$r),e($r,n_),e(pe,c_),e(pe,os),e(os,ei),e(ei,Vf),e(Vf,u_),e(os,f_),e(os,ti),e(ti,d_),e(pe,p_),e(pe,ns),e(ns,si),e(si,Kf),e(Kf,h_),e(ns,g_),e(ns,ai),e(ai,m_),e(pe,v_),e(pe,cs),e(cs,li),e(li,Xf),e(Xf,__),e(cs,k_),e(cs,ri),e(ri,E_),f(s,$p,d),f(s,ii,d),e(ii,b_),f(s,eh,d),f(s,us,d),e(us,fs),e(fs,Zf),e(us,x_),f(s,th,d),f(s,Ka,d),Ka.innerHTML=z9,f(s,sh,d),f(s,Xa,d),Xa.innerHTML=N9,f(s,ah,d),f(s,ds,d),e(ds,ps),e(ps,Qf),e(ds,y_),f(s,lh,d),f(s,It,d),e(It,oi),e(oi,Ue),e(Ue,ni),e(ni,w_),e(Ue,T_),e(Ue,ci),e(ci,R_),e(Ue,S_),e(Ue,ui),e(ui,D_),e(It,A_),e(It,he),e(he,Be),e(Be,fi),e(fi,L_),e(Be,I_),e(Be,di),e(di,P_),e(Be,O_),e(Be,pi),e(pi,z_),e(he,N_),e(he,We),e(We,hi),e(hi,C_),e(We,G_),e(We,gi),e(gi,H_),e(We,q_),e(We,mi),e(mi,M_),e(he,U_),e(he,je),e(je,vi),e(vi,B_),e(je,W_),e(je,_i),e(_i,j_),e(je,F_),e(je,ki),e(ki,Y_),e(he,V_),e(he,Fe),e(Fe,Ei),e(Ei,K_),e(Fe,X_),e(Fe,bi),e(bi,Z_),e(Fe,Q_),e(Fe,xi),e(xi,J_),f(s,rh,d),f(s,ih,d),f(s,oh,d),f(s,hs,d),e(hs,gs),e(gs,Jf),e(hs,$_),f(s,nh,d),f(s,ms,d),e(ms,e1),e(ms,Za),e(Za,t1),e(ms,s1),f(s,ch,d),f(s,vs,d),e(vs,_s),e(_s,$f),e(vs,a1),f(s,uh,d),f(s,ks,d),e(ks,l1),e(ks,Qa),e(Qa,r1),e(ks,i1),f(s,fh,d),f(s,Ja,d),Ja.innerHTML=C9,f(s,dh,d),f(s,Es,d),e(Es,bs),e(bs,ed),e(Es,o1),f(s,ph,d),f(s,Ye,d),e(Ye,td),e(td,n1),e(Ye,c1),e(Ye,sd),e(sd,u1),e(Ye,f1),e(Ye,ad),e(ad,d1),f(s,hh,d),f(s,xs,d),e(xs,ys),e(ys,ld),e(xs,p1),f(s,gh,d),f(s,Ve,d),e(Ve,rd),e(rd,h1),e(Ve,g1),e(Ve,id),e(id,m1),e(Ve,v1),e(Ve,od),e(od,_1),f(s,mh,d),f(s,ws,d),e(ws,Ts),e(Ts,nd),e(ws,k1),f(s,vh,d),f(s,$a,d),e($a,cd),e(cd,E1),e($a,b1),f(s,_h,d),f(s,el,d),el.innerHTML=G9,f(s,kh,d),f(s,Rs,d),e(Rs,Ss),e(Ss,ud),e(Rs,x1),f(s,Eh,d),f(s,Ke,d),e(Ke,fd),e(fd,y1),e(Ke,w1),e(Ke,dd),e(dd,T1),e(Ke,R1),e(Ke,pd),e(pd,S1),f(s,bh,d),f(s,tl,d),e(tl,yi),e(yi,D1),f(s,xh,d),f(s,Ds,d),e(Ds,As),e(As,hd),e(Ds,A1),f(s,yh,d),f(s,sl,d),e(sl,gd),e(gd,L1),e(sl,I1),f(s,wh,d),f(s,wi,d),e(wi,P1),f(s,Th,d),f(s,Xe,d),e(Xe,al),e(al,O1),e(al,Ti),e(Ti,z1),e(al,N1),e(Xe,C1),e(Xe,md),e(md,G1),e(Xe,H1),e(Xe,vd),e(vd,q1),f(s,Rh,d),f(s,ll,d),e(ll,Ri),e(Ri,M1),f(s,Sh,d),f(s,Ls,d),e(Ls,Is),e(Is,_d),e(Ls,U1),f(s,Dh,d),f(s,rl,d),e(rl,kd),e(kd,B1),e(rl,W1),f(s,Ah,d),f(s,il,d),il.innerHTML=H9,f(s,Lh,d),f(s,Si,d),e(Si,j1),f(s,Ih,d),f(s,Ze,d),e(Ze,Ed),e(Ed,F1),e(Ze,Y1),e(Ze,bd),e(bd,V1),e(Ze,K1),e(Ze,xd),e(xd,X1),f(s,Ph,d),f(s,ol,d),e(ol,Di),e(Di,Z1),f(s,Oh,d),f(s,Ps,d),e(Ps,Os),e(Os,yd),e(Ps,Q1),f(s,zh,d),f(s,zs,d),e(zs,J1),e(zs,wd),e(wd,$1),e(zs,ek),f(s,Nh,d),f(s,nl,d),nl.innerHTML=q9,f(s,Ch,d),f(s,cl,d),cl.innerHTML=M9,f(s,Gh,d),f(s,ul,d),e(ul,Td),e(Td,tk),e(ul,sk),f(s,Hh,d),f(s,Qe,d),e(Qe,Rd),e(Rd,ak),e(Qe,lk),e(Qe,Sd),e(Sd,rk),e(Qe,ik),e(Qe,Dd),e(Dd,ok),f(s,qh,d),f(s,Pt,d),e(Pt,Ai),e(Ai,ge),e(ge,Li),e(Li,nk),e(ge,ck),e(ge,Ii),e(Ii,uk),e(ge,fk),e(ge,Pi),e(Pi,dk),e(ge,pk),e(ge,Oi),e(Oi,hk),e(Pt,gk),e(Pt,le),e(le,me),e(me,zi),e(zi,mk),e(me,vk),e(me,Ni),e(Ni,_k),e(me,kk),e(me,Ci),e(Ci,Ek),e(me,bk),e(me,Gi),e(Gi,xk),e(le,yk),e(le,ve),e(ve,Hi),e(Hi,wk),e(ve,Tk),e(ve,qi),e(qi,Rk),e(ve,Sk),e(ve,Mi),e(Mi,Dk),e(ve,Ak),e(ve,Ui),e(Ui,Lk),e(le,Ik),e(le,_e),e(_e,Bi),e(Bi,Pk),e(_e,Ok),e(_e,Wi),e(Wi,zk),e(_e,Nk),e(_e,Ns),e(Ns,Ck),e(Ns,Ad),e(Ad,Gk),e(Ns,Hk),e(_e,qk),e(_e,Je),e(Je,Mk),e(Je,ji),e(ji,Uk),e(Je,Bk),e(Je,Fi),e(Fi,Wk),e(Je,jk),e(le,Fk),e(le,ke),e(ke,Yi),e(Yi,Yk),e(ke,Vk),e(ke,Vi),e(Vi,Kk),e(ke,Xk),e(ke,Ki),e(Ki,Zk),e(ke,Qk),e(ke,Xi),e(Xi,Jk),e(le,$k),e(le,Ee),e(Ee,Zi),e(Zi,eE),e(Ee,tE),e(Ee,Qi),e(Qi,sE),e(Ee,aE),e(Ee,Ji),e(Ji,lE),e(Ee,rE),e(Ee,$i),e($i,iE),f(s,Mh,d),f(s,Uh,d),f(s,Bh,d),f(s,Cs,d),e(Cs,Gs),e(Gs,Ld),e(Cs,oE),f(s,Wh,d),f(s,Hs,d),e(Hs,nE),e(Hs,eo),e(eo,cE),e(Hs,uE),f(s,jh,d),f(s,ue,d),e(ue,fE),e(ue,to),e(to,dE),e(ue,pE),e(ue,so),e(so,hE),e(ue,gE),e(ue,ao),e(ao,mE),e(ue,vE),e(ue,lo),e(lo,_E),f(s,Fh,d),f(s,ro,d),e(ro,kE),f(s,Yh,d),f(s,qs,d),e(qs,Ms),e(Ms,Id),e(qs,EE),f(s,Vh,d),f(s,$e,d),e($e,Pd),e(Pd,fl),e(fl,Od),e(Od,bE),e(fl,xE),e(fl,yE),e($e,wE),e($e,zd),e(zd,dl),e(dl,Nd),e(Nd,TE),e(dl,RE),e(dl,SE),e($e,DE),e($e,Cd),e(Cd,pl),e(pl,Gd),e(Gd,AE),e(pl,LE),e(pl,IE),f(s,Kh,d),tr(hl,s,d),f(s,Xh,d),f(s,Us,d),e(Us,Bs),e(Bs,Hd),e(Us,PE),f(s,Zh,d),f(s,Ws,d),e(Ws,OE),e(Ws,gl),e(gl,zE),e(Ws,NE),f(s,Qh,d),f(s,et,d),e(et,CE),e(et,io),e(io,GE),e(et,HE),e(et,oo),e(oo,qE),e(et,ME),f(s,Jh,d),f(s,J,d),e(J,qd),e(qd,no),e(no,UE),e(no,co),e(co,BE),e(J,WE),e(J,Md),e(Md,ml),e(ml,jE),e(ml,uo),e(uo,FE),e(ml,YE),e(J,VE),e(J,Ud),e(Ud,V),e(V,KE),e(V,fo),e(fo,XE),e(V,ZE),e(V,po),e(po,QE),e(V,JE),e(V,ho),e(ho,$E),e(V,eb),e(V,go),e(go,tb),e(V,sb),e(V,mo),e(mo,ab),e(V,lb),e(V,vo),e(vo,rb),e(V,ib),e(V,_o),e(_o,ob),e(V,nb),e(V,ko),e(ko,cb),e(J,ub),e(J,Bd),e(Bd,$),e($,fb),e($,Eo),e(Eo,db),e($,pb),e($,bo),e(bo,hb),e($,gb),e($,xo),e(xo,mb),e($,vb),e($,yo),e(yo,_b),e($,kb),e($,wo),e(wo,Eb),e($,bb),e($,To),e(To,xb),e($,yb),e($,Ro),e(Ro,wb),e(J,Tb),e(J,Wd),e(Wd,K),e(K,Rb),e(K,So),e(So,Sb),e(K,Db),e(K,Do),e(Do,Ab),e(K,Lb),e(K,Ao),e(Ao,Ib),e(K,Pb),e(K,Lo),e(Lo,Ob),e(K,zb),e(K,Io),e(Io,Nb),e(K,Cb),e(K,Po),e(Po,Gb),e(K,Hb),e(K,Oo),e(Oo,qb),e(K,Mb),e(K,zo),e(zo,Ub),e(J,Bb),e(J,jd),e(jd,No),e(No,Wb),e(No,Co),e(Co,jb),e(J,Fb),e(J,Fd),e(Fd,js),e(js,Yb),e(js,Go),e(Go,Vb),e(js,Kb),e(js,Ho),e(Ho,Xb),f(s,$h,d),f(s,tt,d),e(tt,Zb),e(tt,qo),e(qo,Qb),e(tt,Jb),e(tt,Mo),e(Mo,$b),e(tt,ex),f(s,eg,d),tr(vl,s,d),f(s,tg,d),f(s,Fs,d),e(Fs,Ys),e(Ys,Yd),e(Fs,tx),f(s,sg,d),f(s,Uo,d),e(Uo,sx),f(s,ag,d),f(s,be,d),e(be,Bo),e(Bo,_l),e(_l,ax),e(Bo,lx),e(be,rx),e(be,Wo),e(Wo,kl),e(kl,ix),e(Wo,ox),e(be,nx),e(be,jo),e(jo,El),e(El,cx),e(jo,ux),e(be,fx),e(be,Fo),e(Fo,bl),e(bl,dx),e(Fo,px),f(s,lg,d),f(s,Vs,d),e(Vs,Ks),e(Ks,Vd),e(Vs,hx),f(s,rg,d),f(s,Xs,d),e(Xs,gx),e(Xs,Yo),e(Yo,mx),e(Xs,vx),f(s,ig,d),f(s,xl,d),xl.innerHTML=U9,f(s,og,d),f(s,st,d),e(st,_x),e(st,Vo),e(Vo,kx),e(st,Ex),e(st,Ko),e(Ko,bx),e(st,xx),f(s,ng,d),f(s,yl,d),e(yl,yx),e(yl,Xo),e(Xo,wx),f(s,cg,d),f(s,Zs,d),e(Zs,Tx),e(Zs,Zo),e(Zo,Rx),e(Zs,Sx),f(s,ug,d),f(s,Qs,d),e(Qs,Js),e(Js,Kd),e(Qs,Dx),f(s,fg,d),f(s,$s,d),e($s,Ax),e($s,wl),e(wl,Lx),e($s,Ix),f(s,dg,d),f(s,Tl,d),e(Tl,ea),e(ea,Px),e(ea,Rl),e(Rl,Ox),e(ea,zx),f(s,pg,d),f(s,ta,d),e(ta,sa),e(sa,Xd),e(ta,Nx),f(s,hg,d),f(s,aa,d),e(aa,Cx),e(aa,Qo),e(Qo,Gx),e(aa,Hx),f(s,gg,d),f(s,Sl,d),Sl.innerHTML=B9,f(s,mg,d),f(s,Jo,d),e(Jo,qx),f(s,vg,d),f(s,Dl,d),Dl.innerHTML=W9,f(s,_g,d),f(s,at,d),e(at,Mx),e(at,$o),e($o,Ux),e(at,Bx),e(at,en),e(en,Wx),e(at,jx),f(s,kg,d),f(s,lt,d),e(lt,Fx),e(lt,tn),e(tn,Yx),e(lt,Vx),e(lt,sn),e(sn,Kx),e(lt,Xx),f(s,Eg,d),f(s,an,d),e(an,Zx),f(s,bg,d),f(s,la,d),e(la,ln),e(ln,Qx),e(ln,Zd),e(Zd,Qd),e(Qd,Jx),e(la,$x),e(la,rn),e(rn,ey),e(rn,Jd),e(Jd,$d),e($d,ty),f(s,xg,d),f(s,on,d),e(on,sy),f(s,yg,d),f(s,Al,d),e(Al,Ll),f(s,wg,d),f(s,ra,d),e(ra,ia),e(ia,ep),e(ra,ay),f(s,Tg,d),f(s,Ot,d),e(Ot,ly),e(Ot,nn),e(nn,ry),e(Ot,iy),e(Ot,cn),e(cn,oy),f(s,Rg,d),f(s,zt,d),e(zt,un),e(un,re),e(re,fn),e(fn,ny),e(re,cy),e(re,dn),e(dn,uy),e(re,fy),e(re,pn),e(pn,dy),e(re,py),e(re,hn),e(hn,hy),e(re,gy),e(re,gn),e(gn,my),e(zt,vy),e(zt,mn),e(mn,ie),e(ie,vn),e(vn,_y),e(ie,ky),e(ie,_n),e(_n,Ey),e(ie,by),e(ie,kn),e(kn,xy),e(ie,yy),e(ie,En),e(En,wy),e(ie,Ty),e(ie,bn),e(bn,Ry),f(s,Sg,d),f(s,xn,d),e(xn,Sy),f(s,Dg,d),f(s,Il,d),Il.innerHTML=j9,f(s,Ag,d),f(s,U,d),e(U,yn),e(yn,Pl),e(Pl,Dy),e(Pl,wn),e(wn,Ay),e(Pl,Ly),e(yn,Iy),e(U,Py),e(U,Tn),e(Tn,Ol),e(Ol,Oy),e(Ol,Rn),e(Rn,zy),e(Ol,Ny),e(Tn,Cy),e(U,Gy),e(U,Sn),e(Sn,zl),e(zl,Hy),e(zl,Dn),e(Dn,qy),e(zl,My),e(Sn,Uy),e(U,By),e(U,An),e(An,Nl),e(Nl,Wy),e(Nl,Ln),e(Ln,jy),e(Nl,Fy),e(An,Yy),e(U,Vy),e(U,In),e(In,Cl),e(Cl,Ky),e(Cl,Pn),e(Pn,Xy),e(Cl,Zy),e(In,Qy),e(U,Jy),e(U,On),e(On,Gl),e(Gl,$y),e(Gl,zn),e(zn,e3),e(Gl,t3),e(On,s3),e(U,a3),e(U,Nn),e(Nn,Hl),e(Hl,l3),e(Hl,Cn),e(Cn,r3),e(Hl,i3),e(Nn,o3),e(U,n3),e(U,Gn),e(Gn,ql),e(ql,c3),e(ql,Hn),e(Hn,u3),e(ql,f3),e(Gn,d3),e(U,p3),e(U,qn),e(qn,Ml),e(Ml,h3),e(Ml,Mn),e(Mn,g3),e(Ml,m3),e(qn,v3),e(U,_3),e(U,Un),e(Un,Ul),e(Ul,k3),e(Ul,Bn),e(Bn,E3),e(Ul,b3),e(Un,x3),e(U,y3),e(U,Wn),e(Wn,Bl),e(Bl,w3),e(Bl,jn),e(jn,T3),e(Bl,R3),e(Wn,S3),f(s,Lg,d),f(s,oa,d),e(oa,na),e(na,tp),e(oa,D3),f(s,Ig,d),f(s,Fn,d),e(Fn,A3),f(s,Pg,d),tr(Wl,s,d),f(s,Og,d),f(s,ca,d),e(ca,ua),e(ua,sp),e(ca,L3),f(s,zg,d),f(s,fa,d),e(fa,I3),e(fa,jl),e(jl,P3),e(fa,O3),f(s,Ng,d),f(s,da,d),e(da,z3),e(da,Yn),e(Yn,N3),e(da,C3),f(s,Cg,d),f(s,oe,d),e(oe,Vn),e(Vn,G3),e(Vn,Gg),e(oe,H3),e(oe,ap),e(ap,q3),e(oe,M3),e(oe,rt),e(rt,U3),e(rt,Kn),e(Kn,B3),e(rt,W3),e(rt,Xn),e(Xn,j3),e(rt,F3),e(rt,Zn),e(Zn,Y3),e(oe,V3),e(oe,Qn),e(Qn,K3),e(Qn,Jn),e(Jn,X3),e(oe,Z3),e(oe,pa),e(pa,Q3),e(pa,$n),e($n,J3),e(pa,$3),e(pa,ec),e(ec,e4),f(s,Hg,d),f(s,it,d),e(it,t4),e(it,tc),e(tc,s4),e(it,a4),e(it,sc),e(sc,l4),e(it,r4),f(s,qg,d),f(s,xe,d),e(xe,ha),e(ha,i4),e(ha,ac),e(ac,o4),e(ha,n4),e(ha,lc),e(lc,c4),e(xe,u4),e(xe,Fl),e(Fl,f4),e(Fl,rc),e(rc,d4),e(Fl,p4),e(xe,h4),e(xe,lp),e(lp,g4),e(xe,m4),e(xe,rp),e(rp,v4),f(s,Mg,d),f(s,ga,d),e(ga,ma),e(ma,ip),e(ga,_4),f(s,Ug,d),f(s,ye,d),e(ye,ic),e(ic,op),e(op,k4),e(ic,E4),e(ye,b4),e(ye,oc),e(oc,np),e(np,x4),e(oc,y4),e(ye,w4),e(ye,nc),e(nc,cp),e(cp,T4),e(nc,R4),e(ye,S4),e(ye,cc),e(cc,up),e(up,D4),e(cc,A4),f(s,Bg,d),f(s,uc,d),e(uc,L4),f(s,Wg,d),f(s,Yl,d),e(Yl,Vl),f(s,jg,d),f(s,va,d),e(va,_a),e(_a,fp),e(va,I4),f(s,Fg,d),f(s,fc,d),e(fc,P4),f(s,Yg,d),f(s,ot,d),e(ot,Kl),e(Kl,O4),e(Kl,dc),e(dc,z4),e(Kl,N4),e(ot,C4),e(ot,Xl),e(Xl,G4),e(Xl,pc),e(pc,H4),e(Xl,q4),e(ot,M4),e(ot,dp),e(dp,U4),f(s,Vg,d),f(s,Nt,d),e(Nt,hc),e(hc,nt),e(nt,gc),e(gc,B4),e(nt,W4),e(nt,mc),e(mc,j4),e(nt,F4),e(nt,vc),e(vc,Y4),e(Nt,V4),e(Nt,we),e(we,ct),e(ct,_c),e(_c,K4),e(ct,X4),e(ct,kc),e(kc,Z4),e(ct,Q4),e(ct,Ec),e(Ec,J4),e(we,$4),e(we,ut),e(ut,bc),e(bc,e0),e(ut,t0),e(ut,xc),e(xc,s0),e(ut,a0),e(ut,yc),e(yc,l0),e(we,r0),e(we,ft),e(ft,wc),e(wc,i0),e(ft,o0),e(ft,Tc),e(Tc,n0),e(ft,c0),e(ft,Rc),e(Rc,u0),e(we,f0),e(we,dt),e(dt,Sc),e(Sc,d0),e(dt,p0),e(dt,Dc),e(Dc,h0),e(dt,g0),e(dt,Ac),e(Ac,m0),f(s,Kg,d),f(s,ka,d),e(ka,Ea),e(Ea,pp),e(ka,v0),f(s,Xg,d),f(s,Lc,d),e(Lc,_0),f(s,Zg,d),f(s,Ct,d),e(Ct,Ic),e(Ic,pt),e(pt,Pc),e(Pc,k0),e(pt,E0),e(pt,Oc),e(Oc,b0),e(pt,x0),e(pt,zc),e(zc,y0),e(Ct,w0),e(Ct,W),e(W,ht),e(ht,Nc),e(Nc,T0),e(ht,R0),e(ht,Cc),e(Cc,S0),e(ht,D0),e(ht,Gc),e(Gc,A0),e(W,L0),e(W,gt),e(gt,Hc),e(Hc,I0),e(gt,P0),e(gt,qc),e(qc,O0),e(gt,z0),e(gt,Mc),e(Mc,N0),e(W,C0),e(W,mt),e(mt,Uc),e(Uc,G0),e(mt,H0),e(mt,Bc),e(Bc,q0),e(mt,M0),e(mt,Wc),e(Wc,U0),e(W,B0),e(W,vt),e(vt,jc),e(jc,W0),e(vt,j0),e(vt,Fc),e(Fc,F0),e(vt,Y0),e(vt,Yc),e(Yc,V0),e(W,K0),e(W,_t),e(_t,Vc),e(Vc,X0),e(_t,Z0),e(_t,Kc),e(Kc,Q0),e(_t,J0),e(_t,Xc),e(Xc,$0),e(W,ew),e(W,kt),e(kt,Zc),e(Zc,tw),e(kt,sw),e(kt,Qc),e(Qc,aw),e(kt,lw),e(kt,Jc),e(Jc,rw),e(W,iw),e(W,Et),e(Et,$c),e($c,ow),e(Et,nw),e(Et,eu),e(eu,cw),e(Et,uw),e(Et,tu),e(tu,fw),e(W,dw),e(W,bt),e(bt,su),e(su,pw),e(bt,hw),e(bt,au),e(au,gw),e(bt,mw),e(bt,lu),e(lu,vw),e(W,_w),e(W,xt),e(xt,ru),e(ru,kw),e(xt,Ew),e(xt,iu),e(iu,bw),e(xt,xw),e(xt,ou),e(ou,yw),e(W,ww),e(W,yt),e(yt,nu),e(nu,Tw),e(yt,Rw),e(yt,cu),e(cu,Sw),e(yt,Dw),e(yt,uu),e(uu,Aw),f(s,Qg,d),f(s,ba,d),e(ba,xa),e(xa,hp),e(ba,Lw),f(s,Jg,d),f(s,fu,d),e(fu,Iw),f(s,$g,d),f(s,du,d),e(du,Pw),f(s,em,d),f(s,Zl,d),e(Zl,Ql),f(s,tm,d),f(s,pu,d),e(pu,Ow),f(s,sm,d),f(s,Gt,d),e(Gt,ya),e(ya,gp),e(Gt,zw),f(s,am,d),Te&&Te.m(s,d),f(s,lm,d),rm=!0},p(s,d){O9&&Te.p(s,d)},i(s){rm||(Ut(Ha.$$.fragment,s),Ut(hl.$$.fragment,s),Ut(vl.$$.fragment,s),Ut(Wl.$$.fragment,s),Ut(Te),rm=!0)},o(s){Bt(Ha.$$.fragment,s),Bt(hl.$$.fragment,s),Bt(vl.$$.fragment,s),Bt(Wl.$$.fragment,s),Bt(Te),rm=!1},d(s){s&&t(p),s&&t(g),s&&t(h),s&&t(k),s&&t(b),s&&t(E),s&&t(y),s&&t(N),s&&t(G),s&&t(A),s&&t(S),s&&t(B),s&&t(C),s&&t(H),s&&t(Z),s&&t(Wt),s&&t(Se),s&&t(bp),s&&t(ar),s&&t(xp),s&&t(jt),s&&t(yp),s&&t(lr),s&&t(wp),s&&t(Ga),s&&t(Tp),sr(Ha,s),s&&t(Rp),s&&t(ir),s&&t(Sp),s&&t(or),s&&t(Dp),s&&t(nr),s&&t(Ap),s&&t(Dt),s&&t(Lp),s&&t(xr),s&&t(Ip),s&&t(yr),s&&t(Pp),s&&t(qa),s&&t(Op),s&&t(Yt),s&&t(zp),s&&t(Ma),s&&t(Np),s&&t(Ua),s&&t(Cp),s&&t(Ba),s&&t(Gp),s&&t(Kt),s&&t(Hp),s&&t(Wa),s&&t(qp),s&&t(ja),s&&t(Mp),s&&t(Fa),s&&t(Up),s&&t(Zt),s&&t(Bp),s&&t(Ya),s&&t(Wp),s&&t(Oe),s&&t(jp),s&&t(ze),s&&t(Fp),s&&t(Va),s&&t(Yp),s&&t($t),s&&t(Vp),s&&t(Ar),s&&t(Kp),s&&t(Ne),s&&t(Xp),s&&t(ts),s&&t(Zp),s&&t(At),s&&t(Qp),s&&t(as),s&&t(Jp),s&&t(Lt),s&&t($p),s&&t(ii),s&&t(eh),s&&t(us),s&&t(th),s&&t(Ka),s&&t(sh),s&&t(Xa),s&&t(ah),s&&t(ds),s&&t(lh),s&&t(It),s&&t(rh),s&&t(ih),s&&t(oh),s&&t(hs),s&&t(nh),s&&t(ms),s&&t(ch),s&&t(vs),s&&t(uh),s&&t(ks),s&&t(fh),s&&t(Ja),s&&t(dh),s&&t(Es),s&&t(ph),s&&t(Ye),s&&t(hh),s&&t(xs),s&&t(gh),s&&t(Ve),s&&t(mh),s&&t(ws),s&&t(vh),s&&t($a),s&&t(_h),s&&t(el),s&&t(kh),s&&t(Rs),s&&t(Eh),s&&t(Ke),s&&t(bh),s&&t(tl),s&&t(xh),s&&t(Ds),s&&t(yh),s&&t(sl),s&&t(wh),s&&t(wi),s&&t(Th),s&&t(Xe),s&&t(Rh),s&&t(ll),s&&t(Sh),s&&t(Ls),s&&t(Dh),s&&t(rl),s&&t(Ah),s&&t(il),s&&t(Lh),s&&t(Si),s&&t(Ih),s&&t(Ze),s&&t(Ph),s&&t(ol),s&&t(Oh),s&&t(Ps),s&&t(zh),s&&t(zs),s&&t(Nh),s&&t(nl),s&&t(Ch),s&&t(cl),s&&t(Gh),s&&t(ul),s&&t(Hh),s&&t(Qe),s&&t(qh),s&&t(Pt),s&&t(Mh),s&&t(Uh),s&&t(Bh),s&&t(Cs),s&&t(Wh),s&&t(Hs),s&&t(jh),s&&t(ue),s&&t(Fh),s&&t(ro),s&&t(Yh),s&&t(qs),s&&t(Vh),s&&t($e),s&&t(Kh),sr(hl,s),s&&t(Xh),s&&t(Us),s&&t(Zh),s&&t(Ws),s&&t(Qh),s&&t(et),s&&t(Jh),s&&t(J),s&&t($h),s&&t(tt),s&&t(eg),sr(vl,s),s&&t(tg),s&&t(Fs),s&&t(sg),s&&t(Uo),s&&t(ag),s&&t(be),s&&t(lg),s&&t(Vs),s&&t(rg),s&&t(Xs),s&&t(ig),s&&t(xl),s&&t(og),s&&t(st),s&&t(ng),s&&t(yl),s&&t(cg),s&&t(Zs),s&&t(ug),s&&t(Qs),s&&t(fg),s&&t($s),s&&t(dg),s&&t(Tl),s&&t(pg),s&&t(ta),s&&t(hg),s&&t(aa),s&&t(gg),s&&t(Sl),s&&t(mg),s&&t(Jo),s&&t(vg),s&&t(Dl),s&&t(_g),s&&t(at),s&&t(kg),s&&t(lt),s&&t(Eg),s&&t(an),s&&t(bg),s&&t(la),s&&t(xg),s&&t(on),s&&t(yg),s&&t(Al),s&&t(wg),s&&t(ra),s&&t(Tg),s&&t(Ot),s&&t(Rg),s&&t(zt),s&&t(Sg),s&&t(xn),s&&t(Dg),s&&t(Il),s&&t(Ag),s&&t(U),s&&t(Lg),s&&t(oa),s&&t(Ig),s&&t(Fn),s&&t(Pg),sr(Wl,s),s&&t(Og),s&&t(ca),s&&t(zg),s&&t(fa),s&&t(Ng),s&&t(da),s&&t(Cg),s&&t(oe),s&&t(Hg),s&&t(it),s&&t(qg),s&&t(xe),s&&t(Mg),s&&t(ga),s&&t(Ug),s&&t(ye),s&&t(Bg),s&&t(uc),s&&t(Wg),s&&t(Yl),s&&t(jg),s&&t(va),s&&t(Fg),s&&t(fc),s&&t(Yg),s&&t(ot),s&&t(Vg),s&&t(Nt),s&&t(Kg),s&&t(ka),s&&t(Xg),s&&t(Lc),s&&t(Zg),s&&t(Ct),s&&t(Qg),s&&t(ba),s&&t(Jg),s&&t(fu),s&&t($g),s&&t(du),s&&t(em),s&&t(Zl),s&&t(tm),s&&t(pu),s&&t(sm),s&&t(Gt),s&&t(am),Te&&Te.d(s),s&&t(lm)}}}function GA(_){let p,m;const g=[_[0],c6];let h={$$slots:{default:[CA]},$$scope:{ctx:_}};for(let v=0;v<g.length;v+=1)h=n6(h,g[v]);return p=new cA({props:h}),{c(){$l(p.$$.fragment)},l(v){er(p.$$.fragment,v)},m(v,k){tr(p,v,k),m=!0},p(v,[k]){const b=k&1?nA(g,[k&1&&R9(v[0]),k&0&&R9(c6)]):{};k&2&&(b.$$scope={dirty:k,ctx:v}),p.$set(b)},i(v){m||(Ut(p.$$.fragment,v),m=!0)},o(v){Bt(p.$$.fragment,v),m=!1},d(v){sr(p,v)}}}const c6={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:ZA,date:QA,modifiedDate:JA,categories:$A,svg:eL,seoImage:tL,shortDescription:sL,author:aL,spacelab:O9,id:HA,spacelabDefaultTitle:qA,spacelabDefaultContent:MA,menu:lL,keywords:rL}=c6;function UA(_,p,m){return _.$$set=g=>{m(0,p=n6(n6({},p),S9(g)))},p=S9(p),[p]}class iL extends ev{constructor(p){super(),tv(this,p,UA,GA,sv,{})}}export{iL as default,c6 as metadata};
