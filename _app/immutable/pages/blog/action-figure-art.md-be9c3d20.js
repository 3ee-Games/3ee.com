import{S as C_,i as G_,s as U_,l as Xd,g as p,E as l9,d as t,v as ox,e as a,t as n,c as l,a as r,h as o,b as i,G as e,j as ce,k as c,m as u,F as ee,H as Ae,N as OP,Y as cx,J as ts,f as es,Z as ux,_ as px,$ as dx,q as ss,o as as,O as fx,w as Gr,x as Ur,y as Hr,B as Mr,C as r9,z as hx,A as PP,a1 as xP}from"../../chunks/index-e7d9e6e8.js";import{P as vx}from"../../chunks/_post-be36280b.js";import{g as t9}from"../../chunks/config-4ae62436.js";import{a as s9}from"../../chunks/accountStore-4bdf1256.js";/* empty css                                                                   */import"../../chunks/Player-27766e67.js";import"../../chunks/menuContextStore-7acd10a7.js";import"../../chunks/index-0edac859.js";function gx(_){let f,g,v,h,m,E,y,z,T,k,b,w,L,I,x,C,S,D;function R(A,G){return typeof A[2].title!="undefined"?Ex:_x}let O=R(_),P=O(_);function Q(A,G){return typeof A[2].description!="undefined"?yx:bx}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&NP(_),N=typeof _[2].footer_description!="undefined"&&CP(_);return{c(){f=a("hr"),g=c(),v=a("div"),P.c(),h=c(),m=a("p"),E=a("ion-icon"),y=n("SpaceLab Content"),z=c(),F.c(),T=c(),B&&B.c(),k=c(),N&&N.c(),b=c(),w=a("button"),L=a("ion-icon"),I=c(),x=a("span"),C=n("SpaceLab"),this.h()},l(A){f=l(A,"HR",{}),g=u(A),v=l(A,"DIV",{class:!0});var G=r(v);P.l(G),h=u(G),m=l(G,"P",{class:!0});var Z=r(m);E=l(Z,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=o(Z,"SpaceLab Content"),Z.forEach(t),z=u(G),F.l(G),T=u(G),B&&B.l(G),k=u(G),N&&N.l(G),b=u(G),w=l(G,"BUTTON",{class:!0});var U=r(w);L=l(U,"ION-ICON",{class:!0,name:!0}),r(L).forEach(t),I=u(U),x=l(U,"SPAN",{});var q=r(x);C=o(q,"SpaceLab"),q.forEach(t),U.forEach(t),G.forEach(t),this.h()},h(){ee(E,"class","icon svelte-s12rf8"),ee(E,"name","lock-closed"),i(m,"class","highlight large svelte-s12rf8"),ee(L,"class","icon svelte-s12rf8"),ee(L,"name","planet"),i(w,"class","button subscribe svelte-s12rf8"),i(v,"class","subscribe svelte-s12rf8")},m(A,G){p(A,f,G),p(A,g,G),p(A,v,G),P.m(v,null),e(v,h),e(v,m),e(m,E),e(m,y),e(v,z),F.m(v,null),e(v,T),B&&B.m(v,null),e(v,k),N&&N.m(v,null),e(v,b),e(v,w),e(w,L),e(w,I),e(w,x),e(x,C),S||(D=Ae(w,"click",_[15]),S=!0)},p(A,G){O===(O=R(A))&&P?P.p(A,G):(P.d(1),P=O(A),P&&(P.c(),P.m(v,h))),j===(j=Q(A))&&F?F.p(A,G):(F.d(1),F=j(A),F&&(F.c(),F.m(v,T))),typeof A[2].list_description!="undefined"?B?B.p(A,G):(B=NP(A),B.c(),B.m(v,k)):B&&(B.d(1),B=null),typeof A[2].footer_description!="undefined"?N?N.p(A,G):(N=CP(A),N.c(),N.m(v,b)):N&&(N.d(1),N=null)},d(A){A&&t(f),A&&t(g),A&&t(v),P.d(),F.d(),B&&B.d(),N&&N.d(),S=!1,D()}}}function mx(_){let f,g,v,h=_[2].title+"",m,E,y,z,T,k,b,w=_[2].description+"",L,I,x,C,S,D,R,O,P,Q,j,F,B,N=typeof _[2].list_description!="undefined"&&GP(_),A=typeof _[2].footer_description!="undefined"&&UP(_);function G(q,H){if(q[2].github_private_repo&&q[2].github_state==="LOG_EXISTS")return zx;if(q[2].github_private_repo&&q[2].github_state==="NO_LOGS")return wx;if(q[2].github_private_repo&&q[2].github_state==="NO_GITHUB_USERNAME")return kx}let Z=G(_),U=Z&&Z(_);return{c(){f=a("hr"),g=c(),v=a("h2"),m=n(h),E=c(),y=a("p"),z=a("ion-icon"),T=n("SpaceLab Content"),k=c(),b=a("p"),L=n(w),I=c(),N&&N.c(),x=c(),A&&A.c(),C=c(),S=a("button"),D=a("ion-icon"),R=c(),O=a("span"),P=n("Download"),Q=c(),U&&U.c(),j=Xd(),this.h()},l(q){f=l(q,"HR",{}),g=u(q),v=l(q,"H2",{class:!0});var H=r(v);m=o(H,h),H.forEach(t),E=u(q),y=l(q,"P",{class:!0});var ls=r(y);z=l(ls,"ION-ICON",{class:!0,name:!0}),r(z).forEach(t),T=o(ls,"SpaceLab Content"),ls.forEach(t),k=u(q),b=l(q,"P",{class:!0});var Le=r(b);L=o(Le,w),Le.forEach(t),I=u(q),N&&N.l(q),x=u(q),A&&A.l(q),C=u(q),S=l(q,"BUTTON",{class:!0});var pe=r(S);D=l(pe,"ION-ICON",{class:!0,name:!0}),r(D).forEach(t),R=u(pe),O=l(pe,"SPAN",{});var Zd=r(O);P=o(Zd,"Download"),Zd.forEach(t),pe.forEach(t),Q=u(q),U&&U.l(q),j=Xd(),this.h()},h(){i(v,"class","svelte-s12rf8"),ee(z,"class","icon svelte-s12rf8"),ee(z,"name","planet-sharp"),i(y,"class","highlight large svelte-s12rf8"),i(b,"class","svelte-s12rf8"),ee(D,"class","icon svelte-s12rf8"),ee(D,"name","cloud-download"),i(S,"class","button svelte-s12rf8")},m(q,H){p(q,f,H),p(q,g,H),p(q,v,H),e(v,m),p(q,E,H),p(q,y,H),e(y,z),e(y,T),p(q,k,H),p(q,b,H),e(b,L),p(q,I,H),N&&N.m(q,H),p(q,x,H),A&&A.m(q,H),p(q,C,H),p(q,S,H),e(S,D),e(S,R),e(S,O),e(O,P),p(q,Q,H),U&&U.m(q,H),p(q,j,H),F||(B=Ae(S,"click",_[10]),F=!0)},p(q,H){H&4&&h!==(h=q[2].title+"")&&ce(m,h),H&4&&w!==(w=q[2].description+"")&&ce(L,w),typeof q[2].list_description!="undefined"?N?N.p(q,H):(N=GP(q),N.c(),N.m(x.parentNode,x)):N&&(N.d(1),N=null),typeof q[2].footer_description!="undefined"?A?A.p(q,H):(A=UP(q),A.c(),A.m(C.parentNode,C)):A&&(A.d(1),A=null),Z===(Z=G(q))&&U?U.p(q,H):(U&&U.d(1),U=Z&&Z(q),U&&(U.c(),U.m(j.parentNode,j)))},d(q){q&&t(f),q&&t(g),q&&t(v),q&&t(E),q&&t(y),q&&t(k),q&&t(b),q&&t(I),N&&N.d(q),q&&t(x),A&&A.d(q),q&&t(C),q&&t(S),q&&t(Q),U&&U.d(q),q&&t(j),F=!1,B()}}}function _x(_){let f,g;return{c(){f=a("h2"),g=n(_[0]),this.h()},l(v){f=l(v,"H2",{class:!0});var h=r(f);g=o(h,_[0]),h.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(v,h){p(v,f,h),e(f,g)},p(v,h){h&1&&ce(g,v[0])},d(v){v&&t(f)}}}function Ex(_){let f,g=_[2].title+"",v;return{c(){f=a("h2"),v=n(g),this.h()},l(h){f=l(h,"H2",{class:!0});var m=r(f);v=o(m,g),m.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,m){p(h,f,m),e(f,v)},p(h,m){m&4&&g!==(g=h[2].title+"")&&ce(v,g)},d(h){h&&t(f)}}}function bx(_){let f,g;return{c(){f=a("p"),g=n(_[1]),this.h()},l(v){f=l(v,"P",{class:!0});var h=r(f);g=o(h,_[1]),h.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(v,h){p(v,f,h),e(f,g)},p(v,h){h&2&&ce(g,v[1])},d(v){v&&t(f)}}}function yx(_){let f,g=_[2].description+"",v;return{c(){f=a("p"),v=n(g),this.h()},l(h){f=l(h,"P",{class:!0});var m=r(f);v=o(m,g),m.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,m){p(h,f,m),e(f,v)},p(h,m){m&4&&g!==(g=h[2].description+"")&&ce(v,g)},d(h){h&&t(f)}}}function NP(_){let f,g,v=_[2].list_description+"",h;return{c(){f=a("div"),g=a("p"),h=n(v),this.h()},l(m){f=l(m,"DIV",{class:!0});var E=r(f);g=l(E,"P",{class:!0});var y=r(g);h=o(y,v),y.forEach(t),E.forEach(t),this.h()},h(){i(g,"class","svelte-s12rf8"),i(f,"class","list-description svelte-s12rf8")},m(m,E){p(m,f,E),e(f,g),e(g,h)},p(m,E){E&4&&v!==(v=m[2].list_description+"")&&ce(h,v)},d(m){m&&t(f)}}}function CP(_){let f,g=_[2].footer_description+"",v;return{c(){f=a("p"),v=n(g),this.h()},l(h){f=l(h,"P",{class:!0});var m=r(f);v=o(m,g),m.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,m){p(h,f,m),e(f,v)},p(h,m){m&4&&g!==(g=h[2].footer_description+"")&&ce(v,g)},d(h){h&&t(f)}}}function GP(_){let f,g,v=_[2].list_description+"",h;return{c(){f=a("div"),g=a("p"),h=n(v),this.h()},l(m){f=l(m,"DIV",{class:!0});var E=r(f);g=l(E,"P",{class:!0});var y=r(g);h=o(y,v),y.forEach(t),E.forEach(t),this.h()},h(){i(g,"class","svelte-s12rf8"),i(f,"class","list-description svelte-s12rf8")},m(m,E){p(m,f,E),e(f,g),e(g,h)},p(m,E){E&4&&v!==(v=m[2].list_description+"")&&ce(h,v)},d(m){m&&t(f)}}}function UP(_){let f,g=_[2].footer_description+"",v;return{c(){f=a("p"),v=n(g),this.h()},l(h){f=l(h,"P",{class:!0});var m=r(f);v=o(m,g),m.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,m){p(h,f,m),e(f,v)},p(h,m){m&4&&g!==(g=h[2].footer_description+"")&&ce(v,g)},d(h){h&&t(f)}}}function kx(_){let f,g,v,h,m,E;function y(k,b){return k[5]?qx:Tx}let z=y(_),T=z(_);return{c(){f=a("h2"),g=n("Private GitHub Access"),v=c(),h=a("form"),T.c(),this.h()},l(k){f=l(k,"H2",{class:!0});var b=r(f);g=o(b,"Private GitHub Access"),b.forEach(t),v=u(k),h=l(k,"FORM",{class:!0});var w=r(h);T.l(w),w.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(k,b){p(k,f,b),e(f,g),p(k,v,b),p(k,h,b),T.m(h,null),m||(E=Ae(h,"submit",_[8]),m=!0)},p(k,b){z===(z=y(k))&&T?T.p(k,b):(T.d(1),T=z(k),T&&(T.c(),T.m(h,null)))},d(k){k&&t(f),k&&t(v),k&&t(h),T.d(),m=!1,E()}}}function wx(_){let f,g,v,h,m,E;function y(k,b){return k[5]?Sx:Rx}let z=y(_),T=z(_);return{c(){f=a("h2"),g=n("Private GitHub Access"),v=c(),h=a("form"),T.c(),this.h()},l(k){f=l(k,"H2",{class:!0});var b=r(f);g=o(b,"Private GitHub Access"),b.forEach(t),v=u(k),h=l(k,"FORM",{});var w=r(h);T.l(w),w.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(k,b){p(k,f,b),e(f,g),p(k,v,b),p(k,h,b),T.m(h,null),m||(E=Ae(h,"submit",_[7]),m=!0)},p(k,b){z===(z=y(k))&&T?T.p(k,b):(T.d(1),T=z(k),T&&(T.c(),T.m(h,null)))},d(k){k&&t(f),k&&t(v),k&&t(h),T.d(),m=!1,E()}}}function zx(_){var D;let f,g,v,h,m,E,y=((D=_[6].profile)==null?void 0:D.githubUsername)+"",z,T,k,b,w,L,I,x,C,S;return{c(){f=a("h2"),g=n("Private GitHub Access"),v=c(),h=a("p"),m=n("Your GitHub account "),E=a("span"),z=n(y),T=n(` is
			linked to this content.`),k=c(),b=a("button"),w=a("ion-icon"),L=c(),I=a("span"),x=n("Open Repository"),this.h()},l(R){f=l(R,"H2",{class:!0});var O=r(f);g=o(O,"Private GitHub Access"),O.forEach(t),v=u(R),h=l(R,"P",{class:!0});var P=r(h);m=o(P,"Your GitHub account "),E=l(P,"SPAN",{class:!0});var Q=r(E);z=o(Q,y),Q.forEach(t),T=o(P,` is
			linked to this content.`),P.forEach(t),k=u(R),b=l(R,"BUTTON",{class:!0});var j=r(b);w=l(j,"ION-ICON",{class:!0,name:!0}),r(w).forEach(t),L=u(j),I=l(j,"SPAN",{});var F=r(I);x=o(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(E,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","rocket-sharp"),i(b,"class","svelte-s12rf8")},m(R,O){p(R,f,O),e(f,g),p(R,v,O),p(R,h,O),e(h,m),e(h,E),e(E,z),e(h,T),p(R,k,O),p(R,b,O),e(b,w),e(b,L),e(b,I),e(I,x),C||(S=Ae(b,"click",_[11]),C=!0)},p(R,O){var P;O&64&&y!==(y=((P=R[6].profile)==null?void 0:P.githubUsername)+"")&&ce(z,y)},d(R){R&&t(f),R&&t(v),R&&t(h),R&&t(k),R&&t(b),C=!1,S()}}}function Tx(_){let f,g,v,h,m,E,y,z,T,k,b,w,L,I,x,C;return{c(){f=a("p"),g=n(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),v=c(),h=a("label"),m=n("Github username:"),E=c(),y=a("input"),T=c(),k=a("button"),b=a("ion-icon"),w=c(),L=a("span"),I=n("Request Permission"),this.h()},l(S){f=l(S,"P",{class:!0});var D=r(f);g=o(D,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),D.forEach(t),v=u(S),h=l(S,"LABEL",{for:!0});var R=r(h);m=o(R,"Github username:"),R.forEach(t),E=u(S),y=l(S,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),T=u(S),k=l(S,"BUTTON",{class:!0});var O=r(k);b=l(O,"ION-ICON",{class:!0,name:!0}),r(b).forEach(t),w=u(O),L=l(O,"SPAN",{});var P=r(L);I=o(P,"Request Permission"),P.forEach(t),O.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(h,"for","username"),i(y,"name","username"),i(y,"id","username"),i(y,"placeholder","enter a username"),i(y,"type","text"),y.required="true",i(y,"class",z=_[4]?"validation-error":""),ee(b,"class","icon svelte-s12rf8"),ee(b,"name","rocket-sharp"),i(k,"class","svelte-s12rf8")},m(S,D){p(S,f,D),e(f,g),p(S,v,D),p(S,h,D),e(h,m),p(S,E,D),p(S,y,D),OP(y,_[3]),p(S,T,D),p(S,k,D),e(k,b),e(k,w),e(k,L),e(L,I),x||(C=Ae(y,"input",_[14]),x=!0)},p(S,D){D&16&&z!==(z=S[4]?"validation-error":"")&&i(y,"class",z),D&8&&y.value!==S[3]&&OP(y,S[3])},d(S){S&&t(f),S&&t(v),S&&t(h),S&&t(E),S&&t(y),S&&t(T),S&&t(k),x=!1,C()}}}function qx(_){let f,g,v,h,m,E,y,z,T,k;return{c(){f=a("p"),g=n(_[5]),v=c(),h=a("button"),m=a("ion-icon"),E=c(),y=a("span"),z=n("Open Repository"),this.h()},l(b){f=l(b,"P",{class:!0});var w=r(f);g=o(w,_[5]),w.forEach(t),v=u(b),h=l(b,"BUTTON",{class:!0});var L=r(h);m=l(L,"ION-ICON",{class:!0,name:!0}),r(m).forEach(t),E=u(L),y=l(L,"SPAN",{});var I=r(y);z=o(I,"Open Repository"),I.forEach(t),L.forEach(t),this.h()},h(){i(f,"class","feedback svelte-s12rf8"),ee(m,"class","icon svelte-s12rf8"),ee(m,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(b,w){p(b,f,w),e(f,g),p(b,v,w),p(b,h,w),e(h,m),e(h,E),e(h,y),e(y,z),T||(k=Ae(h,"click",_[13]),T=!0)},p(b,w){w&32&&ce(g,b[5])},d(b){b&&t(f),b&&t(v),b&&t(h),T=!1,k()}}}function Rx(_){var L;let f,g,v,h=((L=_[6].profile)==null?void 0:L.githubUsername)+"",m,E,y,z,T,k,b,w;return{c(){f=a("p"),g=n("This content can grant access to a private GitHub repository. Allow "),v=a("span"),m=n(h),E=n(" access to this repo?"),y=c(),z=a("button"),T=a("ion-icon"),k=c(),b=a("span"),w=n("Request Permission"),this.h()},l(I){f=l(I,"P",{class:!0});var x=r(f);g=o(x,"This content can grant access to a private GitHub repository. Allow "),v=l(x,"SPAN",{class:!0});var C=r(v);m=o(C,h),C.forEach(t),E=o(x," access to this repo?"),x.forEach(t),y=u(I),z=l(I,"BUTTON",{class:!0});var S=r(z);T=l(S,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),k=u(S),b=l(S,"SPAN",{});var D=r(b);w=o(D,"Request Permission"),D.forEach(t),S.forEach(t),this.h()},h(){i(v,"class","highlight svelte-s12rf8"),i(f,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","rocket-sharp"),i(z,"class","svelte-s12rf8")},m(I,x){p(I,f,x),e(f,g),e(f,v),e(v,m),e(f,E),p(I,y,x),p(I,z,x),e(z,T),e(z,k),e(z,b),e(b,w)},p(I,x){var C;x&64&&h!==(h=((C=I[6].profile)==null?void 0:C.githubUsername)+"")&&ce(m,h)},d(I){I&&t(f),I&&t(y),I&&t(z)}}}function Sx(_){let f,g,v,h,m,E,y,z,T,k;return{c(){f=a("p"),g=n(_[5]),v=c(),h=a("button"),m=a("ion-icon"),E=c(),y=a("span"),z=n("Open Repository"),this.h()},l(b){f=l(b,"P",{class:!0});var w=r(f);g=o(w,_[5]),w.forEach(t),v=u(b),h=l(b,"BUTTON",{class:!0});var L=r(h);m=l(L,"ION-ICON",{class:!0,name:!0}),r(m).forEach(t),E=u(L),y=l(L,"SPAN",{});var I=r(y);z=o(I,"Open Repository"),I.forEach(t),L.forEach(t),this.h()},h(){i(f,"class","feedback svelte-s12rf8"),ee(m,"class","icon svelte-s12rf8"),ee(m,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(b,w){p(b,f,w),e(f,g),p(b,v,w),p(b,h,w),e(h,m),e(h,E),e(h,y),e(y,z),T||(k=Ae(h,"click",_[12]),T=!0)},p(b,w){w&32&&ce(g,b[5])},d(b){b&&t(f),b&&t(v),b&&t(h),T=!1,k()}}}function Dx(_){let f;function g(m,E){return typeof m[2]!="undefined"&&typeof m[2].pk!="undefined"?mx:gx}let v=g(_),h=v(_);return{c(){h.c(),f=Xd()},l(m){h.l(m),f=Xd()},m(m,E){h.m(m,E),p(m,f,E)},p(m,[E]){v===(v=g(m))&&h?h.p(m,E):(h.d(1),h=v(m),h&&(h.c(),h.m(f.parentNode,f)))},i:l9,o:l9,d(m){h.d(m),m&&t(f)}}}function a9(_){window.open(_,"_blank")||window.location.replace(_)}function Ax(_,f,g){let{id:v}=f,{spacelabDefaultTitle:h="Spacelab Content"}=f,{spacelabDefaultContent:m="To access this content, you need a SpaceLab subscription."}=f,E={},y="",z=!1,T="",k;s9.subscribe(R=>{g(6,k=R)}),ox(async()=>{if(typeof(k==null?void 0:k.token)!="undefined"){const R=await fetch(`${t9().serviceUrl}/education/spacelab/${v}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors"});if(R.status===401){s9.set({}),s9.deleteLocalStorage();return}let O=await R.json();g(2,E=O)}else g(2,E.success=!1,E)});async function b(R){R.preventDefault();const O={};try{const P=await fetch(`${t9().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(O)});if(P.ok)g(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await P.json();g(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(P){console.error("Error while sending GitHub access request:",P),g(5,T="An unexpected error occurred. Please try again later.")}}async function w(R){if(R.preventDefault(),!y.trim()){g(4,z=!0),g(5,T="Please enter a valid GitHub username.");return}g(4,z=!1);const O={github_username:y};try{const P=await fetch(`${t9().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(O)});if(P.ok)g(5,T="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await P.json();g(5,T=Q.message||"An error occurred while requesting access. Please try again.")}}catch(P){console.error("Error while sending GitHub access request:",P),g(5,T="An unexpected error occurred. Please try again later.")}}const L=()=>window.open(E.url,"_blank"),I=()=>a9(`https://github.com/${E.github_repo_name}`),x=()=>a9(`https://github.com/${E.github_repo_name}`),C=()=>a9(`https://github.com/${E.github_repo_name}`);function S(){y=this.value,g(3,y)}const D=()=>window.open("/spacelab/","_blank");return _.$$set=R=>{"id"in R&&g(9,v=R.id),"spacelabDefaultTitle"in R&&g(0,h=R.spacelabDefaultTitle),"spacelabDefaultContent"in R&&g(1,m=R.spacelabDefaultContent)},[h,m,E,y,z,T,k,b,w,v,L,I,x,C,S,D]}class Lx extends C_{constructor(f){super(),G_(this,f,Ax,Dx,U_,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const Ix=_=>({}),HP=_=>({});function Ox(_){let f;return{c(){f=n(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(g){f=o(g,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(g,v){p(g,f,v)},d(g){g&&t(f)}}}function Px(_){let f,g,v,h,m,E,y,z,T,k,b,w,L,I;const x=_[7]["slider-label"],C=cx(x,_,_[6],HP),S=C||Ox();return{c(){f=a("div"),g=a("img"),h=c(),m=a("img"),y=c(),z=a("label"),T=a("span"),S&&S.c(),k=c(),b=a("input"),this.h()},l(D){f=l(D,"DIV",{class:!0,style:!0,"data-testid":!0});var R=r(f);g=l(R,"IMG",{src:!0,alt:!0,class:!0}),h=u(R),m=l(R,"IMG",{src:!0,alt:!0,class:!0}),y=u(R),z=l(R,"LABEL",{class:!0});var O=r(z);T=l(O,"SPAN",{class:!0});var P=r(T);S&&S.l(P),P.forEach(t),k=u(O),b=l(O,"INPUT",{type:!0,min:!0,max:!0,class:!0}),O.forEach(t),R.forEach(t),this.h()},h(){ts(g.src,v=_[0])||i(g,"src",v),i(g,"alt",_[1]),i(g,"class","left-img svelte-1po6qlg"),ts(m.src,E=_[2])||i(m,"src",E),i(m,"alt",_[3]),i(m,"class","right-img svelte-1po6qlg"),i(T,"class","visually-hidden svelte-1po6qlg"),i(b,"type","range"),i(b,"min","0"),i(b,"max","100"),b.value=_[4],i(b,"class","svelte-1po6qlg"),i(z,"class","svelte-1po6qlg"),i(f,"class","svelte-compare-image-container svelte-1po6qlg"),es(f,"--slider-position",_[4]+"%"),i(f,"data-testid","svelte-compare-image")},m(D,R){p(D,f,R),e(f,g),e(f,h),e(f,m),e(f,y),e(f,z),e(z,T),S&&S.m(T,null),e(z,k),e(z,b),w=!0,L||(I=[Ae(b,"input",_[5]),Ae(b,"change",_[5]),Ae(b,"click",xx)],L=!0)},p(D,[R]){(!w||R&1&&!ts(g.src,v=D[0]))&&i(g,"src",v),(!w||R&2)&&i(g,"alt",D[1]),(!w||R&4&&!ts(m.src,E=D[2]))&&i(m,"src",E),(!w||R&8)&&i(m,"alt",D[3]),C&&C.p&&(!w||R&64)&&ux(C,x,D,D[6],w?dx(x,D[6],R,Ix):px(D[6]),HP),(!w||R&16)&&(b.value=D[4]),(!w||R&16)&&es(f,"--slider-position",D[4]+"%")},i(D){w||(ss(S,D),w=!0)},o(D){as(S,D),w=!1},d(D){D&&t(f),S&&S.d(D),L=!1,fx(I)}}}function xx(_){_.target.focus()}function Nx(_,f,g){let{$$slots:v={},$$scope:h}=f,{imageLeftSrc:m=""}=f,{imageLeftAlt:E=""}=f,{imageRightSrc:y=""}=f,{imageRightAlt:z=""}=f,T=50,k=null;function b(w){k&&cancelAnimationFrame(k),k=requestAnimationFrame(()=>{g(4,T=w.target.valueAsNumber)})}return _.$$set=w=>{"imageLeftSrc"in w&&g(0,m=w.imageLeftSrc),"imageLeftAlt"in w&&g(1,E=w.imageLeftAlt),"imageRightSrc"in w&&g(2,y=w.imageRightSrc),"imageRightAlt"in w&&g(3,z=w.imageRightAlt),"$$scope"in w&&g(6,h=w.$$scope)},[m,E,y,z,T,b,h,v]}class Cx extends C_{constructor(f){super(),G_(this,f,Nx,Px,U_,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function Gx(_){let f;return{c(){f=n(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(g){f=o(g,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(g,v){p(g,f,v)},d(g){g&&t(f)}}}function Ux(_){let f,g,v,h;return g=new Cx({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[Gx]},$$scope:{ctx:_}}}),{c(){f=a("div"),v=a("div"),Gr(g.$$.fragment),this.h()},l(m){f=l(m,"DIV",{class:!0});var E=r(f);v=l(E,"DIV",{style:!0});var y=r(v);Ur(g.$$.fragment,y),E.forEach(t),this.h()},h(){es(v,"display","contents"),es(v,"--handle-size","2.5rem"),es(v,"--handle-background-color","rgba(0, 0, 0, 0.6)"),es(v,"--handle-background-image",_[4]),es(v,"--handle-border-width","0.125rem"),es(v,"--slider-color","#ffffff"),es(v,"--slider-width","0.125rem"),i(f,"class","image-compare-container svelte-s79nww")},m(m,E){p(m,f,E),e(f,v),Hr(g,v,null),h=!0},p(m,[E]){const y={};E&1&&(y.imageLeftSrc=m[0]),E&2&&(y.imageLeftAlt=m[1]),E&4&&(y.imageRightSrc=m[2]),E&8&&(y.imageRightAlt=m[3]),E&32&&(y.$$scope={dirty:E,ctx:m}),g.$set(y)},i(m){h||(ss(g.$$.fragment,m),h=!0)},o(m){as(g.$$.fragment,m),h=!1},d(m){m&&t(f),Mr(g)}}}function Hx(_,f,g){const v=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=f,{imageLeftAlt:m="left"}=f,{imageRightSrc:E="https://via.placeholder.com/512x512/00aaff/ffffff/"}=f,{imageRightAlt:y="right"}=f;return _.$$set=z=>{"imageLeftSrc"in z&&g(0,h=z.imageLeftSrc),"imageLeftAlt"in z&&g(1,m=z.imageLeftAlt),"imageRightSrc"in z&&g(2,E=z.imageRightSrc),"imageRightAlt"in z&&g(3,y=z.imageRightAlt)},[h,m,E,y,v]}class N_ extends C_{constructor(f){super(),G_(this,f,Hx,Ux,U_,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function Mx(_){let f,g;return f=new Lx({props:{id:jx,spacelabDefaultTitle:Fx,spacelabDefaultContent:Vx}}),{c(){Gr(f.$$.fragment)},l(v){Ur(f.$$.fragment,v)},m(v,h){Hr(f,v,h),g=!0},p:l9,i(v){g||(ss(f.$$.fragment,v),g=!0)},o(v){as(f.$$.fragment,v),g=!1},d(v){Mr(f,v)}}}function Bx(_){let f,g,v,h,m,E,y,z,T,k,b,w,L,I,x,C,S,D,R,O,P,Q,j,F,B,N,A,G,Z,U,q,H,ls,Le,pe,Zd,Dv,Br,H_,Av,rs,is,Qd,M_,Lv,Wr,B_,Iv,fl,jr,W_,Ov,hl,Pv,Fr,j_,xv,Vr,F_,Nv,Kr,V_,Cv,Ht,Yr,Ie,Xr,K_,Y_,Zr,X_,Z_,Qr,Q_,J_,Oe,Pe,Jr,Jd,$_,eE,$r,tE,sE,ei,aE,lE,xe,ti,$d,rE,iE,si,nE,oE,ai,cE,uE,Ne,li,ef,pE,dE,ri,fE,hE,ii,vE,Gv,ni,gE,Uv,oi,mE,Hv,vl,ci,_E,Mv,ns,os,tf,EE,Bv,gl,sf,bE,yE,Wv,ml,af,kE,wE,jv,_l,lf,zE,TE,Fv,cs,us,rf,qE,Vv,El,nf,RE,SE,Kv,bl,of,DE,AE,Yv,yl,cf,LE,IE,Xv,ps,ds,uf,OE,Zv,kl,pf,PE,xE,Qv,Ce,NE,df,CE,GE,ff,UE,HE,Jv,Ge,ui,hf,ME,BE,WE,pi,vf,jE,FE,VE,fs,gf,KE,YE,di,XE,ZE,$v,wl,fi,QE,eg,hs,vs,mf,_f,JE,tg,hi,$E,sg,Ue,vi,Ef,e2,t2,s2,gi,bf,a2,l2,r2,mi,yf,i2,n2,ag,gs,ms,kf,wf,o2,lg,Mt,_i,He,Ei,zf,c2,u2,bi,Tf,p2,d2,yi,qf,f2,h2,de,Me,ki,Rf,v2,g2,wi,m2,_2,zi,E2,b2,Be,Ti,Sf,y2,k2,qi,w2,z2,Ri,T2,q2,We,Si,Df,R2,S2,Di,D2,A2,Ai,L2,I2,je,Li,Af,O2,P2,Ii,x2,N2,Oi,C2,rg,_s,Es,Lf,G2,ig,Bt,Pi,bs,xi,U2,H2,Ni,M2,B2,fe,ys,Ci,If,W2,j2,Gi,F2,V2,ks,Ui,Of,K2,Y2,Hi,X2,Z2,ws,Mi,Pf,Q2,J2,Bi,$2,eb,zs,Wi,xf,tb,sb,ji,ab,ng,Fi,lb,og,Ts,qs,Nf,rb,cg,he,ib,Cf,nb,ob,Vi,cb,ub,Ki,pb,db,ug,ve,fb,Yi,hb,vb,Xi,gb,mb,Zi,_b,Eb,pg,zl,BP=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,dg,Tl,WP=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,fg,Rs,Ss,Gf,bb,hg,Wt,Qi,Fe,Ji,yb,kb,$i,wb,zb,en,Tb,qb,ge,Ve,tn,Rb,Sb,sn,Db,Ab,an,Lb,Ib,Ke,ln,Ob,Pb,rn,xb,Nb,nn,Cb,Gb,Ye,on,Ub,Hb,cn,Mb,Bb,un,Wb,jb,Xe,pn,Fb,Vb,dn,Kb,Yb,fn,Xb,vg,hn,Zb,gg,vn,Qb,mg,gn,Jb,_g,Eg,bg,Ds,As,Uf,$b,yg,Ls,ey,ql,ty,sy,kg,Is,Os,Hf,ay,wg,Ps,ly,Rl,ry,iy,zg,Sl,jP=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,Tg,xs,Ns,Mf,ny,qg,Ze,Bf,oy,cy,Wf,uy,py,jf,dy,Rg,Cs,Gs,Ff,fy,Sg,Qe,Vf,hy,vy,Kf,gy,my,Yf,_y,Dg,Us,Hs,Xf,Ey,Ag,Dl,Zf,by,yy,Lg,Al,FP=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,Ig,Ms,Bs,Qf,ky,Og,Je,Jf,wy,zy,$f,Ty,qy,eh,Ry,Pg,Ll,mn,Sy,xg,Ws,js,th,Dy,Ng,Il,sh,Ay,Ly,Cg,_n,Iy,Gg,$e,Ol,Oy,En,Py,xy,Ny,ah,Cy,Gy,lh,Uy,Ug,Pl,bn,Hy,Hg,Fs,Vs,rh,My,Mg,xl,ih,By,Wy,Bg,Nl,VP=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Wg,yn,jy,jg,et,nh,Fy,Vy,oh,Ky,Yy,ch,Xy,Fg,Cl,kn,Zy,Vg,Ks,Ys,uh,Qy,Kg,Xs,Jy,ph,$y,e4,Yg,Gl,KP=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,Xg,jt,wn,tt,zn,t4,s4,Tn,a4,l4,qn,r4,i4,st,at,Rn,Sn,n4,o4,Dn,c4,u4,An,p4,d4,lt,Ln,In,f4,h4,On,v4,g4,Pn,m4,_4,rt,xn,Nn,E4,b4,Cn,y4,k4,Gn,w4,Zg,Zs,Qs,dh,z4,Qg,it,Ul,T4,Un,q4,R4,S4,Re,D4,Hn,A4,L4,Mn,I4,O4,Bn,P4,x4,N4,Ft,C4,Wn,G4,U4,jn,H4,M4,Jg,Js,$s,fh,B4,$g,Fn,W4,em,Vn,ea,hh,j4,F4,Kn,V4,K4,tm,ta,sa,vh,Y4,sm,nt,gh,X4,Z4,mh,Q4,J4,_h,$4,am,Yn,e3,lm,aa,la,Eh,t3,rm,Xn,s3,im,ra,Zn,bh,a3,l3,r3,Hl,yh,i3,n3,Vt,Qn,kh,o3,c3,u3,Jn,wh,p3,d3,f3,$n,zh,h3,v3,nm,eo,g3,om,ia,to,Th,m3,_3,E3,so,qh,b3,y3,cm,ao,k3,um,Ml,Rh,w3,z3,pm,ot,Sh,T3,q3,Dh,R3,S3,Ah,D3,dm,Kt,lo,me,ro,A3,L3,io,I3,O3,no,P3,x3,oo,N3,C3,le,_e,co,G3,U3,uo,H3,M3,po,B3,W3,fo,j3,F3,Ee,ho,V3,K3,vo,Y3,X3,go,Z3,Q3,mo,J3,$3,be,_o,ek,tk,Eo,sk,ak,na,lk,Lh,rk,ik,nk,ct,ok,bo,ck,uk,yo,pk,dk,fk,ye,ko,hk,vk,wo,gk,mk,zo,_k,Ek,To,bk,yk,ke,qo,kk,wk,Ro,zk,Tk,So,qk,Rk,Do,Sk,fm,hm,vm,oa,ca,Ih,Dk,gm,ua,Ak,Ao,Lk,Ik,mm,ue,Ok,Lo,Pk,xk,Io,Nk,Ck,Oo,Gk,Uk,Po,Hk,_m,xo,Mk,Em,pa,da,Oh,Bk,bm,ut,Ph,Bl,xh,Wk,jk,Fk,Vk,Nh,Wl,Ch,Kk,Yk,Xk,Zk,Gh,jl,Uh,Qk,Jk,$k,ym,Fl,km,fa,ha,Hh,e0,wm,va,t0,Vl,s0,a0,zm,pt,l0,No,r0,i0,Co,n0,o0,Tm,J,Mh,Go,c0,Uo,u0,p0,Bh,Kl,d0,Ho,f0,h0,v0,Wh,K,g0,Mo,m0,_0,Bo,E0,b0,Wo,y0,k0,jo,w0,z0,Fo,T0,q0,Vo,R0,S0,Ko,D0,A0,Yo,L0,I0,jh,$,O0,Xo,P0,x0,Zo,N0,C0,Qo,G0,U0,Jo,H0,M0,$o,B0,W0,ec,j0,F0,tc,V0,K0,Fh,Y,Y0,sc,X0,Z0,ac,Q0,J0,lc,$0,e5,rc,t5,s5,ic,a5,l5,nc,r5,i5,oc,n5,o5,cc,c5,u5,Vh,uc,p5,pc,d5,f5,Kh,ga,h5,dc,v5,g5,fc,m5,qm,dt,_5,hc,E5,b5,vc,y5,k5,Rm,Yl,Sm,ma,_a,Yh,w5,Dm,gc,z5,Am,we,mc,Xl,T5,q5,R5,_c,Zl,S5,D5,A5,Ec,Ql,L5,I5,O5,bc,Jl,P5,x5,Lm,Ea,ba,Xh,N5,Im,yc,C5,Om,kc,G5,Pm,ft,wc,Zh,U5,H5,M5,ht,Qh,B5,W5,zc,j5,F5,Tc,V5,K5,Y5,qc,Jh,X5,Z5,xm,$l,YP=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,Nm,ya,er,Q5,Rc,J5,$5,ew,tr,tw,Sc,sw,aw,Cm,ka,$h,lw,rw,Dc,iw,Gm,wa,za,ev,nw,Um,vt,ow,sr,cw,uw,ar,pw,dw,Hm,lr,Ta,fw,rr,hw,vw,Mm,ir,Se,gw,nr,mw,_w,or,Ew,bw,cr,yw,Bm,qa,Ra,tv,kw,Wm,Sa,ww,Ac,zw,Tw,jm,ur,XP=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Fm,Lc,qw,Vm,pr,ZP='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Km,Da,Rw,Ic,Sw,Dw,Ym,dr,Aa,Aw,Oc,Lw,Iw,Xm,gt,Ow,Pc,Pw,xw,xc,Nw,Cw,Zm,Nc,Gw,Qm,La,Cc,Uw,sv,av,Hw,Mw,Gc,Bw,lv,rv,Ww,Jm,Uc,jw,$m,fr,hr,n9,e1,Ia,Oa,iv,Fw,t1,Yt,Vw,Hc,Kw,Yw,Mc,Xw,s1,Xt,Bc,re,Wc,Zw,Qw,jc,Jw,$w,Fc,ez,tz,Vc,sz,az,Kc,lz,rz,Yc,ie,Xc,iz,nz,Zc,oz,cz,Qc,uz,pz,Jc,dz,fz,$c,hz,a1,eu,vz,l1,vr,QP=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,r1,M,tu,gr,gz,su,mz,_z,Ez,bz,au,mr,yz,lu,kz,wz,zz,Tz,ru,_r,qz,iu,Rz,Sz,Dz,Az,nu,Er,Lz,ou,Iz,Oz,Pz,xz,cu,nv,Nz,Cz,Gz,uu,br,Uz,pu,Hz,Mz,Bz,Wz,du,yr,jz,fu,Fz,Vz,Kz,Yz,hu,kr,Xz,vu,Zz,Qz,Jz,$z,gu,wr,e6,mu,t6,s6,a6,l6,_u,zr,r6,Eu,i6,n6,o6,c6,bu,Tr,u6,yu,p6,d6,f6,i1,Pa,xa,ov,h6,n1,ku,v6,o1,qr,c1,Na,Ca,cv,g6,u1,Ga,m6,Rr,_6,E6,p1,Ua,b6,wu,y6,k6,d1,ne,zu,w6,f1,z6,uv,T6,q6,mt,R6,Tu,S6,D6,qu,A6,L6,Ru,I6,O6,Su,P6,Du,x6,N6,Ha,C6,Au,G6,U6,Lu,H6,h1,_t,M6,Iu,B6,W6,Ou,j6,F6,v1,ze,Ma,V6,Pu,K6,Y6,xu,X6,Z6,Sr,Q6,Nu,J6,$6,e8,pv,t8,s8,dv,a8,g1,Ba,Wa,fv,l8,m1,Te,Cu,hv,r8,i8,n8,Gu,vv,o8,c8,u8,Uu,gv,p8,d8,f8,Hu,mv,h8,v8,_1,Mu,g8,E1,Dr,Ar,o9,b1,ja,Fa,_v,m8,y1,Bu,_8,k1,Et,Lr,E8,Wu,b8,y8,k8,Ir,w8,ju,z8,T8,q8,Ev,R8,w1,Zt,Fu,bt,Vu,S8,D8,Ku,A8,L8,Yu,I8,O8,qe,yt,Xu,P8,x8,Zu,N8,C8,Qu,G8,U8,kt,Ju,H8,M8,$u,B8,W8,ep,j8,F8,wt,tp,V8,K8,sp,Y8,X8,ap,Z8,Q8,zt,lp,J8,$8,rp,e7,t7,ip,s7,z1,Va,Ka,bv,a7,T1,np,l7,q1,Qt,op,Tt,cp,r7,i7,up,n7,o7,pp,c7,u7,W,qt,dp,p7,d7,fp,f7,h7,hp,v7,g7,Rt,vp,m7,_7,gp,E7,b7,mp,y7,k7,St,_p,w7,z7,Ep,T7,q7,bp,R7,S7,Dt,yp,D7,A7,kp,L7,I7,wp,O7,P7,At,zp,x7,N7,Tp,C7,G7,qp,U7,H7,Lt,Rp,M7,B7,Sp,W7,j7,Dp,F7,V7,It,Ap,K7,Y7,Lp,X7,Z7,Ip,Q7,J7,Ot,Op,$7,eT,Pp,tT,sT,xp,aT,lT,Pt,Np,rT,iT,Cp,nT,oT,Gp,cT,uT,xt,Up,pT,dT,Hp,fT,hT,Mp,vT,R1,Ya,Xa,yv,gT,S1,Bp,mT,D1,Wp,_T,A1,Or,Pr,c9,L1,jp,ET,I1,Jt,Za,kv,bT,O1,P1,x1;hl=new N_({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),Fl=new N_({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),Yl=new N_({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),qr=new N_({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let De=MP&&Mx();return{c(){f=a("p"),g=n("Growing up in the \u201880s, I loved vintage action figures: their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),v=c(),h=a("p"),m=n("I wanted to go further to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),E=c(),y=a("h4"),z=a("a"),T=a("span"),k=n("Experiment 1: Anime-Inspired Heroism"),b=c(),w=a("p"),L=a("img"),x=c(),C=a("p"),S=n("I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),D=c(),R=a("ul"),O=a("li"),P=n("My action figure photos (for costume accuracy)."),Q=c(),j=a("li"),F=n("Stylized anime references (for anatomy and texture)."),B=c(),N=a("p"),A=n("The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting.  Bridging the gap between toy and anime hero."),G=c(),Z=a("h4"),U=a("a"),q=a("span"),H=n("Experiment 2: Retro Cartoon Resurrection"),ls=c(),Le=a("p"),pe=a("img"),Dv=c(),Br=a("p"),H_=n("Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),Av=c(),rs=a("h2"),is=a("a"),Qd=a("span"),M_=n("What are Regularization Images?"),Lv=c(),Wr=a("p"),B_=n("Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),Iv=c(),fl=a("blockquote"),jr=a("p"),W_=n("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),Ov=c(),Gr(hl.$$.fragment),Pv=c(),Fr=a("p"),j_=n("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),xv=c(),Vr=a("p"),F_=n("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),Nv=c(),Kr=a("p"),V_=n("Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),Cv=c(),Ht=a("table"),Yr=a("thead"),Ie=a("tr"),Xr=a("th"),K_=n("Aspect"),Y_=c(),Zr=a("th"),X_=n("Regularization"),Z_=c(),Qr=a("th"),Q_=n("No Regularization"),J_=c(),Oe=a("tbody"),Pe=a("tr"),Jr=a("td"),Jd=a("strong"),$_=n("Class Definition"),eE=c(),$r=a("td"),tE=n("Explicit anchoring"),sE=c(),ei=a("td"),aE=n("Implicit learning"),lE=c(),xe=a("tr"),ti=a("td"),$d=a("strong"),rE=n("Failure Modes"),iE=c(),si=a("td"),nE=n("Underfitting if overdone"),oE=c(),ai=a("td"),cE=n("Overfitting/drift"),uE=c(),Ne=a("tr"),li=a("td"),ef=a("strong"),pE=n("Data Efficiency"),dE=c(),ri=a("td"),fE=n("Better generalization"),hE=c(),ii=a("td"),vE=n("Requires more data"),Gv=c(),ni=a("p"),gE=n("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Uv=c(),oi=a("p"),mE=n("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Hv=c(),vl=a("blockquote"),ci=a("p"),_E=n("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Mv=c(),ns=a("h4"),os=a("a"),tf=a("span"),EE=n("Scenario 1: Limited Training Data"),Bv=c(),gl=a("p"),sf=a("strong"),bE=n("Situation"),yE=n(": You only have a few images of your cat and no other cat images."),Wv=c(),ml=a("p"),af=a("strong"),kE=n("Problem"),wE=n(": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),jv=c(),_l=a("p"),lf=a("strong"),zE=n("Solution"),TE=n(": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),Fv=c(),cs=a("h4"),us=a("a"),rf=a("span"),qE=n("Scenario 2: Imbalanced Training Data"),Vv=c(),El=a("p"),nf=a("strong"),RE=n("Situation"),SE=n(": You have many images of other cats but only a few of your cat."),Kv=c(),bl=a("p"),of=a("strong"),DE=n("Problem"),AE=n(": The model may focus too much on the other cats, failing to learn the unique features of your cat."),Yv=c(),yl=a("p"),cf=a("strong"),LE=n("Solution"),IE=n(": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),Xv=c(),ps=a("h2"),ds=a("a"),uf=a("span"),OE=n("Divergence"),Zv=c(),kl=a("p"),pf=a("strong"),PE=n("Divergence"),xE=n(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Qv=c(),Ce=a("p"),NE=n("Preventing divergence starts with "),df=a("strong"),CE=n("careful dataset curation"),GE=n(" selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),ff=a("strong"),UE=n("regularization techniques"),HE=n(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Jv=c(),Ge=a("ul"),ui=a("li"),hf=a("strong"),ME=n("Chaotic outputs"),BE=n(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),WE=c(),pi=a("li"),vf=a("strong"),jE=n("Exploding gradients"),FE=n(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),VE=c(),fs=a("li"),gf=a("strong"),KE=n("Loss value instability (NaN/infinity values)"),YE=n(" The training loss fluctuates wildly, sometimes becoming "),di=a("code"),XE=n("NaN"),ZE=n(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),$v=c(),wl=a("blockquote"),fi=a("p"),QE=n("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),eg=c(),hs=a("h2"),vs=a("a"),mf=a("span"),_f=a("strong"),JE=n("Overfitting"),tg=c(),hi=a("p"),$E=n("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),sg=c(),Ue=a("ul"),vi=a("li"),Ef=a("strong"),e2=n("Perfectly replicates training samples"),t2=n(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),s2=c(),gi=a("li"),bf=a("strong"),a2=n("Fails to generalize to new inputs"),l2=n(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),r2=c(),mi=a("li"),yf=a("strong"),i2=n("Shows excellent training loss but poor validation loss"),n2=n(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),ag=c(),gs=a("h3"),ms=a("a"),kf=a("span"),wf=a("strong"),o2=n("Key Differences"),lg=c(),Mt=a("table"),_i=a("thead"),He=a("tr"),Ei=a("th"),zf=a("strong"),c2=n("Aspect"),u2=c(),bi=a("th"),Tf=a("strong"),p2=n("Divergence"),d2=c(),yi=a("th"),qf=a("strong"),f2=n("Overfitting"),h2=c(),de=a("tbody"),Me=a("tr"),ki=a("td"),Rf=a("strong"),v2=n("Cause"),g2=c(),wi=a("td"),m2=n("Excessive learning rate"),_2=c(),zi=a("td"),E2=n("Insufficient regularization"),b2=c(),Be=a("tr"),Ti=a("td"),Sf=a("strong"),y2=n("Loss Behavior"),k2=c(),qi=a("td"),w2=n("Sudden spikes/NaN values"),z2=c(),Ri=a("td"),T2=n("Steady decrease then rise"),q2=c(),We=a("tr"),Si=a("td"),Df=a("strong"),R2=n("Output Quality"),S2=c(),Di=a("td"),D2=n("Random noise/artifacts"),A2=c(),Ai=a("td"),L2=n("Overly detailed replicas"),I2=c(),je=a("tr"),Li=a("td"),Af=a("strong"),O2=n("Recovery"),P2=c(),Ii=a("td"),x2=n("Requires restart"),N2=c(),Oi=a("td"),C2=n("Early stopping works"),rg=c(),_s=a("h3"),Es=a("a"),Lf=a("span"),G2=n("Preventing Divergence"),ig=c(),Bt=a("table"),Pi=a("thead"),bs=a("tr"),xi=a("th"),U2=n("Situation"),H2=c(),Ni=a("th"),M2=n("Outcome"),B2=c(),fe=a("tbody"),ys=a("tr"),Ci=a("td"),If=a("strong"),W2=n("Excessive/inconsistent data"),j2=c(),Gi=a("td"),F2=n("Model struggles to learn and produces unreliable predictions."),V2=c(),ks=a("tr"),Ui=a("td"),Of=a("strong"),K2=n("Lack of unique features"),Y2=c(),Hi=a("td"),X2=n("Poor generalization leading to inaccurate outputs."),Z2=c(),ws=a("tr"),Mi=a("td"),Pf=a("strong"),Q2=n("Carefully curated datasets"),J2=c(),Bi=a("td"),$2=n("Improved learning by ensuring the model sees only relevant, high-quality data."),eb=c(),zs=a("tr"),Wi=a("td"),xf=a("strong"),tb=n("Regularization techniques"),sb=c(),ji=a("td"),ab=n("Helps maintain focus on essential features and prevents instability."),ng=c(),Fi=a("p"),lb=n("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),og=c(),Ts=a("h3"),qs=a("a"),Nf=a("span"),rb=n("Implement these Strategies"),cg=c(),he=a("p"),ib=n("To prevent divergence and overfitting during training, carefully configure your training parameters and regularization techniques. Start with a "),Cf=a("strong"),nb=n("conservative learning rate"),ob=n(" (e.g., "),Vi=a("code"),cb=n("1e-5"),ub=n(") to avoid sudden spikes or NaN values in the loss, which are signs of divergence. Use gradient clipping ("),Ki=a("code"),pb=n("max_grad_norm: 1.0"),db=n(") to stabilize training by preventing excessively large updates to the model weights. A cosine learning rate scheduler ensures a smooth and stable adjustment of the learning rate over time, reducing the risk of instability."),ug=c(),ve=a("p"),fb=n("For regularization, incorporate techniques like dropout ("),Yi=a("code"),hb=n("dropout_prob: 0.1"),vb=n(") to prevent the model from over-relying on specific features, improving generalization. Use a small batch size ("),Xi=a("code"),gb=n("train_batch_size: 2"),mb=n(") to introduce noise into the training process, which can help avoid overfitting. Additionally, limit the number of training steps ("),Zi=a("code"),_b=n("max_train_steps: 1500"),Eb=n(") to prevent the model from memorizing the dataset.  By combining these strategies, you can train a robust model that generalizes well and avoids divergence / overfitting."),pg=c(),zl=a("pre"),dg=c(),Tl=a("pre"),fg=c(),Rs=a("h4"),Ss=a("a"),Gf=a("span"),bb=n("Data Considerations"),hg=c(),Wt=a("table"),Qi=a("thead"),Fe=a("tr"),Ji=a("th"),yb=n("Situation"),kb=c(),$i=a("th"),wb=n("Actual Risk"),zb=c(),en=a("th"),Tb=n("Solution"),qb=c(),ge=a("tbody"),Ve=a("tr"),tn=a("td"),Rb=n("High LR + small batch size"),Sb=c(),sn=a("td"),Db=n("Divergence"),Ab=c(),an=a("td"),Lb=n("Lower LR, increase batch size"),Ib=c(),Ke=a("tr"),ln=a("td"),Ob=n("Inconsistent features"),Pb=c(),rn=a("td"),xb=n("Overfitting"),Nb=c(),nn=a("td"),Cb=n("Improve dataset consistency"),Gb=c(),Ye=a("tr"),on=a("td"),Ub=n("Insufficient reg images"),Hb=c(),cn=a("td"),Mb=n("Class leakage"),Bb=c(),un=a("td"),Wb=n("Add 100-300 class images"),jb=c(),Xe=a("tr"),pn=a("td"),Fb=n("High variance in training data"),Vb=c(),dn=a("td"),Kb=n("Mode collapse"),Yb=c(),fn=a("td"),Xb=n("Curate focused dataset"),vg=c(),hn=a("p"),Zb=n("This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs: fix this by lowering the learning rate and increasing the batch size."),gg=c(),vn=a("p"),Qb=n("Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects, adding 100-300 images helps."),mg=c(),gn=a("p"),Jb=n("High variance in training data can result in mode collapse, producing repetitive outputs.  Keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),_g=c(),Eg=a("hr"),bg=c(),Ds=a("h2"),As=a("a"),Uf=a("span"),$b=n("Monitoring Tips"),yg=c(),Ls=a("p"),ey=n("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),ql=a("a"),ty=n("kohya-ss/sd-scripts"),sy=n(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),kg=c(),Is=a("h3"),Os=a("a"),Hf=a("span"),ay=n("Track loss curves"),wg=c(),Ps=a("p"),ly=n("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Rl=a("a"),ry=n("TensorBoard"),iy=n(" to create these graphs."),zg=c(),Sl=a("pre"),Tg=c(),xs=a("h4"),Ns=a("a"),Mf=a("span"),ny=n("What to Monitor:"),qg=c(),Ze=a("ul"),Bf=a("li"),oy=n("Training Loss: Should decrease steadily but not too quickly."),cy=c(),Wf=a("li"),uy=n("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),py=c(),jf=a("li"),dy=n("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),Rg=c(),Cs=a("h4"),Gs=a("a"),Ff=a("span"),fy=n("Warning Signs:"),Sg=c(),Qe=a("ul"),Vf=a("li"),hy=n("Sudden spikes in loss \u2192 Likely divergence."),vy=c(),Kf=a("li"),gy=n("Loss plateauing too early \u2192 Learning rate may be too low."),my=c(),Yf=a("li"),_y=n("Validation loss increasing while training loss decreases \u2192 Overfitting."),Dg=c(),Us=a("h4"),Hs=a("a"),Xf=a("span"),Ey=n("Generate validation images every 100 steps"),Ag=c(),Dl=a("p"),Zf=a("strong"),by=n("Why It Matters"),yy=n(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),Lg=c(),Al=a("pre"),Ig=c(),Ms=a("h4"),Bs=a("a"),Qf=a("span"),ky=n("What to Look For:"),Og=c(),Je=a("ul"),Jf=a("li"),wy=n("Consistency: Outputs should align with the training data style."),zy=c(),$f=a("li"),Ty=n("Artifacts: Check for distortions, noise, or unnatural features."),qy=c(),eh=a("li"),Ry=n("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),Pg=c(),Ll=a("blockquote"),mn=a("p"),Sy=n("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),xg=c(),Ws=a("h4"),js=a("a"),th=a("span"),Dy=n("Use Gradient Clipping"),Ng=c(),Il=a("p"),sh=a("strong"),Ay=n("Why It Matters"),Ly=n(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),Cg=c(),_n=a("p"),Iy=n("Key Insights:"),Gg=c(),$e=a("ul"),Ol=a("li"),Oy=n("Gradient Norm "),En=a("code"),Py=n("<"),xy=n(" than 0.1: Training may stall due to tiny updates."),Ny=c(),ah=a("li"),Cy=n("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),Gy=c(),lh=a("li"),Uy=n("Ideal Range: 0.1 to 2.0 for stable training."),Ug=c(),Pl=a("blockquote"),bn=a("p"),Hy=n("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Hg=c(),Fs=a("h4"),Vs=a("a"),rh=a("span"),My=n("Enable Mixed Precision Training"),Mg=c(),xl=a("p"),ih=a("strong"),By=n("Why It Matters"),Wy=n(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),Bg=c(),Nl=a("pre"),Wg=c(),yn=a("p"),jy=n("Benefits:"),jg=c(),et=a("ul"),nh=a("li"),Fy=n("2-3x Faster Training: Leverages GPU tensor cores."),Vy=c(),oh=a("li"),Ky=n("50% Less VRAM Usage: Allows larger batch sizes or models."),Yy=c(),ch=a("li"),Xy=n("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),Fg=c(),Cl=a("blockquote"),kn=a("p"),Zy=n("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),Vg=c(),Ks=a("h4"),Ys=a("a"),uh=a("span"),Qy=n("Start with Conservative Learning Rates"),Kg=c(),Xs=a("p"),Jy=n("Start off with 1e-5 to 1e-6.  "),ph=a("strong"),$y=n("Why It Matters"),e4=n(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Yg=c(),Gl=a("pre"),Xg=c(),jt=a("table"),wn=a("thead"),tt=a("tr"),zn=a("th"),t4=n("Option"),s4=c(),Tn=a("th"),a4=n("Values"),l4=c(),qn=a("th"),r4=n("Effect"),i4=c(),st=a("tbody"),at=a("tr"),Rn=a("td"),Sn=a("code"),n4=n("learning_rate"),o4=c(),Dn=a("td"),c4=n("0.005 - 0.0001"),u4=c(),An=a("td"),p4=n("Main control for learning rate. Sets defaults for the other two."),d4=c(),lt=a("tr"),Ln=a("td"),In=a("code"),f4=n("unet_lr"),h4=c(),On=a("td"),v4=n("0.0001 - 0.005"),g4=c(),Pn=a("td"),m4=n("Sets Unet\u2019s learning rate. Most sensitive part; avoid setting too high."),_4=c(),rt=a("tr"),xn=a("td"),Nn=a("code"),E4=n("text_encoder_lr"),b4=c(),Cn=a("td"),y4=n("0.00001 - 0.00005"),k4=c(),Gn=a("td"),w4=n("Sets text encoder\u2019s learning rate. Keep much lower than Unet\u2019s."),Zg=c(),Zs=a("h4"),Qs=a("a"),dh=a("span"),z4=n("What does this mean?"),Qg=c(),it=a("ul"),Ul=a("li"),T4=n("If you don\u2019t want to fine-tune, just use "),Un=a("code"),q4=n("--learning_rate"),R4=n(" to set the other two automatically."),S4=c(),Re=a("li"),D4=n("If you want more control, set "),Hn=a("code"),A4=n("--unet_lr"),L4=n(" and "),Mn=a("code"),I4=n("--text_encoder_lr"),O4=n(" individually. Setting "),Bn=a("code"),P4=n("--learning_rate"),x4=n(" becomes redundant in this case."),N4=c(),Ft=a("li"),C4=n("A common approach is to set "),Wn=a("code"),G4=n("--learning_rate"),U4=n(" the same as "),jn=a("code"),H4=n("--unet_lr"),M4=n(" for simplicity."),Jg=c(),Js=a("h4"),$s=a("a"),fh=a("span"),B4=n("Text Encoder Learning Rate"),$g=c(),Fn=a("p"),W4=n("The text encoder interprets text prompts and links tags/tokens to data in the Unet during training."),em=c(),Vn=a("ul"),ea=a("li"),hh=a("strong"),j4=n("Default Value"),F4=n(": 5e-5 (or uses "),Kn=a("code"),V4=n("--learning_rate"),K4=n(" if not specified)."),tm=c(),ta=a("h4"),sa=a("a"),vh=a("span"),Y4=n("Effects:"),sm=c(),nt=a("ul"),gh=a("li"),X4=n("Lowering it helps separate objects better in generations."),Z4=c(),mh=a("li"),Q4=n("If unwanted objects appear, try lowering it."),J4=c(),_h=a("li"),$4=n("If prompts require heavy weighting to make things appear, it\u2019s set too low."),am=c(),Yn=a("p"),e3=n("A well-trained text encoder improves prompt control and feature granularity."),lm=c(),aa=a("h4"),la=a("a"),Eh=a("span"),t3=n("Unet Learning Rate"),rm=c(),Xn=a("p"),s3=n("The Unet acts as the model\u2019s \u201Cvisual memory,\u201D handling image structure, detail, and relationships between elements."),im=c(),ra=a("ul"),Zn=a("li"),bh=a("strong"),a3=n("Default Value"),l3=n(": 1e-4 (avoid changing unless necessary)."),r3=c(),Hl=a("li"),yh=a("strong"),i3=n("Issues & Fixes"),n3=n(":"),Vt=a("ul"),Qn=a("li"),kh=a("strong"),o3=n("Overfitting"),c3=n(": Reduce learning rate, steps, or use dampeners."),u3=c(),Jn=a("li"),wh=a("strong"),p3=n("Visual Noise (blobs)"),d3=n(": Learning rate is too high: divide by at least 8."),f3=c(),$n=a("li"),zh=a("strong"),h3=n("Weak Details"),v3=n(": Increase learning rate or train for more steps."),nm=c(),eo=a("p"),g3=n("The Unet works progressively, starting with broad shapes and adding finer details. Overcooking it can lead to misplaced or excessive features (e.g., eyes everywhere)."),om=c(),ia=a("ul"),to=a("li"),Th=a("strong"),m3=n("Visualization"),_3=n(": Think of it as zooming in from a blurry silhouette to pixel-level detail."),E3=c(),so=a("li"),qh=a("strong"),b3=n("Structure"),y3=n(": IN blocks handle planning, OUT blocks manage fine details like texture."),cm=c(),ao=a("p"),k3=n("Burning the Unet results in chaotic outputs."),um=c(),Ml=a("p"),Rh=a("strong"),w3=n("Warning Signs"),z3=n(":"),pm=c(),ot=a("ul"),Sh=a("li"),T3=n("Loss Spikes: Learning rate is too high."),q3=c(),Dh=a("li"),R3=n("Slow Convergence: Learning rate is too low."),S3=c(),Ah=a("li"),D3=n("Oscillating Loss: Poor scheduling or unstable gradients."),dm=c(),Kt=a("table"),lo=a("thead"),me=a("tr"),ro=a("th"),A3=n("Practice"),L3=c(),io=a("th"),I3=n("Key Benefit"),O3=c(),no=a("th"),P3=n("Tool/Setting"),x3=c(),oo=a("th"),N3=n("Warning Signs"),C3=c(),le=a("tbody"),_e=a("tr"),co=a("td"),G3=n("Track Loss Curves"),U3=c(),uo=a("td"),H3=n("Detect overfitting/divergence early"),M3=c(),po=a("td"),B3=n("TensorBoard, Weights & Biases"),W3=c(),fo=a("td"),j3=n("Spikes, plateaus, growing gaps"),F3=c(),Ee=a("tr"),ho=a("td"),V3=n("Generate Validation Images"),K3=c(),vo=a("td"),Y3=n("Visualize model progress"),X3=c(),go=a("td"),Z3=n("Fixed prompts/seeds"),Q3=c(),mo=a("td"),J3=n("Artifacts, mode collapse"),$3=c(),be=a("tr"),_o=a("td"),ek=n("Gradient Clipping"),tk=c(),Eo=a("td"),sk=n("Prevent exploding gradients"),ak=c(),na=a("td"),lk=n("clip"),Lh=a("em"),rk=n("grad_norm"),ik=n(" (1.0-2.0)"),nk=c(),ct=a("td"),ok=n("Norm "),bo=a("code"),ck=n(">"),uk=n(" 10.0 or "),yo=a("code"),pk=n("<"),dk=n(" 0.1"),fk=c(),ye=a("tr"),ko=a("td"),hk=n("Mixed Precision Training"),vk=c(),wo=a("td"),gk=n("Faster training, lower VRAM usage"),mk=c(),zo=a("td"),_k=n("PyTorch AMP (torch.cuda.amp)"),Ek=c(),To=a("td"),bk=n("NaN values (disable if unstable)"),yk=c(),ke=a("tr"),qo=a("td"),kk=n("Conservative Learning Rates"),wk=c(),Ro=a("td"),zk=n("Stable training, avoid divergence"),Tk=c(),So=a("td"),qk=n("Start at 1e-5 to 1e-6, use scheduler"),Rk=c(),Do=a("td"),Sk=n("Spikes, slow convergence"),fm=c(),hm=a("hr"),vm=c(),oa=a("h2"),ca=a("a"),Ih=a("span"),Dk=n("Generating Regularization images"),gm=c(),ua=a("p"),Ak=n("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Ao=a("code"),Lk=n("1boy"),Ik=n(")."),mm=c(),ue=a("p"),Ok=n("According to the Dreambooth technique, "),Lo=a("code"),Pk=n("200"),xk=n(" regularization images per training image.  For example, if you have "),Io=a("code"),Nk=n("16"),Ck=n(" images: "),Oo=a("code"),Gk=n("200 * 16 = 3200"),Uk=n(" total regularization images.  When training, the math involved for calculating total steps is: "),Po=a("code"),Hk=n("repeats * training images >= repeats * regularization images"),_m=c(),xo=a("p"),Mk=n("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),Em=c(),pa=a("h4"),da=a("a"),Oh=a("span"),Bk=n("Important considerations"),bm=c(),ut=a("ol"),Ph=a("li"),Bl=a("p"),xh=a("strong"),Wk=n("Use the same base model for regularization images and training"),jk=a("br"),Fk=n(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Vk=c(),Nh=a("li"),Wl=a("p"),Ch=a("strong"),Kk=n("Maintain consistent class representation"),Yk=a("br"),Xk=n(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Zk=c(),Gh=a("li"),jl=a("p"),Uh=a("strong"),Qk=n("Match output resolution to training data"),Jk=a("br"),$k=n(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),ym=c(),Gr(Fl.$$.fragment),km=c(),fa=a("h4"),ha=a("a"),Hh=a("span"),e0=n("Generate using Stable Diffusion web UI"),wm=c(),va=a("p"),t0=n("We\u2019re going to use "),Vl=a("a"),s0=n("Stable Diffusion web UI"),a0=n(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),zm=c(),pt=a("p"),l0=n("We\u2019re going to use the "),No=a("code"),r0=n("X/Y/Z plot"),i0=n(" script to use "),Co=a("code"),n0=n("Prompt Search & Replace"),o0=n(" to dynamically build a prompt that will generate hundreds of regularization images."),Tm=c(),J=a("ol"),Mh=a("li"),Go=a("p"),c0=n("Select the text 2 image tab.  Enter a generic prompt "),Uo=a("code"),u0=n("princeadam, portrait, looking_at_viewer, forest"),p0=c(),Bh=a("li"),Kl=a("p"),d0=n("In generation parameters and select the "),Ho=a("code"),f0=n("X/Y/Z plot"),h0=n(" script."),v0=c(),Wh=a("li"),K=a("p"),g0=n("Select the "),Mo=a("code"),m0=n("X"),_0=n(" parameter and "),Bo=a("code"),E0=n("Prompt SR"),b0=n(" for Prompt Replace.  We\u2019re going to replace "),Wo=a("code"),y0=n("portrait"),k0=n(" with different camera angle tags: "),jo=a("code"),w0=n("close-up"),z0=n(", "),Fo=a("code"),T0=n("upper_body"),q0=n(", "),Vo=a("code"),R0=n("from_below"),S0=n(", "),Ko=a("code"),D0=n("from_above"),A0=n(", "),Yo=a("code"),L0=n("dutch_angle"),I0=c(),jh=a("li"),$=a("p"),O0=n("Select the "),Xo=a("code"),P0=n("Y"),x0=n(" parameter and "),Zo=a("code"),N0=n("Prompt SR"),C0=n(" for Prompt Replace.  Replace "),Qo=a("code"),G0=n("looking_at_viewer"),U0=n(": "),Jo=a("code"),H0=n("looking_away"),M0=n(", "),$o=a("code"),B0=n("looking_to_the_side"),W0=n(", "),ec=a("code"),j0=n("looking_ahead"),F0=n(", "),tc=a("code"),V0=n("looking_down"),K0=c(),Fh=a("li"),Y=a("p"),Y0=n("Select the "),sc=a("code"),X0=n("Z"),Z0=n(" parameter and "),ac=a("code"),Q0=n("Prompt SR"),J0=n(" for Prompt Replace. Replace "),lc=a("code"),$0=n("forest"),e5=n(" with a vareity of locatinos: "),rc=a("code"),t5=n("castle"),s5=n(", "),ic=a("code"),a5=n("mountain"),l5=n(", "),nc=a("code"),r5=n("cave"),i5=n(", "),oc=a("code"),n5=n("farm"),o5=n(", "),cc=a("code"),c5=n("ocean"),u5=c(),Vh=a("li"),uc=a("p"),p5=n("Select a fast sampler like "),pc=a("code"),d5=n("DPM2 KARRAS"),f5=c(),Kh=a("li"),ga=a("p"),h5=n("CFG Scale set to "),dc=a("code"),v5=n("7"),g5=n(" and Steps to "),fc=a("code"),m5=n("20"),qm=c(),dt=a("p"),_5=n("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),hc=a("code"),E5=n("150"),b5=n(" - "),vc=a("code"),y5=n("200"),k5=n(" and keep in mind we can add and remove as we try different training settings with different output."),Rm=c(),Gr(Yl.$$.fragment),Sm=c(),ma=a("h4"),_a=a("a"),Yh=a("span"),w5=n("Download images"),Dm=c(),gc=a("p"),z5=n("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Am=c(),we=a("ul"),mc=a("li"),Xl=a("a"),T5=n("3ee Games regularization images"),q5=n(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),R5=c(),_c=a("li"),Zl=a("a"),S5=n("Pre-Rendered Regularization Images"),D5=n(": Includes 1500 regularization images."),A5=c(),Ec=a("li"),Ql=a("a"),L5=n("Stable Diffusion 1.5 Regularization Images"),I5=n(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),O5=c(),bc=a("li"),Jl=a("a"),P5=n("Aitrepreneur SDXL image set"),x5=n(": a large image set generated with Stable Diffusion SDXL."),Lm=c(),Ea=a("h4"),ba=a("a"),Xh=a("span"),N5=n("Captioning Regularization images"),Im=c(),yc=a("p"),C5=n("While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts.  Critical for maintaining style consistency."),Om=c(),kc=a("p"),G5=n("Here\u2019s the workflow I used:"),Pm=c(),ft=a("ul"),wc=a("li"),Zh=a("strong"),U5=n("Structured Filenames"),H5=n(": Stable Diffusion Web UI automatically embeds prompts in filenames"),M5=c(),ht=a("li"),Qh=a("strong"),B5=n("Automated Extraction"),W5=n(": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),zc=a("code"),j5=n("1boy"),F5=n(" or "),Tc=a("code"),V5=n("purple_vest"),K5=n("."),Y5=c(),qc=a("li"),Jh=a("strong"),X5=n("Manual Verification"),Z5=n(": Spot-checked captions to ensure accuracy."),xm=c(),$l=a("pre"),Nm=c(),ya=a("ol"),er=a("li"),Q5=n("Save this file as "),Rc=a("code"),J5=n("filename2txt.bat"),$5=n(" and place it into the regularization images directory"),ew=c(),tr=a("li"),tw=n("Run: "),Sc=a("code"),sw=n(".\\filename2txt.bat"),aw=n(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Cm=c(),ka=a("p"),$h=a("strong"),lw=n("Example filename"),rw=n(": "),Dc=a("code"),iw=n("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),Gm=c(),wa=a("h2"),za=a("a"),ev=a("span"),nw=n("Training a LoRA"),Um=c(),vt=a("p"),ow=n("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),sr=a("a"),cw=n("Kohya\u2019s Stable Diffusion trainers"),uw=n(".  If you want to use a GUI, use "),ar=a("a"),pw=n("Kohya\u2019s GUI"),dw=n(".  In this article, you can will able to use either since the settings config can be modified in json and reloaded in the GUI."),Hm=c(),lr=a("blockquote"),Ta=a("p"),fw=n("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),rr=a("a"),hw=n("Kohya SD script documentation"),vw=n("."),Mm=c(),ir=a("blockquote"),Se=a("p"),gw=n("\u{1F4C4} Recommended reading: "),nr=a("a"),mw=n("https://rentry.org/59xed3"),_w=n(", "),or=a("a"),Ew=n("https://rentry.org/ezlora"),bw=n(", "),cr=a("a"),yw=n("https://rentry.org/lora_train"),Bm=c(),qa=a("h3"),Ra=a("a"),tv=a("span"),kw=n("Directory setup"),Wm=c(),Sa=a("p"),ww=n("In your configuration json, use "),Ac=a("code"),zw=n("reg_data_dir"),Tw=n(" to point to the directory with your regularization images:"),jm=c(),ur=a("pre"),Fm=c(),Lc=a("p"),qw=n("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Vm=c(),pr=a("pre"),Km=c(),Da=a("p"),Rw=n("Set the "),Ic=a("code"),Sw=n("number of iterations"),Dw=n(" so that training images are used as often as or more often than regularization images."),Ym=c(),dr=a("blockquote"),Aa=a("p"),Aw=n("In one epoch, the total data is "),Oc=a("code"),Lw=n("training images \xD7 iterations"),Iw=n(". If there are more regularization images than this, the extras won\u2019t be used."),Xm=c(),gt=a("p"),Ow=n("Create folders in the training image folder with the format "),Pc=a("code"),Pw=n("<repetition count>_<class>"),xw=n(" multiple times, and similarly create folders in the regularization image folder with the format "),xc=a("code"),Nw=n("<repetition count>_<class>"),Cw=n("."),Zm=c(),Nc=a("p"),Gw=n("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Qm=c(),La=a("ul"),Cc=a("li"),Uw=n("train_data_dir"),sv=a("ul"),av=a("li"),Hw=n("10_princeadam"),Mw=c(),Gc=a("li"),Bw=n("reg_dir"),lv=a("ul"),rv=a("li"),Ww=n("1_1boy"),Jm=c(),Uc=a("p"),jw=n("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),$m=c(),fr=a("p"),hr=a("img"),e1=c(),Ia=a("h3"),Oa=a("a"),iv=a("span"),Fw=n("Training Settings"),t1=c(),Yt=a("p"),Vw=n("The training setup we\u2019re going to use is:  "),Hc=a("code"),Kw=n("Number of images * repeats * epoch / batch size = total steps"),Yw=n(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Mc=a("code"),Xw=n("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),s1=c(),Xt=a("table"),Bc=a("thead"),re=a("tr"),Wc=a("th"),Zw=n("Number of Images"),Qw=c(),jc=a("th"),Jw=n("Repeats"),$w=c(),Fc=a("th"),ez=n("Epochs"),tz=c(),Vc=a("th"),sz=n("Batch Size"),az=c(),Kc=a("th"),lz=n("Total Steps"),rz=c(),Yc=a("tbody"),ie=a("tr"),Xc=a("td"),iz=n("45"),nz=c(),Zc=a("td"),oz=n("10"),cz=c(),Qc=a("td"),uz=n("20"),pz=c(),Jc=a("td"),dz=n("2"),fz=c(),$c=a("td"),hz=n("4500"),a1=c(),eu=a("p"),vz=n("Now let\u2019s focus on these training settings:"),l1=c(),vr=a("pre"),r1=c(),M=a("ul"),tu=a("li"),gr=a("strong"),gz=n("Learning Rate ("),su=a("code"),mz=n("learning_rate"),_z=n(")"),Ez=n(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),bz=c(),au=a("li"),mr=a("strong"),yz=n("Text Encoder Learning Rate ("),lu=a("code"),kz=n("text_encoder_lr"),wz=n(")"),zz=n(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Tz=c(),ru=a("li"),_r=a("strong"),qz=n("UNet Learning Rate ("),iu=a("code"),Rz=n("unet_lr"),Sz=n(")"),Dz=n(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Az=c(),nu=a("li"),Er=a("strong"),Lz=n("Learning Rate Scheduler ("),ou=a("code"),Iz=n("lr_scheduler"),Oz=n(")"),Pz=n(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),xz=c(),cu=a("li"),nv=a("strong"),Nz=n("Number of Cycles"),Cz=n(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Gz=c(),uu=a("li"),br=a("strong"),Uz=n("Network Dimension ("),pu=a("code"),Hz=n("network_dim"),Mz=n(")"),Bz=n(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Wz=c(),du=a("li"),yr=a("strong"),jz=n("Network Alpha ("),fu=a("code"),Fz=n("network_alpha"),Vz=n(")"),Kz=n(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Yz=c(),hu=a("li"),kr=a("strong"),Xz=n("Clip Skip ("),vu=a("code"),Zz=n("clip_skip"),Qz=n(")"),Jz=n(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),$z=c(),gu=a("li"),wr=a("strong"),e6=n("Max Token Length ("),mu=a("code"),t6=n("max_token_length"),s6=n(")"),a6=n(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),l6=c(),_u=a("li"),zr=a("strong"),r6=n("Noise Offset ("),Eu=a("code"),i6=n("noise_offset"),n6=n(")"),o6=n(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),c6=c(),bu=a("li"),Tr=a("strong"),u6=n("Regularization Data Directory ("),yu=a("code"),p6=n("reg_data_dir"),d6=n(")"),f6=n(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),i1=c(),Pa=a("h3"),xa=a("a"),ov=a("span"),h6=n("Fine Tuning"),n1=c(),ku=a("p"),v6=n("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),o1=c(),Gr(qr.$$.fragment),c1=c(),Na=a("h4"),Ca=a("a"),cv=a("span"),g6=n("Workflow with Auto1111 WebUI"),u1=c(),Ga=a("p"),m6=n("We\u2019re going to use "),Rr=a("a"),_6=n("Stable Diffusion web UI"),E6=n(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),p1=c(),Ua=a("p"),b6=n("We\u2019re going to use the "),wu=a("code"),y6=n("X/Y/Z plot"),k6=n(" script to compare different epochs."),d1=c(),ne=a("ul"),zu=a("li"),w6=n("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),f1=a("princeadam0001:0.7"),z6=c(),uv=a("li"),T6=n("In generation parameters and select the X/Y/Z plot script."),q6=c(),mt=a("li"),R6=n("Select "),Tu=a("code"),S6=n("Prompt SR"),D6=n(" for Prompt Replace.  We\u2019re going to replace "),qu=a("code"),A6=n("<princeadam0001:0.7>"),L6=n(" with different epoch: "),Ru=a("code"),I6=n("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),O6=c(),Su=a("li"),P6=n("Select a fast sampler like "),Du=a("code"),x6=n("DPM2 KARRAS"),N6=c(),Ha=a("li"),C6=n("CFG Scale set to "),Au=a("code"),G6=n("7"),U6=n(" and Steps to "),Lu=a("code"),H6=n("20"),h1=c(),_t=a("p"),M6=n("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Iu=a("code"),B6=n("network_dim"),W6=n(" and "),Ou=a("code"),j6=n("network_alpha"),F6=n(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),v1=c(),ze=a("ul"),Ma=a("li"),V6=n("Select "),Pu=a("code"),K6=n("Prompt SR"),Y6=n(" for Prompt Replace.  We\u2019re going to replace the weights "),xu=a("code"),X6=n("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),Z6=c(),Sr=a("li"),Q6=n("Use Prompt SR to generate a variety of angles: Select "),Nu=a("code"),J6=n("Prompt SR"),$6=n(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),e8=c(),pv=a("li"),t8=n("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),s8=c(),dv=a("li"),a8=n("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),g1=c(),Ba=a("h4"),Wa=a("a"),fv=a("span"),l8=n("Issues to look for"),m1=c(),Te=a("ul"),Cu=a("li"),hv=a("strong"),r8=n("Undercooked:"),i8=n(" Lacks output, adjust unet learning rate or extend training duration."),n8=c(),Gu=a("li"),vv=a("strong"),o8=n("Overcooked:"),c8=n(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),u8=c(),Uu=a("li"),gv=a("strong"),p8=n("Overfit:"),d8=n(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),f8=c(),Hu=a("li"),mv=a("strong"),h8=n("Mismatched:"),v8=n(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),_1=c(),Mu=a("p"),g8=n("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),E1=c(),Dr=a("p"),Ar=a("img"),b1=c(),ja=a("h3"),Fa=a("a"),_v=a("span"),m8=n("Troubleshooting"),y1=c(),Bu=a("p"),_8=n("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),k1=c(),Et=a("ul"),Lr=a("li"),E8=n("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Wu=a("code"),b8=n("200"),y8=n(" regularization images per training image."),k8=c(),Ir=a("li"),w8=n("Repeats of regularization images, but may overfit more.  Increasing the "),ju=a("code"),z8=n("repetition_count"),T8=n(" will cycle through the images more but the results may have results that overfit the model."),q8=c(),Ev=a("li"),R8=n("Create more regularization images without increasing repeats will help with the overfitting."),w1=c(),Zt=a("table"),Fu=a("thead"),bt=a("tr"),Vu=a("th"),S8=n("Issue"),D8=c(),Ku=a("th"),A8=n("Situation"),L8=c(),Yu=a("th"),I8=n("Recommendation"),O8=c(),qe=a("tbody"),yt=a("tr"),Xu=a("td"),P8=n("Varying quality"),x8=c(),Zu=a("td"),N8=n("Results differ from expectations"),C8=c(),Qu=a("td"),G8=n("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),U8=c(),kt=a("tr"),Ju=a("td"),H8=n("Inadequate regularization for input data"),M8=c(),$u=a("td"),B8=n("Lower input images, less regularization needed"),W8=c(),ep=a("td"),j8=n("Reduce the number of input images or increasing the quantity of reg images."),F8=c(),wt=a("tr"),tp=a("td"),V8=n("Overfitting due to repetition"),K8=c(),sp=a("td"),Y8=n("Repeats of reg images, risk of overfitting"),X8=c(),ap=a("td"),Z8=n("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),Q8=c(),zt=a("tr"),lp=a("td"),J8=n("Mitigate overfitting while increasing diversity"),$8=c(),rp=a("td"),e7=n("Create more reg images without repeats"),t7=c(),ip=a("td"),s7=n("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),z1=c(),Va=a("h4"),Ka=a("a"),bv=a("span"),a7=n("More Solutions"),T1=c(),np=a("p"),l7=n("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),q1=c(),Qt=a("table"),op=a("thead"),Tt=a("tr"),cp=a("th"),r7=n("Symptom"),i7=c(),up=a("th"),n7=n("Likely Cause"),o7=c(),pp=a("th"),c7=n("Solution"),u7=c(),W=a("tbody"),qt=a("tr"),dp=a("td"),p7=n("Plastic texture persists"),d7=c(),fp=a("td"),f7=n("Insufficient human reg images"),h7=c(),hp=a("td"),v7=n("Add real photos to reg set"),g7=c(),Rt=a("tr"),vp=a("td"),m7=n("Loss plateaus early"),_7=c(),gp=a("td"),E7=n("Learning rate too low"),b7=c(),mp=a("td"),y7=n("Increase LR by 10x"),k7=c(),St=a("tr"),_p=a("td"),w7=n("Features blurry"),z7=c(),Ep=a("td"),T7=n("Network dimension too small"),q7=c(),bp=a("td"),R7=n("Increase network_dim to 64+"),S7=c(),Dt=a("tr"),yp=a("td"),D7=n("Color distortion"),A7=c(),kp=a("td"),L7=n("Noise offset conflict"),I7=c(),wp=a("td"),O7=n("Try noise_offset 0.05-0.1"),P7=c(),At=a("tr"),zp=a("td"),x7=n("Overly stylized outputs"),N7=c(),Tp=a("td"),C7=n("Reg image style mismatch"),G7=c(),qp=a("td"),U7=n("Regenerate reg images with base model"),H7=c(),Lt=a("tr"),Rp=a("td"),M7=n("Training instability"),B7=c(),Sp=a("td"),W7=n("Batch size too large"),j7=c(),Dp=a("td"),F7=n("Reduce batch_size to 1-2"),V7=c(),It=a("tr"),Ap=a("td"),K7=n("Slow convergence"),Y7=c(),Lp=a("td"),X7=n("Network_alpha too high"),Z7=c(),Ip=a("td"),Q7=n("Set alpha = dim/2 (e.g., 64/2 = 32)"),J7=c(),Ot=a("tr"),Op=a("td"),$7=n("Loss divergence"),eT=c(),Pp=a("td"),tT=n("Text encoder LR too high"),sT=c(),xp=a("td"),aT=n("Reduce text_encoder_lr by 10x"),lT=c(),Pt=a("tr"),Np=a("td"),rT=n("Poor prompt adherence"),iT=c(),Cp=a("td"),nT=n("Clip skip too high"),oT=c(),Gp=a("td"),cT=n("Reduce clip_skip to 1-2"),uT=c(),xt=a("tr"),Up=a("td"),pT=n("Memory errors"),dT=c(),Hp=a("td"),fT=n("Resolution too high"),hT=c(),Mp=a("td"),vT=n("Reduce to 512-768px, enable gradient checkpointing"),R1=c(),Ya=a("h2"),Xa=a("a"),yv=a("span"),gT=n("Results"),S1=c(),Bp=a("p"),mT=n("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),D1=c(),Wp=a("p"),_T=n("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),A1=c(),Or=a("p"),Pr=a("img"),L1=c(),jp=a("p"),ET=n("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),I1=c(),Jt=a("h2"),Za=a("a"),kv=a("span"),bT=n("spacelab"),O1=c(),De&&De.c(),P1=Xd(),this.h()},l(s){f=l(s,"P",{});var d=r(f);g=o(d,"Growing up in the \u201880s, I loved vintage action figures: their bold colors, dynamic poses, worn paint and plastic seams. So when I trained a Stable Diffusion LoRA model using photos of my Masters of the Universe Prince Adam figure, I ran into a problem: the AI was too accurate. It perfectly replicated the figure\u2019s plastic texture, paint flaws, and stiff pose, making the results look more like a toy than a legendary hero."),d.forEach(t),v=u(s),h=l(s,"P",{});var u9=r(h);m=o(u9,"I wanted to go further to transform Prince Adam into different styles, free from his plastic origins. That\u2019s where regularization images came in, helping to prevent overfitting and guide the AI\u2019s creative direction. My goal? Keep his iconic costume (white shirt, pink vest) but reimagine him in nostalgic, artistic styles."),u9.forEach(t),E=u(s),y=l(s,"H4",{id:!0});var yT=r(y);z=l(yT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var p9=r(z);T=l(p9,"SPAN",{class:!0}),r(T).forEach(t),p9.forEach(t),k=o(yT,"Experiment 1: Anime-Inspired Heroism"),yT.forEach(t),b=u(s),w=l(s,"P",{class:!0});var d9=r(w);L=l(d9,"IMG",{src:!0,alt:!0,class:!0}),d9.forEach(t),x=u(s),C=l(s,"P",{});var f9=r(C);S=o(f9,"I first generated regularization images of anime-style characters wearing Prince Adam\u2019s outfit. This gave the AI two guides:"),f9.forEach(t),D=u(s),R=l(s,"UL",{});var N1=r(R);O=l(N1,"LI",{});var h9=r(O);P=o(h9,"My action figure photos (for costume accuracy)."),h9.forEach(t),Q=u(N1),j=l(N1,"LI",{});var v9=r(j);F=o(v9,"Stylized anime references (for anatomy and texture)."),v9.forEach(t),N1.forEach(t),B=u(s),N=l(s,"P",{});var g9=r(N);A=o(g9,"The result? A Prince Adam with flowing hair, fabric-like clothing, and dynamic lighting.  Bridging the gap between toy and anime hero."),g9.forEach(t),G=u(s),Z=l(s,"H4",{id:!0});var kT=r(Z);U=l(kT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var m9=r(U);q=l(m9,"SPAN",{class:!0}),r(q).forEach(t),m9.forEach(t),H=o(kT,"Experiment 2: Retro Cartoon Resurrection"),kT.forEach(t),ls=u(s),Le=l(s,"P",{class:!0});var _9=r(Le);pe=l(_9,"IMG",{src:!0,alt:!0,class:!0}),_9.forEach(t),Dv=u(s),Br=l(s,"P",{});var E9=r(Br);H_=o(E9,"Next, I used screenshots from the original 1983 Masters of the Universe cartoon as regularization images. This transformed the plastic sheen into cel-shaded vibrancy and replaced his stiff pose with a battle-ready stance, straight out of the show."),E9.forEach(t),Av=u(s),rs=l(s,"H2",{id:!0});var wT=r(rs);is=l(wT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var b9=r(is);Qd=l(b9,"SPAN",{class:!0}),r(Qd).forEach(t),b9.forEach(t),M_=o(wT,"What are Regularization Images?"),wT.forEach(t),Lv=u(s),Wr=l(s,"P",{});var y9=r(Wr);B_=o(y9,"Regularization images are used to prevent overfitting and language drifting during model training. They work by implementing prior-preservation loss, which ensures the model retains its understanding of the original class (e.g., \u201C1boy\u201D or \u201Cperson\u201D) while learning new concepts (e.g., a specific action figure). Without regularization, the model might overfit to the training data, losing its ability to generate diverse, class-consistent outputs or correctly interpret prompts. By including generic images of the original class, regularization keeps the model balanced and prevents it from \u201Cforgetting\u201D its prior knowledge."),y9.forEach(t),Iv=u(s),fl=l(s,"BLOCKQUOTE",{class:!0});var k9=r(fl);jr=l(k9,"P",{class:!0});var w9=r(jr);W_=o(w9,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),w9.forEach(t),k9.forEach(t),Ov=u(s),Ur(hl.$$.fragment,s),Pv=u(s),Fr=l(s,"P",{});var z9=r(Fr);j_=o(z9,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),z9.forEach(t),xv=u(s),Vr=l(s,"P",{});var T9=r(Vr);F_=o(T9,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),T9.forEach(t),Nv=u(s),Kr=l(s,"P",{});var q9=r(Kr);V_=o(q9,"Regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),q9.forEach(t),Cv=u(s),Ht=l(s,"TABLE",{class:!0});var C1=r(Ht);Yr=l(C1,"THEAD",{class:!0});var R9=r(Yr);Ie=l(R9,"TR",{class:!0});var Fp=r(Ie);Xr=l(Fp,"TH",{class:!0});var S9=r(Xr);K_=o(S9,"Aspect"),S9.forEach(t),Y_=u(Fp),Zr=l(Fp,"TH",{class:!0});var D9=r(Zr);X_=o(D9,"Regularization"),D9.forEach(t),Z_=u(Fp),Qr=l(Fp,"TH",{class:!0});var A9=r(Qr);Q_=o(A9,"No Regularization"),A9.forEach(t),Fp.forEach(t),R9.forEach(t),J_=u(C1),Oe=l(C1,"TBODY",{class:!0});var Vp=r(Oe);Pe=l(Vp,"TR",{class:!0});var Kp=r(Pe);Jr=l(Kp,"TD",{class:!0});var L9=r(Jr);Jd=l(L9,"STRONG",{});var I9=r(Jd);$_=o(I9,"Class Definition"),I9.forEach(t),L9.forEach(t),eE=u(Kp),$r=l(Kp,"TD",{class:!0});var O9=r($r);tE=o(O9,"Explicit anchoring"),O9.forEach(t),sE=u(Kp),ei=l(Kp,"TD",{class:!0});var P9=r(ei);aE=o(P9,"Implicit learning"),P9.forEach(t),Kp.forEach(t),lE=u(Vp),xe=l(Vp,"TR",{class:!0});var Yp=r(xe);ti=l(Yp,"TD",{class:!0});var x9=r(ti);$d=l(x9,"STRONG",{});var N9=r($d);rE=o(N9,"Failure Modes"),N9.forEach(t),x9.forEach(t),iE=u(Yp),si=l(Yp,"TD",{class:!0});var C9=r(si);nE=o(C9,"Underfitting if overdone"),C9.forEach(t),oE=u(Yp),ai=l(Yp,"TD",{class:!0});var G9=r(ai);cE=o(G9,"Overfitting/drift"),G9.forEach(t),Yp.forEach(t),uE=u(Vp),Ne=l(Vp,"TR",{class:!0});var Xp=r(Ne);li=l(Xp,"TD",{class:!0});var U9=r(li);ef=l(U9,"STRONG",{});var H9=r(ef);pE=o(H9,"Data Efficiency"),H9.forEach(t),U9.forEach(t),dE=u(Xp),ri=l(Xp,"TD",{class:!0});var M9=r(ri);fE=o(M9,"Better generalization"),M9.forEach(t),hE=u(Xp),ii=l(Xp,"TD",{class:!0});var B9=r(ii);vE=o(B9,"Requires more data"),B9.forEach(t),Xp.forEach(t),Vp.forEach(t),C1.forEach(t),Gv=u(s),ni=l(s,"P",{});var W9=r(ni);gE=o(W9,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),W9.forEach(t),Uv=u(s),oi=l(s,"P",{});var j9=r(oi);mE=o(j9,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),j9.forEach(t),Hv=u(s),vl=l(s,"BLOCKQUOTE",{class:!0});var F9=r(vl);ci=l(F9,"P",{class:!0});var V9=r(ci);_E=o(V9,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),V9.forEach(t),F9.forEach(t),Mv=u(s),ns=l(s,"H4",{id:!0});var zT=r(ns);os=l(zT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var K9=r(os);tf=l(K9,"SPAN",{class:!0}),r(tf).forEach(t),K9.forEach(t),EE=o(zT,"Scenario 1: Limited Training Data"),zT.forEach(t),Bv=u(s),gl=l(s,"P",{});var TT=r(gl);sf=l(TT,"STRONG",{});var Y9=r(sf);bE=o(Y9,"Situation"),Y9.forEach(t),yE=o(TT,": You only have a few images of your cat and no other cat images."),TT.forEach(t),Wv=u(s),ml=l(s,"P",{});var qT=r(ml);af=l(qT,"STRONG",{});var X9=r(af);kE=o(X9,"Problem"),X9.forEach(t),wE=o(qT,": The model lacks sufficient data to learn general \u201Ccat\u201D features, making it unable to accurately recognize your cat."),qT.forEach(t),jv=u(s),_l=l(s,"P",{});var RT=r(_l);lf=l(RT,"STRONG",{});var Z9=r(lf);zE=o(Z9,"Solution"),Z9.forEach(t),TE=o(RT,": Use regularization images of diverse cats to teach the model general cat characteristics, improving its ability to recognize your specific cat."),RT.forEach(t),Fv=u(s),cs=l(s,"H4",{id:!0});var ST=r(cs);us=l(ST,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Q9=r(us);rf=l(Q9,"SPAN",{class:!0}),r(rf).forEach(t),Q9.forEach(t),qE=o(ST,"Scenario 2: Imbalanced Training Data"),ST.forEach(t),Vv=u(s),El=l(s,"P",{});var DT=r(El);nf=l(DT,"STRONG",{});var J9=r(nf);RE=o(J9,"Situation"),J9.forEach(t),SE=o(DT,": You have many images of other cats but only a few of your cat."),DT.forEach(t),Kv=u(s),bl=l(s,"P",{});var AT=r(bl);of=l(AT,"STRONG",{});var $9=r(of);DE=o($9,"Problem"),$9.forEach(t),AE=o(AT,": The model may focus too much on the other cats, failing to learn the unique features of your cat."),AT.forEach(t),Yv=u(s),yl=l(s,"P",{});var LT=r(yl);cf=l(LT,"STRONG",{});var eR=r(cf);LE=o(eR,"Solution"),eR.forEach(t),IE=o(LT,": Add regularization images of generic cats to help the model focus on general cat features, ensuring it doesn\u2019t get distracted by irrelevant details from the other cats."),LT.forEach(t),Xv=u(s),ps=l(s,"H2",{id:!0});var IT=r(ps);ds=l(IT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var tR=r(ds);uf=l(tR,"SPAN",{class:!0}),r(uf).forEach(t),tR.forEach(t),OE=o(IT,"Divergence"),IT.forEach(t),Zv=u(s),kl=l(s,"P",{});var OT=r(kl);pf=l(OT,"STRONG",{});var sR=r(pf);PE=o(sR,"Divergence"),sR.forEach(t),xE=o(OT," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),OT.forEach(t),Qv=u(s),Ce=l(s,"P",{});var Zp=r(Ce);NE=o(Zp,"Preventing divergence starts with "),df=l(Zp,"STRONG",{});var aR=r(df);CE=o(aR,"careful dataset curation"),aR.forEach(t),GE=o(Zp," selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),ff=l(Zp,"STRONG",{});var lR=r(ff);UE=o(lR,"regularization techniques"),lR.forEach(t),HE=o(Zp," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Zp.forEach(t),Jv=u(s),Ge=l(s,"UL",{});var Qp=r(Ge);ui=l(Qp,"LI",{});var PT=r(ui);hf=l(PT,"STRONG",{});var rR=r(hf);ME=o(rR,"Chaotic outputs"),rR.forEach(t),BE=o(PT," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),PT.forEach(t),WE=u(Qp),pi=l(Qp,"LI",{});var xT=r(pi);vf=l(xT,"STRONG",{});var iR=r(vf);jE=o(iR,"Exploding gradients"),iR.forEach(t),FE=o(xT," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),xT.forEach(t),VE=u(Qp),fs=l(Qp,"LI",{});var wv=r(fs);gf=l(wv,"STRONG",{});var nR=r(gf);KE=o(nR,"Loss value instability (NaN/infinity values)"),nR.forEach(t),YE=o(wv," The training loss fluctuates wildly, sometimes becoming "),di=l(wv,"CODE",{class:!0});var oR=r(di);XE=o(oR,"NaN"),oR.forEach(t),ZE=o(wv," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),wv.forEach(t),Qp.forEach(t),$v=u(s),wl=l(s,"BLOCKQUOTE",{class:!0});var cR=r(wl);fi=l(cR,"P",{class:!0});var uR=r(fi);QE=o(uR,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),uR.forEach(t),cR.forEach(t),eg=u(s),hs=l(s,"H2",{id:!0});var NT=r(hs);vs=l(NT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var pR=r(vs);mf=l(pR,"SPAN",{class:!0}),r(mf).forEach(t),pR.forEach(t),_f=l(NT,"STRONG",{});var dR=r(_f);JE=o(dR,"Overfitting"),dR.forEach(t),NT.forEach(t),tg=u(s),hi=l(s,"P",{});var fR=r(hi);$E=o(fR,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),fR.forEach(t),sg=u(s),Ue=l(s,"UL",{});var Jp=r(Ue);vi=l(Jp,"LI",{});var CT=r(vi);Ef=l(CT,"STRONG",{});var hR=r(Ef);e2=o(hR,"Perfectly replicates training samples"),hR.forEach(t),t2=o(CT," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),CT.forEach(t),s2=u(Jp),gi=l(Jp,"LI",{});var GT=r(gi);bf=l(GT,"STRONG",{});var vR=r(bf);a2=o(vR,"Fails to generalize to new inputs"),vR.forEach(t),l2=o(GT," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),GT.forEach(t),r2=u(Jp),mi=l(Jp,"LI",{});var UT=r(mi);yf=l(UT,"STRONG",{});var gR=r(yf);i2=o(gR,"Shows excellent training loss but poor validation loss"),gR.forEach(t),n2=o(UT," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),UT.forEach(t),Jp.forEach(t),ag=u(s),gs=l(s,"H3",{id:!0});var HT=r(gs);ms=l(HT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mR=r(ms);kf=l(mR,"SPAN",{class:!0}),r(kf).forEach(t),mR.forEach(t),wf=l(HT,"STRONG",{});var _R=r(wf);o2=o(_R,"Key Differences"),_R.forEach(t),HT.forEach(t),lg=u(s),Mt=l(s,"TABLE",{class:!0});var G1=r(Mt);_i=l(G1,"THEAD",{class:!0});var ER=r(_i);He=l(ER,"TR",{class:!0});var $p=r(He);Ei=l($p,"TH",{class:!0});var bR=r(Ei);zf=l(bR,"STRONG",{});var yR=r(zf);c2=o(yR,"Aspect"),yR.forEach(t),bR.forEach(t),u2=u($p),bi=l($p,"TH",{class:!0});var kR=r(bi);Tf=l(kR,"STRONG",{});var wR=r(Tf);p2=o(wR,"Divergence"),wR.forEach(t),kR.forEach(t),d2=u($p),yi=l($p,"TH",{class:!0});var zR=r(yi);qf=l(zR,"STRONG",{});var TR=r(qf);f2=o(TR,"Overfitting"),TR.forEach(t),zR.forEach(t),$p.forEach(t),ER.forEach(t),h2=u(G1),de=l(G1,"TBODY",{class:!0});var Qa=r(de);Me=l(Qa,"TR",{class:!0});var ed=r(Me);ki=l(ed,"TD",{class:!0});var qR=r(ki);Rf=l(qR,"STRONG",{});var RR=r(Rf);v2=o(RR,"Cause"),RR.forEach(t),qR.forEach(t),g2=u(ed),wi=l(ed,"TD",{class:!0});var SR=r(wi);m2=o(SR,"Excessive learning rate"),SR.forEach(t),_2=u(ed),zi=l(ed,"TD",{class:!0});var DR=r(zi);E2=o(DR,"Insufficient regularization"),DR.forEach(t),ed.forEach(t),b2=u(Qa),Be=l(Qa,"TR",{class:!0});var td=r(Be);Ti=l(td,"TD",{class:!0});var AR=r(Ti);Sf=l(AR,"STRONG",{});var LR=r(Sf);y2=o(LR,"Loss Behavior"),LR.forEach(t),AR.forEach(t),k2=u(td),qi=l(td,"TD",{class:!0});var IR=r(qi);w2=o(IR,"Sudden spikes/NaN values"),IR.forEach(t),z2=u(td),Ri=l(td,"TD",{class:!0});var OR=r(Ri);T2=o(OR,"Steady decrease then rise"),OR.forEach(t),td.forEach(t),q2=u(Qa),We=l(Qa,"TR",{class:!0});var sd=r(We);Si=l(sd,"TD",{class:!0});var PR=r(Si);Df=l(PR,"STRONG",{});var xR=r(Df);R2=o(xR,"Output Quality"),xR.forEach(t),PR.forEach(t),S2=u(sd),Di=l(sd,"TD",{class:!0});var NR=r(Di);D2=o(NR,"Random noise/artifacts"),NR.forEach(t),A2=u(sd),Ai=l(sd,"TD",{class:!0});var CR=r(Ai);L2=o(CR,"Overly detailed replicas"),CR.forEach(t),sd.forEach(t),I2=u(Qa),je=l(Qa,"TR",{class:!0});var ad=r(je);Li=l(ad,"TD",{class:!0});var GR=r(Li);Af=l(GR,"STRONG",{});var UR=r(Af);O2=o(UR,"Recovery"),UR.forEach(t),GR.forEach(t),P2=u(ad),Ii=l(ad,"TD",{class:!0});var HR=r(Ii);x2=o(HR,"Requires restart"),HR.forEach(t),N2=u(ad),Oi=l(ad,"TD",{class:!0});var MR=r(Oi);C2=o(MR,"Early stopping works"),MR.forEach(t),ad.forEach(t),Qa.forEach(t),G1.forEach(t),rg=u(s),_s=l(s,"H3",{id:!0});var MT=r(_s);Es=l(MT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var BR=r(Es);Lf=l(BR,"SPAN",{class:!0}),r(Lf).forEach(t),BR.forEach(t),G2=o(MT,"Preventing Divergence"),MT.forEach(t),ig=u(s),Bt=l(s,"TABLE",{class:!0});var U1=r(Bt);Pi=l(U1,"THEAD",{class:!0});var WR=r(Pi);bs=l(WR,"TR",{class:!0});var H1=r(bs);xi=l(H1,"TH",{class:!0});var jR=r(xi);U2=o(jR,"Situation"),jR.forEach(t),H2=u(H1),Ni=l(H1,"TH",{class:!0});var FR=r(Ni);M2=o(FR,"Outcome"),FR.forEach(t),H1.forEach(t),WR.forEach(t),B2=u(U1),fe=l(U1,"TBODY",{class:!0});var Ja=r(fe);ys=l(Ja,"TR",{class:!0});var M1=r(ys);Ci=l(M1,"TD",{class:!0});var VR=r(Ci);If=l(VR,"STRONG",{});var KR=r(If);W2=o(KR,"Excessive/inconsistent data"),KR.forEach(t),VR.forEach(t),j2=u(M1),Gi=l(M1,"TD",{class:!0});var YR=r(Gi);F2=o(YR,"Model struggles to learn and produces unreliable predictions."),YR.forEach(t),M1.forEach(t),V2=u(Ja),ks=l(Ja,"TR",{class:!0});var B1=r(ks);Ui=l(B1,"TD",{class:!0});var XR=r(Ui);Of=l(XR,"STRONG",{});var ZR=r(Of);K2=o(ZR,"Lack of unique features"),ZR.forEach(t),XR.forEach(t),Y2=u(B1),Hi=l(B1,"TD",{class:!0});var QR=r(Hi);X2=o(QR,"Poor generalization leading to inaccurate outputs."),QR.forEach(t),B1.forEach(t),Z2=u(Ja),ws=l(Ja,"TR",{class:!0});var W1=r(ws);Mi=l(W1,"TD",{class:!0});var JR=r(Mi);Pf=l(JR,"STRONG",{});var $R=r(Pf);Q2=o($R,"Carefully curated datasets"),$R.forEach(t),JR.forEach(t),J2=u(W1),Bi=l(W1,"TD",{class:!0});var eS=r(Bi);$2=o(eS,"Improved learning by ensuring the model sees only relevant, high-quality data."),eS.forEach(t),W1.forEach(t),eb=u(Ja),zs=l(Ja,"TR",{class:!0});var j1=r(zs);Wi=l(j1,"TD",{class:!0});var tS=r(Wi);xf=l(tS,"STRONG",{});var sS=r(xf);tb=o(sS,"Regularization techniques"),sS.forEach(t),tS.forEach(t),sb=u(j1),ji=l(j1,"TD",{class:!0});var aS=r(ji);ab=o(aS,"Helps maintain focus on essential features and prevents instability."),aS.forEach(t),j1.forEach(t),Ja.forEach(t),U1.forEach(t),ng=u(s),Fi=l(s,"P",{});var lS=r(Fi);lb=o(lS,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),lS.forEach(t),og=u(s),Ts=l(s,"H3",{id:!0});var BT=r(Ts);qs=l(BT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var rS=r(qs);Nf=l(rS,"SPAN",{class:!0}),r(Nf).forEach(t),rS.forEach(t),rb=o(BT,"Implement these Strategies"),BT.forEach(t),cg=u(s),he=l(s,"P",{});var $a=r(he);ib=o($a,"To prevent divergence and overfitting during training, carefully configure your training parameters and regularization techniques. Start with a "),Cf=l($a,"STRONG",{});var iS=r(Cf);nb=o(iS,"conservative learning rate"),iS.forEach(t),ob=o($a," (e.g., "),Vi=l($a,"CODE",{class:!0});var nS=r(Vi);cb=o(nS,"1e-5"),nS.forEach(t),ub=o($a,") to avoid sudden spikes or NaN values in the loss, which are signs of divergence. Use gradient clipping ("),Ki=l($a,"CODE",{class:!0});var oS=r(Ki);pb=o(oS,"max_grad_norm: 1.0"),oS.forEach(t),db=o($a,") to stabilize training by preventing excessively large updates to the model weights. A cosine learning rate scheduler ensures a smooth and stable adjustment of the learning rate over time, reducing the risk of instability."),$a.forEach(t),ug=u(s),ve=l(s,"P",{});var el=r(ve);fb=o(el,"For regularization, incorporate techniques like dropout ("),Yi=l(el,"CODE",{class:!0});var cS=r(Yi);hb=o(cS,"dropout_prob: 0.1"),cS.forEach(t),vb=o(el,") to prevent the model from over-relying on specific features, improving generalization. Use a small batch size ("),Xi=l(el,"CODE",{class:!0});var uS=r(Xi);gb=o(uS,"train_batch_size: 2"),uS.forEach(t),mb=o(el,") to introduce noise into the training process, which can help avoid overfitting. Additionally, limit the number of training steps ("),Zi=l(el,"CODE",{class:!0});var pS=r(Zi);_b=o(pS,"max_train_steps: 1500"),pS.forEach(t),Eb=o(el,") to prevent the model from memorizing the dataset.  By combining these strategies, you can train a robust model that generalizes well and avoids divergence / overfitting."),el.forEach(t),pg=u(s),zl=l(s,"PRE",{class:!0});var JP=r(zl);JP.forEach(t),dg=u(s),Tl=l(s,"PRE",{class:!0});var $P=r(Tl);$P.forEach(t),fg=u(s),Rs=l(s,"H4",{id:!0});var WT=r(Rs);Ss=l(WT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var dS=r(Ss);Gf=l(dS,"SPAN",{class:!0}),r(Gf).forEach(t),dS.forEach(t),bb=o(WT,"Data Considerations"),WT.forEach(t),hg=u(s),Wt=l(s,"TABLE",{class:!0});var F1=r(Wt);Qi=l(F1,"THEAD",{class:!0});var fS=r(Qi);Fe=l(fS,"TR",{class:!0});var ld=r(Fe);Ji=l(ld,"TH",{class:!0});var hS=r(Ji);yb=o(hS,"Situation"),hS.forEach(t),kb=u(ld),$i=l(ld,"TH",{class:!0});var vS=r($i);wb=o(vS,"Actual Risk"),vS.forEach(t),zb=u(ld),en=l(ld,"TH",{class:!0});var gS=r(en);Tb=o(gS,"Solution"),gS.forEach(t),ld.forEach(t),fS.forEach(t),qb=u(F1),ge=l(F1,"TBODY",{class:!0});var tl=r(ge);Ve=l(tl,"TR",{class:!0});var rd=r(Ve);tn=l(rd,"TD",{class:!0});var mS=r(tn);Rb=o(mS,"High LR + small batch size"),mS.forEach(t),Sb=u(rd),sn=l(rd,"TD",{class:!0});var _S=r(sn);Db=o(_S,"Divergence"),_S.forEach(t),Ab=u(rd),an=l(rd,"TD",{class:!0});var ES=r(an);Lb=o(ES,"Lower LR, increase batch size"),ES.forEach(t),rd.forEach(t),Ib=u(tl),Ke=l(tl,"TR",{class:!0});var id=r(Ke);ln=l(id,"TD",{class:!0});var bS=r(ln);Ob=o(bS,"Inconsistent features"),bS.forEach(t),Pb=u(id),rn=l(id,"TD",{class:!0});var yS=r(rn);xb=o(yS,"Overfitting"),yS.forEach(t),Nb=u(id),nn=l(id,"TD",{class:!0});var kS=r(nn);Cb=o(kS,"Improve dataset consistency"),kS.forEach(t),id.forEach(t),Gb=u(tl),Ye=l(tl,"TR",{class:!0});var nd=r(Ye);on=l(nd,"TD",{class:!0});var wS=r(on);Ub=o(wS,"Insufficient reg images"),wS.forEach(t),Hb=u(nd),cn=l(nd,"TD",{class:!0});var zS=r(cn);Mb=o(zS,"Class leakage"),zS.forEach(t),Bb=u(nd),un=l(nd,"TD",{class:!0});var TS=r(un);Wb=o(TS,"Add 100-300 class images"),TS.forEach(t),nd.forEach(t),jb=u(tl),Xe=l(tl,"TR",{class:!0});var od=r(Xe);pn=l(od,"TD",{class:!0});var qS=r(pn);Fb=o(qS,"High variance in training data"),qS.forEach(t),Vb=u(od),dn=l(od,"TD",{class:!0});var RS=r(dn);Kb=o(RS,"Mode collapse"),RS.forEach(t),Yb=u(od),fn=l(od,"TD",{class:!0});var SS=r(fn);Xb=o(SS,"Curate focused dataset"),SS.forEach(t),od.forEach(t),tl.forEach(t),F1.forEach(t),vg=u(s),hn=l(s,"P",{});var DS=r(hn);Zb=o(DS,"This table outlines key AI training challenges, their risks, and solutions. A high learning rate with a small batch size can cause divergence, leading to chaotic outputs: fix this by lowering the learning rate and increasing the batch size."),DS.forEach(t),gg=u(s),vn=l(s,"P",{});var AS=r(vn);Qb=o(AS,"Inconsistent features (e.g., lighting, poses) lead to overfitting, which a curated dataset prevents. Too few regularization images cause class leakage, making it harder to distinguish subjects, adding 100-300 images helps."),AS.forEach(t),mg=u(s),gn=l(s,"P",{});var LS=r(gn);Jb=o(LS,"High variance in training data can result in mode collapse, producing repetitive outputs.  Keeping the dataset focused ensures consistency. Each row offers a direct solution for better model performance."),LS.forEach(t),_g=u(s),Eg=l(s,"HR",{}),bg=u(s),Ds=l(s,"H2",{id:!0});var jT=r(Ds);As=l(jT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var IS=r(As);Uf=l(IS,"SPAN",{class:!0}),r(Uf).forEach(t),IS.forEach(t),$b=o(jT,"Monitoring Tips"),jT.forEach(t),yg=u(s),Ls=l(s,"P",{});var V1=r(Ls);ey=o(V1,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),ql=l(V1,"A",{href:!0,rel:!0});var OS=r(ql);ty=o(OS,"kohya-ss/sd-scripts"),OS.forEach(t),sy=o(V1,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),V1.forEach(t),kg=u(s),Is=l(s,"H3",{id:!0});var FT=r(Is);Os=l(FT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var PS=r(Os);Hf=l(PS,"SPAN",{class:!0}),r(Hf).forEach(t),PS.forEach(t),ay=o(FT,"Track loss curves"),FT.forEach(t),wg=u(s),Ps=l(s,"P",{});var K1=r(Ps);ly=o(K1,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Rl=l(K1,"A",{href:!0,rel:!0});var xS=r(Rl);ry=o(xS,"TensorBoard"),xS.forEach(t),iy=o(K1," to create these graphs."),K1.forEach(t),zg=u(s),Sl=l(s,"PRE",{class:!0});var ex=r(Sl);ex.forEach(t),Tg=u(s),xs=l(s,"H4",{id:!0});var VT=r(xs);Ns=l(VT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var NS=r(Ns);Mf=l(NS,"SPAN",{class:!0}),r(Mf).forEach(t),NS.forEach(t),ny=o(VT,"What to Monitor:"),VT.forEach(t),qg=u(s),Ze=l(s,"UL",{});var cd=r(Ze);Bf=l(cd,"LI",{});var CS=r(Bf);oy=o(CS,"Training Loss: Should decrease steadily but not too quickly."),CS.forEach(t),cy=u(cd),Wf=l(cd,"LI",{});var GS=r(Wf);uy=o(GS,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),GS.forEach(t),py=u(cd),jf=l(cd,"LI",{});var US=r(jf);dy=o(US,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),US.forEach(t),cd.forEach(t),Rg=u(s),Cs=l(s,"H4",{id:!0});var KT=r(Cs);Gs=l(KT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var HS=r(Gs);Ff=l(HS,"SPAN",{class:!0}),r(Ff).forEach(t),HS.forEach(t),fy=o(KT,"Warning Signs:"),KT.forEach(t),Sg=u(s),Qe=l(s,"UL",{});var ud=r(Qe);Vf=l(ud,"LI",{});var MS=r(Vf);hy=o(MS,"Sudden spikes in loss \u2192 Likely divergence."),MS.forEach(t),vy=u(ud),Kf=l(ud,"LI",{});var BS=r(Kf);gy=o(BS,"Loss plateauing too early \u2192 Learning rate may be too low."),BS.forEach(t),my=u(ud),Yf=l(ud,"LI",{});var WS=r(Yf);_y=o(WS,"Validation loss increasing while training loss decreases \u2192 Overfitting."),WS.forEach(t),ud.forEach(t),Dg=u(s),Us=l(s,"H4",{id:!0});var YT=r(Us);Hs=l(YT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jS=r(Hs);Xf=l(jS,"SPAN",{class:!0}),r(Xf).forEach(t),jS.forEach(t),Ey=o(YT,"Generate validation images every 100 steps"),YT.forEach(t),Ag=u(s),Dl=l(s,"P",{});var XT=r(Dl);Zf=l(XT,"STRONG",{});var FS=r(Zf);by=o(FS,"Why It Matters"),FS.forEach(t),yy=o(XT," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),XT.forEach(t),Lg=u(s),Al=l(s,"PRE",{class:!0});var tx=r(Al);tx.forEach(t),Ig=u(s),Ms=l(s,"H4",{id:!0});var ZT=r(Ms);Bs=l(ZT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var VS=r(Bs);Qf=l(VS,"SPAN",{class:!0}),r(Qf).forEach(t),VS.forEach(t),ky=o(ZT,"What to Look For:"),ZT.forEach(t),Og=u(s),Je=l(s,"UL",{});var pd=r(Je);Jf=l(pd,"LI",{});var KS=r(Jf);wy=o(KS,"Consistency: Outputs should align with the training data style."),KS.forEach(t),zy=u(pd),$f=l(pd,"LI",{});var YS=r($f);Ty=o(YS,"Artifacts: Check for distortions, noise, or unnatural features."),YS.forEach(t),qy=u(pd),eh=l(pd,"LI",{});var XS=r(eh);Ry=o(XS,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),XS.forEach(t),pd.forEach(t),Pg=u(s),Ll=l(s,"BLOCKQUOTE",{class:!0});var ZS=r(Ll);mn=l(ZS,"P",{class:!0});var QS=r(mn);Sy=o(QS,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),QS.forEach(t),ZS.forEach(t),xg=u(s),Ws=l(s,"H4",{id:!0});var QT=r(Ws);js=l(QT,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var JS=r(js);th=l(JS,"SPAN",{class:!0}),r(th).forEach(t),JS.forEach(t),Dy=o(QT,"Use Gradient Clipping"),QT.forEach(t),Ng=u(s),Il=l(s,"P",{});var JT=r(Il);sh=l(JT,"STRONG",{});var $S=r(sh);Ay=o($S,"Why It Matters"),$S.forEach(t),Ly=o(JT,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),JT.forEach(t),Cg=u(s),_n=l(s,"P",{});var eD=r(_n);Iy=o(eD,"Key Insights:"),eD.forEach(t),Gg=u(s),$e=l(s,"UL",{});var dd=r($e);Ol=l(dd,"LI",{});var Y1=r(Ol);Oy=o(Y1,"Gradient Norm "),En=l(Y1,"CODE",{class:!0});var tD=r(En);Py=o(tD,"<"),tD.forEach(t),xy=o(Y1," than 0.1: Training may stall due to tiny updates."),Y1.forEach(t),Ny=u(dd),ah=l(dd,"LI",{});var sD=r(ah);Cy=o(sD,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),sD.forEach(t),Gy=u(dd),lh=l(dd,"LI",{});var aD=r(lh);Uy=o(aD,"Ideal Range: 0.1 to 2.0 for stable training."),aD.forEach(t),dd.forEach(t),Ug=u(s),Pl=l(s,"BLOCKQUOTE",{class:!0});var lD=r(Pl);bn=l(lD,"P",{class:!0});var rD=r(bn);Hy=o(rD,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),rD.forEach(t),lD.forEach(t),Hg=u(s),Fs=l(s,"H4",{id:!0});var $T=r(Fs);Vs=l($T,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var iD=r(Vs);rh=l(iD,"SPAN",{class:!0}),r(rh).forEach(t),iD.forEach(t),My=o($T,"Enable Mixed Precision Training"),$T.forEach(t),Mg=u(s),xl=l(s,"P",{});var eq=r(xl);ih=l(eq,"STRONG",{});var nD=r(ih);By=o(nD,"Why It Matters"),nD.forEach(t),Wy=o(eq,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),eq.forEach(t),Bg=u(s),Nl=l(s,"PRE",{class:!0});var sx=r(Nl);sx.forEach(t),Wg=u(s),yn=l(s,"P",{});var oD=r(yn);jy=o(oD,"Benefits:"),oD.forEach(t),jg=u(s),et=l(s,"UL",{});var fd=r(et);nh=l(fd,"LI",{});var cD=r(nh);Fy=o(cD,"2-3x Faster Training: Leverages GPU tensor cores."),cD.forEach(t),Vy=u(fd),oh=l(fd,"LI",{});var uD=r(oh);Ky=o(uD,"50% Less VRAM Usage: Allows larger batch sizes or models."),uD.forEach(t),Yy=u(fd),ch=l(fd,"LI",{});var pD=r(ch);Xy=o(pD,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),pD.forEach(t),fd.forEach(t),Fg=u(s),Cl=l(s,"BLOCKQUOTE",{class:!0});var dD=r(Cl);kn=l(dD,"P",{class:!0});var fD=r(kn);Zy=o(fD,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),fD.forEach(t),dD.forEach(t),Vg=u(s),Ks=l(s,"H4",{id:!0});var tq=r(Ks);Ys=l(tq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var hD=r(Ys);uh=l(hD,"SPAN",{class:!0}),r(uh).forEach(t),hD.forEach(t),Qy=o(tq,"Start with Conservative Learning Rates"),tq.forEach(t),Kg=u(s),Xs=l(s,"P",{});var X1=r(Xs);Jy=o(X1,"Start off with 1e-5 to 1e-6.  "),ph=l(X1,"STRONG",{});var vD=r(ph);$y=o(vD,"Why It Matters"),vD.forEach(t),e4=o(X1,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),X1.forEach(t),Yg=u(s),Gl=l(s,"PRE",{class:!0});var ax=r(Gl);ax.forEach(t),Xg=u(s),jt=l(s,"TABLE",{class:!0});var Z1=r(jt);wn=l(Z1,"THEAD",{class:!0});var gD=r(wn);tt=l(gD,"TR",{class:!0});var hd=r(tt);zn=l(hd,"TH",{class:!0});var mD=r(zn);t4=o(mD,"Option"),mD.forEach(t),s4=u(hd),Tn=l(hd,"TH",{class:!0});var _D=r(Tn);a4=o(_D,"Values"),_D.forEach(t),l4=u(hd),qn=l(hd,"TH",{class:!0});var ED=r(qn);r4=o(ED,"Effect"),ED.forEach(t),hd.forEach(t),gD.forEach(t),i4=u(Z1),st=l(Z1,"TBODY",{class:!0});var vd=r(st);at=l(vd,"TR",{class:!0});var gd=r(at);Rn=l(gd,"TD",{class:!0});var bD=r(Rn);Sn=l(bD,"CODE",{class:!0});var yD=r(Sn);n4=o(yD,"learning_rate"),yD.forEach(t),bD.forEach(t),o4=u(gd),Dn=l(gd,"TD",{class:!0});var kD=r(Dn);c4=o(kD,"0.005 - 0.0001"),kD.forEach(t),u4=u(gd),An=l(gd,"TD",{class:!0});var wD=r(An);p4=o(wD,"Main control for learning rate. Sets defaults for the other two."),wD.forEach(t),gd.forEach(t),d4=u(vd),lt=l(vd,"TR",{class:!0});var md=r(lt);Ln=l(md,"TD",{class:!0});var zD=r(Ln);In=l(zD,"CODE",{class:!0});var TD=r(In);f4=o(TD,"unet_lr"),TD.forEach(t),zD.forEach(t),h4=u(md),On=l(md,"TD",{class:!0});var qD=r(On);v4=o(qD,"0.0001 - 0.005"),qD.forEach(t),g4=u(md),Pn=l(md,"TD",{class:!0});var RD=r(Pn);m4=o(RD,"Sets Unet\u2019s learning rate. Most sensitive part; avoid setting too high."),RD.forEach(t),md.forEach(t),_4=u(vd),rt=l(vd,"TR",{class:!0});var _d=r(rt);xn=l(_d,"TD",{class:!0});var SD=r(xn);Nn=l(SD,"CODE",{class:!0});var DD=r(Nn);E4=o(DD,"text_encoder_lr"),DD.forEach(t),SD.forEach(t),b4=u(_d),Cn=l(_d,"TD",{class:!0});var AD=r(Cn);y4=o(AD,"0.00001 - 0.00005"),AD.forEach(t),k4=u(_d),Gn=l(_d,"TD",{class:!0});var LD=r(Gn);w4=o(LD,"Sets text encoder\u2019s learning rate. Keep much lower than Unet\u2019s."),LD.forEach(t),_d.forEach(t),vd.forEach(t),Z1.forEach(t),Zg=u(s),Zs=l(s,"H4",{id:!0});var sq=r(Zs);Qs=l(sq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ID=r(Qs);dh=l(ID,"SPAN",{class:!0}),r(dh).forEach(t),ID.forEach(t),z4=o(sq,"What does this mean?"),sq.forEach(t),Qg=u(s),it=l(s,"UL",{});var Ed=r(it);Ul=l(Ed,"LI",{});var Q1=r(Ul);T4=o(Q1,"If you don\u2019t want to fine-tune, just use "),Un=l(Q1,"CODE",{class:!0});var OD=r(Un);q4=o(OD,"--learning_rate"),OD.forEach(t),R4=o(Q1," to set the other two automatically."),Q1.forEach(t),S4=u(Ed),Re=l(Ed,"LI",{});var sl=r(Re);D4=o(sl,"If you want more control, set "),Hn=l(sl,"CODE",{class:!0});var PD=r(Hn);A4=o(PD,"--unet_lr"),PD.forEach(t),L4=o(sl," and "),Mn=l(sl,"CODE",{class:!0});var xD=r(Mn);I4=o(xD,"--text_encoder_lr"),xD.forEach(t),O4=o(sl," individually. Setting "),Bn=l(sl,"CODE",{class:!0});var ND=r(Bn);P4=o(ND,"--learning_rate"),ND.forEach(t),x4=o(sl," becomes redundant in this case."),sl.forEach(t),N4=u(Ed),Ft=l(Ed,"LI",{});var bd=r(Ft);C4=o(bd,"A common approach is to set "),Wn=l(bd,"CODE",{class:!0});var CD=r(Wn);G4=o(CD,"--learning_rate"),CD.forEach(t),U4=o(bd," the same as "),jn=l(bd,"CODE",{class:!0});var GD=r(jn);H4=o(GD,"--unet_lr"),GD.forEach(t),M4=o(bd," for simplicity."),bd.forEach(t),Ed.forEach(t),Jg=u(s),Js=l(s,"H4",{id:!0});var aq=r(Js);$s=l(aq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var UD=r($s);fh=l(UD,"SPAN",{class:!0}),r(fh).forEach(t),UD.forEach(t),B4=o(aq,"Text Encoder Learning Rate"),aq.forEach(t),$g=u(s),Fn=l(s,"P",{});var HD=r(Fn);W4=o(HD,"The text encoder interprets text prompts and links tags/tokens to data in the Unet during training."),HD.forEach(t),em=u(s),Vn=l(s,"UL",{});var MD=r(Vn);ea=l(MD,"LI",{});var zv=r(ea);hh=l(zv,"STRONG",{});var BD=r(hh);j4=o(BD,"Default Value"),BD.forEach(t),F4=o(zv,": 5e-5 (or uses "),Kn=l(zv,"CODE",{class:!0});var WD=r(Kn);V4=o(WD,"--learning_rate"),WD.forEach(t),K4=o(zv," if not specified)."),zv.forEach(t),MD.forEach(t),tm=u(s),ta=l(s,"H4",{id:!0});var lq=r(ta);sa=l(lq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var jD=r(sa);vh=l(jD,"SPAN",{class:!0}),r(vh).forEach(t),jD.forEach(t),Y4=o(lq,"Effects:"),lq.forEach(t),sm=u(s),nt=l(s,"UL",{});var yd=r(nt);gh=l(yd,"LI",{});var FD=r(gh);X4=o(FD,"Lowering it helps separate objects better in generations."),FD.forEach(t),Z4=u(yd),mh=l(yd,"LI",{});var VD=r(mh);Q4=o(VD,"If unwanted objects appear, try lowering it."),VD.forEach(t),J4=u(yd),_h=l(yd,"LI",{});var KD=r(_h);$4=o(KD,"If prompts require heavy weighting to make things appear, it\u2019s set too low."),KD.forEach(t),yd.forEach(t),am=u(s),Yn=l(s,"P",{});var YD=r(Yn);e3=o(YD,"A well-trained text encoder improves prompt control and feature granularity."),YD.forEach(t),lm=u(s),aa=l(s,"H4",{id:!0});var rq=r(aa);la=l(rq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var XD=r(la);Eh=l(XD,"SPAN",{class:!0}),r(Eh).forEach(t),XD.forEach(t),t3=o(rq,"Unet Learning Rate"),rq.forEach(t),rm=u(s),Xn=l(s,"P",{});var ZD=r(Xn);s3=o(ZD,"The Unet acts as the model\u2019s \u201Cvisual memory,\u201D handling image structure, detail, and relationships between elements."),ZD.forEach(t),im=u(s),ra=l(s,"UL",{});var J1=r(ra);Zn=l(J1,"LI",{});var iq=r(Zn);bh=l(iq,"STRONG",{});var QD=r(bh);a3=o(QD,"Default Value"),QD.forEach(t),l3=o(iq,": 1e-4 (avoid changing unless necessary)."),iq.forEach(t),r3=u(J1),Hl=l(J1,"LI",{});var $1=r(Hl);yh=l($1,"STRONG",{});var JD=r(yh);i3=o(JD,"Issues & Fixes"),JD.forEach(t),n3=o($1,":"),Vt=l($1,"UL",{});var kd=r(Vt);Qn=l(kd,"LI",{});var nq=r(Qn);kh=l(nq,"STRONG",{});var $D=r(kh);o3=o($D,"Overfitting"),$D.forEach(t),c3=o(nq,": Reduce learning rate, steps, or use dampeners."),nq.forEach(t),u3=u(kd),Jn=l(kd,"LI",{});var oq=r(Jn);wh=l(oq,"STRONG",{});var eA=r(wh);p3=o(eA,"Visual Noise (blobs)"),eA.forEach(t),d3=o(oq,": Learning rate is too high: divide by at least 8."),oq.forEach(t),f3=u(kd),$n=l(kd,"LI",{});var cq=r($n);zh=l(cq,"STRONG",{});var tA=r(zh);h3=o(tA,"Weak Details"),tA.forEach(t),v3=o(cq,": Increase learning rate or train for more steps."),cq.forEach(t),kd.forEach(t),$1.forEach(t),J1.forEach(t),nm=u(s),eo=l(s,"P",{});var sA=r(eo);g3=o(sA,"The Unet works progressively, starting with broad shapes and adding finer details. Overcooking it can lead to misplaced or excessive features (e.g., eyes everywhere)."),sA.forEach(t),om=u(s),ia=l(s,"UL",{});var e_=r(ia);to=l(e_,"LI",{});var uq=r(to);Th=l(uq,"STRONG",{});var aA=r(Th);m3=o(aA,"Visualization"),aA.forEach(t),_3=o(uq,": Think of it as zooming in from a blurry silhouette to pixel-level detail."),uq.forEach(t),E3=u(e_),so=l(e_,"LI",{});var pq=r(so);qh=l(pq,"STRONG",{});var lA=r(qh);b3=o(lA,"Structure"),lA.forEach(t),y3=o(pq,": IN blocks handle planning, OUT blocks manage fine details like texture."),pq.forEach(t),e_.forEach(t),cm=u(s),ao=l(s,"P",{});var rA=r(ao);k3=o(rA,"Burning the Unet results in chaotic outputs."),rA.forEach(t),um=u(s),Ml=l(s,"P",{});var dq=r(Ml);Rh=l(dq,"STRONG",{});var iA=r(Rh);w3=o(iA,"Warning Signs"),iA.forEach(t),z3=o(dq,":"),dq.forEach(t),pm=u(s),ot=l(s,"UL",{});var wd=r(ot);Sh=l(wd,"LI",{});var nA=r(Sh);T3=o(nA,"Loss Spikes: Learning rate is too high."),nA.forEach(t),q3=u(wd),Dh=l(wd,"LI",{});var oA=r(Dh);R3=o(oA,"Slow Convergence: Learning rate is too low."),oA.forEach(t),S3=u(wd),Ah=l(wd,"LI",{});var cA=r(Ah);D3=o(cA,"Oscillating Loss: Poor scheduling or unstable gradients."),cA.forEach(t),wd.forEach(t),dm=u(s),Kt=l(s,"TABLE",{class:!0});var t_=r(Kt);lo=l(t_,"THEAD",{class:!0});var uA=r(lo);me=l(uA,"TR",{class:!0});var al=r(me);ro=l(al,"TH",{class:!0});var pA=r(ro);A3=o(pA,"Practice"),pA.forEach(t),L3=u(al),io=l(al,"TH",{class:!0});var dA=r(io);I3=o(dA,"Key Benefit"),dA.forEach(t),O3=u(al),no=l(al,"TH",{class:!0});var fA=r(no);P3=o(fA,"Tool/Setting"),fA.forEach(t),x3=u(al),oo=l(al,"TH",{class:!0});var hA=r(oo);N3=o(hA,"Warning Signs"),hA.forEach(t),al.forEach(t),uA.forEach(t),C3=u(t_),le=l(t_,"TBODY",{class:!0});var Nt=r(le);_e=l(Nt,"TR",{class:!0});var ll=r(_e);co=l(ll,"TD",{class:!0});var vA=r(co);G3=o(vA,"Track Loss Curves"),vA.forEach(t),U3=u(ll),uo=l(ll,"TD",{class:!0});var gA=r(uo);H3=o(gA,"Detect overfitting/divergence early"),gA.forEach(t),M3=u(ll),po=l(ll,"TD",{class:!0});var mA=r(po);B3=o(mA,"TensorBoard, Weights & Biases"),mA.forEach(t),W3=u(ll),fo=l(ll,"TD",{class:!0});var _A=r(fo);j3=o(_A,"Spikes, plateaus, growing gaps"),_A.forEach(t),ll.forEach(t),F3=u(Nt),Ee=l(Nt,"TR",{class:!0});var rl=r(Ee);ho=l(rl,"TD",{class:!0});var EA=r(ho);V3=o(EA,"Generate Validation Images"),EA.forEach(t),K3=u(rl),vo=l(rl,"TD",{class:!0});var bA=r(vo);Y3=o(bA,"Visualize model progress"),bA.forEach(t),X3=u(rl),go=l(rl,"TD",{class:!0});var yA=r(go);Z3=o(yA,"Fixed prompts/seeds"),yA.forEach(t),Q3=u(rl),mo=l(rl,"TD",{class:!0});var kA=r(mo);J3=o(kA,"Artifacts, mode collapse"),kA.forEach(t),rl.forEach(t),$3=u(Nt),be=l(Nt,"TR",{class:!0});var il=r(be);_o=l(il,"TD",{class:!0});var wA=r(_o);ek=o(wA,"Gradient Clipping"),wA.forEach(t),tk=u(il),Eo=l(il,"TD",{class:!0});var zA=r(Eo);sk=o(zA,"Prevent exploding gradients"),zA.forEach(t),ak=u(il),na=l(il,"TD",{class:!0});var s_=r(na);lk=o(s_,"clip"),Lh=l(s_,"EM",{});var TA=r(Lh);rk=o(TA,"grad_norm"),TA.forEach(t),ik=o(s_," (1.0-2.0)"),s_.forEach(t),nk=u(il),ct=l(il,"TD",{class:!0});var zd=r(ct);ok=o(zd,"Norm "),bo=l(zd,"CODE",{class:!0});var qA=r(bo);ck=o(qA,">"),qA.forEach(t),uk=o(zd," 10.0 or "),yo=l(zd,"CODE",{class:!0});var RA=r(yo);pk=o(RA,"<"),RA.forEach(t),dk=o(zd," 0.1"),zd.forEach(t),il.forEach(t),fk=u(Nt),ye=l(Nt,"TR",{class:!0});var nl=r(ye);ko=l(nl,"TD",{class:!0});var SA=r(ko);hk=o(SA,"Mixed Precision Training"),SA.forEach(t),vk=u(nl),wo=l(nl,"TD",{class:!0});var DA=r(wo);gk=o(DA,"Faster training, lower VRAM usage"),DA.forEach(t),mk=u(nl),zo=l(nl,"TD",{class:!0});var AA=r(zo);_k=o(AA,"PyTorch AMP (torch.cuda.amp)"),AA.forEach(t),Ek=u(nl),To=l(nl,"TD",{class:!0});var LA=r(To);bk=o(LA,"NaN values (disable if unstable)"),LA.forEach(t),nl.forEach(t),yk=u(Nt),ke=l(Nt,"TR",{class:!0});var ol=r(ke);qo=l(ol,"TD",{class:!0});var IA=r(qo);kk=o(IA,"Conservative Learning Rates"),IA.forEach(t),wk=u(ol),Ro=l(ol,"TD",{class:!0});var OA=r(Ro);zk=o(OA,"Stable training, avoid divergence"),OA.forEach(t),Tk=u(ol),So=l(ol,"TD",{class:!0});var PA=r(So);qk=o(PA,"Start at 1e-5 to 1e-6, use scheduler"),PA.forEach(t),Rk=u(ol),Do=l(ol,"TD",{class:!0});var xA=r(Do);Sk=o(xA,"Spikes, slow convergence"),xA.forEach(t),ol.forEach(t),Nt.forEach(t),t_.forEach(t),fm=u(s),hm=l(s,"HR",{}),vm=u(s),oa=l(s,"H2",{id:!0});var fq=r(oa);ca=l(fq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var NA=r(ca);Ih=l(NA,"SPAN",{class:!0}),r(Ih).forEach(t),NA.forEach(t),Dk=o(fq,"Generating Regularization images"),fq.forEach(t),gm=u(s),ua=l(s,"P",{});var a_=r(ua);Ak=o(a_,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Ao=l(a_,"CODE",{class:!0});var CA=r(Ao);Lk=o(CA,"1boy"),CA.forEach(t),Ik=o(a_,")."),a_.forEach(t),mm=u(s),ue=l(s,"P",{});var $t=r(ue);Ok=o($t,"According to the Dreambooth technique, "),Lo=l($t,"CODE",{class:!0});var GA=r(Lo);Pk=o(GA,"200"),GA.forEach(t),xk=o($t," regularization images per training image.  For example, if you have "),Io=l($t,"CODE",{class:!0});var UA=r(Io);Nk=o(UA,"16"),UA.forEach(t),Ck=o($t," images: "),Oo=l($t,"CODE",{class:!0});var HA=r(Oo);Gk=o(HA,"200 * 16 = 3200"),HA.forEach(t),Uk=o($t," total regularization images.  When training, the math involved for calculating total steps is: "),Po=l($t,"CODE",{class:!0});var MA=r(Po);Hk=o(MA,"repeats * training images >= repeats * regularization images"),MA.forEach(t),$t.forEach(t),_m=u(s),xo=l(s,"P",{});var BA=r(xo);Mk=o(BA,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),BA.forEach(t),Em=u(s),pa=l(s,"H4",{id:!0});var hq=r(pa);da=l(hq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var WA=r(da);Oh=l(WA,"SPAN",{class:!0}),r(Oh).forEach(t),WA.forEach(t),Bk=o(hq,"Important considerations"),hq.forEach(t),bm=u(s),ut=l(s,"OL",{});var Td=r(ut);Ph=l(Td,"LI",{});var jA=r(Ph);Bl=l(jA,"P",{});var l_=r(Bl);xh=l(l_,"STRONG",{});var FA=r(xh);Wk=o(FA,"Use the same base model for regularization images and training"),FA.forEach(t),jk=l(l_,"BR",{}),Fk=o(l_,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),l_.forEach(t),jA.forEach(t),Vk=u(Td),Nh=l(Td,"LI",{});var VA=r(Nh);Wl=l(VA,"P",{});var r_=r(Wl);Ch=l(r_,"STRONG",{});var KA=r(Ch);Kk=o(KA,"Maintain consistent class representation"),KA.forEach(t),Yk=l(r_,"BR",{}),Xk=o(r_,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),r_.forEach(t),VA.forEach(t),Zk=u(Td),Gh=l(Td,"LI",{});var YA=r(Gh);jl=l(YA,"P",{});var i_=r(jl);Uh=l(i_,"STRONG",{});var XA=r(Uh);Qk=o(XA,"Match output resolution to training data"),XA.forEach(t),Jk=l(i_,"BR",{}),$k=o(i_,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),i_.forEach(t),YA.forEach(t),Td.forEach(t),ym=u(s),Ur(Fl.$$.fragment,s),km=u(s),fa=l(s,"H4",{id:!0});var vq=r(fa);ha=l(vq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ZA=r(ha);Hh=l(ZA,"SPAN",{class:!0}),r(Hh).forEach(t),ZA.forEach(t),e0=o(vq,"Generate using Stable Diffusion web UI"),vq.forEach(t),wm=u(s),va=l(s,"P",{});var n_=r(va);t0=o(n_,"We\u2019re going to use "),Vl=l(n_,"A",{href:!0,rel:!0});var QA=r(Vl);s0=o(QA,"Stable Diffusion web UI"),QA.forEach(t),a0=o(n_," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),n_.forEach(t),zm=u(s),pt=l(s,"P",{});var qd=r(pt);l0=o(qd,"We\u2019re going to use the "),No=l(qd,"CODE",{class:!0});var JA=r(No);r0=o(JA,"X/Y/Z plot"),JA.forEach(t),i0=o(qd," script to use "),Co=l(qd,"CODE",{class:!0});var $A=r(Co);n0=o($A,"Prompt Search & Replace"),$A.forEach(t),o0=o(qd," to dynamically build a prompt that will generate hundreds of regularization images."),qd.forEach(t),Tm=u(s),J=l(s,"OL",{});var oe=r(J);Mh=l(oe,"LI",{});var eL=r(Mh);Go=l(eL,"P",{});var gq=r(Go);c0=o(gq,"Select the text 2 image tab.  Enter a generic prompt "),Uo=l(gq,"CODE",{class:!0});var tL=r(Uo);u0=o(tL,"princeadam, portrait, looking_at_viewer, forest"),tL.forEach(t),gq.forEach(t),eL.forEach(t),p0=u(oe),Bh=l(oe,"LI",{});var sL=r(Bh);Kl=l(sL,"P",{});var o_=r(Kl);d0=o(o_,"In generation parameters and select the "),Ho=l(o_,"CODE",{class:!0});var aL=r(Ho);f0=o(aL,"X/Y/Z plot"),aL.forEach(t),h0=o(o_," script."),o_.forEach(t),sL.forEach(t),v0=u(oe),Wh=l(oe,"LI",{});var lL=r(Wh);K=l(lL,"P",{});var te=r(K);g0=o(te,"Select the "),Mo=l(te,"CODE",{class:!0});var rL=r(Mo);m0=o(rL,"X"),rL.forEach(t),_0=o(te," parameter and "),Bo=l(te,"CODE",{class:!0});var iL=r(Bo);E0=o(iL,"Prompt SR"),iL.forEach(t),b0=o(te," for Prompt Replace.  We\u2019re going to replace "),Wo=l(te,"CODE",{class:!0});var nL=r(Wo);y0=o(nL,"portrait"),nL.forEach(t),k0=o(te," with different camera angle tags: "),jo=l(te,"CODE",{class:!0});var oL=r(jo);w0=o(oL,"close-up"),oL.forEach(t),z0=o(te,", "),Fo=l(te,"CODE",{class:!0});var cL=r(Fo);T0=o(cL,"upper_body"),cL.forEach(t),q0=o(te,", "),Vo=l(te,"CODE",{class:!0});var uL=r(Vo);R0=o(uL,"from_below"),uL.forEach(t),S0=o(te,", "),Ko=l(te,"CODE",{class:!0});var pL=r(Ko);D0=o(pL,"from_above"),pL.forEach(t),A0=o(te,", "),Yo=l(te,"CODE",{class:!0});var dL=r(Yo);L0=o(dL,"dutch_angle"),dL.forEach(t),te.forEach(t),lL.forEach(t),I0=u(oe),jh=l(oe,"LI",{});var fL=r(jh);$=l(fL,"P",{});var ae=r($);O0=o(ae,"Select the "),Xo=l(ae,"CODE",{class:!0});var hL=r(Xo);P0=o(hL,"Y"),hL.forEach(t),x0=o(ae," parameter and "),Zo=l(ae,"CODE",{class:!0});var vL=r(Zo);N0=o(vL,"Prompt SR"),vL.forEach(t),C0=o(ae," for Prompt Replace.  Replace "),Qo=l(ae,"CODE",{class:!0});var gL=r(Qo);G0=o(gL,"looking_at_viewer"),gL.forEach(t),U0=o(ae,": "),Jo=l(ae,"CODE",{class:!0});var mL=r(Jo);H0=o(mL,"looking_away"),mL.forEach(t),M0=o(ae,", "),$o=l(ae,"CODE",{class:!0});var _L=r($o);B0=o(_L,"looking_to_the_side"),_L.forEach(t),W0=o(ae,", "),ec=l(ae,"CODE",{class:!0});var EL=r(ec);j0=o(EL,"looking_ahead"),EL.forEach(t),F0=o(ae,", "),tc=l(ae,"CODE",{class:!0});var bL=r(tc);V0=o(bL,"looking_down"),bL.forEach(t),ae.forEach(t),fL.forEach(t),K0=u(oe),Fh=l(oe,"LI",{});var yL=r(Fh);Y=l(yL,"P",{});var se=r(Y);Y0=o(se,"Select the "),sc=l(se,"CODE",{class:!0});var kL=r(sc);X0=o(kL,"Z"),kL.forEach(t),Z0=o(se," parameter and "),ac=l(se,"CODE",{class:!0});var wL=r(ac);Q0=o(wL,"Prompt SR"),wL.forEach(t),J0=o(se," for Prompt Replace. Replace "),lc=l(se,"CODE",{class:!0});var zL=r(lc);$0=o(zL,"forest"),zL.forEach(t),e5=o(se," with a vareity of locatinos: "),rc=l(se,"CODE",{class:!0});var TL=r(rc);t5=o(TL,"castle"),TL.forEach(t),s5=o(se,", "),ic=l(se,"CODE",{class:!0});var qL=r(ic);a5=o(qL,"mountain"),qL.forEach(t),l5=o(se,", "),nc=l(se,"CODE",{class:!0});var RL=r(nc);r5=o(RL,"cave"),RL.forEach(t),i5=o(se,", "),oc=l(se,"CODE",{class:!0});var SL=r(oc);n5=o(SL,"farm"),SL.forEach(t),o5=o(se,", "),cc=l(se,"CODE",{class:!0});var DL=r(cc);c5=o(DL,"ocean"),DL.forEach(t),se.forEach(t),yL.forEach(t),u5=u(oe),Vh=l(oe,"LI",{});var AL=r(Vh);uc=l(AL,"P",{});var mq=r(uc);p5=o(mq,"Select a fast sampler like "),pc=l(mq,"CODE",{class:!0});var LL=r(pc);d5=o(LL,"DPM2 KARRAS"),LL.forEach(t),mq.forEach(t),AL.forEach(t),f5=u(oe),Kh=l(oe,"LI",{});var IL=r(Kh);ga=l(IL,"P",{});var Tv=r(ga);h5=o(Tv,"CFG Scale set to "),dc=l(Tv,"CODE",{class:!0});var OL=r(dc);v5=o(OL,"7"),OL.forEach(t),g5=o(Tv," and Steps to "),fc=l(Tv,"CODE",{class:!0});var PL=r(fc);m5=o(PL,"20"),PL.forEach(t),Tv.forEach(t),IL.forEach(t),oe.forEach(t),qm=u(s),dt=l(s,"P",{});var Rd=r(dt);_5=o(Rd,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),hc=l(Rd,"CODE",{class:!0});var xL=r(hc);E5=o(xL,"150"),xL.forEach(t),b5=o(Rd," - "),vc=l(Rd,"CODE",{class:!0});var NL=r(vc);y5=o(NL,"200"),NL.forEach(t),k5=o(Rd," and keep in mind we can add and remove as we try different training settings with different output."),Rd.forEach(t),Rm=u(s),Ur(Yl.$$.fragment,s),Sm=u(s),ma=l(s,"H4",{id:!0});var _q=r(ma);_a=l(_q,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var CL=r(_a);Yh=l(CL,"SPAN",{class:!0}),r(Yh).forEach(t),CL.forEach(t),w5=o(_q,"Download images"),_q.forEach(t),Dm=u(s),gc=l(s,"P",{});var GL=r(gc);z5=o(GL,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),GL.forEach(t),Am=u(s),we=l(s,"UL",{});var cl=r(we);mc=l(cl,"LI",{});var Eq=r(mc);Xl=l(Eq,"A",{href:!0,rel:!0});var UL=r(Xl);T5=o(UL,"3ee Games regularization images"),UL.forEach(t),q5=o(Eq,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),Eq.forEach(t),R5=u(cl),_c=l(cl,"LI",{});var bq=r(_c);Zl=l(bq,"A",{href:!0,rel:!0});var HL=r(Zl);S5=o(HL,"Pre-Rendered Regularization Images"),HL.forEach(t),D5=o(bq,": Includes 1500 regularization images."),bq.forEach(t),A5=u(cl),Ec=l(cl,"LI",{});var yq=r(Ec);Ql=l(yq,"A",{href:!0,rel:!0});var ML=r(Ql);L5=o(ML,"Stable Diffusion 1.5 Regularization Images"),ML.forEach(t),I5=o(yq,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),yq.forEach(t),O5=u(cl),bc=l(cl,"LI",{});var kq=r(bc);Jl=l(kq,"A",{href:!0,rel:!0});var BL=r(Jl);P5=o(BL,"Aitrepreneur SDXL image set"),BL.forEach(t),x5=o(kq,": a large image set generated with Stable Diffusion SDXL."),kq.forEach(t),cl.forEach(t),Lm=u(s),Ea=l(s,"H4",{id:!0});var wq=r(Ea);ba=l(wq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var WL=r(ba);Xh=l(WL,"SPAN",{class:!0}),r(Xh).forEach(t),WL.forEach(t),N5=o(wq,"Captioning Regularization images"),wq.forEach(t),Im=u(s),yc=l(s,"P",{});var jL=r(yc);C5=o(jL,"While captioning regularization images isn\u2019t strictly required, it significantly improves your model\u2019s ability to learn meaningful patterns. Just like training images, captions help Stable Diffusion understand the relationship between visual features and text prompts.  Critical for maintaining style consistency."),jL.forEach(t),Om=u(s),kc=l(s,"P",{});var FL=r(kc);G5=o(FL,"Here\u2019s the workflow I used:"),FL.forEach(t),Pm=u(s),ft=l(s,"UL",{});var Sd=r(ft);wc=l(Sd,"LI",{});var zq=r(wc);Zh=l(zq,"STRONG",{});var VL=r(Zh);U5=o(VL,"Structured Filenames"),VL.forEach(t),H5=o(zq,": Stable Diffusion Web UI automatically embeds prompts in filenames"),zq.forEach(t),M5=u(Sd),ht=l(Sd,"LI",{});var xr=r(ht);Qh=l(xr,"STRONG",{});var KL=r(Qh);B5=o(KL,"Automated Extraction"),KL.forEach(t),W5=o(xr,": I wrote a simple script to convert filenames into .txt captions, preserving key details like "),zc=l(xr,"CODE",{class:!0});var YL=r(zc);j5=o(YL,"1boy"),YL.forEach(t),F5=o(xr," or "),Tc=l(xr,"CODE",{class:!0});var XL=r(Tc);V5=o(XL,"purple_vest"),XL.forEach(t),K5=o(xr,"."),xr.forEach(t),Y5=u(Sd),qc=l(Sd,"LI",{});var Tq=r(qc);Jh=l(Tq,"STRONG",{});var ZL=r(Jh);X5=o(ZL,"Manual Verification"),ZL.forEach(t),Z5=o(Tq,": Spot-checked captions to ensure accuracy."),Tq.forEach(t),Sd.forEach(t),xm=u(s),$l=l(s,"PRE",{class:!0});var lx=r($l);lx.forEach(t),Nm=u(s),ya=l(s,"OL",{});var c_=r(ya);er=l(c_,"LI",{});var u_=r(er);Q5=o(u_,"Save this file as "),Rc=l(u_,"CODE",{class:!0});var QL=r(Rc);J5=o(QL,"filename2txt.bat"),QL.forEach(t),$5=o(u_," and place it into the regularization images directory"),u_.forEach(t),ew=u(c_),tr=l(c_,"LI",{});var p_=r(tr);tw=o(p_,"Run: "),Sc=l(p_,"CODE",{class:!0});var JL=r(Sc);sw=o(JL,".\\filename2txt.bat"),JL.forEach(t),aw=o(p_,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),p_.forEach(t),c_.forEach(t),Cm=u(s),ka=l(s,"P",{});var d_=r(ka);$h=l(d_,"STRONG",{});var $L=r($h);lw=o($L,"Example filename"),$L.forEach(t),rw=o(d_,": "),Dc=l(d_,"CODE",{class:!0});var eI=r(Dc);iw=o(eI,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),eI.forEach(t),d_.forEach(t),Gm=u(s),wa=l(s,"H2",{id:!0});var qq=r(wa);za=l(qq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var tI=r(za);ev=l(tI,"SPAN",{class:!0}),r(ev).forEach(t),tI.forEach(t),nw=o(qq,"Training a LoRA"),qq.forEach(t),Um=u(s),vt=l(s,"P",{});var Dd=r(vt);ow=o(Dd,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),sr=l(Dd,"A",{href:!0,rel:!0});var sI=r(sr);cw=o(sI,"Kohya\u2019s Stable Diffusion trainers"),sI.forEach(t),uw=o(Dd,".  If you want to use a GUI, use "),ar=l(Dd,"A",{href:!0,rel:!0});var aI=r(ar);pw=o(aI,"Kohya\u2019s GUI"),aI.forEach(t),dw=o(Dd,".  In this article, you can will able to use either since the settings config can be modified in json and reloaded in the GUI."),Dd.forEach(t),Hm=u(s),lr=l(s,"BLOCKQUOTE",{class:!0});var lI=r(lr);Ta=l(lI,"P",{class:!0});var f_=r(Ta);fw=o(f_,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),rr=l(f_,"A",{href:!0,rel:!0});var rI=r(rr);hw=o(rI,"Kohya SD script documentation"),rI.forEach(t),vw=o(f_,"."),f_.forEach(t),lI.forEach(t),Mm=u(s),ir=l(s,"BLOCKQUOTE",{class:!0});var iI=r(ir);Se=l(iI,"P",{class:!0});var Nr=r(Se);gw=o(Nr,"\u{1F4C4} Recommended reading: "),nr=l(Nr,"A",{href:!0,rel:!0});var nI=r(nr);mw=o(nI,"https://rentry.org/59xed3"),nI.forEach(t),_w=o(Nr,", "),or=l(Nr,"A",{href:!0,rel:!0});var oI=r(or);Ew=o(oI,"https://rentry.org/ezlora"),oI.forEach(t),bw=o(Nr,", "),cr=l(Nr,"A",{href:!0,rel:!0});var cI=r(cr);yw=o(cI,"https://rentry.org/lora_train"),cI.forEach(t),Nr.forEach(t),iI.forEach(t),Bm=u(s),qa=l(s,"H3",{id:!0});var Rq=r(qa);Ra=l(Rq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uI=r(Ra);tv=l(uI,"SPAN",{class:!0}),r(tv).forEach(t),uI.forEach(t),kw=o(Rq,"Directory setup"),Rq.forEach(t),Wm=u(s),Sa=l(s,"P",{});var h_=r(Sa);ww=o(h_,"In your configuration json, use "),Ac=l(h_,"CODE",{class:!0});var pI=r(Ac);zw=o(pI,"reg_data_dir"),pI.forEach(t),Tw=o(h_," to point to the directory with your regularization images:"),h_.forEach(t),jm=u(s),ur=l(s,"PRE",{class:!0});var rx=r(ur);rx.forEach(t),Fm=u(s),Lc=l(s,"P",{});var dI=r(Lc);qw=o(dI,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),dI.forEach(t),Vm=u(s),pr=l(s,"PRE",{class:!0});var ix=r(pr);ix.forEach(t),Km=u(s),Da=l(s,"P",{});var v_=r(Da);Rw=o(v_,"Set the "),Ic=l(v_,"CODE",{class:!0});var fI=r(Ic);Sw=o(fI,"number of iterations"),fI.forEach(t),Dw=o(v_," so that training images are used as often as or more often than regularization images."),v_.forEach(t),Ym=u(s),dr=l(s,"BLOCKQUOTE",{class:!0});var hI=r(dr);Aa=l(hI,"P",{class:!0});var g_=r(Aa);Aw=o(g_,"In one epoch, the total data is "),Oc=l(g_,"CODE",{class:!0});var vI=r(Oc);Lw=o(vI,"training images \xD7 iterations"),vI.forEach(t),Iw=o(g_,". If there are more regularization images than this, the extras won\u2019t be used."),g_.forEach(t),hI.forEach(t),Xm=u(s),gt=l(s,"P",{});var Ad=r(gt);Ow=o(Ad,"Create folders in the training image folder with the format "),Pc=l(Ad,"CODE",{class:!0});var gI=r(Pc);Pw=o(gI,"<repetition count>_<class>"),gI.forEach(t),xw=o(Ad," multiple times, and similarly create folders in the regularization image folder with the format "),xc=l(Ad,"CODE",{class:!0});var mI=r(xc);Nw=o(mI,"<repetition count>_<class>"),mI.forEach(t),Cw=o(Ad,"."),Ad.forEach(t),Zm=u(s),Nc=l(s,"P",{});var _I=r(Nc);Gw=o(_I,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),_I.forEach(t),Qm=u(s),La=l(s,"UL",{});var m_=r(La);Cc=l(m_,"LI",{});var Sq=r(Cc);Uw=o(Sq,"train_data_dir"),sv=l(Sq,"UL",{});var EI=r(sv);av=l(EI,"LI",{});var bI=r(av);Hw=o(bI,"10_princeadam"),bI.forEach(t),EI.forEach(t),Sq.forEach(t),Mw=u(m_),Gc=l(m_,"LI",{});var Dq=r(Gc);Bw=o(Dq,"reg_dir"),lv=l(Dq,"UL",{});var yI=r(lv);rv=l(yI,"LI",{});var kI=r(rv);Ww=o(kI,"1_1boy"),kI.forEach(t),yI.forEach(t),Dq.forEach(t),m_.forEach(t),Jm=u(s),Uc=l(s,"P",{});var wI=r(Uc);jw=o(wI,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),wI.forEach(t),$m=u(s),fr=l(s,"P",{class:!0});var zI=r(fr);hr=l(zI,"IMG",{src:!0,alt:!0,class:!0}),zI.forEach(t),e1=u(s),Ia=l(s,"H3",{id:!0});var Aq=r(Ia);Oa=l(Aq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var TI=r(Oa);iv=l(TI,"SPAN",{class:!0}),r(iv).forEach(t),TI.forEach(t),Fw=o(Aq,"Training Settings"),Aq.forEach(t),t1=u(s),Yt=l(s,"P",{});var qv=r(Yt);Vw=o(qv,"The training setup we\u2019re going to use is:  "),Hc=l(qv,"CODE",{class:!0});var qI=r(Hc);Kw=o(qI,"Number of images * repeats * epoch / batch size = total steps"),qI.forEach(t),Yw=o(qv,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Mc=l(qv,"CODE",{class:!0});var RI=r(Mc);Xw=o(RI,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),RI.forEach(t),qv.forEach(t),s1=u(s),Xt=l(s,"TABLE",{class:!0});var __=r(Xt);Bc=l(__,"THEAD",{class:!0});var SI=r(Bc);re=l(SI,"TR",{class:!0});var Ct=r(re);Wc=l(Ct,"TH",{class:!0});var DI=r(Wc);Zw=o(DI,"Number of Images"),DI.forEach(t),Qw=u(Ct),jc=l(Ct,"TH",{class:!0});var AI=r(jc);Jw=o(AI,"Repeats"),AI.forEach(t),$w=u(Ct),Fc=l(Ct,"TH",{class:!0});var LI=r(Fc);ez=o(LI,"Epochs"),LI.forEach(t),tz=u(Ct),Vc=l(Ct,"TH",{class:!0});var II=r(Vc);sz=o(II,"Batch Size"),II.forEach(t),az=u(Ct),Kc=l(Ct,"TH",{class:!0});var OI=r(Kc);lz=o(OI,"Total Steps"),OI.forEach(t),Ct.forEach(t),SI.forEach(t),rz=u(__),Yc=l(__,"TBODY",{class:!0});var PI=r(Yc);ie=l(PI,"TR",{class:!0});var Gt=r(ie);Xc=l(Gt,"TD",{class:!0});var xI=r(Xc);iz=o(xI,"45"),xI.forEach(t),nz=u(Gt),Zc=l(Gt,"TD",{class:!0});var NI=r(Zc);oz=o(NI,"10"),NI.forEach(t),cz=u(Gt),Qc=l(Gt,"TD",{class:!0});var CI=r(Qc);uz=o(CI,"20"),CI.forEach(t),pz=u(Gt),Jc=l(Gt,"TD",{class:!0});var GI=r(Jc);dz=o(GI,"2"),GI.forEach(t),fz=u(Gt),$c=l(Gt,"TD",{class:!0});var UI=r($c);hz=o(UI,"4500"),UI.forEach(t),Gt.forEach(t),PI.forEach(t),__.forEach(t),a1=u(s),eu=l(s,"P",{});var HI=r(eu);vz=o(HI,"Now let\u2019s focus on these training settings:"),HI.forEach(t),l1=u(s),vr=l(s,"PRE",{class:!0});var nx=r(vr);nx.forEach(t),r1=u(s),M=l(s,"UL",{});var V=r(M);tu=l(V,"LI",{});var Lq=r(tu);gr=l(Lq,"STRONG",{});var E_=r(gr);gz=o(E_,"Learning Rate ("),su=l(E_,"CODE",{class:!0});var MI=r(su);mz=o(MI,"learning_rate"),MI.forEach(t),_z=o(E_,")"),E_.forEach(t),Ez=o(Lq,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Lq.forEach(t),bz=u(V),au=l(V,"LI",{});var Iq=r(au);mr=l(Iq,"STRONG",{});var b_=r(mr);yz=o(b_,"Text Encoder Learning Rate ("),lu=l(b_,"CODE",{class:!0});var BI=r(lu);kz=o(BI,"text_encoder_lr"),BI.forEach(t),wz=o(b_,")"),b_.forEach(t),zz=o(Iq,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Iq.forEach(t),Tz=u(V),ru=l(V,"LI",{});var Oq=r(ru);_r=l(Oq,"STRONG",{});var y_=r(_r);qz=o(y_,"UNet Learning Rate ("),iu=l(y_,"CODE",{class:!0});var WI=r(iu);Rz=o(WI,"unet_lr"),WI.forEach(t),Sz=o(y_,")"),y_.forEach(t),Dz=o(Oq,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Oq.forEach(t),Az=u(V),nu=l(V,"LI",{});var Pq=r(nu);Er=l(Pq,"STRONG",{});var k_=r(Er);Lz=o(k_,"Learning Rate Scheduler ("),ou=l(k_,"CODE",{class:!0});var jI=r(ou);Iz=o(jI,"lr_scheduler"),jI.forEach(t),Oz=o(k_,")"),k_.forEach(t),Pz=o(Pq,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Pq.forEach(t),xz=u(V),cu=l(V,"LI",{});var xq=r(cu);nv=l(xq,"STRONG",{});var FI=r(nv);Nz=o(FI,"Number of Cycles"),FI.forEach(t),Cz=o(xq,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),xq.forEach(t),Gz=u(V),uu=l(V,"LI",{});var Nq=r(uu);br=l(Nq,"STRONG",{});var w_=r(br);Uz=o(w_,"Network Dimension ("),pu=l(w_,"CODE",{class:!0});var VI=r(pu);Hz=o(VI,"network_dim"),VI.forEach(t),Mz=o(w_,")"),w_.forEach(t),Bz=o(Nq,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Nq.forEach(t),Wz=u(V),du=l(V,"LI",{});var Cq=r(du);yr=l(Cq,"STRONG",{});var z_=r(yr);jz=o(z_,"Network Alpha ("),fu=l(z_,"CODE",{class:!0});var KI=r(fu);Fz=o(KI,"network_alpha"),KI.forEach(t),Vz=o(z_,")"),z_.forEach(t),Kz=o(Cq,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Cq.forEach(t),Yz=u(V),hu=l(V,"LI",{});var Gq=r(hu);kr=l(Gq,"STRONG",{});var T_=r(kr);Xz=o(T_,"Clip Skip ("),vu=l(T_,"CODE",{class:!0});var YI=r(vu);Zz=o(YI,"clip_skip"),YI.forEach(t),Qz=o(T_,")"),T_.forEach(t),Jz=o(Gq,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Gq.forEach(t),$z=u(V),gu=l(V,"LI",{});var Uq=r(gu);wr=l(Uq,"STRONG",{});var q_=r(wr);e6=o(q_,"Max Token Length ("),mu=l(q_,"CODE",{class:!0});var XI=r(mu);t6=o(XI,"max_token_length"),XI.forEach(t),s6=o(q_,")"),q_.forEach(t),a6=o(Uq,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Uq.forEach(t),l6=u(V),_u=l(V,"LI",{});var Hq=r(_u);zr=l(Hq,"STRONG",{});var R_=r(zr);r6=o(R_,"Noise Offset ("),Eu=l(R_,"CODE",{class:!0});var ZI=r(Eu);i6=o(ZI,"noise_offset"),ZI.forEach(t),n6=o(R_,")"),R_.forEach(t),o6=o(Hq,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Hq.forEach(t),c6=u(V),bu=l(V,"LI",{});var Mq=r(bu);Tr=l(Mq,"STRONG",{});var S_=r(Tr);u6=o(S_,"Regularization Data Directory ("),yu=l(S_,"CODE",{class:!0});var QI=r(yu);p6=o(QI,"reg_data_dir"),QI.forEach(t),d6=o(S_,")"),S_.forEach(t),f6=o(Mq,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Mq.forEach(t),V.forEach(t),i1=u(s),Pa=l(s,"H3",{id:!0});var Bq=r(Pa);xa=l(Bq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var JI=r(xa);ov=l(JI,"SPAN",{class:!0}),r(ov).forEach(t),JI.forEach(t),h6=o(Bq,"Fine Tuning"),Bq.forEach(t),n1=u(s),ku=l(s,"P",{});var $I=r(ku);v6=o($I,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),$I.forEach(t),o1=u(s),Ur(qr.$$.fragment,s),c1=u(s),Na=l(s,"H4",{id:!0});var Wq=r(Na);Ca=l(Wq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var eO=r(Ca);cv=l(eO,"SPAN",{class:!0}),r(cv).forEach(t),eO.forEach(t),g6=o(Wq,"Workflow with Auto1111 WebUI"),Wq.forEach(t),u1=u(s),Ga=l(s,"P",{});var D_=r(Ga);m6=o(D_,"We\u2019re going to use "),Rr=l(D_,"A",{href:!0,rel:!0});var tO=r(Rr);_6=o(tO,"Stable Diffusion web UI"),tO.forEach(t),E6=o(D_," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),D_.forEach(t),p1=u(s),Ua=l(s,"P",{});var A_=r(Ua);b6=o(A_,"We\u2019re going to use the "),wu=l(A_,"CODE",{class:!0});var sO=r(wu);y6=o(sO,"X/Y/Z plot"),sO.forEach(t),k6=o(A_," script to compare different epochs."),A_.forEach(t),d1=u(s),ne=l(s,"UL",{});var Ut=r(ne);zu=l(Ut,"LI",{});var jq=r(zu);w6=o(jq,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),f1=l(jq,"PRINCEADAM0001:0.7",{}),r(f1).forEach(t),jq.forEach(t),z6=u(Ut),uv=l(Ut,"LI",{});var aO=r(uv);T6=o(aO,"In generation parameters and select the X/Y/Z plot script."),aO.forEach(t),q6=u(Ut),mt=l(Ut,"LI",{});var Cr=r(mt);R6=o(Cr,"Select "),Tu=l(Cr,"CODE",{class:!0});var lO=r(Tu);S6=o(lO,"Prompt SR"),lO.forEach(t),D6=o(Cr," for Prompt Replace.  We\u2019re going to replace "),qu=l(Cr,"CODE",{class:!0});var rO=r(qu);A6=o(rO,"<princeadam0001:0.7>"),rO.forEach(t),L6=o(Cr," with different epoch: "),Ru=l(Cr,"CODE",{class:!0});var iO=r(Ru);I6=o(iO,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),iO.forEach(t),Cr.forEach(t),O6=u(Ut),Su=l(Ut,"LI",{});var Fq=r(Su);P6=o(Fq,"Select a fast sampler like "),Du=l(Fq,"CODE",{class:!0});var nO=r(Du);x6=o(nO,"DPM2 KARRAS"),nO.forEach(t),Fq.forEach(t),N6=u(Ut),Ha=l(Ut,"LI",{});var Rv=r(Ha);C6=o(Rv,"CFG Scale set to "),Au=l(Rv,"CODE",{class:!0});var oO=r(Au);G6=o(oO,"7"),oO.forEach(t),U6=o(Rv," and Steps to "),Lu=l(Rv,"CODE",{class:!0});var cO=r(Lu);H6=o(cO,"20"),cO.forEach(t),Rv.forEach(t),Ut.forEach(t),h1=u(s),_t=l(s,"P",{});var Ld=r(_t);M6=o(Ld,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Iu=l(Ld,"CODE",{class:!0});var uO=r(Iu);B6=o(uO,"network_dim"),uO.forEach(t),W6=o(Ld," and "),Ou=l(Ld,"CODE",{class:!0});var pO=r(Ou);j6=o(pO,"network_alpha"),pO.forEach(t),F6=o(Ld,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Ld.forEach(t),v1=u(s),ze=l(s,"UL",{});var ul=r(ze);Ma=l(ul,"LI",{});var Sv=r(Ma);V6=o(Sv,"Select "),Pu=l(Sv,"CODE",{class:!0});var dO=r(Pu);K6=o(dO,"Prompt SR"),dO.forEach(t),Y6=o(Sv," for Prompt Replace.  We\u2019re going to replace the weights "),xu=l(Sv,"CODE",{class:!0});var fO=r(xu);X6=o(fO,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),fO.forEach(t),Sv.forEach(t),Z6=u(ul),Sr=l(ul,"LI",{});var L_=r(Sr);Q6=o(L_,"Use Prompt SR to generate a variety of angles: Select "),Nu=l(L_,"CODE",{class:!0});var hO=r(Nu);J6=o(hO,"Prompt SR"),hO.forEach(t),$6=o(L_," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),L_.forEach(t),e8=u(ul),pv=l(ul,"LI",{});var vO=r(pv);t8=o(vO,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),vO.forEach(t),s8=u(ul),dv=l(ul,"LI",{});var gO=r(dv);a8=o(gO,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),gO.forEach(t),ul.forEach(t),g1=u(s),Ba=l(s,"H4",{id:!0});var Vq=r(Ba);Wa=l(Vq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var mO=r(Wa);fv=l(mO,"SPAN",{class:!0}),r(fv).forEach(t),mO.forEach(t),l8=o(Vq,"Issues to look for"),Vq.forEach(t),m1=u(s),Te=l(s,"UL",{});var pl=r(Te);Cu=l(pl,"LI",{});var Kq=r(Cu);hv=l(Kq,"STRONG",{});var _O=r(hv);r8=o(_O,"Undercooked:"),_O.forEach(t),i8=o(Kq," Lacks output, adjust unet learning rate or extend training duration."),Kq.forEach(t),n8=u(pl),Gu=l(pl,"LI",{});var Yq=r(Gu);vv=l(Yq,"STRONG",{});var EO=r(vv);o8=o(EO,"Overcooked:"),EO.forEach(t),c8=o(Yq," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Yq.forEach(t),u8=u(pl),Uu=l(pl,"LI",{});var Xq=r(Uu);gv=l(Xq,"STRONG",{});var bO=r(gv);p8=o(bO,"Overfit:"),bO.forEach(t),d8=o(Xq," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),Xq.forEach(t),f8=u(pl),Hu=l(pl,"LI",{});var Zq=r(Hu);mv=l(Zq,"STRONG",{});var yO=r(mv);h8=o(yO,"Mismatched:"),yO.forEach(t),v8=o(Zq," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Zq.forEach(t),pl.forEach(t),_1=u(s),Mu=l(s,"P",{});var kO=r(Mu);g8=o(kO,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),kO.forEach(t),E1=u(s),Dr=l(s,"P",{class:!0});var wO=r(Dr);Ar=l(wO,"IMG",{src:!0,alt:!0,class:!0}),wO.forEach(t),b1=u(s),ja=l(s,"H3",{id:!0});var Qq=r(ja);Fa=l(Qq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var zO=r(Fa);_v=l(zO,"SPAN",{class:!0}),r(_v).forEach(t),zO.forEach(t),m8=o(Qq,"Troubleshooting"),Qq.forEach(t),y1=u(s),Bu=l(s,"P",{});var TO=r(Bu);_8=o(TO,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),TO.forEach(t),k1=u(s),Et=l(s,"UL",{});var Id=r(Et);Lr=l(Id,"LI",{});var I_=r(Lr);E8=o(I_,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Wu=l(I_,"CODE",{class:!0});var qO=r(Wu);b8=o(qO,"200"),qO.forEach(t),y8=o(I_," regularization images per training image."),I_.forEach(t),k8=u(Id),Ir=l(Id,"LI",{});var O_=r(Ir);w8=o(O_,"Repeats of regularization images, but may overfit more.  Increasing the "),ju=l(O_,"CODE",{class:!0});var RO=r(ju);z8=o(RO,"repetition_count"),RO.forEach(t),T8=o(O_," will cycle through the images more but the results may have results that overfit the model."),O_.forEach(t),q8=u(Id),Ev=l(Id,"LI",{});var SO=r(Ev);R8=o(SO,"Create more regularization images without increasing repeats will help with the overfitting."),SO.forEach(t),Id.forEach(t),w1=u(s),Zt=l(s,"TABLE",{class:!0});var P_=r(Zt);Fu=l(P_,"THEAD",{class:!0});var DO=r(Fu);bt=l(DO,"TR",{class:!0});var Od=r(bt);Vu=l(Od,"TH",{class:!0});var AO=r(Vu);S8=o(AO,"Issue"),AO.forEach(t),D8=u(Od),Ku=l(Od,"TH",{class:!0});var LO=r(Ku);A8=o(LO,"Situation"),LO.forEach(t),L8=u(Od),Yu=l(Od,"TH",{class:!0});var IO=r(Yu);I8=o(IO,"Recommendation"),IO.forEach(t),Od.forEach(t),DO.forEach(t),O8=u(P_),qe=l(P_,"TBODY",{class:!0});var dl=r(qe);yt=l(dl,"TR",{class:!0});var Pd=r(yt);Xu=l(Pd,"TD",{class:!0});var OO=r(Xu);P8=o(OO,"Varying quality"),OO.forEach(t),x8=u(Pd),Zu=l(Pd,"TD",{class:!0});var PO=r(Zu);N8=o(PO,"Results differ from expectations"),PO.forEach(t),C8=u(Pd),Qu=l(Pd,"TD",{class:!0});var xO=r(Qu);G8=o(xO,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),xO.forEach(t),Pd.forEach(t),U8=u(dl),kt=l(dl,"TR",{class:!0});var xd=r(kt);Ju=l(xd,"TD",{class:!0});var NO=r(Ju);H8=o(NO,"Inadequate regularization for input data"),NO.forEach(t),M8=u(xd),$u=l(xd,"TD",{class:!0});var CO=r($u);B8=o(CO,"Lower input images, less regularization needed"),CO.forEach(t),W8=u(xd),ep=l(xd,"TD",{class:!0});var GO=r(ep);j8=o(GO,"Reduce the number of input images or increasing the quantity of reg images."),GO.forEach(t),xd.forEach(t),F8=u(dl),wt=l(dl,"TR",{class:!0});var Nd=r(wt);tp=l(Nd,"TD",{class:!0});var UO=r(tp);V8=o(UO,"Overfitting due to repetition"),UO.forEach(t),K8=u(Nd),sp=l(Nd,"TD",{class:!0});var HO=r(sp);Y8=o(HO,"Repeats of reg images, risk of overfitting"),HO.forEach(t),X8=u(Nd),ap=l(Nd,"TD",{class:!0});var MO=r(ap);Z8=o(MO,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),MO.forEach(t),Nd.forEach(t),Q8=u(dl),zt=l(dl,"TR",{class:!0});var Cd=r(zt);lp=l(Cd,"TD",{class:!0});var BO=r(lp);J8=o(BO,"Mitigate overfitting while increasing diversity"),BO.forEach(t),$8=u(Cd),rp=l(Cd,"TD",{class:!0});var WO=r(rp);e7=o(WO,"Create more reg images without repeats"),WO.forEach(t),t7=u(Cd),ip=l(Cd,"TD",{class:!0});var jO=r(ip);s7=o(jO,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),jO.forEach(t),Cd.forEach(t),dl.forEach(t),P_.forEach(t),z1=u(s),Va=l(s,"H4",{id:!0});var Jq=r(Va);Ka=l(Jq,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var FO=r(Ka);bv=l(FO,"SPAN",{class:!0}),r(bv).forEach(t),FO.forEach(t),a7=o(Jq,"More Solutions"),Jq.forEach(t),T1=u(s),np=l(s,"P",{});var VO=r(np);l7=o(VO,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),VO.forEach(t),q1=u(s),Qt=l(s,"TABLE",{class:!0});var x_=r(Qt);op=l(x_,"THEAD",{class:!0});var KO=r(op);Tt=l(KO,"TR",{class:!0});var Gd=r(Tt);cp=l(Gd,"TH",{class:!0});var YO=r(cp);r7=o(YO,"Symptom"),YO.forEach(t),i7=u(Gd),up=l(Gd,"TH",{class:!0});var XO=r(up);n7=o(XO,"Likely Cause"),XO.forEach(t),o7=u(Gd),pp=l(Gd,"TH",{class:!0});var ZO=r(pp);c7=o(ZO,"Solution"),ZO.forEach(t),Gd.forEach(t),KO.forEach(t),u7=u(x_),W=l(x_,"TBODY",{class:!0});var X=r(W);qt=l(X,"TR",{class:!0});var Ud=r(qt);dp=l(Ud,"TD",{class:!0});var QO=r(dp);p7=o(QO,"Plastic texture persists"),QO.forEach(t),d7=u(Ud),fp=l(Ud,"TD",{class:!0});var JO=r(fp);f7=o(JO,"Insufficient human reg images"),JO.forEach(t),h7=u(Ud),hp=l(Ud,"TD",{class:!0});var $O=r(hp);v7=o($O,"Add real photos to reg set"),$O.forEach(t),Ud.forEach(t),g7=u(X),Rt=l(X,"TR",{class:!0});var Hd=r(Rt);vp=l(Hd,"TD",{class:!0});var eP=r(vp);m7=o(eP,"Loss plateaus early"),eP.forEach(t),_7=u(Hd),gp=l(Hd,"TD",{class:!0});var tP=r(gp);E7=o(tP,"Learning rate too low"),tP.forEach(t),b7=u(Hd),mp=l(Hd,"TD",{class:!0});var sP=r(mp);y7=o(sP,"Increase LR by 10x"),sP.forEach(t),Hd.forEach(t),k7=u(X),St=l(X,"TR",{class:!0});var Md=r(St);_p=l(Md,"TD",{class:!0});var aP=r(_p);w7=o(aP,"Features blurry"),aP.forEach(t),z7=u(Md),Ep=l(Md,"TD",{class:!0});var lP=r(Ep);T7=o(lP,"Network dimension too small"),lP.forEach(t),q7=u(Md),bp=l(Md,"TD",{class:!0});var rP=r(bp);R7=o(rP,"Increase network_dim to 64+"),rP.forEach(t),Md.forEach(t),S7=u(X),Dt=l(X,"TR",{class:!0});var Bd=r(Dt);yp=l(Bd,"TD",{class:!0});var iP=r(yp);D7=o(iP,"Color distortion"),iP.forEach(t),A7=u(Bd),kp=l(Bd,"TD",{class:!0});var nP=r(kp);L7=o(nP,"Noise offset conflict"),nP.forEach(t),I7=u(Bd),wp=l(Bd,"TD",{class:!0});var oP=r(wp);O7=o(oP,"Try noise_offset 0.05-0.1"),oP.forEach(t),Bd.forEach(t),P7=u(X),At=l(X,"TR",{class:!0});var Wd=r(At);zp=l(Wd,"TD",{class:!0});var cP=r(zp);x7=o(cP,"Overly stylized outputs"),cP.forEach(t),N7=u(Wd),Tp=l(Wd,"TD",{class:!0});var uP=r(Tp);C7=o(uP,"Reg image style mismatch"),uP.forEach(t),G7=u(Wd),qp=l(Wd,"TD",{class:!0});var pP=r(qp);U7=o(pP,"Regenerate reg images with base model"),pP.forEach(t),Wd.forEach(t),H7=u(X),Lt=l(X,"TR",{class:!0});var jd=r(Lt);Rp=l(jd,"TD",{class:!0});var dP=r(Rp);M7=o(dP,"Training instability"),dP.forEach(t),B7=u(jd),Sp=l(jd,"TD",{class:!0});var fP=r(Sp);W7=o(fP,"Batch size too large"),fP.forEach(t),j7=u(jd),Dp=l(jd,"TD",{class:!0});var hP=r(Dp);F7=o(hP,"Reduce batch_size to 1-2"),hP.forEach(t),jd.forEach(t),V7=u(X),It=l(X,"TR",{class:!0});var Fd=r(It);Ap=l(Fd,"TD",{class:!0});var vP=r(Ap);K7=o(vP,"Slow convergence"),vP.forEach(t),Y7=u(Fd),Lp=l(Fd,"TD",{class:!0});var gP=r(Lp);X7=o(gP,"Network_alpha too high"),gP.forEach(t),Z7=u(Fd),Ip=l(Fd,"TD",{class:!0});var mP=r(Ip);Q7=o(mP,"Set alpha = dim/2 (e.g., 64/2 = 32)"),mP.forEach(t),Fd.forEach(t),J7=u(X),Ot=l(X,"TR",{class:!0});var Vd=r(Ot);Op=l(Vd,"TD",{class:!0});var _P=r(Op);$7=o(_P,"Loss divergence"),_P.forEach(t),eT=u(Vd),Pp=l(Vd,"TD",{class:!0});var EP=r(Pp);tT=o(EP,"Text encoder LR too high"),EP.forEach(t),sT=u(Vd),xp=l(Vd,"TD",{class:!0});var bP=r(xp);aT=o(bP,"Reduce text_encoder_lr by 10x"),bP.forEach(t),Vd.forEach(t),lT=u(X),Pt=l(X,"TR",{class:!0});var Kd=r(Pt);Np=l(Kd,"TD",{class:!0});var yP=r(Np);rT=o(yP,"Poor prompt adherence"),yP.forEach(t),iT=u(Kd),Cp=l(Kd,"TD",{class:!0});var kP=r(Cp);nT=o(kP,"Clip skip too high"),kP.forEach(t),oT=u(Kd),Gp=l(Kd,"TD",{class:!0});var wP=r(Gp);cT=o(wP,"Reduce clip_skip to 1-2"),wP.forEach(t),Kd.forEach(t),uT=u(X),xt=l(X,"TR",{class:!0});var Yd=r(xt);Up=l(Yd,"TD",{class:!0});var zP=r(Up);pT=o(zP,"Memory errors"),zP.forEach(t),dT=u(Yd),Hp=l(Yd,"TD",{class:!0});var TP=r(Hp);fT=o(TP,"Resolution too high"),TP.forEach(t),hT=u(Yd),Mp=l(Yd,"TD",{class:!0});var qP=r(Mp);vT=o(qP,"Reduce to 512-768px, enable gradient checkpointing"),qP.forEach(t),Yd.forEach(t),X.forEach(t),x_.forEach(t),R1=u(s),Ya=l(s,"H2",{id:!0});var $q=r(Ya);Xa=l($q,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var RP=r(Xa);yv=l(RP,"SPAN",{class:!0}),r(yv).forEach(t),RP.forEach(t),gT=o($q,"Results"),$q.forEach(t),S1=u(s),Bp=l(s,"P",{});var SP=r(Bp);mT=o(SP,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),SP.forEach(t),D1=u(s),Wp=l(s,"P",{});var DP=r(Wp);_T=o(DP,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),DP.forEach(t),A1=u(s),Or=l(s,"P",{class:!0});var AP=r(Or);Pr=l(AP,"IMG",{src:!0,alt:!0,class:!0}),AP.forEach(t),L1=u(s),jp=l(s,"P",{});var LP=r(jp);ET=o(LP,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),LP.forEach(t),I1=u(s),Jt=l(s,"H2",{id:!0,class:!0});var e9=r(Jt);Za=l(e9,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var IP=r(Za);kv=l(IP,"SPAN",{class:!0}),r(kv).forEach(t),IP.forEach(t),bT=o(e9,"spacelab"),e9.forEach(t),O1=u(s),De&&De.l(s),P1=Xd(),this.h()},h(){i(T,"class","icon icon-link"),i(z,"aria-hidden","true"),i(z,"tabindex","-1"),i(z,"href","#experiment-1-anime-inspired-heroism"),i(y,"id","experiment-1-anime-inspired-heroism"),ts(L.src,I="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png")||i(L,"src",I),i(L,"alt","image"),i(L,"class","svelte-1nszpqs"),i(w,"class","svelte-1nszpqs"),i(q,"class","icon icon-link"),i(U,"aria-hidden","true"),i(U,"tabindex","-1"),i(U,"href","#experiment-2-retro-cartoon-resurrection"),i(Z,"id","experiment-2-retro-cartoon-resurrection"),ts(pe.src,Zd="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1738190889/blog/fiz3ariex9rpsoovdccl.png")||i(pe,"src",Zd),i(pe,"alt","image"),i(pe,"class","svelte-1nszpqs"),i(Le,"class","svelte-1nszpqs"),i(Qd,"class","icon icon-link"),i(is,"aria-hidden","true"),i(is,"tabindex","-1"),i(is,"href","#what-are-regularization-images"),i(rs,"id","what-are-regularization-images"),i(jr,"class","svelte-1nszpqs"),i(fl,"class","svelte-1nszpqs"),i(Xr,"class","svelte-1nszpqs"),i(Zr,"class","svelte-1nszpqs"),i(Qr,"class","svelte-1nszpqs"),i(Ie,"class","svelte-1nszpqs"),i(Yr,"class","svelte-1nszpqs"),i(Jr,"class","svelte-1nszpqs"),i($r,"class","svelte-1nszpqs"),i(ei,"class","svelte-1nszpqs"),i(Pe,"class","svelte-1nszpqs"),i(ti,"class","svelte-1nszpqs"),i(si,"class","svelte-1nszpqs"),i(ai,"class","svelte-1nszpqs"),i(xe,"class","svelte-1nszpqs"),i(li,"class","svelte-1nszpqs"),i(ri,"class","svelte-1nszpqs"),i(ii,"class","svelte-1nszpqs"),i(Ne,"class","svelte-1nszpqs"),i(Oe,"class","svelte-1nszpqs"),i(Ht,"class","svelte-1nszpqs"),i(ci,"class","svelte-1nszpqs"),i(vl,"class","svelte-1nszpqs"),i(tf,"class","icon icon-link"),i(os,"aria-hidden","true"),i(os,"tabindex","-1"),i(os,"href","#scenario-1-limited-training-data"),i(ns,"id","scenario-1-limited-training-data"),i(rf,"class","icon icon-link"),i(us,"aria-hidden","true"),i(us,"tabindex","-1"),i(us,"href","#scenario-2-imbalanced-training-data"),i(cs,"id","scenario-2-imbalanced-training-data"),i(uf,"class","icon icon-link"),i(ds,"aria-hidden","true"),i(ds,"tabindex","-1"),i(ds,"href","#divergence"),i(ps,"id","divergence"),i(di,"class","svelte-1nszpqs"),i(fi,"class","svelte-1nszpqs"),i(wl,"class","svelte-1nszpqs"),i(mf,"class","icon icon-link"),i(vs,"aria-hidden","true"),i(vs,"tabindex","-1"),i(vs,"href","#overfitting"),i(hs,"id","overfitting"),i(kf,"class","icon icon-link"),i(ms,"aria-hidden","true"),i(ms,"tabindex","-1"),i(ms,"href","#key-differences"),i(gs,"id","key-differences"),i(Ei,"class","svelte-1nszpqs"),i(bi,"class","svelte-1nszpqs"),i(yi,"class","svelte-1nszpqs"),i(He,"class","svelte-1nszpqs"),i(_i,"class","svelte-1nszpqs"),i(ki,"class","svelte-1nszpqs"),i(wi,"class","svelte-1nszpqs"),i(zi,"class","svelte-1nszpqs"),i(Me,"class","svelte-1nszpqs"),i(Ti,"class","svelte-1nszpqs"),i(qi,"class","svelte-1nszpqs"),i(Ri,"class","svelte-1nszpqs"),i(Be,"class","svelte-1nszpqs"),i(Si,"class","svelte-1nszpqs"),i(Di,"class","svelte-1nszpqs"),i(Ai,"class","svelte-1nszpqs"),i(We,"class","svelte-1nszpqs"),i(Li,"class","svelte-1nszpqs"),i(Ii,"class","svelte-1nszpqs"),i(Oi,"class","svelte-1nszpqs"),i(je,"class","svelte-1nszpqs"),i(de,"class","svelte-1nszpqs"),i(Mt,"class","svelte-1nszpqs"),i(Lf,"class","icon icon-link"),i(Es,"aria-hidden","true"),i(Es,"tabindex","-1"),i(Es,"href","#preventing-divergence"),i(_s,"id","preventing-divergence"),i(xi,"class","svelte-1nszpqs"),i(Ni,"class","svelte-1nszpqs"),i(bs,"class","svelte-1nszpqs"),i(Pi,"class","svelte-1nszpqs"),i(Ci,"class","svelte-1nszpqs"),i(Gi,"class","svelte-1nszpqs"),i(ys,"class","svelte-1nszpqs"),i(Ui,"class","svelte-1nszpqs"),i(Hi,"class","svelte-1nszpqs"),i(ks,"class","svelte-1nszpqs"),i(Mi,"class","svelte-1nszpqs"),i(Bi,"class","svelte-1nszpqs"),i(ws,"class","svelte-1nszpqs"),i(Wi,"class","svelte-1nszpqs"),i(ji,"class","svelte-1nszpqs"),i(zs,"class","svelte-1nszpqs"),i(fe,"class","svelte-1nszpqs"),i(Bt,"class","svelte-1nszpqs"),i(Nf,"class","icon icon-link"),i(qs,"aria-hidden","true"),i(qs,"tabindex","-1"),i(qs,"href","#implement-these-strategies"),i(Ts,"id","implement-these-strategies"),i(Vi,"class","svelte-1nszpqs"),i(Ki,"class","svelte-1nszpqs"),i(Yi,"class","svelte-1nszpqs"),i(Xi,"class","svelte-1nszpqs"),i(Zi,"class","svelte-1nszpqs"),i(zl,"class","language-python"),i(Tl,"class","language-python"),i(Gf,"class","icon icon-link"),i(Ss,"aria-hidden","true"),i(Ss,"tabindex","-1"),i(Ss,"href","#data-considerations"),i(Rs,"id","data-considerations"),i(Ji,"class","svelte-1nszpqs"),i($i,"class","svelte-1nszpqs"),i(en,"class","svelte-1nszpqs"),i(Fe,"class","svelte-1nszpqs"),i(Qi,"class","svelte-1nszpqs"),i(tn,"class","svelte-1nszpqs"),i(sn,"class","svelte-1nszpqs"),i(an,"class","svelte-1nszpqs"),i(Ve,"class","svelte-1nszpqs"),i(ln,"class","svelte-1nszpqs"),i(rn,"class","svelte-1nszpqs"),i(nn,"class","svelte-1nszpqs"),i(Ke,"class","svelte-1nszpqs"),i(on,"class","svelte-1nszpqs"),i(cn,"class","svelte-1nszpqs"),i(un,"class","svelte-1nszpqs"),i(Ye,"class","svelte-1nszpqs"),i(pn,"class","svelte-1nszpqs"),i(dn,"class","svelte-1nszpqs"),i(fn,"class","svelte-1nszpqs"),i(Xe,"class","svelte-1nszpqs"),i(ge,"class","svelte-1nszpqs"),i(Wt,"class","svelte-1nszpqs"),i(Uf,"class","icon icon-link"),i(As,"aria-hidden","true"),i(As,"tabindex","-1"),i(As,"href","#monitoring-tips"),i(Ds,"id","monitoring-tips"),i(ql,"href","https://github.com/kohya-ss/sd-scripts"),i(ql,"rel","nofollow"),i(Hf,"class","icon icon-link"),i(Os,"aria-hidden","true"),i(Os,"tabindex","-1"),i(Os,"href","#track-loss-curves"),i(Is,"id","track-loss-curves"),i(Rl,"href","https://www.tensorflow.org/tensorboard"),i(Rl,"rel","nofollow"),i(Sl,"class","language-bash"),i(Mf,"class","icon icon-link"),i(Ns,"aria-hidden","true"),i(Ns,"tabindex","-1"),i(Ns,"href","#what-to-monitor"),i(xs,"id","what-to-monitor"),i(Ff,"class","icon icon-link"),i(Gs,"aria-hidden","true"),i(Gs,"tabindex","-1"),i(Gs,"href","#warning-signs"),i(Cs,"id","warning-signs"),i(Xf,"class","icon icon-link"),i(Hs,"aria-hidden","true"),i(Hs,"tabindex","-1"),i(Hs,"href","#generate-validation-images-every-100-steps"),i(Us,"id","generate-validation-images-every-100-steps"),i(Al,"class","language-json"),i(Qf,"class","icon icon-link"),i(Bs,"aria-hidden","true"),i(Bs,"tabindex","-1"),i(Bs,"href","#what-to-look-for"),i(Ms,"id","what-to-look-for"),i(mn,"class","svelte-1nszpqs"),i(Ll,"class","svelte-1nszpqs"),i(th,"class","icon icon-link"),i(js,"aria-hidden","true"),i(js,"tabindex","-1"),i(js,"href","#use-gradient-clipping"),i(Ws,"id","use-gradient-clipping"),i(En,"class","svelte-1nszpqs"),i(bn,"class","svelte-1nszpqs"),i(Pl,"class","svelte-1nszpqs"),i(rh,"class","icon icon-link"),i(Vs,"aria-hidden","true"),i(Vs,"tabindex","-1"),i(Vs,"href","#enable-mixed-precision-training"),i(Fs,"id","enable-mixed-precision-training"),i(Nl,"class","language-python"),i(kn,"class","svelte-1nszpqs"),i(Cl,"class","svelte-1nszpqs"),i(uh,"class","icon icon-link"),i(Ys,"aria-hidden","true"),i(Ys,"tabindex","-1"),i(Ys,"href","#start-with-conservative-learning-rates"),i(Ks,"id","start-with-conservative-learning-rates"),i(Gl,"class","language-yml"),i(zn,"class","svelte-1nszpqs"),i(Tn,"class","svelte-1nszpqs"),i(qn,"class","svelte-1nszpqs"),i(tt,"class","svelte-1nszpqs"),i(wn,"class","svelte-1nszpqs"),i(Sn,"class","svelte-1nszpqs"),i(Rn,"class","svelte-1nszpqs"),i(Dn,"class","svelte-1nszpqs"),i(An,"class","svelte-1nszpqs"),i(at,"class","svelte-1nszpqs"),i(In,"class","svelte-1nszpqs"),i(Ln,"class","svelte-1nszpqs"),i(On,"class","svelte-1nszpqs"),i(Pn,"class","svelte-1nszpqs"),i(lt,"class","svelte-1nszpqs"),i(Nn,"class","svelte-1nszpqs"),i(xn,"class","svelte-1nszpqs"),i(Cn,"class","svelte-1nszpqs"),i(Gn,"class","svelte-1nszpqs"),i(rt,"class","svelte-1nszpqs"),i(st,"class","svelte-1nszpqs"),i(jt,"class","svelte-1nszpqs"),i(dh,"class","icon icon-link"),i(Qs,"aria-hidden","true"),i(Qs,"tabindex","-1"),i(Qs,"href","#what-does-this-mean"),i(Zs,"id","what-does-this-mean"),i(Un,"class","svelte-1nszpqs"),i(Hn,"class","svelte-1nszpqs"),i(Mn,"class","svelte-1nszpqs"),i(Bn,"class","svelte-1nszpqs"),i(Wn,"class","svelte-1nszpqs"),i(jn,"class","svelte-1nszpqs"),i(fh,"class","icon icon-link"),i($s,"aria-hidden","true"),i($s,"tabindex","-1"),i($s,"href","#text-encoder-learning-rate"),i(Js,"id","text-encoder-learning-rate"),i(Kn,"class","svelte-1nszpqs"),i(vh,"class","icon icon-link"),i(sa,"aria-hidden","true"),i(sa,"tabindex","-1"),i(sa,"href","#effects"),i(ta,"id","effects"),i(Eh,"class","icon icon-link"),i(la,"aria-hidden","true"),i(la,"tabindex","-1"),i(la,"href","#unet-learning-rate"),i(aa,"id","unet-learning-rate"),i(ro,"class","svelte-1nszpqs"),i(io,"class","svelte-1nszpqs"),i(no,"class","svelte-1nszpqs"),i(oo,"class","svelte-1nszpqs"),i(me,"class","svelte-1nszpqs"),i(lo,"class","svelte-1nszpqs"),i(co,"class","svelte-1nszpqs"),i(uo,"class","svelte-1nszpqs"),i(po,"class","svelte-1nszpqs"),i(fo,"class","svelte-1nszpqs"),i(_e,"class","svelte-1nszpqs"),i(ho,"class","svelte-1nszpqs"),i(vo,"class","svelte-1nszpqs"),i(go,"class","svelte-1nszpqs"),i(mo,"class","svelte-1nszpqs"),i(Ee,"class","svelte-1nszpqs"),i(_o,"class","svelte-1nszpqs"),i(Eo,"class","svelte-1nszpqs"),i(na,"class","svelte-1nszpqs"),i(bo,"class","svelte-1nszpqs"),i(yo,"class","svelte-1nszpqs"),i(ct,"class","svelte-1nszpqs"),i(be,"class","svelte-1nszpqs"),i(ko,"class","svelte-1nszpqs"),i(wo,"class","svelte-1nszpqs"),i(zo,"class","svelte-1nszpqs"),i(To,"class","svelte-1nszpqs"),i(ye,"class","svelte-1nszpqs"),i(qo,"class","svelte-1nszpqs"),i(Ro,"class","svelte-1nszpqs"),i(So,"class","svelte-1nszpqs"),i(Do,"class","svelte-1nszpqs"),i(ke,"class","svelte-1nszpqs"),i(le,"class","svelte-1nszpqs"),i(Kt,"class","svelte-1nszpqs"),i(Ih,"class","icon icon-link"),i(ca,"aria-hidden","true"),i(ca,"tabindex","-1"),i(ca,"href","#generating-regularization-images"),i(oa,"id","generating-regularization-images"),i(Ao,"class","svelte-1nszpqs"),i(Lo,"class","svelte-1nszpqs"),i(Io,"class","svelte-1nszpqs"),i(Oo,"class","svelte-1nszpqs"),i(Po,"class","svelte-1nszpqs"),i(Oh,"class","icon icon-link"),i(da,"aria-hidden","true"),i(da,"tabindex","-1"),i(da,"href","#important-considerations"),i(pa,"id","important-considerations"),i(Hh,"class","icon icon-link"),i(ha,"aria-hidden","true"),i(ha,"tabindex","-1"),i(ha,"href","#generate-using-stable-diffusion-web-ui"),i(fa,"id","generate-using-stable-diffusion-web-ui"),i(Vl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(Vl,"rel","nofollow"),i(No,"class","svelte-1nszpqs"),i(Co,"class","svelte-1nszpqs"),i(Uo,"class","svelte-1nszpqs"),i(Ho,"class","svelte-1nszpqs"),i(Mo,"class","svelte-1nszpqs"),i(Bo,"class","svelte-1nszpqs"),i(Wo,"class","svelte-1nszpqs"),i(jo,"class","svelte-1nszpqs"),i(Fo,"class","svelte-1nszpqs"),i(Vo,"class","svelte-1nszpqs"),i(Ko,"class","svelte-1nszpqs"),i(Yo,"class","svelte-1nszpqs"),i(Xo,"class","svelte-1nszpqs"),i(Zo,"class","svelte-1nszpqs"),i(Qo,"class","svelte-1nszpqs"),i(Jo,"class","svelte-1nszpqs"),i($o,"class","svelte-1nszpqs"),i(ec,"class","svelte-1nszpqs"),i(tc,"class","svelte-1nszpqs"),i(sc,"class","svelte-1nszpqs"),i(ac,"class","svelte-1nszpqs"),i(lc,"class","svelte-1nszpqs"),i(rc,"class","svelte-1nszpqs"),i(ic,"class","svelte-1nszpqs"),i(nc,"class","svelte-1nszpqs"),i(oc,"class","svelte-1nszpqs"),i(cc,"class","svelte-1nszpqs"),i(pc,"class","svelte-1nszpqs"),i(dc,"class","svelte-1nszpqs"),i(fc,"class","svelte-1nszpqs"),i(hc,"class","svelte-1nszpqs"),i(vc,"class","svelte-1nszpqs"),i(Yh,"class","icon icon-link"),i(_a,"aria-hidden","true"),i(_a,"tabindex","-1"),i(_a,"href","#download-images"),i(ma,"id","download-images"),i(Xl,"href","https://huggingface.co/3ee"),i(Xl,"rel","nofollow"),i(Zl,"href","https://github.com/Luehrsen/sd_regularization_images"),i(Zl,"rel","nofollow"),i(Ql,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(Ql,"rel","nofollow"),i(Jl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(Jl,"rel","nofollow"),i(Xh,"class","icon icon-link"),i(ba,"aria-hidden","true"),i(ba,"tabindex","-1"),i(ba,"href","#captioning-regularization-images"),i(Ea,"id","captioning-regularization-images"),i(zc,"class","svelte-1nszpqs"),i(Tc,"class","svelte-1nszpqs"),i($l,"class","language-shell"),i(Rc,"class","svelte-1nszpqs"),i(Sc,"class","svelte-1nszpqs"),i(Dc,"class","svelte-1nszpqs"),i(ev,"class","icon icon-link"),i(za,"aria-hidden","true"),i(za,"tabindex","-1"),i(za,"href","#training-a-lora"),i(wa,"id","training-a-lora"),i(sr,"href","https://github.com/kohya-ss/sd-scripts"),i(sr,"rel","nofollow"),i(ar,"href","https://github.com/bmaltais/kohya_ss"),i(ar,"rel","nofollow"),i(rr,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(rr,"rel","nofollow"),i(Ta,"class","svelte-1nszpqs"),i(lr,"class","svelte-1nszpqs"),i(nr,"href","https://rentry.org/59xed3"),i(nr,"rel","nofollow"),i(or,"href","https://rentry.org/ezlora"),i(or,"rel","nofollow"),i(cr,"href","https://rentry.org/lora_train"),i(cr,"rel","nofollow"),i(Se,"class","svelte-1nszpqs"),i(ir,"class","svelte-1nszpqs"),i(tv,"class","icon icon-link"),i(Ra,"aria-hidden","true"),i(Ra,"tabindex","-1"),i(Ra,"href","#directory-setup"),i(qa,"id","directory-setup"),i(Ac,"class","svelte-1nszpqs"),i(ur,"class","language-json"),i(pr,"class","language-xml"),i(Ic,"class","svelte-1nszpqs"),i(Oc,"class","svelte-1nszpqs"),i(Aa,"class","svelte-1nszpqs"),i(dr,"class","svelte-1nszpqs"),i(Pc,"class","svelte-1nszpqs"),i(xc,"class","svelte-1nszpqs"),ts(hr.src,n9="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(hr,"src",n9),i(hr,"alt","image"),i(hr,"class","svelte-1nszpqs"),i(fr,"class","svelte-1nszpqs"),i(iv,"class","icon icon-link"),i(Oa,"aria-hidden","true"),i(Oa,"tabindex","-1"),i(Oa,"href","#training-settings"),i(Ia,"id","training-settings"),i(Hc,"class","svelte-1nszpqs"),i(Mc,"class","svelte-1nszpqs"),i(Wc,"class","svelte-1nszpqs"),i(jc,"class","svelte-1nszpqs"),i(Fc,"class","svelte-1nszpqs"),i(Vc,"class","svelte-1nszpqs"),i(Kc,"class","svelte-1nszpqs"),i(re,"class","svelte-1nszpqs"),i(Bc,"class","svelte-1nszpqs"),i(Xc,"class","svelte-1nszpqs"),i(Zc,"class","svelte-1nszpqs"),i(Qc,"class","svelte-1nszpqs"),i(Jc,"class","svelte-1nszpqs"),i($c,"class","svelte-1nszpqs"),i(ie,"class","svelte-1nszpqs"),i(Yc,"class","svelte-1nszpqs"),i(Xt,"class","svelte-1nszpqs"),i(vr,"class","language-json"),i(su,"class","svelte-1nszpqs"),i(lu,"class","svelte-1nszpqs"),i(iu,"class","svelte-1nszpqs"),i(ou,"class","svelte-1nszpqs"),i(pu,"class","svelte-1nszpqs"),i(fu,"class","svelte-1nszpqs"),i(vu,"class","svelte-1nszpqs"),i(mu,"class","svelte-1nszpqs"),i(Eu,"class","svelte-1nszpqs"),i(yu,"class","svelte-1nszpqs"),i(ov,"class","icon icon-link"),i(xa,"aria-hidden","true"),i(xa,"tabindex","-1"),i(xa,"href","#fine-tuning"),i(Pa,"id","fine-tuning"),i(cv,"class","icon icon-link"),i(Ca,"aria-hidden","true"),i(Ca,"tabindex","-1"),i(Ca,"href","#workflow-with-auto1111-webui"),i(Na,"id","workflow-with-auto1111-webui"),i(Rr,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(Rr,"rel","nofollow"),i(wu,"class","svelte-1nszpqs"),i(Tu,"class","svelte-1nszpqs"),i(qu,"class","svelte-1nszpqs"),i(Ru,"class","svelte-1nszpqs"),i(Du,"class","svelte-1nszpqs"),i(Au,"class","svelte-1nszpqs"),i(Lu,"class","svelte-1nszpqs"),i(Iu,"class","svelte-1nszpqs"),i(Ou,"class","svelte-1nszpqs"),i(Pu,"class","svelte-1nszpqs"),i(xu,"class","svelte-1nszpqs"),i(Nu,"class","svelte-1nszpqs"),i(fv,"class","icon icon-link"),i(Wa,"aria-hidden","true"),i(Wa,"tabindex","-1"),i(Wa,"href","#issues-to-look-for"),i(Ba,"id","issues-to-look-for"),ts(Ar.src,o9="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(Ar,"src",o9),i(Ar,"alt","image"),i(Ar,"class","svelte-1nszpqs"),i(Dr,"class","svelte-1nszpqs"),i(_v,"class","icon icon-link"),i(Fa,"aria-hidden","true"),i(Fa,"tabindex","-1"),i(Fa,"href","#troubleshooting"),i(ja,"id","troubleshooting"),i(Wu,"class","svelte-1nszpqs"),i(ju,"class","svelte-1nszpqs"),i(Vu,"class","svelte-1nszpqs"),i(Ku,"class","svelte-1nszpqs"),i(Yu,"class","svelte-1nszpqs"),i(bt,"class","svelte-1nszpqs"),i(Fu,"class","svelte-1nszpqs"),i(Xu,"class","svelte-1nszpqs"),i(Zu,"class","svelte-1nszpqs"),i(Qu,"class","svelte-1nszpqs"),i(yt,"class","svelte-1nszpqs"),i(Ju,"class","svelte-1nszpqs"),i($u,"class","svelte-1nszpqs"),i(ep,"class","svelte-1nszpqs"),i(kt,"class","svelte-1nszpqs"),i(tp,"class","svelte-1nszpqs"),i(sp,"class","svelte-1nszpqs"),i(ap,"class","svelte-1nszpqs"),i(wt,"class","svelte-1nszpqs"),i(lp,"class","svelte-1nszpqs"),i(rp,"class","svelte-1nszpqs"),i(ip,"class","svelte-1nszpqs"),i(zt,"class","svelte-1nszpqs"),i(qe,"class","svelte-1nszpqs"),i(Zt,"class","svelte-1nszpqs"),i(bv,"class","icon icon-link"),i(Ka,"aria-hidden","true"),i(Ka,"tabindex","-1"),i(Ka,"href","#more-solutions"),i(Va,"id","more-solutions"),i(cp,"class","svelte-1nszpqs"),i(up,"class","svelte-1nszpqs"),i(pp,"class","svelte-1nszpqs"),i(Tt,"class","svelte-1nszpqs"),i(op,"class","svelte-1nszpqs"),i(dp,"class","svelte-1nszpqs"),i(fp,"class","svelte-1nszpqs"),i(hp,"class","svelte-1nszpqs"),i(qt,"class","svelte-1nszpqs"),i(vp,"class","svelte-1nszpqs"),i(gp,"class","svelte-1nszpqs"),i(mp,"class","svelte-1nszpqs"),i(Rt,"class","svelte-1nszpqs"),i(_p,"class","svelte-1nszpqs"),i(Ep,"class","svelte-1nszpqs"),i(bp,"class","svelte-1nszpqs"),i(St,"class","svelte-1nszpqs"),i(yp,"class","svelte-1nszpqs"),i(kp,"class","svelte-1nszpqs"),i(wp,"class","svelte-1nszpqs"),i(Dt,"class","svelte-1nszpqs"),i(zp,"class","svelte-1nszpqs"),i(Tp,"class","svelte-1nszpqs"),i(qp,"class","svelte-1nszpqs"),i(At,"class","svelte-1nszpqs"),i(Rp,"class","svelte-1nszpqs"),i(Sp,"class","svelte-1nszpqs"),i(Dp,"class","svelte-1nszpqs"),i(Lt,"class","svelte-1nszpqs"),i(Ap,"class","svelte-1nszpqs"),i(Lp,"class","svelte-1nszpqs"),i(Ip,"class","svelte-1nszpqs"),i(It,"class","svelte-1nszpqs"),i(Op,"class","svelte-1nszpqs"),i(Pp,"class","svelte-1nszpqs"),i(xp,"class","svelte-1nszpqs"),i(Ot,"class","svelte-1nszpqs"),i(Np,"class","svelte-1nszpqs"),i(Cp,"class","svelte-1nszpqs"),i(Gp,"class","svelte-1nszpqs"),i(Pt,"class","svelte-1nszpqs"),i(Up,"class","svelte-1nszpqs"),i(Hp,"class","svelte-1nszpqs"),i(Mp,"class","svelte-1nszpqs"),i(xt,"class","svelte-1nszpqs"),i(W,"class","svelte-1nszpqs"),i(Qt,"class","svelte-1nszpqs"),i(yv,"class","icon icon-link"),i(Xa,"aria-hidden","true"),i(Xa,"tabindex","-1"),i(Xa,"href","#results"),i(Ya,"id","results"),ts(Pr.src,c9="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(Pr,"src",c9),i(Pr,"alt","image"),i(Pr,"class","svelte-1nszpqs"),i(Or,"class","svelte-1nszpqs"),i(kv,"class","icon icon-link"),i(Za,"aria-hidden","true"),i(Za,"tabindex","-1"),i(Za,"href","#spacelab"),i(Jt,"id","spacelab"),i(Jt,"class","svelte-1nszpqs")},m(s,d){p(s,f,d),e(f,g),p(s,v,d),p(s,h,d),e(h,m),p(s,E,d),p(s,y,d),e(y,z),e(z,T),e(y,k),p(s,b,d),p(s,w,d),e(w,L),p(s,x,d),p(s,C,d),e(C,S),p(s,D,d),p(s,R,d),e(R,O),e(O,P),e(R,Q),e(R,j),e(j,F),p(s,B,d),p(s,N,d),e(N,A),p(s,G,d),p(s,Z,d),e(Z,U),e(U,q),e(Z,H),p(s,ls,d),p(s,Le,d),e(Le,pe),p(s,Dv,d),p(s,Br,d),e(Br,H_),p(s,Av,d),p(s,rs,d),e(rs,is),e(is,Qd),e(rs,M_),p(s,Lv,d),p(s,Wr,d),e(Wr,B_),p(s,Iv,d),p(s,fl,d),e(fl,jr),e(jr,W_),p(s,Ov,d),Hr(hl,s,d),p(s,Pv,d),p(s,Fr,d),e(Fr,j_),p(s,xv,d),p(s,Vr,d),e(Vr,F_),p(s,Nv,d),p(s,Kr,d),e(Kr,V_),p(s,Cv,d),p(s,Ht,d),e(Ht,Yr),e(Yr,Ie),e(Ie,Xr),e(Xr,K_),e(Ie,Y_),e(Ie,Zr),e(Zr,X_),e(Ie,Z_),e(Ie,Qr),e(Qr,Q_),e(Ht,J_),e(Ht,Oe),e(Oe,Pe),e(Pe,Jr),e(Jr,Jd),e(Jd,$_),e(Pe,eE),e(Pe,$r),e($r,tE),e(Pe,sE),e(Pe,ei),e(ei,aE),e(Oe,lE),e(Oe,xe),e(xe,ti),e(ti,$d),e($d,rE),e(xe,iE),e(xe,si),e(si,nE),e(xe,oE),e(xe,ai),e(ai,cE),e(Oe,uE),e(Oe,Ne),e(Ne,li),e(li,ef),e(ef,pE),e(Ne,dE),e(Ne,ri),e(ri,fE),e(Ne,hE),e(Ne,ii),e(ii,vE),p(s,Gv,d),p(s,ni,d),e(ni,gE),p(s,Uv,d),p(s,oi,d),e(oi,mE),p(s,Hv,d),p(s,vl,d),e(vl,ci),e(ci,_E),p(s,Mv,d),p(s,ns,d),e(ns,os),e(os,tf),e(ns,EE),p(s,Bv,d),p(s,gl,d),e(gl,sf),e(sf,bE),e(gl,yE),p(s,Wv,d),p(s,ml,d),e(ml,af),e(af,kE),e(ml,wE),p(s,jv,d),p(s,_l,d),e(_l,lf),e(lf,zE),e(_l,TE),p(s,Fv,d),p(s,cs,d),e(cs,us),e(us,rf),e(cs,qE),p(s,Vv,d),p(s,El,d),e(El,nf),e(nf,RE),e(El,SE),p(s,Kv,d),p(s,bl,d),e(bl,of),e(of,DE),e(bl,AE),p(s,Yv,d),p(s,yl,d),e(yl,cf),e(cf,LE),e(yl,IE),p(s,Xv,d),p(s,ps,d),e(ps,ds),e(ds,uf),e(ps,OE),p(s,Zv,d),p(s,kl,d),e(kl,pf),e(pf,PE),e(kl,xE),p(s,Qv,d),p(s,Ce,d),e(Ce,NE),e(Ce,df),e(df,CE),e(Ce,GE),e(Ce,ff),e(ff,UE),e(Ce,HE),p(s,Jv,d),p(s,Ge,d),e(Ge,ui),e(ui,hf),e(hf,ME),e(ui,BE),e(Ge,WE),e(Ge,pi),e(pi,vf),e(vf,jE),e(pi,FE),e(Ge,VE),e(Ge,fs),e(fs,gf),e(gf,KE),e(fs,YE),e(fs,di),e(di,XE),e(fs,ZE),p(s,$v,d),p(s,wl,d),e(wl,fi),e(fi,QE),p(s,eg,d),p(s,hs,d),e(hs,vs),e(vs,mf),e(hs,_f),e(_f,JE),p(s,tg,d),p(s,hi,d),e(hi,$E),p(s,sg,d),p(s,Ue,d),e(Ue,vi),e(vi,Ef),e(Ef,e2),e(vi,t2),e(Ue,s2),e(Ue,gi),e(gi,bf),e(bf,a2),e(gi,l2),e(Ue,r2),e(Ue,mi),e(mi,yf),e(yf,i2),e(mi,n2),p(s,ag,d),p(s,gs,d),e(gs,ms),e(ms,kf),e(gs,wf),e(wf,o2),p(s,lg,d),p(s,Mt,d),e(Mt,_i),e(_i,He),e(He,Ei),e(Ei,zf),e(zf,c2),e(He,u2),e(He,bi),e(bi,Tf),e(Tf,p2),e(He,d2),e(He,yi),e(yi,qf),e(qf,f2),e(Mt,h2),e(Mt,de),e(de,Me),e(Me,ki),e(ki,Rf),e(Rf,v2),e(Me,g2),e(Me,wi),e(wi,m2),e(Me,_2),e(Me,zi),e(zi,E2),e(de,b2),e(de,Be),e(Be,Ti),e(Ti,Sf),e(Sf,y2),e(Be,k2),e(Be,qi),e(qi,w2),e(Be,z2),e(Be,Ri),e(Ri,T2),e(de,q2),e(de,We),e(We,Si),e(Si,Df),e(Df,R2),e(We,S2),e(We,Di),e(Di,D2),e(We,A2),e(We,Ai),e(Ai,L2),e(de,I2),e(de,je),e(je,Li),e(Li,Af),e(Af,O2),e(je,P2),e(je,Ii),e(Ii,x2),e(je,N2),e(je,Oi),e(Oi,C2),p(s,rg,d),p(s,_s,d),e(_s,Es),e(Es,Lf),e(_s,G2),p(s,ig,d),p(s,Bt,d),e(Bt,Pi),e(Pi,bs),e(bs,xi),e(xi,U2),e(bs,H2),e(bs,Ni),e(Ni,M2),e(Bt,B2),e(Bt,fe),e(fe,ys),e(ys,Ci),e(Ci,If),e(If,W2),e(ys,j2),e(ys,Gi),e(Gi,F2),e(fe,V2),e(fe,ks),e(ks,Ui),e(Ui,Of),e(Of,K2),e(ks,Y2),e(ks,Hi),e(Hi,X2),e(fe,Z2),e(fe,ws),e(ws,Mi),e(Mi,Pf),e(Pf,Q2),e(ws,J2),e(ws,Bi),e(Bi,$2),e(fe,eb),e(fe,zs),e(zs,Wi),e(Wi,xf),e(xf,tb),e(zs,sb),e(zs,ji),e(ji,ab),p(s,ng,d),p(s,Fi,d),e(Fi,lb),p(s,og,d),p(s,Ts,d),e(Ts,qs),e(qs,Nf),e(Ts,rb),p(s,cg,d),p(s,he,d),e(he,ib),e(he,Cf),e(Cf,nb),e(he,ob),e(he,Vi),e(Vi,cb),e(he,ub),e(he,Ki),e(Ki,pb),e(he,db),p(s,ug,d),p(s,ve,d),e(ve,fb),e(ve,Yi),e(Yi,hb),e(ve,vb),e(ve,Xi),e(Xi,gb),e(ve,mb),e(ve,Zi),e(Zi,_b),e(ve,Eb),p(s,pg,d),p(s,zl,d),zl.innerHTML=BP,p(s,dg,d),p(s,Tl,d),Tl.innerHTML=WP,p(s,fg,d),p(s,Rs,d),e(Rs,Ss),e(Ss,Gf),e(Rs,bb),p(s,hg,d),p(s,Wt,d),e(Wt,Qi),e(Qi,Fe),e(Fe,Ji),e(Ji,yb),e(Fe,kb),e(Fe,$i),e($i,wb),e(Fe,zb),e(Fe,en),e(en,Tb),e(Wt,qb),e(Wt,ge),e(ge,Ve),e(Ve,tn),e(tn,Rb),e(Ve,Sb),e(Ve,sn),e(sn,Db),e(Ve,Ab),e(Ve,an),e(an,Lb),e(ge,Ib),e(ge,Ke),e(Ke,ln),e(ln,Ob),e(Ke,Pb),e(Ke,rn),e(rn,xb),e(Ke,Nb),e(Ke,nn),e(nn,Cb),e(ge,Gb),e(ge,Ye),e(Ye,on),e(on,Ub),e(Ye,Hb),e(Ye,cn),e(cn,Mb),e(Ye,Bb),e(Ye,un),e(un,Wb),e(ge,jb),e(ge,Xe),e(Xe,pn),e(pn,Fb),e(Xe,Vb),e(Xe,dn),e(dn,Kb),e(Xe,Yb),e(Xe,fn),e(fn,Xb),p(s,vg,d),p(s,hn,d),e(hn,Zb),p(s,gg,d),p(s,vn,d),e(vn,Qb),p(s,mg,d),p(s,gn,d),e(gn,Jb),p(s,_g,d),p(s,Eg,d),p(s,bg,d),p(s,Ds,d),e(Ds,As),e(As,Uf),e(Ds,$b),p(s,yg,d),p(s,Ls,d),e(Ls,ey),e(Ls,ql),e(ql,ty),e(Ls,sy),p(s,kg,d),p(s,Is,d),e(Is,Os),e(Os,Hf),e(Is,ay),p(s,wg,d),p(s,Ps,d),e(Ps,ly),e(Ps,Rl),e(Rl,ry),e(Ps,iy),p(s,zg,d),p(s,Sl,d),Sl.innerHTML=jP,p(s,Tg,d),p(s,xs,d),e(xs,Ns),e(Ns,Mf),e(xs,ny),p(s,qg,d),p(s,Ze,d),e(Ze,Bf),e(Bf,oy),e(Ze,cy),e(Ze,Wf),e(Wf,uy),e(Ze,py),e(Ze,jf),e(jf,dy),p(s,Rg,d),p(s,Cs,d),e(Cs,Gs),e(Gs,Ff),e(Cs,fy),p(s,Sg,d),p(s,Qe,d),e(Qe,Vf),e(Vf,hy),e(Qe,vy),e(Qe,Kf),e(Kf,gy),e(Qe,my),e(Qe,Yf),e(Yf,_y),p(s,Dg,d),p(s,Us,d),e(Us,Hs),e(Hs,Xf),e(Us,Ey),p(s,Ag,d),p(s,Dl,d),e(Dl,Zf),e(Zf,by),e(Dl,yy),p(s,Lg,d),p(s,Al,d),Al.innerHTML=FP,p(s,Ig,d),p(s,Ms,d),e(Ms,Bs),e(Bs,Qf),e(Ms,ky),p(s,Og,d),p(s,Je,d),e(Je,Jf),e(Jf,wy),e(Je,zy),e(Je,$f),e($f,Ty),e(Je,qy),e(Je,eh),e(eh,Ry),p(s,Pg,d),p(s,Ll,d),e(Ll,mn),e(mn,Sy),p(s,xg,d),p(s,Ws,d),e(Ws,js),e(js,th),e(Ws,Dy),p(s,Ng,d),p(s,Il,d),e(Il,sh),e(sh,Ay),e(Il,Ly),p(s,Cg,d),p(s,_n,d),e(_n,Iy),p(s,Gg,d),p(s,$e,d),e($e,Ol),e(Ol,Oy),e(Ol,En),e(En,Py),e(Ol,xy),e($e,Ny),e($e,ah),e(ah,Cy),e($e,Gy),e($e,lh),e(lh,Uy),p(s,Ug,d),p(s,Pl,d),e(Pl,bn),e(bn,Hy),p(s,Hg,d),p(s,Fs,d),e(Fs,Vs),e(Vs,rh),e(Fs,My),p(s,Mg,d),p(s,xl,d),e(xl,ih),e(ih,By),e(xl,Wy),p(s,Bg,d),p(s,Nl,d),Nl.innerHTML=VP,p(s,Wg,d),p(s,yn,d),e(yn,jy),p(s,jg,d),p(s,et,d),e(et,nh),e(nh,Fy),e(et,Vy),e(et,oh),e(oh,Ky),e(et,Yy),e(et,ch),e(ch,Xy),p(s,Fg,d),p(s,Cl,d),e(Cl,kn),e(kn,Zy),p(s,Vg,d),p(s,Ks,d),e(Ks,Ys),e(Ys,uh),e(Ks,Qy),p(s,Kg,d),p(s,Xs,d),e(Xs,Jy),e(Xs,ph),e(ph,$y),e(Xs,e4),p(s,Yg,d),p(s,Gl,d),Gl.innerHTML=KP,p(s,Xg,d),p(s,jt,d),e(jt,wn),e(wn,tt),e(tt,zn),e(zn,t4),e(tt,s4),e(tt,Tn),e(Tn,a4),e(tt,l4),e(tt,qn),e(qn,r4),e(jt,i4),e(jt,st),e(st,at),e(at,Rn),e(Rn,Sn),e(Sn,n4),e(at,o4),e(at,Dn),e(Dn,c4),e(at,u4),e(at,An),e(An,p4),e(st,d4),e(st,lt),e(lt,Ln),e(Ln,In),e(In,f4),e(lt,h4),e(lt,On),e(On,v4),e(lt,g4),e(lt,Pn),e(Pn,m4),e(st,_4),e(st,rt),e(rt,xn),e(xn,Nn),e(Nn,E4),e(rt,b4),e(rt,Cn),e(Cn,y4),e(rt,k4),e(rt,Gn),e(Gn,w4),p(s,Zg,d),p(s,Zs,d),e(Zs,Qs),e(Qs,dh),e(Zs,z4),p(s,Qg,d),p(s,it,d),e(it,Ul),e(Ul,T4),e(Ul,Un),e(Un,q4),e(Ul,R4),e(it,S4),e(it,Re),e(Re,D4),e(Re,Hn),e(Hn,A4),e(Re,L4),e(Re,Mn),e(Mn,I4),e(Re,O4),e(Re,Bn),e(Bn,P4),e(Re,x4),e(it,N4),e(it,Ft),e(Ft,C4),e(Ft,Wn),e(Wn,G4),e(Ft,U4),e(Ft,jn),e(jn,H4),e(Ft,M4),p(s,Jg,d),p(s,Js,d),e(Js,$s),e($s,fh),e(Js,B4),p(s,$g,d),p(s,Fn,d),e(Fn,W4),p(s,em,d),p(s,Vn,d),e(Vn,ea),e(ea,hh),e(hh,j4),e(ea,F4),e(ea,Kn),e(Kn,V4),e(ea,K4),p(s,tm,d),p(s,ta,d),e(ta,sa),e(sa,vh),e(ta,Y4),p(s,sm,d),p(s,nt,d),e(nt,gh),e(gh,X4),e(nt,Z4),e(nt,mh),e(mh,Q4),e(nt,J4),e(nt,_h),e(_h,$4),p(s,am,d),p(s,Yn,d),e(Yn,e3),p(s,lm,d),p(s,aa,d),e(aa,la),e(la,Eh),e(aa,t3),p(s,rm,d),p(s,Xn,d),e(Xn,s3),p(s,im,d),p(s,ra,d),e(ra,Zn),e(Zn,bh),e(bh,a3),e(Zn,l3),e(ra,r3),e(ra,Hl),e(Hl,yh),e(yh,i3),e(Hl,n3),e(Hl,Vt),e(Vt,Qn),e(Qn,kh),e(kh,o3),e(Qn,c3),e(Vt,u3),e(Vt,Jn),e(Jn,wh),e(wh,p3),e(Jn,d3),e(Vt,f3),e(Vt,$n),e($n,zh),e(zh,h3),e($n,v3),p(s,nm,d),p(s,eo,d),e(eo,g3),p(s,om,d),p(s,ia,d),e(ia,to),e(to,Th),e(Th,m3),e(to,_3),e(ia,E3),e(ia,so),e(so,qh),e(qh,b3),e(so,y3),p(s,cm,d),p(s,ao,d),e(ao,k3),p(s,um,d),p(s,Ml,d),e(Ml,Rh),e(Rh,w3),e(Ml,z3),p(s,pm,d),p(s,ot,d),e(ot,Sh),e(Sh,T3),e(ot,q3),e(ot,Dh),e(Dh,R3),e(ot,S3),e(ot,Ah),e(Ah,D3),p(s,dm,d),p(s,Kt,d),e(Kt,lo),e(lo,me),e(me,ro),e(ro,A3),e(me,L3),e(me,io),e(io,I3),e(me,O3),e(me,no),e(no,P3),e(me,x3),e(me,oo),e(oo,N3),e(Kt,C3),e(Kt,le),e(le,_e),e(_e,co),e(co,G3),e(_e,U3),e(_e,uo),e(uo,H3),e(_e,M3),e(_e,po),e(po,B3),e(_e,W3),e(_e,fo),e(fo,j3),e(le,F3),e(le,Ee),e(Ee,ho),e(ho,V3),e(Ee,K3),e(Ee,vo),e(vo,Y3),e(Ee,X3),e(Ee,go),e(go,Z3),e(Ee,Q3),e(Ee,mo),e(mo,J3),e(le,$3),e(le,be),e(be,_o),e(_o,ek),e(be,tk),e(be,Eo),e(Eo,sk),e(be,ak),e(be,na),e(na,lk),e(na,Lh),e(Lh,rk),e(na,ik),e(be,nk),e(be,ct),e(ct,ok),e(ct,bo),e(bo,ck),e(ct,uk),e(ct,yo),e(yo,pk),e(ct,dk),e(le,fk),e(le,ye),e(ye,ko),e(ko,hk),e(ye,vk),e(ye,wo),e(wo,gk),e(ye,mk),e(ye,zo),e(zo,_k),e(ye,Ek),e(ye,To),e(To,bk),e(le,yk),e(le,ke),e(ke,qo),e(qo,kk),e(ke,wk),e(ke,Ro),e(Ro,zk),e(ke,Tk),e(ke,So),e(So,qk),e(ke,Rk),e(ke,Do),e(Do,Sk),p(s,fm,d),p(s,hm,d),p(s,vm,d),p(s,oa,d),e(oa,ca),e(ca,Ih),e(oa,Dk),p(s,gm,d),p(s,ua,d),e(ua,Ak),e(ua,Ao),e(Ao,Lk),e(ua,Ik),p(s,mm,d),p(s,ue,d),e(ue,Ok),e(ue,Lo),e(Lo,Pk),e(ue,xk),e(ue,Io),e(Io,Nk),e(ue,Ck),e(ue,Oo),e(Oo,Gk),e(ue,Uk),e(ue,Po),e(Po,Hk),p(s,_m,d),p(s,xo,d),e(xo,Mk),p(s,Em,d),p(s,pa,d),e(pa,da),e(da,Oh),e(pa,Bk),p(s,bm,d),p(s,ut,d),e(ut,Ph),e(Ph,Bl),e(Bl,xh),e(xh,Wk),e(Bl,jk),e(Bl,Fk),e(ut,Vk),e(ut,Nh),e(Nh,Wl),e(Wl,Ch),e(Ch,Kk),e(Wl,Yk),e(Wl,Xk),e(ut,Zk),e(ut,Gh),e(Gh,jl),e(jl,Uh),e(Uh,Qk),e(jl,Jk),e(jl,$k),p(s,ym,d),Hr(Fl,s,d),p(s,km,d),p(s,fa,d),e(fa,ha),e(ha,Hh),e(fa,e0),p(s,wm,d),p(s,va,d),e(va,t0),e(va,Vl),e(Vl,s0),e(va,a0),p(s,zm,d),p(s,pt,d),e(pt,l0),e(pt,No),e(No,r0),e(pt,i0),e(pt,Co),e(Co,n0),e(pt,o0),p(s,Tm,d),p(s,J,d),e(J,Mh),e(Mh,Go),e(Go,c0),e(Go,Uo),e(Uo,u0),e(J,p0),e(J,Bh),e(Bh,Kl),e(Kl,d0),e(Kl,Ho),e(Ho,f0),e(Kl,h0),e(J,v0),e(J,Wh),e(Wh,K),e(K,g0),e(K,Mo),e(Mo,m0),e(K,_0),e(K,Bo),e(Bo,E0),e(K,b0),e(K,Wo),e(Wo,y0),e(K,k0),e(K,jo),e(jo,w0),e(K,z0),e(K,Fo),e(Fo,T0),e(K,q0),e(K,Vo),e(Vo,R0),e(K,S0),e(K,Ko),e(Ko,D0),e(K,A0),e(K,Yo),e(Yo,L0),e(J,I0),e(J,jh),e(jh,$),e($,O0),e($,Xo),e(Xo,P0),e($,x0),e($,Zo),e(Zo,N0),e($,C0),e($,Qo),e(Qo,G0),e($,U0),e($,Jo),e(Jo,H0),e($,M0),e($,$o),e($o,B0),e($,W0),e($,ec),e(ec,j0),e($,F0),e($,tc),e(tc,V0),e(J,K0),e(J,Fh),e(Fh,Y),e(Y,Y0),e(Y,sc),e(sc,X0),e(Y,Z0),e(Y,ac),e(ac,Q0),e(Y,J0),e(Y,lc),e(lc,$0),e(Y,e5),e(Y,rc),e(rc,t5),e(Y,s5),e(Y,ic),e(ic,a5),e(Y,l5),e(Y,nc),e(nc,r5),e(Y,i5),e(Y,oc),e(oc,n5),e(Y,o5),e(Y,cc),e(cc,c5),e(J,u5),e(J,Vh),e(Vh,uc),e(uc,p5),e(uc,pc),e(pc,d5),e(J,f5),e(J,Kh),e(Kh,ga),e(ga,h5),e(ga,dc),e(dc,v5),e(ga,g5),e(ga,fc),e(fc,m5),p(s,qm,d),p(s,dt,d),e(dt,_5),e(dt,hc),e(hc,E5),e(dt,b5),e(dt,vc),e(vc,y5),e(dt,k5),p(s,Rm,d),Hr(Yl,s,d),p(s,Sm,d),p(s,ma,d),e(ma,_a),e(_a,Yh),e(ma,w5),p(s,Dm,d),p(s,gc,d),e(gc,z5),p(s,Am,d),p(s,we,d),e(we,mc),e(mc,Xl),e(Xl,T5),e(mc,q5),e(we,R5),e(we,_c),e(_c,Zl),e(Zl,S5),e(_c,D5),e(we,A5),e(we,Ec),e(Ec,Ql),e(Ql,L5),e(Ec,I5),e(we,O5),e(we,bc),e(bc,Jl),e(Jl,P5),e(bc,x5),p(s,Lm,d),p(s,Ea,d),e(Ea,ba),e(ba,Xh),e(Ea,N5),p(s,Im,d),p(s,yc,d),e(yc,C5),p(s,Om,d),p(s,kc,d),e(kc,G5),p(s,Pm,d),p(s,ft,d),e(ft,wc),e(wc,Zh),e(Zh,U5),e(wc,H5),e(ft,M5),e(ft,ht),e(ht,Qh),e(Qh,B5),e(ht,W5),e(ht,zc),e(zc,j5),e(ht,F5),e(ht,Tc),e(Tc,V5),e(ht,K5),e(ft,Y5),e(ft,qc),e(qc,Jh),e(Jh,X5),e(qc,Z5),p(s,xm,d),p(s,$l,d),$l.innerHTML=YP,p(s,Nm,d),p(s,ya,d),e(ya,er),e(er,Q5),e(er,Rc),e(Rc,J5),e(er,$5),e(ya,ew),e(ya,tr),e(tr,tw),e(tr,Sc),e(Sc,sw),e(tr,aw),p(s,Cm,d),p(s,ka,d),e(ka,$h),e($h,lw),e(ka,rw),e(ka,Dc),e(Dc,iw),p(s,Gm,d),p(s,wa,d),e(wa,za),e(za,ev),e(wa,nw),p(s,Um,d),p(s,vt,d),e(vt,ow),e(vt,sr),e(sr,cw),e(vt,uw),e(vt,ar),e(ar,pw),e(vt,dw),p(s,Hm,d),p(s,lr,d),e(lr,Ta),e(Ta,fw),e(Ta,rr),e(rr,hw),e(Ta,vw),p(s,Mm,d),p(s,ir,d),e(ir,Se),e(Se,gw),e(Se,nr),e(nr,mw),e(Se,_w),e(Se,or),e(or,Ew),e(Se,bw),e(Se,cr),e(cr,yw),p(s,Bm,d),p(s,qa,d),e(qa,Ra),e(Ra,tv),e(qa,kw),p(s,Wm,d),p(s,Sa,d),e(Sa,ww),e(Sa,Ac),e(Ac,zw),e(Sa,Tw),p(s,jm,d),p(s,ur,d),ur.innerHTML=XP,p(s,Fm,d),p(s,Lc,d),e(Lc,qw),p(s,Vm,d),p(s,pr,d),pr.innerHTML=ZP,p(s,Km,d),p(s,Da,d),e(Da,Rw),e(Da,Ic),e(Ic,Sw),e(Da,Dw),p(s,Ym,d),p(s,dr,d),e(dr,Aa),e(Aa,Aw),e(Aa,Oc),e(Oc,Lw),e(Aa,Iw),p(s,Xm,d),p(s,gt,d),e(gt,Ow),e(gt,Pc),e(Pc,Pw),e(gt,xw),e(gt,xc),e(xc,Nw),e(gt,Cw),p(s,Zm,d),p(s,Nc,d),e(Nc,Gw),p(s,Qm,d),p(s,La,d),e(La,Cc),e(Cc,Uw),e(Cc,sv),e(sv,av),e(av,Hw),e(La,Mw),e(La,Gc),e(Gc,Bw),e(Gc,lv),e(lv,rv),e(rv,Ww),p(s,Jm,d),p(s,Uc,d),e(Uc,jw),p(s,$m,d),p(s,fr,d),e(fr,hr),p(s,e1,d),p(s,Ia,d),e(Ia,Oa),e(Oa,iv),e(Ia,Fw),p(s,t1,d),p(s,Yt,d),e(Yt,Vw),e(Yt,Hc),e(Hc,Kw),e(Yt,Yw),e(Yt,Mc),e(Mc,Xw),p(s,s1,d),p(s,Xt,d),e(Xt,Bc),e(Bc,re),e(re,Wc),e(Wc,Zw),e(re,Qw),e(re,jc),e(jc,Jw),e(re,$w),e(re,Fc),e(Fc,ez),e(re,tz),e(re,Vc),e(Vc,sz),e(re,az),e(re,Kc),e(Kc,lz),e(Xt,rz),e(Xt,Yc),e(Yc,ie),e(ie,Xc),e(Xc,iz),e(ie,nz),e(ie,Zc),e(Zc,oz),e(ie,cz),e(ie,Qc),e(Qc,uz),e(ie,pz),e(ie,Jc),e(Jc,dz),e(ie,fz),e(ie,$c),e($c,hz),p(s,a1,d),p(s,eu,d),e(eu,vz),p(s,l1,d),p(s,vr,d),vr.innerHTML=QP,p(s,r1,d),p(s,M,d),e(M,tu),e(tu,gr),e(gr,gz),e(gr,su),e(su,mz),e(gr,_z),e(tu,Ez),e(M,bz),e(M,au),e(au,mr),e(mr,yz),e(mr,lu),e(lu,kz),e(mr,wz),e(au,zz),e(M,Tz),e(M,ru),e(ru,_r),e(_r,qz),e(_r,iu),e(iu,Rz),e(_r,Sz),e(ru,Dz),e(M,Az),e(M,nu),e(nu,Er),e(Er,Lz),e(Er,ou),e(ou,Iz),e(Er,Oz),e(nu,Pz),e(M,xz),e(M,cu),e(cu,nv),e(nv,Nz),e(cu,Cz),e(M,Gz),e(M,uu),e(uu,br),e(br,Uz),e(br,pu),e(pu,Hz),e(br,Mz),e(uu,Bz),e(M,Wz),e(M,du),e(du,yr),e(yr,jz),e(yr,fu),e(fu,Fz),e(yr,Vz),e(du,Kz),e(M,Yz),e(M,hu),e(hu,kr),e(kr,Xz),e(kr,vu),e(vu,Zz),e(kr,Qz),e(hu,Jz),e(M,$z),e(M,gu),e(gu,wr),e(wr,e6),e(wr,mu),e(mu,t6),e(wr,s6),e(gu,a6),e(M,l6),e(M,_u),e(_u,zr),e(zr,r6),e(zr,Eu),e(Eu,i6),e(zr,n6),e(_u,o6),e(M,c6),e(M,bu),e(bu,Tr),e(Tr,u6),e(Tr,yu),e(yu,p6),e(Tr,d6),e(bu,f6),p(s,i1,d),p(s,Pa,d),e(Pa,xa),e(xa,ov),e(Pa,h6),p(s,n1,d),p(s,ku,d),e(ku,v6),p(s,o1,d),Hr(qr,s,d),p(s,c1,d),p(s,Na,d),e(Na,Ca),e(Ca,cv),e(Na,g6),p(s,u1,d),p(s,Ga,d),e(Ga,m6),e(Ga,Rr),e(Rr,_6),e(Ga,E6),p(s,p1,d),p(s,Ua,d),e(Ua,b6),e(Ua,wu),e(wu,y6),e(Ua,k6),p(s,d1,d),p(s,ne,d),e(ne,zu),e(zu,w6),e(zu,f1),e(ne,z6),e(ne,uv),e(uv,T6),e(ne,q6),e(ne,mt),e(mt,R6),e(mt,Tu),e(Tu,S6),e(mt,D6),e(mt,qu),e(qu,A6),e(mt,L6),e(mt,Ru),e(Ru,I6),e(ne,O6),e(ne,Su),e(Su,P6),e(Su,Du),e(Du,x6),e(ne,N6),e(ne,Ha),e(Ha,C6),e(Ha,Au),e(Au,G6),e(Ha,U6),e(Ha,Lu),e(Lu,H6),p(s,h1,d),p(s,_t,d),e(_t,M6),e(_t,Iu),e(Iu,B6),e(_t,W6),e(_t,Ou),e(Ou,j6),e(_t,F6),p(s,v1,d),p(s,ze,d),e(ze,Ma),e(Ma,V6),e(Ma,Pu),e(Pu,K6),e(Ma,Y6),e(Ma,xu),e(xu,X6),e(ze,Z6),e(ze,Sr),e(Sr,Q6),e(Sr,Nu),e(Nu,J6),e(Sr,$6),e(ze,e8),e(ze,pv),e(pv,t8),e(ze,s8),e(ze,dv),e(dv,a8),p(s,g1,d),p(s,Ba,d),e(Ba,Wa),e(Wa,fv),e(Ba,l8),p(s,m1,d),p(s,Te,d),e(Te,Cu),e(Cu,hv),e(hv,r8),e(Cu,i8),e(Te,n8),e(Te,Gu),e(Gu,vv),e(vv,o8),e(Gu,c8),e(Te,u8),e(Te,Uu),e(Uu,gv),e(gv,p8),e(Uu,d8),e(Te,f8),e(Te,Hu),e(Hu,mv),e(mv,h8),e(Hu,v8),p(s,_1,d),p(s,Mu,d),e(Mu,g8),p(s,E1,d),p(s,Dr,d),e(Dr,Ar),p(s,b1,d),p(s,ja,d),e(ja,Fa),e(Fa,_v),e(ja,m8),p(s,y1,d),p(s,Bu,d),e(Bu,_8),p(s,k1,d),p(s,Et,d),e(Et,Lr),e(Lr,E8),e(Lr,Wu),e(Wu,b8),e(Lr,y8),e(Et,k8),e(Et,Ir),e(Ir,w8),e(Ir,ju),e(ju,z8),e(Ir,T8),e(Et,q8),e(Et,Ev),e(Ev,R8),p(s,w1,d),p(s,Zt,d),e(Zt,Fu),e(Fu,bt),e(bt,Vu),e(Vu,S8),e(bt,D8),e(bt,Ku),e(Ku,A8),e(bt,L8),e(bt,Yu),e(Yu,I8),e(Zt,O8),e(Zt,qe),e(qe,yt),e(yt,Xu),e(Xu,P8),e(yt,x8),e(yt,Zu),e(Zu,N8),e(yt,C8),e(yt,Qu),e(Qu,G8),e(qe,U8),e(qe,kt),e(kt,Ju),e(Ju,H8),e(kt,M8),e(kt,$u),e($u,B8),e(kt,W8),e(kt,ep),e(ep,j8),e(qe,F8),e(qe,wt),e(wt,tp),e(tp,V8),e(wt,K8),e(wt,sp),e(sp,Y8),e(wt,X8),e(wt,ap),e(ap,Z8),e(qe,Q8),e(qe,zt),e(zt,lp),e(lp,J8),e(zt,$8),e(zt,rp),e(rp,e7),e(zt,t7),e(zt,ip),e(ip,s7),p(s,z1,d),p(s,Va,d),e(Va,Ka),e(Ka,bv),e(Va,a7),p(s,T1,d),p(s,np,d),e(np,l7),p(s,q1,d),p(s,Qt,d),e(Qt,op),e(op,Tt),e(Tt,cp),e(cp,r7),e(Tt,i7),e(Tt,up),e(up,n7),e(Tt,o7),e(Tt,pp),e(pp,c7),e(Qt,u7),e(Qt,W),e(W,qt),e(qt,dp),e(dp,p7),e(qt,d7),e(qt,fp),e(fp,f7),e(qt,h7),e(qt,hp),e(hp,v7),e(W,g7),e(W,Rt),e(Rt,vp),e(vp,m7),e(Rt,_7),e(Rt,gp),e(gp,E7),e(Rt,b7),e(Rt,mp),e(mp,y7),e(W,k7),e(W,St),e(St,_p),e(_p,w7),e(St,z7),e(St,Ep),e(Ep,T7),e(St,q7),e(St,bp),e(bp,R7),e(W,S7),e(W,Dt),e(Dt,yp),e(yp,D7),e(Dt,A7),e(Dt,kp),e(kp,L7),e(Dt,I7),e(Dt,wp),e(wp,O7),e(W,P7),e(W,At),e(At,zp),e(zp,x7),e(At,N7),e(At,Tp),e(Tp,C7),e(At,G7),e(At,qp),e(qp,U7),e(W,H7),e(W,Lt),e(Lt,Rp),e(Rp,M7),e(Lt,B7),e(Lt,Sp),e(Sp,W7),e(Lt,j7),e(Lt,Dp),e(Dp,F7),e(W,V7),e(W,It),e(It,Ap),e(Ap,K7),e(It,Y7),e(It,Lp),e(Lp,X7),e(It,Z7),e(It,Ip),e(Ip,Q7),e(W,J7),e(W,Ot),e(Ot,Op),e(Op,$7),e(Ot,eT),e(Ot,Pp),e(Pp,tT),e(Ot,sT),e(Ot,xp),e(xp,aT),e(W,lT),e(W,Pt),e(Pt,Np),e(Np,rT),e(Pt,iT),e(Pt,Cp),e(Cp,nT),e(Pt,oT),e(Pt,Gp),e(Gp,cT),e(W,uT),e(W,xt),e(xt,Up),e(Up,pT),e(xt,dT),e(xt,Hp),e(Hp,fT),e(xt,hT),e(xt,Mp),e(Mp,vT),p(s,R1,d),p(s,Ya,d),e(Ya,Xa),e(Xa,yv),e(Ya,gT),p(s,S1,d),p(s,Bp,d),e(Bp,mT),p(s,D1,d),p(s,Wp,d),e(Wp,_T),p(s,A1,d),p(s,Or,d),e(Or,Pr),p(s,L1,d),p(s,jp,d),e(jp,ET),p(s,I1,d),p(s,Jt,d),e(Jt,Za),e(Za,kv),e(Jt,bT),p(s,O1,d),De&&De.m(s,d),p(s,P1,d),x1=!0},p(s,d){MP&&De.p(s,d)},i(s){x1||(ss(hl.$$.fragment,s),ss(Fl.$$.fragment,s),ss(Yl.$$.fragment,s),ss(qr.$$.fragment,s),ss(De),x1=!0)},o(s){as(hl.$$.fragment,s),as(Fl.$$.fragment,s),as(Yl.$$.fragment,s),as(qr.$$.fragment,s),as(De),x1=!1},d(s){s&&t(f),s&&t(v),s&&t(h),s&&t(E),s&&t(y),s&&t(b),s&&t(w),s&&t(x),s&&t(C),s&&t(D),s&&t(R),s&&t(B),s&&t(N),s&&t(G),s&&t(Z),s&&t(ls),s&&t(Le),s&&t(Dv),s&&t(Br),s&&t(Av),s&&t(rs),s&&t(Lv),s&&t(Wr),s&&t(Iv),s&&t(fl),s&&t(Ov),Mr(hl,s),s&&t(Pv),s&&t(Fr),s&&t(xv),s&&t(Vr),s&&t(Nv),s&&t(Kr),s&&t(Cv),s&&t(Ht),s&&t(Gv),s&&t(ni),s&&t(Uv),s&&t(oi),s&&t(Hv),s&&t(vl),s&&t(Mv),s&&t(ns),s&&t(Bv),s&&t(gl),s&&t(Wv),s&&t(ml),s&&t(jv),s&&t(_l),s&&t(Fv),s&&t(cs),s&&t(Vv),s&&t(El),s&&t(Kv),s&&t(bl),s&&t(Yv),s&&t(yl),s&&t(Xv),s&&t(ps),s&&t(Zv),s&&t(kl),s&&t(Qv),s&&t(Ce),s&&t(Jv),s&&t(Ge),s&&t($v),s&&t(wl),s&&t(eg),s&&t(hs),s&&t(tg),s&&t(hi),s&&t(sg),s&&t(Ue),s&&t(ag),s&&t(gs),s&&t(lg),s&&t(Mt),s&&t(rg),s&&t(_s),s&&t(ig),s&&t(Bt),s&&t(ng),s&&t(Fi),s&&t(og),s&&t(Ts),s&&t(cg),s&&t(he),s&&t(ug),s&&t(ve),s&&t(pg),s&&t(zl),s&&t(dg),s&&t(Tl),s&&t(fg),s&&t(Rs),s&&t(hg),s&&t(Wt),s&&t(vg),s&&t(hn),s&&t(gg),s&&t(vn),s&&t(mg),s&&t(gn),s&&t(_g),s&&t(Eg),s&&t(bg),s&&t(Ds),s&&t(yg),s&&t(Ls),s&&t(kg),s&&t(Is),s&&t(wg),s&&t(Ps),s&&t(zg),s&&t(Sl),s&&t(Tg),s&&t(xs),s&&t(qg),s&&t(Ze),s&&t(Rg),s&&t(Cs),s&&t(Sg),s&&t(Qe),s&&t(Dg),s&&t(Us),s&&t(Ag),s&&t(Dl),s&&t(Lg),s&&t(Al),s&&t(Ig),s&&t(Ms),s&&t(Og),s&&t(Je),s&&t(Pg),s&&t(Ll),s&&t(xg),s&&t(Ws),s&&t(Ng),s&&t(Il),s&&t(Cg),s&&t(_n),s&&t(Gg),s&&t($e),s&&t(Ug),s&&t(Pl),s&&t(Hg),s&&t(Fs),s&&t(Mg),s&&t(xl),s&&t(Bg),s&&t(Nl),s&&t(Wg),s&&t(yn),s&&t(jg),s&&t(et),s&&t(Fg),s&&t(Cl),s&&t(Vg),s&&t(Ks),s&&t(Kg),s&&t(Xs),s&&t(Yg),s&&t(Gl),s&&t(Xg),s&&t(jt),s&&t(Zg),s&&t(Zs),s&&t(Qg),s&&t(it),s&&t(Jg),s&&t(Js),s&&t($g),s&&t(Fn),s&&t(em),s&&t(Vn),s&&t(tm),s&&t(ta),s&&t(sm),s&&t(nt),s&&t(am),s&&t(Yn),s&&t(lm),s&&t(aa),s&&t(rm),s&&t(Xn),s&&t(im),s&&t(ra),s&&t(nm),s&&t(eo),s&&t(om),s&&t(ia),s&&t(cm),s&&t(ao),s&&t(um),s&&t(Ml),s&&t(pm),s&&t(ot),s&&t(dm),s&&t(Kt),s&&t(fm),s&&t(hm),s&&t(vm),s&&t(oa),s&&t(gm),s&&t(ua),s&&t(mm),s&&t(ue),s&&t(_m),s&&t(xo),s&&t(Em),s&&t(pa),s&&t(bm),s&&t(ut),s&&t(ym),Mr(Fl,s),s&&t(km),s&&t(fa),s&&t(wm),s&&t(va),s&&t(zm),s&&t(pt),s&&t(Tm),s&&t(J),s&&t(qm),s&&t(dt),s&&t(Rm),Mr(Yl,s),s&&t(Sm),s&&t(ma),s&&t(Dm),s&&t(gc),s&&t(Am),s&&t(we),s&&t(Lm),s&&t(Ea),s&&t(Im),s&&t(yc),s&&t(Om),s&&t(kc),s&&t(Pm),s&&t(ft),s&&t(xm),s&&t($l),s&&t(Nm),s&&t(ya),s&&t(Cm),s&&t(ka),s&&t(Gm),s&&t(wa),s&&t(Um),s&&t(vt),s&&t(Hm),s&&t(lr),s&&t(Mm),s&&t(ir),s&&t(Bm),s&&t(qa),s&&t(Wm),s&&t(Sa),s&&t(jm),s&&t(ur),s&&t(Fm),s&&t(Lc),s&&t(Vm),s&&t(pr),s&&t(Km),s&&t(Da),s&&t(Ym),s&&t(dr),s&&t(Xm),s&&t(gt),s&&t(Zm),s&&t(Nc),s&&t(Qm),s&&t(La),s&&t(Jm),s&&t(Uc),s&&t($m),s&&t(fr),s&&t(e1),s&&t(Ia),s&&t(t1),s&&t(Yt),s&&t(s1),s&&t(Xt),s&&t(a1),s&&t(eu),s&&t(l1),s&&t(vr),s&&t(r1),s&&t(M),s&&t(i1),s&&t(Pa),s&&t(n1),s&&t(ku),s&&t(o1),Mr(qr,s),s&&t(c1),s&&t(Na),s&&t(u1),s&&t(Ga),s&&t(p1),s&&t(Ua),s&&t(d1),s&&t(ne),s&&t(h1),s&&t(_t),s&&t(v1),s&&t(ze),s&&t(g1),s&&t(Ba),s&&t(m1),s&&t(Te),s&&t(_1),s&&t(Mu),s&&t(E1),s&&t(Dr),s&&t(b1),s&&t(ja),s&&t(y1),s&&t(Bu),s&&t(k1),s&&t(Et),s&&t(w1),s&&t(Zt),s&&t(z1),s&&t(Va),s&&t(T1),s&&t(np),s&&t(q1),s&&t(Qt),s&&t(R1),s&&t(Ya),s&&t(S1),s&&t(Bp),s&&t(D1),s&&t(Wp),s&&t(A1),s&&t(Or),s&&t(L1),s&&t(jp),s&&t(I1),s&&t(Jt),s&&t(O1),De&&De.d(s),s&&t(P1)}}}function Wx(_){let f,g;const v=[_[0],i9];let h={$$slots:{default:[Bx]},$$scope:{ctx:_}};for(let m=0;m<v.length;m+=1)h=r9(h,v[m]);return f=new vx({props:h}),{c(){Gr(f.$$.fragment)},l(m){Ur(f.$$.fragment,m)},m(m,E){Hr(f,m,E),g=!0},p(m,[E]){const y=E&1?hx(v,[E&1&&PP(m[0]),E&0&&PP(i9)]):{};E&2&&(y.$$scope={dirty:E,ctx:m}),f.$set(y)},i(m){g||(ss(f.$$.fragment,m),g=!0)},o(m){as(f.$$.fragment,m),g=!1},d(m){Mr(f,m)}}}const i9={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-31 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!1,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Monitoring",icon:"\u{1F4C9}",url:"/blog/action-figure-art/#monitoring-tips"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:sN,date:aN,modifiedDate:lN,categories:rN,svg:iN,seoImage:nN,shortDescription:oN,author:cN,spacelab:MP,id:jx,spacelabDefaultTitle:Fx,spacelabDefaultContent:Vx,menu:uN,keywords:pN}=i9;function Kx(_,f,g){return _.$$set=v=>{g(0,f=r9(r9({},f),xP(v)))},f=xP(f),[f]}class dN extends C_{constructor(f){super(),G_(this,f,Kx,Wx,U_,{})}}export{dN as default,i9 as metadata};
