import{S as vp,i as _p,s as bp,l as rc,g as f,E as X3,d as t,v as u0,e as s,t as o,c as l,a as i,h as n,b as r,G as e,j as ce,k as c,m as u,F as ee,H as Ee,N as j5,Y as f0,J as js,f as wt,Z as d0,_ as p0,$ as h0,q as pt,o as ht,O as m0,w as Ua,x as Ma,y as Ba,B as ja,C as Z3,z as g0,A as W5,a1 as F5}from"../../chunks/index-2a82a4a8.js";import{P as v0}from"../../chunks/_post-913f18eb.js";import{g as W3}from"../../chunks/config-201c2df4.js";import{a as F3}from"../../chunks/accountStore-3492c591.js";import{R as _0}from"../../chunks/ResponsivePicture-526d3695.js";import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function b0(_){let d,g,m,h,v,b,y,R,D,k,E,w,z,L,P,q,S,O;function A(I,H){return typeof I[2].title!="undefined"?k0:y0}let N=A(_),C=N(_);function Q(I,H){return typeof I[2].description!="undefined"?T0:w0}let W=Q(_),F=W(_),B=typeof _[2].list_description!="undefined"&&Y5(_),x=typeof _[2].footer_description!="undefined"&&X5(_);return{c(){d=s("hr"),g=c(),m=s("div"),C.c(),h=c(),v=s("p"),b=s("ion-icon"),y=o("SpaceLab Content"),R=c(),F.c(),D=c(),B&&B.c(),k=c(),x&&x.c(),E=c(),w=s("button"),z=s("ion-icon"),L=c(),P=s("span"),q=o("SpaceLab"),this.h()},l(I){d=l(I,"HR",{}),g=u(I),m=l(I,"DIV",{class:!0});var H=i(m);C.l(H),h=u(H),v=l(H,"P",{class:!0});var X=i(v);b=l(X,"ION-ICON",{class:!0,name:!0}),i(b).forEach(t),y=n(X,"SpaceLab Content"),X.forEach(t),R=u(H),F.l(H),D=u(H),B&&B.l(H),k=u(H),x&&x.l(H),E=u(H),w=l(H,"BUTTON",{class:!0});var U=i(w);z=l(U,"ION-ICON",{class:!0,name:!0}),i(z).forEach(t),L=u(U),P=l(U,"SPAN",{});var T=i(P);q=n(T,"SpaceLab"),T.forEach(t),U.forEach(t),H.forEach(t),this.h()},h(){ee(b,"class","icon svelte-s12rf8"),ee(b,"name","lock-closed"),r(v,"class","highlight large svelte-s12rf8"),ee(z,"class","icon svelte-s12rf8"),ee(z,"name","planet"),r(w,"class","button subscribe svelte-s12rf8"),r(m,"class","subscribe svelte-s12rf8")},m(I,H){f(I,d,H),f(I,g,H),f(I,m,H),C.m(m,null),e(m,h),e(m,v),e(v,b),e(v,y),e(m,R),F.m(m,null),e(m,D),B&&B.m(m,null),e(m,k),x&&x.m(m,null),e(m,E),e(m,w),e(w,z),e(w,L),e(w,P),e(P,q),S||(O=Ee(w,"click",_[15]),S=!0)},p(I,H){N===(N=A(I))&&C?C.p(I,H):(C.d(1),C=N(I),C&&(C.c(),C.m(m,h))),W===(W=Q(I))&&F?F.p(I,H):(F.d(1),F=W(I),F&&(F.c(),F.m(m,D))),typeof I[2].list_description!="undefined"?B?B.p(I,H):(B=Y5(I),B.c(),B.m(m,k)):B&&(B.d(1),B=null),typeof I[2].footer_description!="undefined"?x?x.p(I,H):(x=X5(I),x.c(),x.m(m,E)):x&&(x.d(1),x=null)},d(I){I&&t(d),I&&t(g),I&&t(m),C.d(),F.d(),B&&B.d(),x&&x.d(),S=!1,O()}}}function E0(_){let d,g,m,h=_[2].title+"",v,b,y,R,D,k,E,w=_[2].description+"",z,L,P,q,S,O,A,N,C,Q,W,F,B,x=typeof _[2].list_description!="undefined"&&Z5(_),I=typeof _[2].footer_description!="undefined"&&K5(_);function H(T,G){if(T[2].github_private_repo&&T[2].github_state==="LOG_EXISTS")return S0;if(T[2].github_private_repo&&T[2].github_state==="NO_LOGS")return D0;if(T[2].github_private_repo&&T[2].github_state==="NO_GITHUB_USERNAME")return R0}let X=H(_),U=X&&X(_);return{c(){d=s("hr"),g=c(),m=s("h2"),v=o(h),b=c(),y=s("p"),R=s("ion-icon"),D=o("SpaceLab Content"),k=c(),E=s("p"),z=o(w),L=c(),x&&x.c(),P=c(),I&&I.c(),q=c(),S=s("button"),O=s("ion-icon"),A=c(),N=s("span"),C=o("Download"),Q=c(),U&&U.c(),W=rc(),this.h()},l(T){d=l(T,"HR",{}),g=u(T),m=l(T,"H2",{class:!0});var G=i(m);v=n(G,h),G.forEach(t),b=u(T),y=l(T,"P",{class:!0});var Wa=i(y);R=l(Wa,"ION-ICON",{class:!0,name:!0}),i(R).forEach(t),D=n(Wa,"SpaceLab Content"),Wa.forEach(t),k=u(T),E=l(T,"P",{class:!0});var Ws=i(E);z=n(Ws,w),Ws.forEach(t),L=u(T),x&&x.l(T),P=u(T),I&&I.l(T),q=u(T),S=l(T,"BUTTON",{class:!0});var _e=i(S);O=l(_e,"ION-ICON",{class:!0,name:!0}),i(O).forEach(t),A=u(_e),N=l(_e,"SPAN",{});var Fs=i(N);C=n(Fs,"Download"),Fs.forEach(t),_e.forEach(t),Q=u(T),U&&U.l(T),W=rc(),this.h()},h(){r(m,"class","svelte-s12rf8"),ee(R,"class","icon svelte-s12rf8"),ee(R,"name","planet-sharp"),r(y,"class","highlight large svelte-s12rf8"),r(E,"class","svelte-s12rf8"),ee(O,"class","icon svelte-s12rf8"),ee(O,"name","cloud-download"),r(S,"class","button svelte-s12rf8")},m(T,G){f(T,d,G),f(T,g,G),f(T,m,G),e(m,v),f(T,b,G),f(T,y,G),e(y,R),e(y,D),f(T,k,G),f(T,E,G),e(E,z),f(T,L,G),x&&x.m(T,G),f(T,P,G),I&&I.m(T,G),f(T,q,G),f(T,S,G),e(S,O),e(S,A),e(S,N),e(N,C),f(T,Q,G),U&&U.m(T,G),f(T,W,G),F||(B=Ee(S,"click",_[10]),F=!0)},p(T,G){G&4&&h!==(h=T[2].title+"")&&ce(v,h),G&4&&w!==(w=T[2].description+"")&&ce(z,w),typeof T[2].list_description!="undefined"?x?x.p(T,G):(x=Z5(T),x.c(),x.m(P.parentNode,P)):x&&(x.d(1),x=null),typeof T[2].footer_description!="undefined"?I?I.p(T,G):(I=K5(T),I.c(),I.m(q.parentNode,q)):I&&(I.d(1),I=null),X===(X=H(T))&&U?U.p(T,G):(U&&U.d(1),U=X&&X(T),U&&(U.c(),U.m(W.parentNode,W)))},d(T){T&&t(d),T&&t(g),T&&t(m),T&&t(b),T&&t(y),T&&t(k),T&&t(E),T&&t(L),x&&x.d(T),T&&t(P),I&&I.d(T),T&&t(q),T&&t(S),T&&t(Q),U&&U.d(T),T&&t(W),F=!1,B()}}}function y0(_){let d,g;return{c(){d=s("h2"),g=o(_[0]),this.h()},l(m){d=l(m,"H2",{class:!0});var h=i(d);g=n(h,_[0]),h.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(m,h){f(m,d,h),e(d,g)},p(m,h){h&1&&ce(g,m[0])},d(m){m&&t(d)}}}function k0(_){let d,g=_[2].title+"",m;return{c(){d=s("h2"),m=o(g),this.h()},l(h){d=l(h,"H2",{class:!0});var v=i(d);m=n(v,g),v.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,m)},p(h,v){v&4&&g!==(g=h[2].title+"")&&ce(m,g)},d(h){h&&t(d)}}}function w0(_){let d,g;return{c(){d=s("p"),g=o(_[1]),this.h()},l(m){d=l(m,"P",{class:!0});var h=i(d);g=n(h,_[1]),h.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(m,h){f(m,d,h),e(d,g)},p(m,h){h&2&&ce(g,m[1])},d(m){m&&t(d)}}}function T0(_){let d,g=_[2].description+"",m;return{c(){d=s("p"),m=o(g),this.h()},l(h){d=l(h,"P",{class:!0});var v=i(d);m=n(v,g),v.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,m)},p(h,v){v&4&&g!==(g=h[2].description+"")&&ce(m,g)},d(h){h&&t(d)}}}function Y5(_){let d,g,m=_[2].list_description+"",h;return{c(){d=s("div"),g=s("p"),h=o(m),this.h()},l(v){d=l(v,"DIV",{class:!0});var b=i(d);g=l(b,"P",{class:!0});var y=i(g);h=n(y,m),y.forEach(t),b.forEach(t),this.h()},h(){r(g,"class","svelte-s12rf8"),r(d,"class","list-description svelte-s12rf8")},m(v,b){f(v,d,b),e(d,g),e(g,h)},p(v,b){b&4&&m!==(m=v[2].list_description+"")&&ce(h,m)},d(v){v&&t(d)}}}function X5(_){let d,g=_[2].footer_description+"",m;return{c(){d=s("p"),m=o(g),this.h()},l(h){d=l(h,"P",{class:!0});var v=i(d);m=n(v,g),v.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,m)},p(h,v){v&4&&g!==(g=h[2].footer_description+"")&&ce(m,g)},d(h){h&&t(d)}}}function Z5(_){let d,g,m=_[2].list_description+"",h;return{c(){d=s("div"),g=s("p"),h=o(m),this.h()},l(v){d=l(v,"DIV",{class:!0});var b=i(d);g=l(b,"P",{class:!0});var y=i(g);h=n(y,m),y.forEach(t),b.forEach(t),this.h()},h(){r(g,"class","svelte-s12rf8"),r(d,"class","list-description svelte-s12rf8")},m(v,b){f(v,d,b),e(d,g),e(g,h)},p(v,b){b&4&&m!==(m=v[2].list_description+"")&&ce(h,m)},d(v){v&&t(d)}}}function K5(_){let d,g=_[2].footer_description+"",m;return{c(){d=s("p"),m=o(g),this.h()},l(h){d=l(h,"P",{class:!0});var v=i(d);m=n(v,g),v.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(h,v){f(h,d,v),e(d,m)},p(h,v){v&4&&g!==(g=h[2].footer_description+"")&&ce(m,g)},d(h){h&&t(d)}}}function R0(_){let d,g,m,h,v,b;function y(k,E){return k[5]?O0:A0}let R=y(_),D=R(_);return{c(){d=s("h2"),g=o("Private GitHub Access"),m=c(),h=s("form"),D.c(),this.h()},l(k){d=l(k,"H2",{class:!0});var E=i(d);g=n(E,"Private GitHub Access"),E.forEach(t),m=u(k),h=l(k,"FORM",{class:!0});var w=i(h);D.l(w),w.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8"),r(h,"class","request-permission svelte-s12rf8")},m(k,E){f(k,d,E),e(d,g),f(k,m,E),f(k,h,E),D.m(h,null),v||(b=Ee(h,"submit",_[8]),v=!0)},p(k,E){R===(R=y(k))&&D?D.p(k,E):(D.d(1),D=R(k),D&&(D.c(),D.m(h,null)))},d(k){k&&t(d),k&&t(m),k&&t(h),D.d(),v=!1,b()}}}function D0(_){let d,g,m,h,v,b;function y(k,E){return k[5]?I0:L0}let R=y(_),D=R(_);return{c(){d=s("h2"),g=o("Private GitHub Access"),m=c(),h=s("form"),D.c(),this.h()},l(k){d=l(k,"H2",{class:!0});var E=i(d);g=n(E,"Private GitHub Access"),E.forEach(t),m=u(k),h=l(k,"FORM",{});var w=i(h);D.l(w),w.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8")},m(k,E){f(k,d,E),e(d,g),f(k,m,E),f(k,h,E),D.m(h,null),v||(b=Ee(h,"submit",_[7]),v=!0)},p(k,E){R===(R=y(k))&&D?D.p(k,E):(D.d(1),D=R(k),D&&(D.c(),D.m(h,null)))},d(k){k&&t(d),k&&t(m),k&&t(h),D.d(),v=!1,b()}}}function S0(_){var O;let d,g,m,h,v,b,y=((O=_[6].profile)==null?void 0:O.githubUsername)+"",R,D,k,E,w,z,L,P,q,S;return{c(){d=s("h2"),g=o("Private GitHub Access"),m=c(),h=s("p"),v=o("Your GitHub account "),b=s("span"),R=o(y),D=o(` is
			linked to this content.`),k=c(),E=s("button"),w=s("ion-icon"),z=c(),L=s("span"),P=o("Open Repository"),this.h()},l(A){d=l(A,"H2",{class:!0});var N=i(d);g=n(N,"Private GitHub Access"),N.forEach(t),m=u(A),h=l(A,"P",{class:!0});var C=i(h);v=n(C,"Your GitHub account "),b=l(C,"SPAN",{class:!0});var Q=i(b);R=n(Q,y),Q.forEach(t),D=n(C,` is
			linked to this content.`),C.forEach(t),k=u(A),E=l(A,"BUTTON",{class:!0});var W=i(E);w=l(W,"ION-ICON",{class:!0,name:!0}),i(w).forEach(t),z=u(W),L=l(W,"SPAN",{});var F=i(L);P=n(F,"Open Repository"),F.forEach(t),W.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8"),r(b,"class","highlight svelte-s12rf8"),r(h,"class","svelte-s12rf8"),ee(w,"class","icon svelte-s12rf8"),ee(w,"name","rocket-sharp"),r(E,"class","svelte-s12rf8")},m(A,N){f(A,d,N),e(d,g),f(A,m,N),f(A,h,N),e(h,v),e(h,b),e(b,R),e(h,D),f(A,k,N),f(A,E,N),e(E,w),e(E,z),e(E,L),e(L,P),q||(S=Ee(E,"click",_[11]),q=!0)},p(A,N){var C;N&64&&y!==(y=((C=A[6].profile)==null?void 0:C.githubUsername)+"")&&ce(R,y)},d(A){A&&t(d),A&&t(m),A&&t(h),A&&t(k),A&&t(E),q=!1,S()}}}function A0(_){let d,g,m,h,v,b,y,R,D,k,E,w,z,L,P,q;return{c(){d=s("p"),g=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),m=c(),h=s("label"),v=o("Github username:"),b=c(),y=s("input"),D=c(),k=s("button"),E=s("ion-icon"),w=c(),z=s("span"),L=o("Request Permission"),this.h()},l(S){d=l(S,"P",{class:!0});var O=i(d);g=n(O,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),O.forEach(t),m=u(S),h=l(S,"LABEL",{for:!0});var A=i(h);v=n(A,"Github username:"),A.forEach(t),b=u(S),y=l(S,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),D=u(S),k=l(S,"BUTTON",{class:!0});var N=i(k);E=l(N,"ION-ICON",{class:!0,name:!0}),i(E).forEach(t),w=u(N),z=l(N,"SPAN",{});var C=i(z);L=n(C,"Request Permission"),C.forEach(t),N.forEach(t),this.h()},h(){r(d,"class","svelte-s12rf8"),r(h,"for","username"),r(y,"name","username"),r(y,"id","username"),r(y,"placeholder","enter a username"),r(y,"type","text"),y.required="true",r(y,"class",R=_[4]?"validation-error":""),ee(E,"class","icon svelte-s12rf8"),ee(E,"name","rocket-sharp"),r(k,"class","svelte-s12rf8")},m(S,O){f(S,d,O),e(d,g),f(S,m,O),f(S,h,O),e(h,v),f(S,b,O),f(S,y,O),j5(y,_[3]),f(S,D,O),f(S,k,O),e(k,E),e(k,w),e(k,z),e(z,L),P||(q=Ee(y,"input",_[14]),P=!0)},p(S,O){O&16&&R!==(R=S[4]?"validation-error":"")&&r(y,"class",R),O&8&&y.value!==S[3]&&j5(y,S[3])},d(S){S&&t(d),S&&t(m),S&&t(h),S&&t(b),S&&t(y),S&&t(D),S&&t(k),P=!1,q()}}}function O0(_){let d,g,m,h,v,b,y,R,D,k;return{c(){d=s("p"),g=o(_[5]),m=c(),h=s("button"),v=s("ion-icon"),b=c(),y=s("span"),R=o("Open Repository"),this.h()},l(E){d=l(E,"P",{class:!0});var w=i(d);g=n(w,_[5]),w.forEach(t),m=u(E),h=l(E,"BUTTON",{class:!0});var z=i(h);v=l(z,"ION-ICON",{class:!0,name:!0}),i(v).forEach(t),b=u(z),y=l(z,"SPAN",{});var L=i(y);R=n(L,"Open Repository"),L.forEach(t),z.forEach(t),this.h()},h(){r(d,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),r(h,"class","svelte-s12rf8")},m(E,w){f(E,d,w),e(d,g),f(E,m,w),f(E,h,w),e(h,v),e(h,b),e(h,y),e(y,R),D||(k=Ee(h,"click",_[13]),D=!0)},p(E,w){w&32&&ce(g,E[5])},d(E){E&&t(d),E&&t(m),E&&t(h),D=!1,k()}}}function L0(_){var z;let d,g,m,h=((z=_[6].profile)==null?void 0:z.githubUsername)+"",v,b,y,R,D,k,E,w;return{c(){d=s("p"),g=o("This content can grant access to a private GitHub repository. Allow "),m=s("span"),v=o(h),b=o(" access to this repo?"),y=c(),R=s("button"),D=s("ion-icon"),k=c(),E=s("span"),w=o("Request Permission"),this.h()},l(L){d=l(L,"P",{class:!0});var P=i(d);g=n(P,"This content can grant access to a private GitHub repository. Allow "),m=l(P,"SPAN",{class:!0});var q=i(m);v=n(q,h),q.forEach(t),b=n(P," access to this repo?"),P.forEach(t),y=u(L),R=l(L,"BUTTON",{class:!0});var S=i(R);D=l(S,"ION-ICON",{class:!0,name:!0}),i(D).forEach(t),k=u(S),E=l(S,"SPAN",{});var O=i(E);w=n(O,"Request Permission"),O.forEach(t),S.forEach(t),this.h()},h(){r(m,"class","highlight svelte-s12rf8"),r(d,"class","svelte-s12rf8"),ee(D,"class","icon svelte-s12rf8"),ee(D,"name","rocket-sharp"),r(R,"class","svelte-s12rf8")},m(L,P){f(L,d,P),e(d,g),e(d,m),e(m,v),e(d,b),f(L,y,P),f(L,R,P),e(R,D),e(R,k),e(R,E),e(E,w)},p(L,P){var q;P&64&&h!==(h=((q=L[6].profile)==null?void 0:q.githubUsername)+"")&&ce(v,h)},d(L){L&&t(d),L&&t(y),L&&t(R)}}}function I0(_){let d,g,m,h,v,b,y,R,D,k;return{c(){d=s("p"),g=o(_[5]),m=c(),h=s("button"),v=s("ion-icon"),b=c(),y=s("span"),R=o("Open Repository"),this.h()},l(E){d=l(E,"P",{class:!0});var w=i(d);g=n(w,_[5]),w.forEach(t),m=u(E),h=l(E,"BUTTON",{class:!0});var z=i(h);v=l(z,"ION-ICON",{class:!0,name:!0}),i(v).forEach(t),b=u(z),y=l(z,"SPAN",{});var L=i(y);R=n(L,"Open Repository"),L.forEach(t),z.forEach(t),this.h()},h(){r(d,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),r(h,"class","svelte-s12rf8")},m(E,w){f(E,d,w),e(d,g),f(E,m,w),f(E,h,w),e(h,v),e(h,b),e(h,y),e(y,R),D||(k=Ee(h,"click",_[12]),D=!0)},p(E,w){w&32&&ce(g,E[5])},d(E){E&&t(d),E&&t(m),E&&t(h),D=!1,k()}}}function z0(_){let d;function g(v,b){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?E0:b0}let m=g(_),h=m(_);return{c(){h.c(),d=rc()},l(v){h.l(v),d=rc()},m(v,b){h.m(v,b),f(v,d,b)},p(v,[b]){m===(m=g(v))&&h?h.p(v,b):(h.d(1),h=m(v),h&&(h.c(),h.m(d.parentNode,d)))},i:X3,o:X3,d(v){h.d(v),v&&t(d)}}}function Y3(_){window.open(_,"_blank")||window.location.replace(_)}function P0(_,d,g){let{id:m}=d,{spacelabDefaultTitle:h="Spacelab Content"}=d,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=d,b={},y="",R=!1,D="",k;F3.subscribe(A=>{g(6,k=A)}),u0(async()=>{if(typeof(k==null?void 0:k.token)!="undefined"){const A=await fetch(`${W3().serviceUrl}/education/spacelab/${m}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors"});if(A.status===401){F3.set({}),F3.deleteLocalStorage();return}let N=await A.json();g(2,b=N)}else g(2,b.success=!1,b)});async function E(A){A.preventDefault();const N={};try{const C=await fetch(`${W3().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(N)});if(C.ok)g(5,D="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await C.json();g(5,D=Q.message||"An error occurred while requesting access. Please try again.")}}catch(C){console.error("Error while sending GitHub access request:",C),g(5,D="An unexpected error occurred. Please try again later.")}}async function w(A){if(A.preventDefault(),!y.trim()){g(4,R=!0),g(5,D="Please enter a valid GitHub username.");return}g(4,R=!1);const N={github_username:y};try{const C=await fetch(`${W3().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+k.token},mode:"cors",body:JSON.stringify(N)});if(C.ok)g(5,D="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await C.json();g(5,D=Q.message||"An error occurred while requesting access. Please try again.")}}catch(C){console.error("Error while sending GitHub access request:",C),g(5,D="An unexpected error occurred. Please try again later.")}}const z=()=>window.open(b.url,"_blank"),L=()=>Y3(`https://github.com/${b.github_repo_name}`),P=()=>Y3(`https://github.com/${b.github_repo_name}`),q=()=>Y3(`https://github.com/${b.github_repo_name}`);function S(){y=this.value,g(3,y)}const O=()=>window.open("/spacelab/","_blank");return _.$$set=A=>{"id"in A&&g(9,m=A.id),"spacelabDefaultTitle"in A&&g(0,h=A.spacelabDefaultTitle),"spacelabDefaultContent"in A&&g(1,v=A.spacelabDefaultContent)},[h,v,b,y,R,D,k,E,w,m,z,L,P,q,S,O]}class N0 extends vp{constructor(d){super(),_p(this,d,P0,z0,bp,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const C0=_=>({}),V5=_=>({});function x0(_){let d;return{c(){d=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(g){d=n(g,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(g,m){f(g,d,m)},d(g){g&&t(d)}}}function q0(_){let d,g,m,h,v,b,y,R,D,k,E,w,z,L;const P=_[7]["slider-label"],q=f0(P,_,_[6],V5),S=q||x0();return{c(){d=s("div"),g=s("img"),h=c(),v=s("img"),y=c(),R=s("label"),D=s("span"),S&&S.c(),k=c(),E=s("input"),this.h()},l(O){d=l(O,"DIV",{class:!0,style:!0,"data-testid":!0});var A=i(d);g=l(A,"IMG",{src:!0,alt:!0,class:!0}),h=u(A),v=l(A,"IMG",{src:!0,alt:!0,class:!0}),y=u(A),R=l(A,"LABEL",{class:!0});var N=i(R);D=l(N,"SPAN",{class:!0});var C=i(D);S&&S.l(C),C.forEach(t),k=u(N),E=l(N,"INPUT",{type:!0,min:!0,max:!0,class:!0}),N.forEach(t),A.forEach(t),this.h()},h(){js(g.src,m=_[0])||r(g,"src",m),r(g,"alt",_[1]),r(g,"class","left-img svelte-1po6qlg"),js(v.src,b=_[2])||r(v,"src",b),r(v,"alt",_[3]),r(v,"class","right-img svelte-1po6qlg"),r(D,"class","visually-hidden svelte-1po6qlg"),r(E,"type","range"),r(E,"min","0"),r(E,"max","100"),E.value=_[4],r(E,"class","svelte-1po6qlg"),r(R,"class","svelte-1po6qlg"),r(d,"class","svelte-compare-image-container svelte-1po6qlg"),wt(d,"--slider-position",_[4]+"%"),r(d,"data-testid","svelte-compare-image")},m(O,A){f(O,d,A),e(d,g),e(d,h),e(d,v),e(d,y),e(d,R),e(R,D),S&&S.m(D,null),e(R,k),e(R,E),w=!0,z||(L=[Ee(E,"input",_[5]),Ee(E,"change",_[5]),Ee(E,"click",G0)],z=!0)},p(O,[A]){(!w||A&1&&!js(g.src,m=O[0]))&&r(g,"src",m),(!w||A&2)&&r(g,"alt",O[1]),(!w||A&4&&!js(v.src,b=O[2]))&&r(v,"src",b),(!w||A&8)&&r(v,"alt",O[3]),q&&q.p&&(!w||A&64)&&d0(q,P,O,O[6],w?h0(P,O[6],A,C0):p0(O[6]),V5),(!w||A&16)&&(E.value=O[4]),(!w||A&16)&&wt(d,"--slider-position",O[4]+"%")},i(O){w||(pt(S,O),w=!0)},o(O){ht(S,O),w=!1},d(O){O&&t(d),S&&S.d(O),z=!1,m0(L)}}}function G0(_){_.target.focus()}function H0(_,d,g){let{$$slots:m={},$$scope:h}=d,{imageLeftSrc:v=""}=d,{imageLeftAlt:b=""}=d,{imageRightSrc:y=""}=d,{imageRightAlt:R=""}=d,D=50,k=null;function E(w){k&&cancelAnimationFrame(k),k=requestAnimationFrame(()=>{g(4,D=w.target.valueAsNumber)})}return _.$$set=w=>{"imageLeftSrc"in w&&g(0,v=w.imageLeftSrc),"imageLeftAlt"in w&&g(1,b=w.imageLeftAlt),"imageRightSrc"in w&&g(2,y=w.imageRightSrc),"imageRightAlt"in w&&g(3,R=w.imageRightAlt),"$$scope"in w&&g(6,h=w.$$scope)},[v,b,y,R,D,E,h,m]}class U0 extends vp{constructor(d){super(),_p(this,d,H0,q0,bp,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function M0(_){let d;return{c(){d=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(g){d=n(g,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(g,m){f(g,d,m)},d(g){g&&t(d)}}}function B0(_){let d,g,m,h;return g=new U0({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[M0]},$$scope:{ctx:_}}}),{c(){d=s("div"),m=s("div"),Ua(g.$$.fragment),this.h()},l(v){d=l(v,"DIV",{class:!0});var b=i(d);m=l(b,"DIV",{style:!0});var y=i(m);Ma(g.$$.fragment,y),b.forEach(t),this.h()},h(){wt(m,"display","contents"),wt(m,"--handle-size","2.5rem"),wt(m,"--handle-background-color","rgba(0, 0, 0, 0.6)"),wt(m,"--handle-background-image",_[4]),wt(m,"--handle-border-width","0.125rem"),wt(m,"--slider-color","#ffffff"),wt(m,"--slider-width","0.125rem"),r(d,"class","image-compare-container svelte-s79nww")},m(v,b){f(v,d,b),e(d,m),Ba(g,m,null),h=!0},p(v,[b]){const y={};b&1&&(y.imageLeftSrc=v[0]),b&2&&(y.imageLeftAlt=v[1]),b&4&&(y.imageRightSrc=v[2]),b&8&&(y.imageRightAlt=v[3]),b&32&&(y.$$scope={dirty:b,ctx:v}),g.$set(y)},i(v){h||(pt(g.$$.fragment,v),h=!0)},o(v){ht(g.$$.fragment,v),h=!1},d(v){v&&t(d),ja(g)}}}function j0(_,d,g){const m=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=d,{imageLeftAlt:v="left"}=d,{imageRightSrc:b="https://via.placeholder.com/512x512/00aaff/ffffff/"}=d,{imageRightAlt:y="right"}=d;return _.$$set=R=>{"imageLeftSrc"in R&&g(0,h=R.imageLeftSrc),"imageLeftAlt"in R&&g(1,v=R.imageLeftAlt),"imageRightSrc"in R&&g(2,b=R.imageRightSrc),"imageRightAlt"in R&&g(3,y=R.imageRightAlt)},[h,v,b,y,m]}class gp extends vp{constructor(d){super(),_p(this,d,j0,B0,bp,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function W0(_){let d,g;return d=new N0({props:{id:X0,spacelabDefaultTitle:Z0,spacelabDefaultContent:K0}}),{c(){Ua(d.$$.fragment)},l(m){Ma(d.$$.fragment,m)},m(m,h){Ba(d,m,h),g=!0},p:X3,i(m){g||(pt(d.$$.fragment,m),g=!0)},o(m){ht(d.$$.fragment,m),g=!1},d(m){ja(d,m)}}}function F0(_){let d,g,m,h,v,b,y,R,D,k,E,w,z,L,P,q,S,O,A,N,C,Q,W,F,B,x,I,H,X,U,T,G,Wa,Ws,_e,Fs,Ep,Ys,yp,kp,ye,ke,Xs,oc,wp,Tp,Zs,Rp,Dp,Ks,Sp,Ap,we,Vs,nc,Op,Lp,Qs,Ip,zp,Js,Pp,Np,Te,$s,cc,Cp,xp,el,qp,Gp,tl,Hp,Gu,al,Up,Hu,sl,Mp,Uu,Fa,ll,Bp,Mu,Ya,uc,jp,Wp,Bu,Xa,fc,Fp,Yp,ju,Za,dc,Xp,Zp,Wu,Ka,pc,Kp,Vp,Fu,Tt,Rt,hc,Qp,Yu,Va,mc,Jp,$p,Xu,Re,eh,gc,th,ah,vc,sh,lh,Zu,De,il,_c,ih,rh,oh,rl,bc,nh,ch,uh,Dt,Ec,fh,dh,ol,ph,hh,Ku,St,At,yc,kc,mh,Vu,nl,gh,Qu,Se,cl,wc,vh,_h,bh,ul,Tc,Eh,yh,kh,fl,Rc,wh,Th,Ju,Ot,Lt,Dc,Sc,Rh,$u,mt,dl,Ae,pl,Ac,Dh,Sh,hl,Oc,Ah,Oh,ml,Lc,Lh,Ih,ue,Oe,gl,Ic,zh,Ph,vl,Nh,Ch,_l,xh,qh,Le,bl,zc,Gh,Hh,El,Uh,Mh,yl,Bh,jh,Ie,kl,Pc,Wh,Fh,wl,Yh,Xh,Tl,Zh,Kh,ze,Rl,Nc,Vh,Qh,Dl,Jh,$h,Sl,em,ef,It,zt,Cc,tm,tf,gt,Al,Pt,Ol,am,sm,Ll,lm,im,fe,Nt,Il,xc,rm,om,zl,nm,cm,Ct,Pl,qc,um,fm,Nl,dm,pm,xt,Cl,Gc,hm,mm,xl,gm,vm,qt,ql,Hc,_m,bm,Gl,Em,af,Hl,ym,sf,Gt,Ht,Uc,km,lf,Qa,J5=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,rf,Ja,$5=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,of,Ut,Mt,Mc,wm,nf,vt,Ul,Pe,Ml,Tm,Rm,Bl,Dm,Sm,jl,Am,Om,de,Ne,Wl,Lm,Im,Fl,zm,Pm,Yl,Nm,Cm,Ce,Xl,xm,qm,Zl,Gm,Hm,Kl,Um,Mm,xe,Vl,Bm,jm,Ql,Wm,Fm,Jl,Ym,Xm,qe,$l,Zm,Km,ei,Vm,Qm,ti,Jm,cf,Bt,jt,Bc,$m,uf,le,ai,eg,$a,tg,ag,jc,sg,lg,Wc,ig,rg,Fc,og,ng,Yc,cg,ff,Wt,Ft,Xc,ug,df,Yt,fg,si,dg,pg,pf,pe,hg,li,mg,gg,ii,vg,_g,ri,bg,Eg,hf,es,oi,ni,yg,mf,ci,kg,gf,Xt,Zt,Zc,wg,vf,Ge,Kc,ts,Vc,Tg,Rg,Dg,Sg,Qc,as,Jc,Ag,Og,Lg,Ig,$c,ss,eu,zg,Pg,Ng,_f,ls,bf,Kt,Vt,tu,Cg,Ef,Qt,xg,is,qg,Gg,yf,He,Hg,ui,Ug,Mg,fi,Bg,jg,kf,J,au,di,Wg,pi,Fg,Yg,su,rs,Xg,hi,Zg,Kg,Vg,lu,Z,Qg,mi,Jg,$g,gi,ev,tv,vi,av,sv,_i,lv,iv,bi,rv,ov,Ei,nv,cv,yi,uv,fv,ki,dv,pv,iu,$,hv,wi,mv,gv,Ti,vv,_v,Ri,bv,Ev,Di,yv,kv,Si,wv,Tv,Ai,Rv,Dv,Oi,Sv,Av,ru,K,Ov,Li,Lv,Iv,Ii,zv,Pv,zi,Nv,Cv,Pi,xv,qv,Ni,Gv,Hv,Ci,Uv,Mv,xi,Bv,jv,qi,Wv,Fv,ou,Gi,Yv,Hi,Xv,Zv,nu,Jt,Kv,Ui,Vv,Qv,Mi,Jv,wf,Ue,$v,Bi,e1,t1,ji,a1,s1,Tf,os,Rf,$t,ea,cu,l1,Df,Wi,i1,Sf,he,Fi,ns,r1,o1,n1,Yi,cs,c1,u1,f1,Xi,us,d1,p1,h1,Zi,fs,m1,g1,Af,ta,aa,uu,v1,Of,sa,_1,Ki,b1,E1,Lf,ds,e0=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,If,Me,y1,Vi,k1,w1,Qi,T1,R1,zf,ps,D1,Ji,S1,Pf,la,A1,$i,O1,L1,Nf,ia,ra,fu,I1,Cf,oa,z1,hs,P1,N1,xf,ms,na,C1,gs,x1,q1,qf,ca,ua,du,G1,Gf,fa,H1,er,U1,M1,Hf,vs,t0=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Uf,tr,B1,Mf,_s,a0='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Bf,Be,j1,ar,W1,F1,sr,Y1,X1,jf,je,Z1,lr,K1,V1,ir,Q1,J1,Wf,rr,$1,Ff,da,or,e2,pu,hu,t2,a2,nr,s2,mu,gu,l2,Yf,cr,i2,Xf,bs,Es,V3,Zf,pa,ha,vu,r2,Kf,_t,o2,ur,n2,c2,fr,u2,Vf,bt,dr,ie,pr,f2,d2,hr,p2,h2,mr,m2,g2,gr,v2,_2,vr,b2,E2,_r,re,br,y2,k2,Er,w2,T2,yr,R2,D2,kr,S2,A2,wr,O2,Qf,Tr,L2,Jf,ys,s0=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,$f,M,Rr,ks,I2,Dr,z2,P2,N2,C2,Sr,ws,x2,Ar,q2,G2,H2,U2,Or,Ts,M2,Lr,B2,j2,W2,F2,Ir,Rs,Y2,zr,X2,Z2,K2,V2,Pr,Ds,Q2,Nr,J2,$2,e_,t_,Cr,Ss,a_,xr,s_,l_,i_,r_,qr,As,o_,Gr,n_,c_,u_,f_,Hr,Os,d_,Ur,p_,h_,m_,g_,Mr,Ls,v_,Br,__,b_,E_,y_,jr,Is,k_,Wr,w_,T_,R_,D_,Fr,zs,S_,Yr,A_,O_,L_,ed,ma,ga,_u,I_,td,Xr,z_,ad,Ps,sd,va,_a,bu,P_,ld,ba,N_,Ns,C_,x_,id,Ea,q_,Zr,G_,H_,rd,oe,Kr,U_,od,M_,Eu,B_,j_,We,W_,Vr,F_,Y_,Qr,X_,Z_,Jr,K_,V_,$r,Q_,eo,J_,$_,ya,eb,to,tb,ab,ao,sb,nd,Fe,lb,so,ib,rb,lo,ob,nb,cd,me,ka,cb,io,ub,fb,ro,db,pb,Cs,hb,oo,mb,gb,vb,yu,_b,bb,ku,Eb,ud,wa,Ta,wu,yb,fd,ge,no,Tu,kb,wb,Tb,co,Ru,Rb,Db,Sb,uo,Du,Ab,Ob,Lb,fo,Su,Ib,zb,dd,po,Pb,pd,xs,qs,Q3,hd,Ra,Da,Au,Nb,md,ho,Cb,gd,Ye,Gs,xb,mo,qb,Gb,Hb,Hs,Ub,go,Mb,Bb,jb,Ou,Wb,vd,Et,vo,Xe,_o,Fb,Yb,bo,Xb,Zb,Eo,Kb,Vb,ve,Ze,yo,Qb,Jb,ko,$b,eE,wo,tE,aE,Ke,To,sE,lE,Ro,iE,rE,Do,oE,nE,Ve,So,cE,uE,Ao,fE,dE,Oo,pE,hE,Qe,Lo,mE,gE,Io,vE,_E,zo,bE,_d,Sa,Aa,Lu,EE,bd,Po,yE,Ed,yt,No,Je,Co,kE,wE,xo,TE,RE,qo,DE,SE,j,$e,Go,AE,OE,Ho,LE,IE,Uo,zE,PE,et,Mo,NE,CE,Bo,xE,qE,jo,GE,HE,tt,Wo,UE,ME,Fo,BE,jE,Yo,WE,FE,at,Xo,YE,XE,Zo,ZE,KE,Ko,VE,QE,st,Vo,JE,$E,Qo,ey,ty,Jo,ay,sy,lt,$o,ly,iy,en,ry,oy,tn,ny,cy,it,an,uy,fy,sn,dy,py,ln,hy,my,rt,rn,gy,vy,on,_y,by,nn,Ey,yy,ot,cn,ky,wy,un,Ty,Ry,fn,Dy,Sy,nt,dn,Ay,Oy,pn,Ly,Iy,hn,zy,yd,Oa,La,Iu,Py,kd,mn,Ny,wd,gn,Cy,Td,Us,Ms,J3,Rd,vn,xy,Dd,kt,Ia,zu,qy,Sd,Ad,Od;h=new _0({props:{smallImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png",largeImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png",alt:"Action Figure with reg images",largeWidth:"968",largeHeight:"512",smallWidth:"484",smallHeight:"256"}}),O=new gp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),ls=new gp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),os=new gp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Ps=new gp({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let be=Q5&&W0();return{c(){d=s("p"),g=o("I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),m=c(),Ua(h.$$.fragment),v=c(),b=s("h2"),y=s("a"),R=s("span"),D=o("What are Regularization Images?"),k=c(),E=s("p"),w=o("Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),z=c(),L=s("blockquote"),P=s("p"),q=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),S=c(),Ua(O.$$.fragment),A=c(),N=s("p"),C=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Q=c(),W=s("p"),F=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),B=c(),x=s("p"),I=o("In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),H=c(),X=s("table"),U=s("thead"),T=s("tr"),G=s("th"),Wa=o("Aspect"),Ws=c(),_e=s("th"),Fs=o("Regularization"),Ep=c(),Ys=s("th"),yp=o("No Regularization"),kp=c(),ye=s("tbody"),ke=s("tr"),Xs=s("td"),oc=s("strong"),wp=o("Class Definition"),Tp=c(),Zs=s("td"),Rp=o("Explicit class anchoring"),Dp=c(),Ks=s("td"),Sp=o("Implicit class learning"),Ap=c(),we=s("tr"),Vs=s("td"),nc=s("strong"),Op=o("Failure Modes"),Lp=c(),Qs=s("td"),Ip=o("Underfitting if overdone"),zp=c(),Js=s("td"),Pp=o("Overfitting/drift"),Np=c(),Te=s("tr"),$s=s("td"),cc=s("strong"),Cp=o("Data Efficiency"),xp=c(),el=s("td"),qp=o("Better generalization"),Gp=c(),tl=s("td"),Hp=o("Requires more data"),Gu=c(),al=s("p"),Up=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Hu=c(),sl=s("p"),Mp=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Uu=c(),Fa=s("blockquote"),ll=s("p"),Bp=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Mu=c(),Ya=s("p"),uc=s("strong"),jp=o("Scenario 1"),Wp=o(": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),Bu=c(),Xa=s("p"),fc=s("strong"),Fp=o("Solution"),Yp=o(": consider using regularization images to help the model learn more about cat features."),ju=c(),Za=s("p"),dc=s("strong"),Xp=o("Scenario 2"),Zp=o(": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),Wu=c(),Ka=s("p"),pc=s("strong"),Kp=o("Solution"),Vp=o(": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),Fu=c(),Tt=s("h2"),Rt=s("a"),hc=s("span"),Qp=o("Divergence"),Yu=c(),Va=s("p"),mc=s("strong"),Jp=o("Divergence"),$p=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Xu=c(),Re=s("p"),eh=o("Preventing divergence starts with "),gc=s("strong"),th=o("careful dataset curation"),ah=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),vc=s("strong"),sh=o("regularization techniques"),lh=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),Zu=c(),De=s("ul"),il=s("li"),_c=s("strong"),ih=o("Chaotic outputs"),rh=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),oh=c(),rl=s("li"),bc=s("strong"),nh=o("Exploding gradients"),ch=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),uh=c(),Dt=s("li"),Ec=s("strong"),fh=o("Loss value instability (NaN/infinity values)"),dh=o(" The training loss fluctuates wildly, sometimes becoming "),ol=s("code"),ph=o("NaN"),hh=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Ku=c(),St=s("h2"),At=s("a"),yc=s("span"),kc=s("strong"),mh=o("Overfitting"),Vu=c(),nl=s("p"),gh=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),Qu=c(),Se=s("ul"),cl=s("li"),wc=s("strong"),vh=o("Perfectly replicates training samples"),_h=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),bh=c(),ul=s("li"),Tc=s("strong"),Eh=o("Fails to generalize to new inputs"),yh=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),kh=c(),fl=s("li"),Rc=s("strong"),wh=o("Shows excellent training loss but poor validation loss"),Th=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),Ju=c(),Ot=s("h3"),Lt=s("a"),Dc=s("span"),Sc=s("strong"),Rh=o("Key Differences"),$u=c(),mt=s("table"),dl=s("thead"),Ae=s("tr"),pl=s("th"),Ac=s("strong"),Dh=o("Aspect"),Sh=c(),hl=s("th"),Oc=s("strong"),Ah=o("Divergence"),Oh=c(),ml=s("th"),Lc=s("strong"),Lh=o("Overfitting"),Ih=c(),ue=s("tbody"),Oe=s("tr"),gl=s("td"),Ic=s("strong"),zh=o("Cause"),Ph=c(),vl=s("td"),Nh=o("Excessive learning rate"),Ch=c(),_l=s("td"),xh=o("Insufficient regularization"),qh=c(),Le=s("tr"),bl=s("td"),zc=s("strong"),Gh=o("Loss Behavior"),Hh=c(),El=s("td"),Uh=o("Sudden spikes/NaN values"),Mh=c(),yl=s("td"),Bh=o("Steady decrease then rise"),jh=c(),Ie=s("tr"),kl=s("td"),Pc=s("strong"),Wh=o("Output Quality"),Fh=c(),wl=s("td"),Yh=o("Random noise/artifacts"),Xh=c(),Tl=s("td"),Zh=o("Overly detailed replicas"),Kh=c(),ze=s("tr"),Rl=s("td"),Nc=s("strong"),Vh=o("Recovery"),Qh=c(),Dl=s("td"),Jh=o("Requires restart"),$h=c(),Sl=s("td"),em=o("Early stopping works"),ef=c(),It=s("h3"),zt=s("a"),Cc=s("span"),tm=o("Preventing Divergence"),tf=c(),gt=s("table"),Al=s("thead"),Pt=s("tr"),Ol=s("th"),am=o("Situation"),sm=c(),Ll=s("th"),lm=o("Outcome"),im=c(),fe=s("tbody"),Nt=s("tr"),Il=s("td"),xc=s("strong"),rm=o("Excessive or inconsistent data"),om=c(),zl=s("td"),nm=o("Model struggles to learn and produces unreliable predictions."),cm=c(),Ct=s("tr"),Pl=s("td"),qc=s("strong"),um=o("Lack of unique and consistent features"),fm=c(),Nl=s("td"),dm=o("Poor generalization, leading to inaccurate or meaningless outputs."),pm=c(),xt=s("tr"),Cl=s("td"),Gc=s("strong"),hm=o("Carefully curated datasets"),mm=c(),xl=s("td"),gm=o("Improved learning by ensuring the model sees only relevant, high-quality data."),vm=c(),qt=s("tr"),ql=s("td"),Hc=s("strong"),_m=o("Effective use of regularization techniques"),bm=c(),Gl=s("td"),Em=o("Helps maintain focus on essential features and prevents instability."),af=c(),Hl=s("p"),ym=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),sf=c(),Gt=s("h3"),Ht=s("a"),Uc=s("span"),km=o("Implementing these Strategies"),lf=c(),Qa=s("pre"),rf=c(),Ja=s("pre"),of=c(),Ut=s("h3"),Mt=s("a"),Mc=s("span"),wm=o("Data Considerations"),nf=c(),vt=s("table"),Ul=s("thead"),Pe=s("tr"),Ml=s("th"),Tm=o("Situation"),Rm=c(),Bl=s("th"),Dm=o("Actual Risk"),Sm=c(),jl=s("th"),Am=o("Solution"),Om=c(),de=s("tbody"),Ne=s("tr"),Wl=s("td"),Lm=o("High LR + small batch size"),Im=c(),Fl=s("td"),zm=o("Divergence"),Pm=c(),Yl=s("td"),Nm=o("Lower LR, increase batch size"),Cm=c(),Ce=s("tr"),Xl=s("td"),xm=o("Inconsistent features"),qm=c(),Zl=s("td"),Gm=o("Overfitting"),Hm=c(),Kl=s("td"),Um=o("Improve dataset consistency"),Mm=c(),xe=s("tr"),Vl=s("td"),Bm=o("Insufficient reg images"),jm=c(),Ql=s("td"),Wm=o("Class leakage"),Fm=c(),Jl=s("td"),Ym=o("Add 100-300 class images"),Xm=c(),qe=s("tr"),$l=s("td"),Zm=o("High variance in training data"),Km=c(),ei=s("td"),Vm=o("Mode collapse"),Qm=c(),ti=s("td"),Jm=o("Curate focused dataset"),cf=c(),Bt=s("h3"),jt=s("a"),Bc=s("span"),$m=o("Monitoring Tips"),uf=c(),le=s("ul"),ai=s("li"),eg=o("Track loss curves with tools like "),$a=s("a"),tg=o("TensorBoard"),ag=c(),jc=s("li"),sg=o("Generate validation images every 100 steps"),lg=c(),Wc=s("li"),ig=o("Use gradient clipping (1.0-2.0 norm)"),rg=c(),Fc=s("li"),og=o("Enable mixed precision training"),ng=c(),Yc=s("li"),cg=o("Start with conservative learning rates (1e-5 to 1e-6)"),ff=c(),Wt=s("h2"),Ft=s("a"),Xc=s("span"),ug=o("Generating Regularization images"),df=c(),Yt=s("p"),fg=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),si=s("code"),dg=o("1boy"),pg=o(")."),pf=c(),pe=s("p"),hg=o("According to the Dreambooth technique, "),li=s("code"),mg=o("200"),gg=o(" regularization images per training image.  For example, if you have "),ii=s("code"),vg=o("16"),_g=o(" images: "),ri=s("code"),bg=o("200 * 16 = 3200"),Eg=o(" total regularization images.  When training, the math involved for calculating total steps is:"),hf=c(),es=s("blockquote"),oi=s("p"),ni=s("code"),yg=o("repeats * training images >= repeats * regularization images"),mf=c(),ci=s("p"),kg=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),gf=c(),Xt=s("h4"),Zt=s("a"),Zc=s("span"),wg=o("Important considerations"),vf=c(),Ge=s("ol"),Kc=s("li"),ts=s("p"),Vc=s("strong"),Tg=o("Use the same base model for regularization images and training"),Rg=s("br"),Dg=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Sg=c(),Qc=s("li"),as=s("p"),Jc=s("strong"),Ag=o("Maintain consistent class representation"),Og=s("br"),Lg=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Ig=c(),$c=s("li"),ss=s("p"),eu=s("strong"),zg=o("Match output resolution to training data"),Pg=s("br"),Ng=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),_f=c(),Ua(ls.$$.fragment),bf=c(),Kt=s("h4"),Vt=s("a"),tu=s("span"),Cg=o("Generate using Stable Diffusion web UI"),Ef=c(),Qt=s("p"),xg=o("We\u2019re going to use "),is=s("a"),qg=o("Stable Diffusion web UI"),Gg=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),yf=c(),He=s("p"),Hg=o("We\u2019re going to use the "),ui=s("code"),Ug=o("X/Y/Z plot"),Mg=o(" script to use "),fi=s("code"),Bg=o("Prompt Search & Replace"),jg=o(" to dynamically build a prompt that will generate hundreds of regularization images."),kf=c(),J=s("ol"),au=s("li"),di=s("p"),Wg=o("Select the text 2 image tab.  Enter a generic prompt "),pi=s("code"),Fg=o("princeadam, portrait, looking_at_viewer, forest"),Yg=c(),su=s("li"),rs=s("p"),Xg=o("In generation parameters and select the "),hi=s("code"),Zg=o("X/Y/Z plot"),Kg=o(" script."),Vg=c(),lu=s("li"),Z=s("p"),Qg=o("Select the "),mi=s("code"),Jg=o("X"),$g=o(" parameter and "),gi=s("code"),ev=o("Prompt SR"),tv=o(" for Prompt Replace.  We\u2019re going to replace "),vi=s("code"),av=o("portrait"),sv=o(" with different camera angle tags: "),_i=s("code"),lv=o("close-up"),iv=o(", "),bi=s("code"),rv=o("upper_body"),ov=o(", "),Ei=s("code"),nv=o("from_below"),cv=o(", "),yi=s("code"),uv=o("from_above"),fv=o(", "),ki=s("code"),dv=o("dutch_angle"),pv=c(),iu=s("li"),$=s("p"),hv=o("Select the "),wi=s("code"),mv=o("Y"),gv=o(" parameter and "),Ti=s("code"),vv=o("Prompt SR"),_v=o(" for Prompt Replace.  Replace "),Ri=s("code"),bv=o("looking_at_viewer"),Ev=o(": "),Di=s("code"),yv=o("looking_away"),kv=o(", "),Si=s("code"),wv=o("looking_to_the_side"),Tv=o(", "),Ai=s("code"),Rv=o("looking_ahead"),Dv=o(", "),Oi=s("code"),Sv=o("looking_down"),Av=c(),ru=s("li"),K=s("p"),Ov=o("Select the "),Li=s("code"),Lv=o("Z"),Iv=o(" parameter and "),Ii=s("code"),zv=o("Prompt SR"),Pv=o(" for Prompt Replace. Replace "),zi=s("code"),Nv=o("forest"),Cv=o(" with a vareity of locatinos: "),Pi=s("code"),xv=o("castle"),qv=o(", "),Ni=s("code"),Gv=o("mountain"),Hv=o(", "),Ci=s("code"),Uv=o("cave"),Mv=o(", "),xi=s("code"),Bv=o("farm"),jv=o(", "),qi=s("code"),Wv=o("ocean"),Fv=c(),ou=s("li"),Gi=s("p"),Yv=o("Select a fast sampler like "),Hi=s("code"),Xv=o("DPM2 KARRAS"),Zv=c(),nu=s("li"),Jt=s("p"),Kv=o("CFG Scale set to "),Ui=s("code"),Vv=o("7"),Qv=o(" and Steps to "),Mi=s("code"),Jv=o("20"),wf=c(),Ue=s("p"),$v=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Bi=s("code"),e1=o("150"),t1=o(" - "),ji=s("code"),a1=o("200"),s1=o(" and keep in mind we can add and remove as we try different training settings with different output."),Tf=c(),Ua(os.$$.fragment),Rf=c(),$t=s("h4"),ea=s("a"),cu=s("span"),l1=o("Download images"),Df=c(),Wi=s("p"),i1=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Sf=c(),he=s("ul"),Fi=s("li"),ns=s("a"),r1=o("3ee Games regularization images"),o1=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),n1=c(),Yi=s("li"),cs=s("a"),c1=o("Pre-Rendered Regularization Images"),u1=o(": Includes 1500 regularization images."),f1=c(),Xi=s("li"),us=s("a"),d1=o("Stable Diffusion 1.5 Regularization Images"),p1=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),h1=c(),Zi=s("li"),fs=s("a"),m1=o("Aitrepreneur SDXL image set"),g1=o(": a large image set generated with Stable Diffusion SDXL."),Af=c(),ta=s("h4"),aa=s("a"),uu=s("span"),v1=o("Captioning Regularization images"),Of=c(),sa=s("p"),_1=o("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Ki=s("code"),b1=o("txt"),E1=o(" files with a shell script:"),Lf=c(),ds=s("pre"),If=c(),Me=s("p"),y1=o("Save this file as "),Vi=s("code"),k1=o("filename2txt.bat"),w1=o(" and place it into the regularization images directory and run: "),Qi=s("code"),T1=o(".\\filename2txt.bat"),R1=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),zf=c(),ps=s("p"),D1=o("Example filename: "),Ji=s("code"),S1=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),Pf=c(),la=s("p"),A1=o("Output: "),$i=s("code"),O1=o("aburbres,princeadam,1boy,close-up,purple_vest"),L1=o(" saved in a text file with the same name as image."),Nf=c(),ia=s("h2"),ra=s("a"),fu=s("span"),I1=o("Training a LoRA"),Cf=c(),oa=s("p"),z1=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),hs=s("a"),P1=o("kohya-ss/sd-scripts"),N1=o("."),xf=c(),ms=s("blockquote"),na=s("p"),C1=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),gs=s("a"),x1=o("Kohya SD script documentation"),q1=o("."),qf=c(),ca=s("h3"),ua=s("a"),du=s("span"),G1=o("Directory setup"),Gf=c(),fa=s("p"),H1=o("In your configuration json, use "),er=s("code"),U1=o("reg_data_dir"),M1=o(" to point to the directory with your regularization images:"),Hf=c(),vs=s("pre"),Uf=c(),tr=s("p"),B1=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Mf=c(),_s=s("pre"),Bf=c(),Be=s("p"),j1=o("Set the "),ar=s("code"),W1=o("number of iterations"),F1=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),sr=s("code"),Y1=o("training images \xD7 iterations"),X1=o(". If there are more regularization images than this, the extras won\u2019t be used."),jf=c(),je=s("p"),Z1=o("Create folders in the training image folder with the format "),lr=s("code"),K1=o("<repetition count>_<class>"),V1=o(" multiple times, and similarly create folders in the regularization image folder with the format "),ir=s("code"),Q1=o("<repetition count>_<class>"),J1=o("."),Wf=c(),rr=s("p"),$1=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Ff=c(),da=s("ul"),or=s("li"),e2=o("train_data_dir"),pu=s("ul"),hu=s("li"),t2=o("10_princeadam"),a2=c(),nr=s("li"),s2=o("reg_dir"),mu=s("ul"),gu=s("li"),l2=o("1_1boy"),Yf=c(),cr=s("p"),i2=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),Xf=c(),bs=s("p"),Es=s("img"),Zf=c(),pa=s("h3"),ha=s("a"),vu=s("span"),r2=o("Training Settings"),Kf=c(),_t=s("p"),o2=o("The training setup we\u2019re going to use is:  "),ur=s("code"),n2=o("Number of images * repeats * epoch / batch size = total steps"),c2=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),fr=s("code"),u2=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Vf=c(),bt=s("table"),dr=s("thead"),ie=s("tr"),pr=s("th"),f2=o("Number of Images"),d2=c(),hr=s("th"),p2=o("Repeats"),h2=c(),mr=s("th"),m2=o("Epochs"),g2=c(),gr=s("th"),v2=o("Batch Size"),_2=c(),vr=s("th"),b2=o("Total Steps"),E2=c(),_r=s("tbody"),re=s("tr"),br=s("td"),y2=o("45"),k2=c(),Er=s("td"),w2=o("10"),T2=c(),yr=s("td"),R2=o("20"),D2=c(),kr=s("td"),S2=o("2"),A2=c(),wr=s("td"),O2=o("4500"),Qf=c(),Tr=s("p"),L2=o("Now let\u2019s focus on these training settings:"),Jf=c(),ys=s("pre"),$f=c(),M=s("ul"),Rr=s("li"),ks=s("strong"),I2=o("Learning Rate ("),Dr=s("code"),z2=o("learning_rate"),P2=o(")"),N2=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),C2=c(),Sr=s("li"),ws=s("strong"),x2=o("Text Encoder Learning Rate ("),Ar=s("code"),q2=o("text_encoder_lr"),G2=o(")"),H2=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),U2=c(),Or=s("li"),Ts=s("strong"),M2=o("UNet Learning Rate ("),Lr=s("code"),B2=o("unet_lr"),j2=o(")"),W2=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),F2=c(),Ir=s("li"),Rs=s("strong"),Y2=o("Learning Rate Scheduler ("),zr=s("code"),X2=o("lr_scheduler"),Z2=o(")"),K2=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),V2=c(),Pr=s("li"),Ds=s("strong"),Q2=o("Number of Cycles in Learning Rate Scheduler ("),Nr=s("code"),J2=o("lr_scheduler_num_cycles"),$2=o(")"),e_=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),t_=c(),Cr=s("li"),Ss=s("strong"),a_=o("Network Dimension ("),xr=s("code"),s_=o("network_dim"),l_=o(")"),i_=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),r_=c(),qr=s("li"),As=s("strong"),o_=o("Network Alpha ("),Gr=s("code"),n_=o("network_alpha"),c_=o(")"),u_=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),f_=c(),Hr=s("li"),Os=s("strong"),d_=o("Clip Skip ("),Ur=s("code"),p_=o("clip_skip"),h_=o(")"),m_=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),g_=c(),Mr=s("li"),Ls=s("strong"),v_=o("Max Token Length ("),Br=s("code"),__=o("max_token_length"),b_=o(")"),E_=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),y_=c(),jr=s("li"),Is=s("strong"),k_=o("Noise Offset ("),Wr=s("code"),w_=o("noise_offset"),T_=o(")"),R_=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),D_=c(),Fr=s("li"),zs=s("strong"),S_=o("Regularization Data Directory ("),Yr=s("code"),A_=o("reg_data_dir"),O_=o(")"),L_=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),ed=c(),ma=s("h3"),ga=s("a"),_u=s("span"),I_=o("Fine Tuning"),td=c(),Xr=s("p"),z_=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),ad=c(),Ua(Ps.$$.fragment),sd=c(),va=s("h4"),_a=s("a"),bu=s("span"),P_=o("Workflow with Auto1111 WebUI"),ld=c(),ba=s("p"),N_=o("We\u2019re going to use "),Ns=s("a"),C_=o("Stable Diffusion web UI"),x_=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),id=c(),Ea=s("p"),q_=o("We\u2019re going to use the "),Zr=s("code"),G_=o("X/Y/Z plot"),H_=o(" script to compare different epochs."),rd=c(),oe=s("ul"),Kr=s("li"),U_=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),od=s("princeadam0001:0.7"),M_=c(),Eu=s("li"),B_=o("In generation parameters and select the X/Y/Z plot script."),j_=c(),We=s("li"),W_=o("Select "),Vr=s("code"),F_=o("Prompt SR"),Y_=o(" for Prompt Replace.  We\u2019re going to replace "),Qr=s("code"),X_=o("<princeadam0001:0.7>"),Z_=o(" with different epoch: "),Jr=s("code"),K_=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),V_=c(),$r=s("li"),Q_=o("Select a fast sampler like "),eo=s("code"),J_=o("DPM2 KARRAS"),$_=c(),ya=s("li"),eb=o("CFG Scale set to "),to=s("code"),tb=o("7"),ab=o(" and Steps to "),ao=s("code"),sb=o("20"),nd=c(),Fe=s("p"),lb=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),so=s("code"),ib=o("network_dim"),rb=o(" and "),lo=s("code"),ob=o("network_alpha"),nb=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),cd=c(),me=s("ul"),ka=s("li"),cb=o("Select "),io=s("code"),ub=o("Prompt SR"),fb=o(" for Prompt Replace.  We\u2019re going to replace the weights "),ro=s("code"),db=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),pb=c(),Cs=s("li"),hb=o("Use Prompt SR to generate a variety of angles: Select "),oo=s("code"),mb=o("Prompt SR"),gb=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),vb=c(),yu=s("li"),_b=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),bb=c(),ku=s("li"),Eb=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),ud=c(),wa=s("h4"),Ta=s("a"),wu=s("span"),yb=o("Issues to look for"),fd=c(),ge=s("ul"),no=s("li"),Tu=s("strong"),kb=o("Undercooked:"),wb=o(" Lacks output, adjust unet learning rate or extend training duration."),Tb=c(),co=s("li"),Ru=s("strong"),Rb=o("Overcooked:"),Db=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Sb=c(),uo=s("li"),Du=s("strong"),Ab=o("Overfit:"),Ob=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),Lb=c(),fo=s("li"),Su=s("strong"),Ib=o("Mismatched:"),zb=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),dd=c(),po=s("p"),Pb=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),pd=c(),xs=s("p"),qs=s("img"),hd=c(),Ra=s("h2"),Da=s("a"),Au=s("span"),Nb=o("Troubleshooting"),md=c(),ho=s("p"),Cb=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),gd=c(),Ye=s("ul"),Gs=s("li"),xb=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),mo=s("code"),qb=o("200"),Gb=o(" regularization images per training image."),Hb=c(),Hs=s("li"),Ub=o("Repeats of regularization images, but may overfit more.  Increasing the "),go=s("code"),Mb=o("repetition_count"),Bb=o(" will cycle through the images more but the results may have results that overfit the model."),jb=c(),Ou=s("li"),Wb=o("Create more regularization images without increasing repeats will help with the overfitting."),vd=c(),Et=s("table"),vo=s("thead"),Xe=s("tr"),_o=s("th"),Fb=o("Issue"),Yb=c(),bo=s("th"),Xb=o("Situation"),Zb=c(),Eo=s("th"),Kb=o("Recommendation"),Vb=c(),ve=s("tbody"),Ze=s("tr"),yo=s("td"),Qb=o("Varying quality"),Jb=c(),ko=s("td"),$b=o("Results differ from expectations"),eE=c(),wo=s("td"),tE=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),aE=c(),Ke=s("tr"),To=s("td"),sE=o("Inadequate regularization for input data"),lE=c(),Ro=s("td"),iE=o("Lower input images, less regularization needed"),rE=c(),Do=s("td"),oE=o("Reduce the number of input images or increasing the quantity of reg images."),nE=c(),Ve=s("tr"),So=s("td"),cE=o("Overfitting due to repetition"),uE=c(),Ao=s("td"),fE=o("Repeats of reg images, risk of overfitting"),dE=c(),Oo=s("td"),pE=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),hE=c(),Qe=s("tr"),Lo=s("td"),mE=o("Mitigate overfitting while increasing diversity"),gE=c(),Io=s("td"),vE=o("Create more reg images without repeats"),_E=c(),zo=s("td"),bE=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),_d=c(),Sa=s("h4"),Aa=s("a"),Lu=s("span"),EE=o("More Solutions"),bd=c(),Po=s("p"),yE=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),Ed=c(),yt=s("table"),No=s("thead"),Je=s("tr"),Co=s("th"),kE=o("Symptom"),wE=c(),xo=s("th"),TE=o("Likely Cause"),RE=c(),qo=s("th"),DE=o("Solution"),SE=c(),j=s("tbody"),$e=s("tr"),Go=s("td"),AE=o("Plastic texture persists"),OE=c(),Ho=s("td"),LE=o("Insufficient human reg images"),IE=c(),Uo=s("td"),zE=o("Add real photos to reg set"),PE=c(),et=s("tr"),Mo=s("td"),NE=o("Loss plateaus early"),CE=c(),Bo=s("td"),xE=o("Learning rate too low"),qE=c(),jo=s("td"),GE=o("Increase LR by 10x"),HE=c(),tt=s("tr"),Wo=s("td"),UE=o("Features blurry"),ME=c(),Fo=s("td"),BE=o("Network dimension too small"),jE=c(),Yo=s("td"),WE=o("Increase network_dim to 64+"),FE=c(),at=s("tr"),Xo=s("td"),YE=o("Color distortion"),XE=c(),Zo=s("td"),ZE=o("Noise offset conflict"),KE=c(),Ko=s("td"),VE=o("Try noise_offset 0.05-0.1"),QE=c(),st=s("tr"),Vo=s("td"),JE=o("Overly stylized outputs"),$E=c(),Qo=s("td"),ey=o("Reg image style mismatch"),ty=c(),Jo=s("td"),ay=o("Regenerate reg images with base model"),sy=c(),lt=s("tr"),$o=s("td"),ly=o("Training instability"),iy=c(),en=s("td"),ry=o("Batch size too large"),oy=c(),tn=s("td"),ny=o("Reduce batch_size to 1-2"),cy=c(),it=s("tr"),an=s("td"),uy=o("Slow convergence"),fy=c(),sn=s("td"),dy=o("Network_alpha too high"),py=c(),ln=s("td"),hy=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),my=c(),rt=s("tr"),rn=s("td"),gy=o("Loss divergence"),vy=c(),on=s("td"),_y=o("Text encoder LR too high"),by=c(),nn=s("td"),Ey=o("Reduce text_encoder_lr by 10x"),yy=c(),ot=s("tr"),cn=s("td"),ky=o("Poor prompt adherence"),wy=c(),un=s("td"),Ty=o("Clip skip too high"),Ry=c(),fn=s("td"),Dy=o("Reduce clip_skip to 1-2"),Sy=c(),nt=s("tr"),dn=s("td"),Ay=o("Memory errors"),Oy=c(),pn=s("td"),Ly=o("Resolution too high"),Iy=c(),hn=s("td"),zy=o("Reduce to 512-768px, enable gradient checkpointing"),yd=c(),Oa=s("h2"),La=s("a"),Iu=s("span"),Py=o("Results"),kd=c(),mn=s("p"),Ny=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),wd=c(),gn=s("p"),Cy=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),Td=c(),Us=s("p"),Ms=s("img"),Rd=c(),vn=s("p"),xy=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),Dd=c(),kt=s("h2"),Ia=s("a"),zu=s("span"),qy=o("spacelab"),Sd=c(),be&&be.c(),Ad=rc(),this.h()},l(a){d=l(a,"P",{});var p=i(d);g=n(p,"I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),p.forEach(t),m=u(a),Ma(h.$$.fragment,a),v=u(a),b=l(a,"H2",{id:!0});var Gy=i(b);y=l(Gy,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var $3=i(y);R=l($3,"SPAN",{class:!0}),i(R).forEach(t),$3.forEach(t),D=n(Gy,"What are Regularization Images?"),Gy.forEach(t),k=u(a),E=l(a,"P",{});var e7=i(E);w=n(e7,"Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),e7.forEach(t),z=u(a),L=l(a,"BLOCKQUOTE",{class:!0});var t7=i(L);P=l(t7,"P",{class:!0});var a7=i(P);q=n(a7,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),a7.forEach(t),t7.forEach(t),S=u(a),Ma(O.$$.fragment,a),A=u(a),N=l(a,"P",{});var s7=i(N);C=n(s7,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),s7.forEach(t),Q=u(a),W=l(a,"P",{});var l7=i(W);F=n(l7,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),l7.forEach(t),B=u(a),x=l(a,"P",{});var i7=i(x);I=n(i7,"In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),i7.forEach(t),H=u(a),X=l(a,"TABLE",{class:!0});var Ld=i(X);U=l(Ld,"THEAD",{class:!0});var r7=i(U);T=l(r7,"TR",{class:!0});var _n=i(T);G=l(_n,"TH",{class:!0});var o7=i(G);Wa=n(o7,"Aspect"),o7.forEach(t),Ws=u(_n),_e=l(_n,"TH",{class:!0});var n7=i(_e);Fs=n(n7,"Regularization"),n7.forEach(t),Ep=u(_n),Ys=l(_n,"TH",{class:!0});var c7=i(Ys);yp=n(c7,"No Regularization"),c7.forEach(t),_n.forEach(t),r7.forEach(t),kp=u(Ld),ye=l(Ld,"TBODY",{class:!0});var bn=i(ye);ke=l(bn,"TR",{class:!0});var En=i(ke);Xs=l(En,"TD",{class:!0});var u7=i(Xs);oc=l(u7,"STRONG",{});var f7=i(oc);wp=n(f7,"Class Definition"),f7.forEach(t),u7.forEach(t),Tp=u(En),Zs=l(En,"TD",{class:!0});var d7=i(Zs);Rp=n(d7,"Explicit class anchoring"),d7.forEach(t),Dp=u(En),Ks=l(En,"TD",{class:!0});var p7=i(Ks);Sp=n(p7,"Implicit class learning"),p7.forEach(t),En.forEach(t),Ap=u(bn),we=l(bn,"TR",{class:!0});var yn=i(we);Vs=l(yn,"TD",{class:!0});var h7=i(Vs);nc=l(h7,"STRONG",{});var m7=i(nc);Op=n(m7,"Failure Modes"),m7.forEach(t),h7.forEach(t),Lp=u(yn),Qs=l(yn,"TD",{class:!0});var g7=i(Qs);Ip=n(g7,"Underfitting if overdone"),g7.forEach(t),zp=u(yn),Js=l(yn,"TD",{class:!0});var v7=i(Js);Pp=n(v7,"Overfitting/drift"),v7.forEach(t),yn.forEach(t),Np=u(bn),Te=l(bn,"TR",{class:!0});var kn=i(Te);$s=l(kn,"TD",{class:!0});var _7=i($s);cc=l(_7,"STRONG",{});var b7=i(cc);Cp=n(b7,"Data Efficiency"),b7.forEach(t),_7.forEach(t),xp=u(kn),el=l(kn,"TD",{class:!0});var E7=i(el);qp=n(E7,"Better generalization"),E7.forEach(t),Gp=u(kn),tl=l(kn,"TD",{class:!0});var y7=i(tl);Hp=n(y7,"Requires more data"),y7.forEach(t),kn.forEach(t),bn.forEach(t),Ld.forEach(t),Gu=u(a),al=l(a,"P",{});var k7=i(al);Up=n(k7,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),k7.forEach(t),Hu=u(a),sl=l(a,"P",{});var w7=i(sl);Mp=n(w7,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),w7.forEach(t),Uu=u(a),Fa=l(a,"BLOCKQUOTE",{class:!0});var T7=i(Fa);ll=l(T7,"P",{class:!0});var R7=i(ll);Bp=n(R7,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),R7.forEach(t),T7.forEach(t),Mu=u(a),Ya=l(a,"P",{});var Hy=i(Ya);uc=l(Hy,"STRONG",{});var D7=i(uc);jp=n(D7,"Scenario 1"),D7.forEach(t),Wp=n(Hy,": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),Hy.forEach(t),Bu=u(a),Xa=l(a,"P",{});var Uy=i(Xa);fc=l(Uy,"STRONG",{});var S7=i(fc);Fp=n(S7,"Solution"),S7.forEach(t),Yp=n(Uy,": consider using regularization images to help the model learn more about cat features."),Uy.forEach(t),ju=u(a),Za=l(a,"P",{});var My=i(Za);dc=l(My,"STRONG",{});var A7=i(dc);Xp=n(A7,"Scenario 2"),A7.forEach(t),Zp=n(My,": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),My.forEach(t),Wu=u(a),Ka=l(a,"P",{});var By=i(Ka);pc=l(By,"STRONG",{});var O7=i(pc);Kp=n(O7,"Solution"),O7.forEach(t),Vp=n(By,": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),By.forEach(t),Fu=u(a),Tt=l(a,"H2",{id:!0});var jy=i(Tt);Rt=l(jy,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var L7=i(Rt);hc=l(L7,"SPAN",{class:!0}),i(hc).forEach(t),L7.forEach(t),Qp=n(jy,"Divergence"),jy.forEach(t),Yu=u(a),Va=l(a,"P",{});var Wy=i(Va);mc=l(Wy,"STRONG",{});var I7=i(mc);Jp=n(I7,"Divergence"),I7.forEach(t),$p=n(Wy," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),Wy.forEach(t),Xu=u(a),Re=l(a,"P",{});var wn=i(Re);eh=n(wn,"Preventing divergence starts with "),gc=l(wn,"STRONG",{});var z7=i(gc);th=n(z7,"careful dataset curation"),z7.forEach(t),ah=n(wn,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),vc=l(wn,"STRONG",{});var P7=i(vc);sh=n(P7,"regularization techniques"),P7.forEach(t),lh=n(wn," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),wn.forEach(t),Zu=u(a),De=l(a,"UL",{});var Tn=i(De);il=l(Tn,"LI",{});var Fy=i(il);_c=l(Fy,"STRONG",{});var N7=i(_c);ih=n(N7,"Chaotic outputs"),N7.forEach(t),rh=n(Fy," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),Fy.forEach(t),oh=u(Tn),rl=l(Tn,"LI",{});var Yy=i(rl);bc=l(Yy,"STRONG",{});var C7=i(bc);nh=n(C7,"Exploding gradients"),C7.forEach(t),ch=n(Yy," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),Yy.forEach(t),uh=u(Tn),Dt=l(Tn,"LI",{});var Pu=i(Dt);Ec=l(Pu,"STRONG",{});var x7=i(Ec);fh=n(x7,"Loss value instability (NaN/infinity values)"),x7.forEach(t),dh=n(Pu," The training loss fluctuates wildly, sometimes becoming "),ol=l(Pu,"CODE",{class:!0});var q7=i(ol);ph=n(q7,"NaN"),q7.forEach(t),hh=n(Pu," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Pu.forEach(t),Tn.forEach(t),Ku=u(a),St=l(a,"H2",{id:!0});var Xy=i(St);At=l(Xy,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var G7=i(At);yc=l(G7,"SPAN",{class:!0}),i(yc).forEach(t),G7.forEach(t),kc=l(Xy,"STRONG",{});var H7=i(kc);mh=n(H7,"Overfitting"),H7.forEach(t),Xy.forEach(t),Vu=u(a),nl=l(a,"P",{});var U7=i(nl);gh=n(U7,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),U7.forEach(t),Qu=u(a),Se=l(a,"UL",{});var Rn=i(Se);cl=l(Rn,"LI",{});var Zy=i(cl);wc=l(Zy,"STRONG",{});var M7=i(wc);vh=n(M7,"Perfectly replicates training samples"),M7.forEach(t),_h=n(Zy," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),Zy.forEach(t),bh=u(Rn),ul=l(Rn,"LI",{});var Ky=i(ul);Tc=l(Ky,"STRONG",{});var B7=i(Tc);Eh=n(B7,"Fails to generalize to new inputs"),B7.forEach(t),yh=n(Ky," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Ky.forEach(t),kh=u(Rn),fl=l(Rn,"LI",{});var Vy=i(fl);Rc=l(Vy,"STRONG",{});var j7=i(Rc);wh=n(j7,"Shows excellent training loss but poor validation loss"),j7.forEach(t),Th=n(Vy," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),Vy.forEach(t),Rn.forEach(t),Ju=u(a),Ot=l(a,"H3",{id:!0});var Qy=i(Ot);Lt=l(Qy,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var W7=i(Lt);Dc=l(W7,"SPAN",{class:!0}),i(Dc).forEach(t),W7.forEach(t),Sc=l(Qy,"STRONG",{});var F7=i(Sc);Rh=n(F7,"Key Differences"),F7.forEach(t),Qy.forEach(t),$u=u(a),mt=l(a,"TABLE",{class:!0});var Id=i(mt);dl=l(Id,"THEAD",{class:!0});var Y7=i(dl);Ae=l(Y7,"TR",{class:!0});var Dn=i(Ae);pl=l(Dn,"TH",{class:!0});var X7=i(pl);Ac=l(X7,"STRONG",{});var Z7=i(Ac);Dh=n(Z7,"Aspect"),Z7.forEach(t),X7.forEach(t),Sh=u(Dn),hl=l(Dn,"TH",{class:!0});var K7=i(hl);Oc=l(K7,"STRONG",{});var V7=i(Oc);Ah=n(V7,"Divergence"),V7.forEach(t),K7.forEach(t),Oh=u(Dn),ml=l(Dn,"TH",{class:!0});var Q7=i(ml);Lc=l(Q7,"STRONG",{});var J7=i(Lc);Lh=n(J7,"Overfitting"),J7.forEach(t),Q7.forEach(t),Dn.forEach(t),Y7.forEach(t),Ih=u(Id),ue=l(Id,"TBODY",{class:!0});var za=i(ue);Oe=l(za,"TR",{class:!0});var Sn=i(Oe);gl=l(Sn,"TD",{class:!0});var $7=i(gl);Ic=l($7,"STRONG",{});var e8=i(Ic);zh=n(e8,"Cause"),e8.forEach(t),$7.forEach(t),Ph=u(Sn),vl=l(Sn,"TD",{class:!0});var t8=i(vl);Nh=n(t8,"Excessive learning rate"),t8.forEach(t),Ch=u(Sn),_l=l(Sn,"TD",{class:!0});var a8=i(_l);xh=n(a8,"Insufficient regularization"),a8.forEach(t),Sn.forEach(t),qh=u(za),Le=l(za,"TR",{class:!0});var An=i(Le);bl=l(An,"TD",{class:!0});var s8=i(bl);zc=l(s8,"STRONG",{});var l8=i(zc);Gh=n(l8,"Loss Behavior"),l8.forEach(t),s8.forEach(t),Hh=u(An),El=l(An,"TD",{class:!0});var i8=i(El);Uh=n(i8,"Sudden spikes/NaN values"),i8.forEach(t),Mh=u(An),yl=l(An,"TD",{class:!0});var r8=i(yl);Bh=n(r8,"Steady decrease then rise"),r8.forEach(t),An.forEach(t),jh=u(za),Ie=l(za,"TR",{class:!0});var On=i(Ie);kl=l(On,"TD",{class:!0});var o8=i(kl);Pc=l(o8,"STRONG",{});var n8=i(Pc);Wh=n(n8,"Output Quality"),n8.forEach(t),o8.forEach(t),Fh=u(On),wl=l(On,"TD",{class:!0});var c8=i(wl);Yh=n(c8,"Random noise/artifacts"),c8.forEach(t),Xh=u(On),Tl=l(On,"TD",{class:!0});var u8=i(Tl);Zh=n(u8,"Overly detailed replicas"),u8.forEach(t),On.forEach(t),Kh=u(za),ze=l(za,"TR",{class:!0});var Ln=i(ze);Rl=l(Ln,"TD",{class:!0});var f8=i(Rl);Nc=l(f8,"STRONG",{});var d8=i(Nc);Vh=n(d8,"Recovery"),d8.forEach(t),f8.forEach(t),Qh=u(Ln),Dl=l(Ln,"TD",{class:!0});var p8=i(Dl);Jh=n(p8,"Requires restart"),p8.forEach(t),$h=u(Ln),Sl=l(Ln,"TD",{class:!0});var h8=i(Sl);em=n(h8,"Early stopping works"),h8.forEach(t),Ln.forEach(t),za.forEach(t),Id.forEach(t),ef=u(a),It=l(a,"H3",{id:!0});var Jy=i(It);zt=l(Jy,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var m8=i(zt);Cc=l(m8,"SPAN",{class:!0}),i(Cc).forEach(t),m8.forEach(t),tm=n(Jy,"Preventing Divergence"),Jy.forEach(t),tf=u(a),gt=l(a,"TABLE",{class:!0});var zd=i(gt);Al=l(zd,"THEAD",{class:!0});var g8=i(Al);Pt=l(g8,"TR",{class:!0});var Pd=i(Pt);Ol=l(Pd,"TH",{class:!0});var v8=i(Ol);am=n(v8,"Situation"),v8.forEach(t),sm=u(Pd),Ll=l(Pd,"TH",{class:!0});var _8=i(Ll);lm=n(_8,"Outcome"),_8.forEach(t),Pd.forEach(t),g8.forEach(t),im=u(zd),fe=l(zd,"TBODY",{class:!0});var Pa=i(fe);Nt=l(Pa,"TR",{class:!0});var Nd=i(Nt);Il=l(Nd,"TD",{class:!0});var b8=i(Il);xc=l(b8,"STRONG",{});var E8=i(xc);rm=n(E8,"Excessive or inconsistent data"),E8.forEach(t),b8.forEach(t),om=u(Nd),zl=l(Nd,"TD",{class:!0});var y8=i(zl);nm=n(y8,"Model struggles to learn and produces unreliable predictions."),y8.forEach(t),Nd.forEach(t),cm=u(Pa),Ct=l(Pa,"TR",{class:!0});var Cd=i(Ct);Pl=l(Cd,"TD",{class:!0});var k8=i(Pl);qc=l(k8,"STRONG",{});var w8=i(qc);um=n(w8,"Lack of unique and consistent features"),w8.forEach(t),k8.forEach(t),fm=u(Cd),Nl=l(Cd,"TD",{class:!0});var T8=i(Nl);dm=n(T8,"Poor generalization, leading to inaccurate or meaningless outputs."),T8.forEach(t),Cd.forEach(t),pm=u(Pa),xt=l(Pa,"TR",{class:!0});var xd=i(xt);Cl=l(xd,"TD",{class:!0});var R8=i(Cl);Gc=l(R8,"STRONG",{});var D8=i(Gc);hm=n(D8,"Carefully curated datasets"),D8.forEach(t),R8.forEach(t),mm=u(xd),xl=l(xd,"TD",{class:!0});var S8=i(xl);gm=n(S8,"Improved learning by ensuring the model sees only relevant, high-quality data."),S8.forEach(t),xd.forEach(t),vm=u(Pa),qt=l(Pa,"TR",{class:!0});var qd=i(qt);ql=l(qd,"TD",{class:!0});var A8=i(ql);Hc=l(A8,"STRONG",{});var O8=i(Hc);_m=n(O8,"Effective use of regularization techniques"),O8.forEach(t),A8.forEach(t),bm=u(qd),Gl=l(qd,"TD",{class:!0});var L8=i(Gl);Em=n(L8,"Helps maintain focus on essential features and prevents instability."),L8.forEach(t),qd.forEach(t),Pa.forEach(t),zd.forEach(t),af=u(a),Hl=l(a,"P",{});var I8=i(Hl);ym=n(I8,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),I8.forEach(t),sf=u(a),Gt=l(a,"H3",{id:!0});var $y=i(Gt);Ht=l($y,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var z8=i(Ht);Uc=l(z8,"SPAN",{class:!0}),i(Uc).forEach(t),z8.forEach(t),km=n($y,"Implementing these Strategies"),$y.forEach(t),lf=u(a),Qa=l(a,"PRE",{class:!0});var l0=i(Qa);l0.forEach(t),rf=u(a),Ja=l(a,"PRE",{class:!0});var i0=i(Ja);i0.forEach(t),of=u(a),Ut=l(a,"H3",{id:!0});var e3=i(Ut);Mt=l(e3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var P8=i(Mt);Mc=l(P8,"SPAN",{class:!0}),i(Mc).forEach(t),P8.forEach(t),wm=n(e3,"Data Considerations"),e3.forEach(t),nf=u(a),vt=l(a,"TABLE",{class:!0});var Gd=i(vt);Ul=l(Gd,"THEAD",{class:!0});var N8=i(Ul);Pe=l(N8,"TR",{class:!0});var In=i(Pe);Ml=l(In,"TH",{class:!0});var C8=i(Ml);Tm=n(C8,"Situation"),C8.forEach(t),Rm=u(In),Bl=l(In,"TH",{class:!0});var x8=i(Bl);Dm=n(x8,"Actual Risk"),x8.forEach(t),Sm=u(In),jl=l(In,"TH",{class:!0});var q8=i(jl);Am=n(q8,"Solution"),q8.forEach(t),In.forEach(t),N8.forEach(t),Om=u(Gd),de=l(Gd,"TBODY",{class:!0});var Na=i(de);Ne=l(Na,"TR",{class:!0});var zn=i(Ne);Wl=l(zn,"TD",{class:!0});var G8=i(Wl);Lm=n(G8,"High LR + small batch size"),G8.forEach(t),Im=u(zn),Fl=l(zn,"TD",{class:!0});var H8=i(Fl);zm=n(H8,"Divergence"),H8.forEach(t),Pm=u(zn),Yl=l(zn,"TD",{class:!0});var U8=i(Yl);Nm=n(U8,"Lower LR, increase batch size"),U8.forEach(t),zn.forEach(t),Cm=u(Na),Ce=l(Na,"TR",{class:!0});var Pn=i(Ce);Xl=l(Pn,"TD",{class:!0});var M8=i(Xl);xm=n(M8,"Inconsistent features"),M8.forEach(t),qm=u(Pn),Zl=l(Pn,"TD",{class:!0});var B8=i(Zl);Gm=n(B8,"Overfitting"),B8.forEach(t),Hm=u(Pn),Kl=l(Pn,"TD",{class:!0});var j8=i(Kl);Um=n(j8,"Improve dataset consistency"),j8.forEach(t),Pn.forEach(t),Mm=u(Na),xe=l(Na,"TR",{class:!0});var Nn=i(xe);Vl=l(Nn,"TD",{class:!0});var W8=i(Vl);Bm=n(W8,"Insufficient reg images"),W8.forEach(t),jm=u(Nn),Ql=l(Nn,"TD",{class:!0});var F8=i(Ql);Wm=n(F8,"Class leakage"),F8.forEach(t),Fm=u(Nn),Jl=l(Nn,"TD",{class:!0});var Y8=i(Jl);Ym=n(Y8,"Add 100-300 class images"),Y8.forEach(t),Nn.forEach(t),Xm=u(Na),qe=l(Na,"TR",{class:!0});var Cn=i(qe);$l=l(Cn,"TD",{class:!0});var X8=i($l);Zm=n(X8,"High variance in training data"),X8.forEach(t),Km=u(Cn),ei=l(Cn,"TD",{class:!0});var Z8=i(ei);Vm=n(Z8,"Mode collapse"),Z8.forEach(t),Qm=u(Cn),ti=l(Cn,"TD",{class:!0});var K8=i(ti);Jm=n(K8,"Curate focused dataset"),K8.forEach(t),Cn.forEach(t),Na.forEach(t),Gd.forEach(t),cf=u(a),Bt=l(a,"H3",{id:!0});var t3=i(Bt);jt=l(t3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var V8=i(jt);Bc=l(V8,"SPAN",{class:!0}),i(Bc).forEach(t),V8.forEach(t),$m=n(t3,"Monitoring Tips"),t3.forEach(t),uf=u(a),le=l(a,"UL",{});var ct=i(le);ai=l(ct,"LI",{});var a3=i(ai);eg=n(a3,"Track loss curves with tools like "),$a=l(a3,"A",{href:!0,rel:!0});var Q8=i($a);tg=n(Q8,"TensorBoard"),Q8.forEach(t),a3.forEach(t),ag=u(ct),jc=l(ct,"LI",{});var J8=i(jc);sg=n(J8,"Generate validation images every 100 steps"),J8.forEach(t),lg=u(ct),Wc=l(ct,"LI",{});var $8=i(Wc);ig=n($8,"Use gradient clipping (1.0-2.0 norm)"),$8.forEach(t),rg=u(ct),Fc=l(ct,"LI",{});var e4=i(Fc);og=n(e4,"Enable mixed precision training"),e4.forEach(t),ng=u(ct),Yc=l(ct,"LI",{});var t4=i(Yc);cg=n(t4,"Start with conservative learning rates (1e-5 to 1e-6)"),t4.forEach(t),ct.forEach(t),ff=u(a),Wt=l(a,"H2",{id:!0});var s3=i(Wt);Ft=l(s3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var a4=i(Ft);Xc=l(a4,"SPAN",{class:!0}),i(Xc).forEach(t),a4.forEach(t),ug=n(s3,"Generating Regularization images"),s3.forEach(t),df=u(a),Yt=l(a,"P",{});var Hd=i(Yt);fg=n(Hd,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),si=l(Hd,"CODE",{class:!0});var s4=i(si);dg=n(s4,"1boy"),s4.forEach(t),pg=n(Hd,")."),Hd.forEach(t),pf=u(a),pe=l(a,"P",{});var Ca=i(pe);hg=n(Ca,"According to the Dreambooth technique, "),li=l(Ca,"CODE",{class:!0});var l4=i(li);mg=n(l4,"200"),l4.forEach(t),gg=n(Ca," regularization images per training image.  For example, if you have "),ii=l(Ca,"CODE",{class:!0});var i4=i(ii);vg=n(i4,"16"),i4.forEach(t),_g=n(Ca," images: "),ri=l(Ca,"CODE",{class:!0});var r4=i(ri);bg=n(r4,"200 * 16 = 3200"),r4.forEach(t),Eg=n(Ca," total regularization images.  When training, the math involved for calculating total steps is:"),Ca.forEach(t),hf=u(a),es=l(a,"BLOCKQUOTE",{class:!0});var o4=i(es);oi=l(o4,"P",{class:!0});var n4=i(oi);ni=l(n4,"CODE",{class:!0});var c4=i(ni);yg=n(c4,"repeats * training images >= repeats * regularization images"),c4.forEach(t),n4.forEach(t),o4.forEach(t),mf=u(a),ci=l(a,"P",{});var u4=i(ci);kg=n(u4,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),u4.forEach(t),gf=u(a),Xt=l(a,"H4",{id:!0});var l3=i(Xt);Zt=l(l3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var f4=i(Zt);Zc=l(f4,"SPAN",{class:!0}),i(Zc).forEach(t),f4.forEach(t),wg=n(l3,"Important considerations"),l3.forEach(t),vf=u(a),Ge=l(a,"OL",{});var xn=i(Ge);Kc=l(xn,"LI",{});var d4=i(Kc);ts=l(d4,"P",{});var Ud=i(ts);Vc=l(Ud,"STRONG",{});var p4=i(Vc);Tg=n(p4,"Use the same base model for regularization images and training"),p4.forEach(t),Rg=l(Ud,"BR",{}),Dg=n(Ud,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Ud.forEach(t),d4.forEach(t),Sg=u(xn),Qc=l(xn,"LI",{});var h4=i(Qc);as=l(h4,"P",{});var Md=i(as);Jc=l(Md,"STRONG",{});var m4=i(Jc);Ag=n(m4,"Maintain consistent class representation"),m4.forEach(t),Og=l(Md,"BR",{}),Lg=n(Md,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Md.forEach(t),h4.forEach(t),Ig=u(xn),$c=l(xn,"LI",{});var g4=i($c);ss=l(g4,"P",{});var Bd=i(ss);eu=l(Bd,"STRONG",{});var v4=i(eu);zg=n(v4,"Match output resolution to training data"),v4.forEach(t),Pg=l(Bd,"BR",{}),Ng=n(Bd,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),Bd.forEach(t),g4.forEach(t),xn.forEach(t),_f=u(a),Ma(ls.$$.fragment,a),bf=u(a),Kt=l(a,"H4",{id:!0});var i3=i(Kt);Vt=l(i3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _4=i(Vt);tu=l(_4,"SPAN",{class:!0}),i(tu).forEach(t),_4.forEach(t),Cg=n(i3,"Generate using Stable Diffusion web UI"),i3.forEach(t),Ef=u(a),Qt=l(a,"P",{});var jd=i(Qt);xg=n(jd,"We\u2019re going to use "),is=l(jd,"A",{href:!0,rel:!0});var b4=i(is);qg=n(b4,"Stable Diffusion web UI"),b4.forEach(t),Gg=n(jd," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),jd.forEach(t),yf=u(a),He=l(a,"P",{});var qn=i(He);Hg=n(qn,"We\u2019re going to use the "),ui=l(qn,"CODE",{class:!0});var E4=i(ui);Ug=n(E4,"X/Y/Z plot"),E4.forEach(t),Mg=n(qn," script to use "),fi=l(qn,"CODE",{class:!0});var y4=i(fi);Bg=n(y4,"Prompt Search & Replace"),y4.forEach(t),jg=n(qn," to dynamically build a prompt that will generate hundreds of regularization images."),qn.forEach(t),kf=u(a),J=l(a,"OL",{});var ne=i(J);au=l(ne,"LI",{});var k4=i(au);di=l(k4,"P",{});var r3=i(di);Wg=n(r3,"Select the text 2 image tab.  Enter a generic prompt "),pi=l(r3,"CODE",{class:!0});var w4=i(pi);Fg=n(w4,"princeadam, portrait, looking_at_viewer, forest"),w4.forEach(t),r3.forEach(t),k4.forEach(t),Yg=u(ne),su=l(ne,"LI",{});var T4=i(su);rs=l(T4,"P",{});var Wd=i(rs);Xg=n(Wd,"In generation parameters and select the "),hi=l(Wd,"CODE",{class:!0});var R4=i(hi);Zg=n(R4,"X/Y/Z plot"),R4.forEach(t),Kg=n(Wd," script."),Wd.forEach(t),T4.forEach(t),Vg=u(ne),lu=l(ne,"LI",{});var D4=i(lu);Z=l(D4,"P",{});var te=i(Z);Qg=n(te,"Select the "),mi=l(te,"CODE",{class:!0});var S4=i(mi);Jg=n(S4,"X"),S4.forEach(t),$g=n(te," parameter and "),gi=l(te,"CODE",{class:!0});var A4=i(gi);ev=n(A4,"Prompt SR"),A4.forEach(t),tv=n(te," for Prompt Replace.  We\u2019re going to replace "),vi=l(te,"CODE",{class:!0});var O4=i(vi);av=n(O4,"portrait"),O4.forEach(t),sv=n(te," with different camera angle tags: "),_i=l(te,"CODE",{class:!0});var L4=i(_i);lv=n(L4,"close-up"),L4.forEach(t),iv=n(te,", "),bi=l(te,"CODE",{class:!0});var I4=i(bi);rv=n(I4,"upper_body"),I4.forEach(t),ov=n(te,", "),Ei=l(te,"CODE",{class:!0});var z4=i(Ei);nv=n(z4,"from_below"),z4.forEach(t),cv=n(te,", "),yi=l(te,"CODE",{class:!0});var P4=i(yi);uv=n(P4,"from_above"),P4.forEach(t),fv=n(te,", "),ki=l(te,"CODE",{class:!0});var N4=i(ki);dv=n(N4,"dutch_angle"),N4.forEach(t),te.forEach(t),D4.forEach(t),pv=u(ne),iu=l(ne,"LI",{});var C4=i(iu);$=l(C4,"P",{});var se=i($);hv=n(se,"Select the "),wi=l(se,"CODE",{class:!0});var x4=i(wi);mv=n(x4,"Y"),x4.forEach(t),gv=n(se," parameter and "),Ti=l(se,"CODE",{class:!0});var q4=i(Ti);vv=n(q4,"Prompt SR"),q4.forEach(t),_v=n(se," for Prompt Replace.  Replace "),Ri=l(se,"CODE",{class:!0});var G4=i(Ri);bv=n(G4,"looking_at_viewer"),G4.forEach(t),Ev=n(se,": "),Di=l(se,"CODE",{class:!0});var H4=i(Di);yv=n(H4,"looking_away"),H4.forEach(t),kv=n(se,", "),Si=l(se,"CODE",{class:!0});var U4=i(Si);wv=n(U4,"looking_to_the_side"),U4.forEach(t),Tv=n(se,", "),Ai=l(se,"CODE",{class:!0});var M4=i(Ai);Rv=n(M4,"looking_ahead"),M4.forEach(t),Dv=n(se,", "),Oi=l(se,"CODE",{class:!0});var B4=i(Oi);Sv=n(B4,"looking_down"),B4.forEach(t),se.forEach(t),C4.forEach(t),Av=u(ne),ru=l(ne,"LI",{});var j4=i(ru);K=l(j4,"P",{});var ae=i(K);Ov=n(ae,"Select the "),Li=l(ae,"CODE",{class:!0});var W4=i(Li);Lv=n(W4,"Z"),W4.forEach(t),Iv=n(ae," parameter and "),Ii=l(ae,"CODE",{class:!0});var F4=i(Ii);zv=n(F4,"Prompt SR"),F4.forEach(t),Pv=n(ae," for Prompt Replace. Replace "),zi=l(ae,"CODE",{class:!0});var Y4=i(zi);Nv=n(Y4,"forest"),Y4.forEach(t),Cv=n(ae," with a vareity of locatinos: "),Pi=l(ae,"CODE",{class:!0});var X4=i(Pi);xv=n(X4,"castle"),X4.forEach(t),qv=n(ae,", "),Ni=l(ae,"CODE",{class:!0});var Z4=i(Ni);Gv=n(Z4,"mountain"),Z4.forEach(t),Hv=n(ae,", "),Ci=l(ae,"CODE",{class:!0});var K4=i(Ci);Uv=n(K4,"cave"),K4.forEach(t),Mv=n(ae,", "),xi=l(ae,"CODE",{class:!0});var V4=i(xi);Bv=n(V4,"farm"),V4.forEach(t),jv=n(ae,", "),qi=l(ae,"CODE",{class:!0});var Q4=i(qi);Wv=n(Q4,"ocean"),Q4.forEach(t),ae.forEach(t),j4.forEach(t),Fv=u(ne),ou=l(ne,"LI",{});var J4=i(ou);Gi=l(J4,"P",{});var o3=i(Gi);Yv=n(o3,"Select a fast sampler like "),Hi=l(o3,"CODE",{class:!0});var $4=i(Hi);Xv=n($4,"DPM2 KARRAS"),$4.forEach(t),o3.forEach(t),J4.forEach(t),Zv=u(ne),nu=l(ne,"LI",{});var ek=i(nu);Jt=l(ek,"P",{});var Nu=i(Jt);Kv=n(Nu,"CFG Scale set to "),Ui=l(Nu,"CODE",{class:!0});var tk=i(Ui);Vv=n(tk,"7"),tk.forEach(t),Qv=n(Nu," and Steps to "),Mi=l(Nu,"CODE",{class:!0});var ak=i(Mi);Jv=n(ak,"20"),ak.forEach(t),Nu.forEach(t),ek.forEach(t),ne.forEach(t),wf=u(a),Ue=l(a,"P",{});var Gn=i(Ue);$v=n(Gn,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),Bi=l(Gn,"CODE",{class:!0});var sk=i(Bi);e1=n(sk,"150"),sk.forEach(t),t1=n(Gn," - "),ji=l(Gn,"CODE",{class:!0});var lk=i(ji);a1=n(lk,"200"),lk.forEach(t),s1=n(Gn," and keep in mind we can add and remove as we try different training settings with different output."),Gn.forEach(t),Tf=u(a),Ma(os.$$.fragment,a),Rf=u(a),$t=l(a,"H4",{id:!0});var n3=i($t);ea=l(n3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ik=i(ea);cu=l(ik,"SPAN",{class:!0}),i(cu).forEach(t),ik.forEach(t),l1=n(n3,"Download images"),n3.forEach(t),Df=u(a),Wi=l(a,"P",{});var rk=i(Wi);i1=n(rk,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),rk.forEach(t),Sf=u(a),he=l(a,"UL",{});var xa=i(he);Fi=l(xa,"LI",{});var c3=i(Fi);ns=l(c3,"A",{href:!0,rel:!0});var ok=i(ns);r1=n(ok,"3ee Games regularization images"),ok.forEach(t),o1=n(c3,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),c3.forEach(t),n1=u(xa),Yi=l(xa,"LI",{});var u3=i(Yi);cs=l(u3,"A",{href:!0,rel:!0});var nk=i(cs);c1=n(nk,"Pre-Rendered Regularization Images"),nk.forEach(t),u1=n(u3,": Includes 1500 regularization images."),u3.forEach(t),f1=u(xa),Xi=l(xa,"LI",{});var f3=i(Xi);us=l(f3,"A",{href:!0,rel:!0});var ck=i(us);d1=n(ck,"Stable Diffusion 1.5 Regularization Images"),ck.forEach(t),p1=n(f3,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),f3.forEach(t),h1=u(xa),Zi=l(xa,"LI",{});var d3=i(Zi);fs=l(d3,"A",{href:!0,rel:!0});var uk=i(fs);m1=n(uk,"Aitrepreneur SDXL image set"),uk.forEach(t),g1=n(d3,": a large image set generated with Stable Diffusion SDXL."),d3.forEach(t),xa.forEach(t),Af=u(a),ta=l(a,"H4",{id:!0});var p3=i(ta);aa=l(p3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var fk=i(aa);uu=l(fk,"SPAN",{class:!0}),i(uu).forEach(t),fk.forEach(t),v1=n(p3,"Captioning Regularization images"),p3.forEach(t),Of=u(a),sa=l(a,"P",{});var Fd=i(sa);_1=n(Fd,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Ki=l(Fd,"CODE",{class:!0});var dk=i(Ki);b1=n(dk,"txt"),dk.forEach(t),E1=n(Fd," files with a shell script:"),Fd.forEach(t),Lf=u(a),ds=l(a,"PRE",{class:!0});var r0=i(ds);r0.forEach(t),If=u(a),Me=l(a,"P",{});var Hn=i(Me);y1=n(Hn,"Save this file as "),Vi=l(Hn,"CODE",{class:!0});var pk=i(Vi);k1=n(pk,"filename2txt.bat"),pk.forEach(t),w1=n(Hn," and place it into the regularization images directory and run: "),Qi=l(Hn,"CODE",{class:!0});var hk=i(Qi);T1=n(hk,".\\filename2txt.bat"),hk.forEach(t),R1=n(Hn,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Hn.forEach(t),zf=u(a),ps=l(a,"P",{});var h3=i(ps);D1=n(h3,"Example filename: "),Ji=l(h3,"CODE",{class:!0});var mk=i(Ji);S1=n(mk,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),mk.forEach(t),h3.forEach(t),Pf=u(a),la=l(a,"P",{});var Yd=i(la);A1=n(Yd,"Output: "),$i=l(Yd,"CODE",{class:!0});var gk=i($i);O1=n(gk,"aburbres,princeadam,1boy,close-up,purple_vest"),gk.forEach(t),L1=n(Yd," saved in a text file with the same name as image."),Yd.forEach(t),Nf=u(a),ia=l(a,"H2",{id:!0});var m3=i(ia);ra=l(m3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var vk=i(ra);fu=l(vk,"SPAN",{class:!0}),i(fu).forEach(t),vk.forEach(t),I1=n(m3,"Training a LoRA"),m3.forEach(t),Cf=u(a),oa=l(a,"P",{});var Xd=i(oa);z1=n(Xd,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),hs=l(Xd,"A",{href:!0,rel:!0});var _k=i(hs);P1=n(_k,"kohya-ss/sd-scripts"),_k.forEach(t),N1=n(Xd,"."),Xd.forEach(t),xf=u(a),ms=l(a,"BLOCKQUOTE",{class:!0});var bk=i(ms);na=l(bk,"P",{class:!0});var Zd=i(na);C1=n(Zd,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),gs=l(Zd,"A",{href:!0,rel:!0});var Ek=i(gs);x1=n(Ek,"Kohya SD script documentation"),Ek.forEach(t),q1=n(Zd,"."),Zd.forEach(t),bk.forEach(t),qf=u(a),ca=l(a,"H3",{id:!0});var g3=i(ca);ua=l(g3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var yk=i(ua);du=l(yk,"SPAN",{class:!0}),i(du).forEach(t),yk.forEach(t),G1=n(g3,"Directory setup"),g3.forEach(t),Gf=u(a),fa=l(a,"P",{});var Kd=i(fa);H1=n(Kd,"In your configuration json, use "),er=l(Kd,"CODE",{class:!0});var kk=i(er);U1=n(kk,"reg_data_dir"),kk.forEach(t),M1=n(Kd," to point to the directory with your regularization images:"),Kd.forEach(t),Hf=u(a),vs=l(a,"PRE",{class:!0});var o0=i(vs);o0.forEach(t),Uf=u(a),tr=l(a,"P",{});var wk=i(tr);B1=n(wk,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),wk.forEach(t),Mf=u(a),_s=l(a,"PRE",{class:!0});var n0=i(_s);n0.forEach(t),Bf=u(a),Be=l(a,"P",{});var Un=i(Be);j1=n(Un,"Set the "),ar=l(Un,"CODE",{class:!0});var Tk=i(ar);W1=n(Tk,"number of iterations"),Tk.forEach(t),F1=n(Un," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),sr=l(Un,"CODE",{class:!0});var Rk=i(sr);Y1=n(Rk,"training images \xD7 iterations"),Rk.forEach(t),X1=n(Un,". If there are more regularization images than this, the extras won\u2019t be used."),Un.forEach(t),jf=u(a),je=l(a,"P",{});var Mn=i(je);Z1=n(Mn,"Create folders in the training image folder with the format "),lr=l(Mn,"CODE",{class:!0});var Dk=i(lr);K1=n(Dk,"<repetition count>_<class>"),Dk.forEach(t),V1=n(Mn," multiple times, and similarly create folders in the regularization image folder with the format "),ir=l(Mn,"CODE",{class:!0});var Sk=i(ir);Q1=n(Sk,"<repetition count>_<class>"),Sk.forEach(t),J1=n(Mn,"."),Mn.forEach(t),Wf=u(a),rr=l(a,"P",{});var Ak=i(rr);$1=n(Ak,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Ak.forEach(t),Ff=u(a),da=l(a,"UL",{});var Vd=i(da);or=l(Vd,"LI",{});var v3=i(or);e2=n(v3,"train_data_dir"),pu=l(v3,"UL",{});var Ok=i(pu);hu=l(Ok,"LI",{});var Lk=i(hu);t2=n(Lk,"10_princeadam"),Lk.forEach(t),Ok.forEach(t),v3.forEach(t),a2=u(Vd),nr=l(Vd,"LI",{});var _3=i(nr);s2=n(_3,"reg_dir"),mu=l(_3,"UL",{});var Ik=i(mu);gu=l(Ik,"LI",{});var zk=i(gu);l2=n(zk,"1_1boy"),zk.forEach(t),Ik.forEach(t),_3.forEach(t),Vd.forEach(t),Yf=u(a),cr=l(a,"P",{});var Pk=i(cr);i2=n(Pk,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),Pk.forEach(t),Xf=u(a),bs=l(a,"P",{class:!0});var Nk=i(bs);Es=l(Nk,"IMG",{src:!0,alt:!0,class:!0}),Nk.forEach(t),Zf=u(a),pa=l(a,"H3",{id:!0});var b3=i(pa);ha=l(b3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Ck=i(ha);vu=l(Ck,"SPAN",{class:!0}),i(vu).forEach(t),Ck.forEach(t),r2=n(b3,"Training Settings"),b3.forEach(t),Kf=u(a),_t=l(a,"P",{});var Cu=i(_t);o2=n(Cu,"The training setup we\u2019re going to use is:  "),ur=l(Cu,"CODE",{class:!0});var xk=i(ur);n2=n(xk,"Number of images * repeats * epoch / batch size = total steps"),xk.forEach(t),c2=n(Cu,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),fr=l(Cu,"CODE",{class:!0});var qk=i(fr);u2=n(qk,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),qk.forEach(t),Cu.forEach(t),Vf=u(a),bt=l(a,"TABLE",{class:!0});var Qd=i(bt);dr=l(Qd,"THEAD",{class:!0});var Gk=i(dr);ie=l(Gk,"TR",{class:!0});var ut=i(ie);pr=l(ut,"TH",{class:!0});var Hk=i(pr);f2=n(Hk,"Number of Images"),Hk.forEach(t),d2=u(ut),hr=l(ut,"TH",{class:!0});var Uk=i(hr);p2=n(Uk,"Repeats"),Uk.forEach(t),h2=u(ut),mr=l(ut,"TH",{class:!0});var Mk=i(mr);m2=n(Mk,"Epochs"),Mk.forEach(t),g2=u(ut),gr=l(ut,"TH",{class:!0});var Bk=i(gr);v2=n(Bk,"Batch Size"),Bk.forEach(t),_2=u(ut),vr=l(ut,"TH",{class:!0});var jk=i(vr);b2=n(jk,"Total Steps"),jk.forEach(t),ut.forEach(t),Gk.forEach(t),E2=u(Qd),_r=l(Qd,"TBODY",{class:!0});var Wk=i(_r);re=l(Wk,"TR",{class:!0});var ft=i(re);br=l(ft,"TD",{class:!0});var Fk=i(br);y2=n(Fk,"45"),Fk.forEach(t),k2=u(ft),Er=l(ft,"TD",{class:!0});var Yk=i(Er);w2=n(Yk,"10"),Yk.forEach(t),T2=u(ft),yr=l(ft,"TD",{class:!0});var Xk=i(yr);R2=n(Xk,"20"),Xk.forEach(t),D2=u(ft),kr=l(ft,"TD",{class:!0});var Zk=i(kr);S2=n(Zk,"2"),Zk.forEach(t),A2=u(ft),wr=l(ft,"TD",{class:!0});var Kk=i(wr);O2=n(Kk,"4500"),Kk.forEach(t),ft.forEach(t),Wk.forEach(t),Qd.forEach(t),Qf=u(a),Tr=l(a,"P",{});var Vk=i(Tr);L2=n(Vk,"Now let\u2019s focus on these training settings:"),Vk.forEach(t),Jf=u(a),ys=l(a,"PRE",{class:!0});var c0=i(ys);c0.forEach(t),$f=u(a),M=l(a,"UL",{});var Y=i(M);Rr=l(Y,"LI",{});var E3=i(Rr);ks=l(E3,"STRONG",{});var Jd=i(ks);I2=n(Jd,"Learning Rate ("),Dr=l(Jd,"CODE",{class:!0});var Qk=i(Dr);z2=n(Qk,"learning_rate"),Qk.forEach(t),P2=n(Jd,")"),Jd.forEach(t),N2=n(E3,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),E3.forEach(t),C2=u(Y),Sr=l(Y,"LI",{});var y3=i(Sr);ws=l(y3,"STRONG",{});var $d=i(ws);x2=n($d,"Text Encoder Learning Rate ("),Ar=l($d,"CODE",{class:!0});var Jk=i(Ar);q2=n(Jk,"text_encoder_lr"),Jk.forEach(t),G2=n($d,")"),$d.forEach(t),H2=n(y3,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),y3.forEach(t),U2=u(Y),Or=l(Y,"LI",{});var k3=i(Or);Ts=l(k3,"STRONG",{});var ep=i(Ts);M2=n(ep,"UNet Learning Rate ("),Lr=l(ep,"CODE",{class:!0});var $k=i(Lr);B2=n($k,"unet_lr"),$k.forEach(t),j2=n(ep,")"),ep.forEach(t),W2=n(k3,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),k3.forEach(t),F2=u(Y),Ir=l(Y,"LI",{});var w3=i(Ir);Rs=l(w3,"STRONG",{});var tp=i(Rs);Y2=n(tp,"Learning Rate Scheduler ("),zr=l(tp,"CODE",{class:!0});var ew=i(zr);X2=n(ew,"lr_scheduler"),ew.forEach(t),Z2=n(tp,")"),tp.forEach(t),K2=n(w3,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),w3.forEach(t),V2=u(Y),Pr=l(Y,"LI",{});var T3=i(Pr);Ds=l(T3,"STRONG",{});var ap=i(Ds);Q2=n(ap,"Number of Cycles in Learning Rate Scheduler ("),Nr=l(ap,"CODE",{class:!0});var tw=i(Nr);J2=n(tw,"lr_scheduler_num_cycles"),tw.forEach(t),$2=n(ap,")"),ap.forEach(t),e_=n(T3,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),T3.forEach(t),t_=u(Y),Cr=l(Y,"LI",{});var R3=i(Cr);Ss=l(R3,"STRONG",{});var sp=i(Ss);a_=n(sp,"Network Dimension ("),xr=l(sp,"CODE",{class:!0});var aw=i(xr);s_=n(aw,"network_dim"),aw.forEach(t),l_=n(sp,")"),sp.forEach(t),i_=n(R3,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),R3.forEach(t),r_=u(Y),qr=l(Y,"LI",{});var D3=i(qr);As=l(D3,"STRONG",{});var lp=i(As);o_=n(lp,"Network Alpha ("),Gr=l(lp,"CODE",{class:!0});var sw=i(Gr);n_=n(sw,"network_alpha"),sw.forEach(t),c_=n(lp,")"),lp.forEach(t),u_=n(D3,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),D3.forEach(t),f_=u(Y),Hr=l(Y,"LI",{});var S3=i(Hr);Os=l(S3,"STRONG",{});var ip=i(Os);d_=n(ip,"Clip Skip ("),Ur=l(ip,"CODE",{class:!0});var lw=i(Ur);p_=n(lw,"clip_skip"),lw.forEach(t),h_=n(ip,")"),ip.forEach(t),m_=n(S3,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),S3.forEach(t),g_=u(Y),Mr=l(Y,"LI",{});var A3=i(Mr);Ls=l(A3,"STRONG",{});var rp=i(Ls);v_=n(rp,"Max Token Length ("),Br=l(rp,"CODE",{class:!0});var iw=i(Br);__=n(iw,"max_token_length"),iw.forEach(t),b_=n(rp,")"),rp.forEach(t),E_=n(A3,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),A3.forEach(t),y_=u(Y),jr=l(Y,"LI",{});var O3=i(jr);Is=l(O3,"STRONG",{});var op=i(Is);k_=n(op,"Noise Offset ("),Wr=l(op,"CODE",{class:!0});var rw=i(Wr);w_=n(rw,"noise_offset"),rw.forEach(t),T_=n(op,")"),op.forEach(t),R_=n(O3,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),O3.forEach(t),D_=u(Y),Fr=l(Y,"LI",{});var L3=i(Fr);zs=l(L3,"STRONG",{});var np=i(zs);S_=n(np,"Regularization Data Directory ("),Yr=l(np,"CODE",{class:!0});var ow=i(Yr);A_=n(ow,"reg_data_dir"),ow.forEach(t),O_=n(np,")"),np.forEach(t),L_=n(L3,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),L3.forEach(t),Y.forEach(t),ed=u(a),ma=l(a,"H3",{id:!0});var I3=i(ma);ga=l(I3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var nw=i(ga);_u=l(nw,"SPAN",{class:!0}),i(_u).forEach(t),nw.forEach(t),I_=n(I3,"Fine Tuning"),I3.forEach(t),td=u(a),Xr=l(a,"P",{});var cw=i(Xr);z_=n(cw,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),cw.forEach(t),ad=u(a),Ma(Ps.$$.fragment,a),sd=u(a),va=l(a,"H4",{id:!0});var z3=i(va);_a=l(z3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var uw=i(_a);bu=l(uw,"SPAN",{class:!0}),i(bu).forEach(t),uw.forEach(t),P_=n(z3,"Workflow with Auto1111 WebUI"),z3.forEach(t),ld=u(a),ba=l(a,"P",{});var cp=i(ba);N_=n(cp,"We\u2019re going to use "),Ns=l(cp,"A",{href:!0,rel:!0});var fw=i(Ns);C_=n(fw,"Stable Diffusion web UI"),fw.forEach(t),x_=n(cp," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),cp.forEach(t),id=u(a),Ea=l(a,"P",{});var up=i(Ea);q_=n(up,"We\u2019re going to use the "),Zr=l(up,"CODE",{class:!0});var dw=i(Zr);G_=n(dw,"X/Y/Z plot"),dw.forEach(t),H_=n(up," script to compare different epochs."),up.forEach(t),rd=u(a),oe=l(a,"UL",{});var dt=i(oe);Kr=l(dt,"LI",{});var P3=i(Kr);U_=n(P3,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),od=l(P3,"PRINCEADAM0001:0.7",{}),i(od).forEach(t),P3.forEach(t),M_=u(dt),Eu=l(dt,"LI",{});var pw=i(Eu);B_=n(pw,"In generation parameters and select the X/Y/Z plot script."),pw.forEach(t),j_=u(dt),We=l(dt,"LI",{});var Bs=i(We);W_=n(Bs,"Select "),Vr=l(Bs,"CODE",{class:!0});var hw=i(Vr);F_=n(hw,"Prompt SR"),hw.forEach(t),Y_=n(Bs," for Prompt Replace.  We\u2019re going to replace "),Qr=l(Bs,"CODE",{class:!0});var mw=i(Qr);X_=n(mw,"<princeadam0001:0.7>"),mw.forEach(t),Z_=n(Bs," with different epoch: "),Jr=l(Bs,"CODE",{class:!0});var gw=i(Jr);K_=n(gw,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),gw.forEach(t),Bs.forEach(t),V_=u(dt),$r=l(dt,"LI",{});var N3=i($r);Q_=n(N3,"Select a fast sampler like "),eo=l(N3,"CODE",{class:!0});var vw=i(eo);J_=n(vw,"DPM2 KARRAS"),vw.forEach(t),N3.forEach(t),$_=u(dt),ya=l(dt,"LI",{});var xu=i(ya);eb=n(xu,"CFG Scale set to "),to=l(xu,"CODE",{class:!0});var _w=i(to);tb=n(_w,"7"),_w.forEach(t),ab=n(xu," and Steps to "),ao=l(xu,"CODE",{class:!0});var bw=i(ao);sb=n(bw,"20"),bw.forEach(t),xu.forEach(t),dt.forEach(t),nd=u(a),Fe=l(a,"P",{});var Bn=i(Fe);lb=n(Bn,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),so=l(Bn,"CODE",{class:!0});var Ew=i(so);ib=n(Ew,"network_dim"),Ew.forEach(t),rb=n(Bn," and "),lo=l(Bn,"CODE",{class:!0});var yw=i(lo);ob=n(yw,"network_alpha"),yw.forEach(t),nb=n(Bn,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Bn.forEach(t),cd=u(a),me=l(a,"UL",{});var qa=i(me);ka=l(qa,"LI",{});var qu=i(ka);cb=n(qu,"Select "),io=l(qu,"CODE",{class:!0});var kw=i(io);ub=n(kw,"Prompt SR"),kw.forEach(t),fb=n(qu," for Prompt Replace.  We\u2019re going to replace the weights "),ro=l(qu,"CODE",{class:!0});var ww=i(ro);db=n(ww,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),ww.forEach(t),qu.forEach(t),pb=u(qa),Cs=l(qa,"LI",{});var fp=i(Cs);hb=n(fp,"Use Prompt SR to generate a variety of angles: Select "),oo=l(fp,"CODE",{class:!0});var Tw=i(oo);mb=n(Tw,"Prompt SR"),Tw.forEach(t),gb=n(fp," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),fp.forEach(t),vb=u(qa),yu=l(qa,"LI",{});var Rw=i(yu);_b=n(Rw,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),Rw.forEach(t),bb=u(qa),ku=l(qa,"LI",{});var Dw=i(ku);Eb=n(Dw,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),Dw.forEach(t),qa.forEach(t),ud=u(a),wa=l(a,"H4",{id:!0});var C3=i(wa);Ta=l(C3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Sw=i(Ta);wu=l(Sw,"SPAN",{class:!0}),i(wu).forEach(t),Sw.forEach(t),yb=n(C3,"Issues to look for"),C3.forEach(t),fd=u(a),ge=l(a,"UL",{});var Ga=i(ge);no=l(Ga,"LI",{});var x3=i(no);Tu=l(x3,"STRONG",{});var Aw=i(Tu);kb=n(Aw,"Undercooked:"),Aw.forEach(t),wb=n(x3," Lacks output, adjust unet learning rate or extend training duration."),x3.forEach(t),Tb=u(Ga),co=l(Ga,"LI",{});var q3=i(co);Ru=l(q3,"STRONG",{});var Ow=i(Ru);Rb=n(Ow,"Overcooked:"),Ow.forEach(t),Db=n(q3," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),q3.forEach(t),Sb=u(Ga),uo=l(Ga,"LI",{});var G3=i(uo);Du=l(G3,"STRONG",{});var Lw=i(Du);Ab=n(Lw,"Overfit:"),Lw.forEach(t),Ob=n(G3," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),G3.forEach(t),Lb=u(Ga),fo=l(Ga,"LI",{});var H3=i(fo);Su=l(H3,"STRONG",{});var Iw=i(Su);Ib=n(Iw,"Mismatched:"),Iw.forEach(t),zb=n(H3," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),H3.forEach(t),Ga.forEach(t),dd=u(a),po=l(a,"P",{});var zw=i(po);Pb=n(zw,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),zw.forEach(t),pd=u(a),xs=l(a,"P",{class:!0});var Pw=i(xs);qs=l(Pw,"IMG",{src:!0,alt:!0,class:!0}),Pw.forEach(t),hd=u(a),Ra=l(a,"H2",{id:!0});var U3=i(Ra);Da=l(U3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Nw=i(Da);Au=l(Nw,"SPAN",{class:!0}),i(Au).forEach(t),Nw.forEach(t),Nb=n(U3,"Troubleshooting"),U3.forEach(t),md=u(a),ho=l(a,"P",{});var Cw=i(ho);Cb=n(Cw,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),Cw.forEach(t),gd=u(a),Ye=l(a,"UL",{});var jn=i(Ye);Gs=l(jn,"LI",{});var dp=i(Gs);xb=n(dp,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),mo=l(dp,"CODE",{class:!0});var xw=i(mo);qb=n(xw,"200"),xw.forEach(t),Gb=n(dp," regularization images per training image."),dp.forEach(t),Hb=u(jn),Hs=l(jn,"LI",{});var pp=i(Hs);Ub=n(pp,"Repeats of regularization images, but may overfit more.  Increasing the "),go=l(pp,"CODE",{class:!0});var qw=i(go);Mb=n(qw,"repetition_count"),qw.forEach(t),Bb=n(pp," will cycle through the images more but the results may have results that overfit the model."),pp.forEach(t),jb=u(jn),Ou=l(jn,"LI",{});var Gw=i(Ou);Wb=n(Gw,"Create more regularization images without increasing repeats will help with the overfitting."),Gw.forEach(t),jn.forEach(t),vd=u(a),Et=l(a,"TABLE",{class:!0});var hp=i(Et);vo=l(hp,"THEAD",{class:!0});var Hw=i(vo);Xe=l(Hw,"TR",{class:!0});var Wn=i(Xe);_o=l(Wn,"TH",{class:!0});var Uw=i(_o);Fb=n(Uw,"Issue"),Uw.forEach(t),Yb=u(Wn),bo=l(Wn,"TH",{class:!0});var Mw=i(bo);Xb=n(Mw,"Situation"),Mw.forEach(t),Zb=u(Wn),Eo=l(Wn,"TH",{class:!0});var Bw=i(Eo);Kb=n(Bw,"Recommendation"),Bw.forEach(t),Wn.forEach(t),Hw.forEach(t),Vb=u(hp),ve=l(hp,"TBODY",{class:!0});var Ha=i(ve);Ze=l(Ha,"TR",{class:!0});var Fn=i(Ze);yo=l(Fn,"TD",{class:!0});var jw=i(yo);Qb=n(jw,"Varying quality"),jw.forEach(t),Jb=u(Fn),ko=l(Fn,"TD",{class:!0});var Ww=i(ko);$b=n(Ww,"Results differ from expectations"),Ww.forEach(t),eE=u(Fn),wo=l(Fn,"TD",{class:!0});var Fw=i(wo);tE=n(Fw,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),Fw.forEach(t),Fn.forEach(t),aE=u(Ha),Ke=l(Ha,"TR",{class:!0});var Yn=i(Ke);To=l(Yn,"TD",{class:!0});var Yw=i(To);sE=n(Yw,"Inadequate regularization for input data"),Yw.forEach(t),lE=u(Yn),Ro=l(Yn,"TD",{class:!0});var Xw=i(Ro);iE=n(Xw,"Lower input images, less regularization needed"),Xw.forEach(t),rE=u(Yn),Do=l(Yn,"TD",{class:!0});var Zw=i(Do);oE=n(Zw,"Reduce the number of input images or increasing the quantity of reg images."),Zw.forEach(t),Yn.forEach(t),nE=u(Ha),Ve=l(Ha,"TR",{class:!0});var Xn=i(Ve);So=l(Xn,"TD",{class:!0});var Kw=i(So);cE=n(Kw,"Overfitting due to repetition"),Kw.forEach(t),uE=u(Xn),Ao=l(Xn,"TD",{class:!0});var Vw=i(Ao);fE=n(Vw,"Repeats of reg images, risk of overfitting"),Vw.forEach(t),dE=u(Xn),Oo=l(Xn,"TD",{class:!0});var Qw=i(Oo);pE=n(Qw,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),Qw.forEach(t),Xn.forEach(t),hE=u(Ha),Qe=l(Ha,"TR",{class:!0});var Zn=i(Qe);Lo=l(Zn,"TD",{class:!0});var Jw=i(Lo);mE=n(Jw,"Mitigate overfitting while increasing diversity"),Jw.forEach(t),gE=u(Zn),Io=l(Zn,"TD",{class:!0});var $w=i(Io);vE=n($w,"Create more reg images without repeats"),$w.forEach(t),_E=u(Zn),zo=l(Zn,"TD",{class:!0});var e5=i(zo);bE=n(e5,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),e5.forEach(t),Zn.forEach(t),Ha.forEach(t),hp.forEach(t),_d=u(a),Sa=l(a,"H4",{id:!0});var M3=i(Sa);Aa=l(M3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var t5=i(Aa);Lu=l(t5,"SPAN",{class:!0}),i(Lu).forEach(t),t5.forEach(t),EE=n(M3,"More Solutions"),M3.forEach(t),bd=u(a),Po=l(a,"P",{});var a5=i(Po);yE=n(a5,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),a5.forEach(t),Ed=u(a),yt=l(a,"TABLE",{class:!0});var mp=i(yt);No=l(mp,"THEAD",{class:!0});var s5=i(No);Je=l(s5,"TR",{class:!0});var Kn=i(Je);Co=l(Kn,"TH",{class:!0});var l5=i(Co);kE=n(l5,"Symptom"),l5.forEach(t),wE=u(Kn),xo=l(Kn,"TH",{class:!0});var i5=i(xo);TE=n(i5,"Likely Cause"),i5.forEach(t),RE=u(Kn),qo=l(Kn,"TH",{class:!0});var r5=i(qo);DE=n(r5,"Solution"),r5.forEach(t),Kn.forEach(t),s5.forEach(t),SE=u(mp),j=l(mp,"TBODY",{class:!0});var V=i(j);$e=l(V,"TR",{class:!0});var Vn=i($e);Go=l(Vn,"TD",{class:!0});var o5=i(Go);AE=n(o5,"Plastic texture persists"),o5.forEach(t),OE=u(Vn),Ho=l(Vn,"TD",{class:!0});var n5=i(Ho);LE=n(n5,"Insufficient human reg images"),n5.forEach(t),IE=u(Vn),Uo=l(Vn,"TD",{class:!0});var c5=i(Uo);zE=n(c5,"Add real photos to reg set"),c5.forEach(t),Vn.forEach(t),PE=u(V),et=l(V,"TR",{class:!0});var Qn=i(et);Mo=l(Qn,"TD",{class:!0});var u5=i(Mo);NE=n(u5,"Loss plateaus early"),u5.forEach(t),CE=u(Qn),Bo=l(Qn,"TD",{class:!0});var f5=i(Bo);xE=n(f5,"Learning rate too low"),f5.forEach(t),qE=u(Qn),jo=l(Qn,"TD",{class:!0});var d5=i(jo);GE=n(d5,"Increase LR by 10x"),d5.forEach(t),Qn.forEach(t),HE=u(V),tt=l(V,"TR",{class:!0});var Jn=i(tt);Wo=l(Jn,"TD",{class:!0});var p5=i(Wo);UE=n(p5,"Features blurry"),p5.forEach(t),ME=u(Jn),Fo=l(Jn,"TD",{class:!0});var h5=i(Fo);BE=n(h5,"Network dimension too small"),h5.forEach(t),jE=u(Jn),Yo=l(Jn,"TD",{class:!0});var m5=i(Yo);WE=n(m5,"Increase network_dim to 64+"),m5.forEach(t),Jn.forEach(t),FE=u(V),at=l(V,"TR",{class:!0});var $n=i(at);Xo=l($n,"TD",{class:!0});var g5=i(Xo);YE=n(g5,"Color distortion"),g5.forEach(t),XE=u($n),Zo=l($n,"TD",{class:!0});var v5=i(Zo);ZE=n(v5,"Noise offset conflict"),v5.forEach(t),KE=u($n),Ko=l($n,"TD",{class:!0});var _5=i(Ko);VE=n(_5,"Try noise_offset 0.05-0.1"),_5.forEach(t),$n.forEach(t),QE=u(V),st=l(V,"TR",{class:!0});var ec=i(st);Vo=l(ec,"TD",{class:!0});var b5=i(Vo);JE=n(b5,"Overly stylized outputs"),b5.forEach(t),$E=u(ec),Qo=l(ec,"TD",{class:!0});var E5=i(Qo);ey=n(E5,"Reg image style mismatch"),E5.forEach(t),ty=u(ec),Jo=l(ec,"TD",{class:!0});var y5=i(Jo);ay=n(y5,"Regenerate reg images with base model"),y5.forEach(t),ec.forEach(t),sy=u(V),lt=l(V,"TR",{class:!0});var tc=i(lt);$o=l(tc,"TD",{class:!0});var k5=i($o);ly=n(k5,"Training instability"),k5.forEach(t),iy=u(tc),en=l(tc,"TD",{class:!0});var w5=i(en);ry=n(w5,"Batch size too large"),w5.forEach(t),oy=u(tc),tn=l(tc,"TD",{class:!0});var T5=i(tn);ny=n(T5,"Reduce batch_size to 1-2"),T5.forEach(t),tc.forEach(t),cy=u(V),it=l(V,"TR",{class:!0});var ac=i(it);an=l(ac,"TD",{class:!0});var R5=i(an);uy=n(R5,"Slow convergence"),R5.forEach(t),fy=u(ac),sn=l(ac,"TD",{class:!0});var D5=i(sn);dy=n(D5,"Network_alpha too high"),D5.forEach(t),py=u(ac),ln=l(ac,"TD",{class:!0});var S5=i(ln);hy=n(S5,"Set alpha = dim/2 (e.g., 64/2 = 32)"),S5.forEach(t),ac.forEach(t),my=u(V),rt=l(V,"TR",{class:!0});var sc=i(rt);rn=l(sc,"TD",{class:!0});var A5=i(rn);gy=n(A5,"Loss divergence"),A5.forEach(t),vy=u(sc),on=l(sc,"TD",{class:!0});var O5=i(on);_y=n(O5,"Text encoder LR too high"),O5.forEach(t),by=u(sc),nn=l(sc,"TD",{class:!0});var L5=i(nn);Ey=n(L5,"Reduce text_encoder_lr by 10x"),L5.forEach(t),sc.forEach(t),yy=u(V),ot=l(V,"TR",{class:!0});var lc=i(ot);cn=l(lc,"TD",{class:!0});var I5=i(cn);ky=n(I5,"Poor prompt adherence"),I5.forEach(t),wy=u(lc),un=l(lc,"TD",{class:!0});var z5=i(un);Ty=n(z5,"Clip skip too high"),z5.forEach(t),Ry=u(lc),fn=l(lc,"TD",{class:!0});var P5=i(fn);Dy=n(P5,"Reduce clip_skip to 1-2"),P5.forEach(t),lc.forEach(t),Sy=u(V),nt=l(V,"TR",{class:!0});var ic=i(nt);dn=l(ic,"TD",{class:!0});var N5=i(dn);Ay=n(N5,"Memory errors"),N5.forEach(t),Oy=u(ic),pn=l(ic,"TD",{class:!0});var C5=i(pn);Ly=n(C5,"Resolution too high"),C5.forEach(t),Iy=u(ic),hn=l(ic,"TD",{class:!0});var x5=i(hn);zy=n(x5,"Reduce to 512-768px, enable gradient checkpointing"),x5.forEach(t),ic.forEach(t),V.forEach(t),mp.forEach(t),yd=u(a),Oa=l(a,"H2",{id:!0});var B3=i(Oa);La=l(B3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var q5=i(La);Iu=l(q5,"SPAN",{class:!0}),i(Iu).forEach(t),q5.forEach(t),Py=n(B3,"Results"),B3.forEach(t),kd=u(a),mn=l(a,"P",{});var G5=i(mn);Ny=n(G5,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),G5.forEach(t),wd=u(a),gn=l(a,"P",{});var H5=i(gn);Cy=n(H5,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),H5.forEach(t),Td=u(a),Us=l(a,"P",{class:!0});var U5=i(Us);Ms=l(U5,"IMG",{src:!0,alt:!0,class:!0}),U5.forEach(t),Rd=u(a),vn=l(a,"P",{});var M5=i(vn);xy=n(M5,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),M5.forEach(t),Dd=u(a),kt=l(a,"H2",{id:!0,class:!0});var j3=i(kt);Ia=l(j3,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var B5=i(Ia);zu=l(B5,"SPAN",{class:!0}),i(zu).forEach(t),B5.forEach(t),qy=n(j3,"spacelab"),j3.forEach(t),Sd=u(a),be&&be.l(a),Ad=rc(),this.h()},h(){r(R,"class","icon icon-link"),r(y,"aria-hidden","true"),r(y,"tabindex","-1"),r(y,"href","#what-are-regularization-images"),r(b,"id","what-are-regularization-images"),r(P,"class","svelte-1ti8m27"),r(L,"class","svelte-1ti8m27"),r(G,"class","svelte-1ti8m27"),r(_e,"class","svelte-1ti8m27"),r(Ys,"class","svelte-1ti8m27"),r(T,"class","svelte-1ti8m27"),r(U,"class","svelte-1ti8m27"),r(Xs,"class","svelte-1ti8m27"),r(Zs,"class","svelte-1ti8m27"),r(Ks,"class","svelte-1ti8m27"),r(ke,"class","svelte-1ti8m27"),r(Vs,"class","svelte-1ti8m27"),r(Qs,"class","svelte-1ti8m27"),r(Js,"class","svelte-1ti8m27"),r(we,"class","svelte-1ti8m27"),r($s,"class","svelte-1ti8m27"),r(el,"class","svelte-1ti8m27"),r(tl,"class","svelte-1ti8m27"),r(Te,"class","svelte-1ti8m27"),r(ye,"class","svelte-1ti8m27"),r(X,"class","svelte-1ti8m27"),r(ll,"class","svelte-1ti8m27"),r(Fa,"class","svelte-1ti8m27"),r(hc,"class","icon icon-link"),r(Rt,"aria-hidden","true"),r(Rt,"tabindex","-1"),r(Rt,"href","#divergence"),r(Tt,"id","divergence"),r(ol,"class","svelte-1ti8m27"),r(yc,"class","icon icon-link"),r(At,"aria-hidden","true"),r(At,"tabindex","-1"),r(At,"href","#overfitting"),r(St,"id","overfitting"),r(Dc,"class","icon icon-link"),r(Lt,"aria-hidden","true"),r(Lt,"tabindex","-1"),r(Lt,"href","#key-differences"),r(Ot,"id","key-differences"),r(pl,"class","svelte-1ti8m27"),r(hl,"class","svelte-1ti8m27"),r(ml,"class","svelte-1ti8m27"),r(Ae,"class","svelte-1ti8m27"),r(dl,"class","svelte-1ti8m27"),r(gl,"class","svelte-1ti8m27"),r(vl,"class","svelte-1ti8m27"),r(_l,"class","svelte-1ti8m27"),r(Oe,"class","svelte-1ti8m27"),r(bl,"class","svelte-1ti8m27"),r(El,"class","svelte-1ti8m27"),r(yl,"class","svelte-1ti8m27"),r(Le,"class","svelte-1ti8m27"),r(kl,"class","svelte-1ti8m27"),r(wl,"class","svelte-1ti8m27"),r(Tl,"class","svelte-1ti8m27"),r(Ie,"class","svelte-1ti8m27"),r(Rl,"class","svelte-1ti8m27"),r(Dl,"class","svelte-1ti8m27"),r(Sl,"class","svelte-1ti8m27"),r(ze,"class","svelte-1ti8m27"),r(ue,"class","svelte-1ti8m27"),r(mt,"class","svelte-1ti8m27"),r(Cc,"class","icon icon-link"),r(zt,"aria-hidden","true"),r(zt,"tabindex","-1"),r(zt,"href","#preventing-divergence"),r(It,"id","preventing-divergence"),r(Ol,"class","svelte-1ti8m27"),r(Ll,"class","svelte-1ti8m27"),r(Pt,"class","svelte-1ti8m27"),r(Al,"class","svelte-1ti8m27"),r(Il,"class","svelte-1ti8m27"),r(zl,"class","svelte-1ti8m27"),r(Nt,"class","svelte-1ti8m27"),r(Pl,"class","svelte-1ti8m27"),r(Nl,"class","svelte-1ti8m27"),r(Ct,"class","svelte-1ti8m27"),r(Cl,"class","svelte-1ti8m27"),r(xl,"class","svelte-1ti8m27"),r(xt,"class","svelte-1ti8m27"),r(ql,"class","svelte-1ti8m27"),r(Gl,"class","svelte-1ti8m27"),r(qt,"class","svelte-1ti8m27"),r(fe,"class","svelte-1ti8m27"),r(gt,"class","svelte-1ti8m27"),r(Uc,"class","icon icon-link"),r(Ht,"aria-hidden","true"),r(Ht,"tabindex","-1"),r(Ht,"href","#implementing-these-strategies"),r(Gt,"id","implementing-these-strategies"),r(Qa,"class","language-python"),r(Ja,"class","language-python"),r(Mc,"class","icon icon-link"),r(Mt,"aria-hidden","true"),r(Mt,"tabindex","-1"),r(Mt,"href","#data-considerations"),r(Ut,"id","data-considerations"),r(Ml,"class","svelte-1ti8m27"),r(Bl,"class","svelte-1ti8m27"),r(jl,"class","svelte-1ti8m27"),r(Pe,"class","svelte-1ti8m27"),r(Ul,"class","svelte-1ti8m27"),r(Wl,"class","svelte-1ti8m27"),r(Fl,"class","svelte-1ti8m27"),r(Yl,"class","svelte-1ti8m27"),r(Ne,"class","svelte-1ti8m27"),r(Xl,"class","svelte-1ti8m27"),r(Zl,"class","svelte-1ti8m27"),r(Kl,"class","svelte-1ti8m27"),r(Ce,"class","svelte-1ti8m27"),r(Vl,"class","svelte-1ti8m27"),r(Ql,"class","svelte-1ti8m27"),r(Jl,"class","svelte-1ti8m27"),r(xe,"class","svelte-1ti8m27"),r($l,"class","svelte-1ti8m27"),r(ei,"class","svelte-1ti8m27"),r(ti,"class","svelte-1ti8m27"),r(qe,"class","svelte-1ti8m27"),r(de,"class","svelte-1ti8m27"),r(vt,"class","svelte-1ti8m27"),r(Bc,"class","icon icon-link"),r(jt,"aria-hidden","true"),r(jt,"tabindex","-1"),r(jt,"href","#monitoring-tips"),r(Bt,"id","monitoring-tips"),r($a,"href","https://www.tensorflow.org/tensorboard"),r($a,"rel","nofollow"),r(Xc,"class","icon icon-link"),r(Ft,"aria-hidden","true"),r(Ft,"tabindex","-1"),r(Ft,"href","#generating-regularization-images"),r(Wt,"id","generating-regularization-images"),r(si,"class","svelte-1ti8m27"),r(li,"class","svelte-1ti8m27"),r(ii,"class","svelte-1ti8m27"),r(ri,"class","svelte-1ti8m27"),r(ni,"class","svelte-1ti8m27"),r(oi,"class","svelte-1ti8m27"),r(es,"class","svelte-1ti8m27"),r(Zc,"class","icon icon-link"),r(Zt,"aria-hidden","true"),r(Zt,"tabindex","-1"),r(Zt,"href","#important-considerations"),r(Xt,"id","important-considerations"),r(tu,"class","icon icon-link"),r(Vt,"aria-hidden","true"),r(Vt,"tabindex","-1"),r(Vt,"href","#generate-using-stable-diffusion-web-ui"),r(Kt,"id","generate-using-stable-diffusion-web-ui"),r(is,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),r(is,"rel","nofollow"),r(ui,"class","svelte-1ti8m27"),r(fi,"class","svelte-1ti8m27"),r(pi,"class","svelte-1ti8m27"),r(hi,"class","svelte-1ti8m27"),r(mi,"class","svelte-1ti8m27"),r(gi,"class","svelte-1ti8m27"),r(vi,"class","svelte-1ti8m27"),r(_i,"class","svelte-1ti8m27"),r(bi,"class","svelte-1ti8m27"),r(Ei,"class","svelte-1ti8m27"),r(yi,"class","svelte-1ti8m27"),r(ki,"class","svelte-1ti8m27"),r(wi,"class","svelte-1ti8m27"),r(Ti,"class","svelte-1ti8m27"),r(Ri,"class","svelte-1ti8m27"),r(Di,"class","svelte-1ti8m27"),r(Si,"class","svelte-1ti8m27"),r(Ai,"class","svelte-1ti8m27"),r(Oi,"class","svelte-1ti8m27"),r(Li,"class","svelte-1ti8m27"),r(Ii,"class","svelte-1ti8m27"),r(zi,"class","svelte-1ti8m27"),r(Pi,"class","svelte-1ti8m27"),r(Ni,"class","svelte-1ti8m27"),r(Ci,"class","svelte-1ti8m27"),r(xi,"class","svelte-1ti8m27"),r(qi,"class","svelte-1ti8m27"),r(Hi,"class","svelte-1ti8m27"),r(Ui,"class","svelte-1ti8m27"),r(Mi,"class","svelte-1ti8m27"),r(Bi,"class","svelte-1ti8m27"),r(ji,"class","svelte-1ti8m27"),r(cu,"class","icon icon-link"),r(ea,"aria-hidden","true"),r(ea,"tabindex","-1"),r(ea,"href","#download-images"),r($t,"id","download-images"),r(ns,"href","https://huggingface.co/3ee"),r(ns,"rel","nofollow"),r(cs,"href","https://github.com/Luehrsen/sd_regularization_images"),r(cs,"rel","nofollow"),r(us,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),r(us,"rel","nofollow"),r(fs,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),r(fs,"rel","nofollow"),r(uu,"class","icon icon-link"),r(aa,"aria-hidden","true"),r(aa,"tabindex","-1"),r(aa,"href","#captioning-regularization-images"),r(ta,"id","captioning-regularization-images"),r(Ki,"class","svelte-1ti8m27"),r(ds,"class","language-shell"),r(Vi,"class","svelte-1ti8m27"),r(Qi,"class","svelte-1ti8m27"),r(Ji,"class","svelte-1ti8m27"),r($i,"class","svelte-1ti8m27"),r(fu,"class","icon icon-link"),r(ra,"aria-hidden","true"),r(ra,"tabindex","-1"),r(ra,"href","#training-a-lora"),r(ia,"id","training-a-lora"),r(hs,"href","https://github.com/kohya-ss/sd-scripts"),r(hs,"rel","nofollow"),r(gs,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),r(gs,"rel","nofollow"),r(na,"class","svelte-1ti8m27"),r(ms,"class","svelte-1ti8m27"),r(du,"class","icon icon-link"),r(ua,"aria-hidden","true"),r(ua,"tabindex","-1"),r(ua,"href","#directory-setup"),r(ca,"id","directory-setup"),r(er,"class","svelte-1ti8m27"),r(vs,"class","language-json"),r(_s,"class","language-xml"),r(ar,"class","svelte-1ti8m27"),r(sr,"class","svelte-1ti8m27"),r(lr,"class","svelte-1ti8m27"),r(ir,"class","svelte-1ti8m27"),js(Es.src,V3="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||r(Es,"src",V3),r(Es,"alt","image"),r(Es,"class","svelte-1ti8m27"),r(bs,"class","svelte-1ti8m27"),r(vu,"class","icon icon-link"),r(ha,"aria-hidden","true"),r(ha,"tabindex","-1"),r(ha,"href","#training-settings"),r(pa,"id","training-settings"),r(ur,"class","svelte-1ti8m27"),r(fr,"class","svelte-1ti8m27"),r(pr,"class","svelte-1ti8m27"),r(hr,"class","svelte-1ti8m27"),r(mr,"class","svelte-1ti8m27"),r(gr,"class","svelte-1ti8m27"),r(vr,"class","svelte-1ti8m27"),r(ie,"class","svelte-1ti8m27"),r(dr,"class","svelte-1ti8m27"),r(br,"class","svelte-1ti8m27"),r(Er,"class","svelte-1ti8m27"),r(yr,"class","svelte-1ti8m27"),r(kr,"class","svelte-1ti8m27"),r(wr,"class","svelte-1ti8m27"),r(re,"class","svelte-1ti8m27"),r(_r,"class","svelte-1ti8m27"),r(bt,"class","svelte-1ti8m27"),r(ys,"class","language-json"),r(Dr,"class","svelte-1ti8m27"),r(Ar,"class","svelte-1ti8m27"),r(Lr,"class","svelte-1ti8m27"),r(zr,"class","svelte-1ti8m27"),r(Nr,"class","svelte-1ti8m27"),r(xr,"class","svelte-1ti8m27"),r(Gr,"class","svelte-1ti8m27"),r(Ur,"class","svelte-1ti8m27"),r(Br,"class","svelte-1ti8m27"),r(Wr,"class","svelte-1ti8m27"),r(Yr,"class","svelte-1ti8m27"),r(_u,"class","icon icon-link"),r(ga,"aria-hidden","true"),r(ga,"tabindex","-1"),r(ga,"href","#fine-tuning"),r(ma,"id","fine-tuning"),r(bu,"class","icon icon-link"),r(_a,"aria-hidden","true"),r(_a,"tabindex","-1"),r(_a,"href","#workflow-with-auto1111-webui"),r(va,"id","workflow-with-auto1111-webui"),r(Ns,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),r(Ns,"rel","nofollow"),r(Zr,"class","svelte-1ti8m27"),r(Vr,"class","svelte-1ti8m27"),r(Qr,"class","svelte-1ti8m27"),r(Jr,"class","svelte-1ti8m27"),r(eo,"class","svelte-1ti8m27"),r(to,"class","svelte-1ti8m27"),r(ao,"class","svelte-1ti8m27"),r(so,"class","svelte-1ti8m27"),r(lo,"class","svelte-1ti8m27"),r(io,"class","svelte-1ti8m27"),r(ro,"class","svelte-1ti8m27"),r(oo,"class","svelte-1ti8m27"),r(wu,"class","icon icon-link"),r(Ta,"aria-hidden","true"),r(Ta,"tabindex","-1"),r(Ta,"href","#issues-to-look-for"),r(wa,"id","issues-to-look-for"),js(qs.src,Q3="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||r(qs,"src",Q3),r(qs,"alt","image"),r(qs,"class","svelte-1ti8m27"),r(xs,"class","svelte-1ti8m27"),r(Au,"class","icon icon-link"),r(Da,"aria-hidden","true"),r(Da,"tabindex","-1"),r(Da,"href","#troubleshooting"),r(Ra,"id","troubleshooting"),r(mo,"class","svelte-1ti8m27"),r(go,"class","svelte-1ti8m27"),r(_o,"class","svelte-1ti8m27"),r(bo,"class","svelte-1ti8m27"),r(Eo,"class","svelte-1ti8m27"),r(Xe,"class","svelte-1ti8m27"),r(vo,"class","svelte-1ti8m27"),r(yo,"class","svelte-1ti8m27"),r(ko,"class","svelte-1ti8m27"),r(wo,"class","svelte-1ti8m27"),r(Ze,"class","svelte-1ti8m27"),r(To,"class","svelte-1ti8m27"),r(Ro,"class","svelte-1ti8m27"),r(Do,"class","svelte-1ti8m27"),r(Ke,"class","svelte-1ti8m27"),r(So,"class","svelte-1ti8m27"),r(Ao,"class","svelte-1ti8m27"),r(Oo,"class","svelte-1ti8m27"),r(Ve,"class","svelte-1ti8m27"),r(Lo,"class","svelte-1ti8m27"),r(Io,"class","svelte-1ti8m27"),r(zo,"class","svelte-1ti8m27"),r(Qe,"class","svelte-1ti8m27"),r(ve,"class","svelte-1ti8m27"),r(Et,"class","svelte-1ti8m27"),r(Lu,"class","icon icon-link"),r(Aa,"aria-hidden","true"),r(Aa,"tabindex","-1"),r(Aa,"href","#more-solutions"),r(Sa,"id","more-solutions"),r(Co,"class","svelte-1ti8m27"),r(xo,"class","svelte-1ti8m27"),r(qo,"class","svelte-1ti8m27"),r(Je,"class","svelte-1ti8m27"),r(No,"class","svelte-1ti8m27"),r(Go,"class","svelte-1ti8m27"),r(Ho,"class","svelte-1ti8m27"),r(Uo,"class","svelte-1ti8m27"),r($e,"class","svelte-1ti8m27"),r(Mo,"class","svelte-1ti8m27"),r(Bo,"class","svelte-1ti8m27"),r(jo,"class","svelte-1ti8m27"),r(et,"class","svelte-1ti8m27"),r(Wo,"class","svelte-1ti8m27"),r(Fo,"class","svelte-1ti8m27"),r(Yo,"class","svelte-1ti8m27"),r(tt,"class","svelte-1ti8m27"),r(Xo,"class","svelte-1ti8m27"),r(Zo,"class","svelte-1ti8m27"),r(Ko,"class","svelte-1ti8m27"),r(at,"class","svelte-1ti8m27"),r(Vo,"class","svelte-1ti8m27"),r(Qo,"class","svelte-1ti8m27"),r(Jo,"class","svelte-1ti8m27"),r(st,"class","svelte-1ti8m27"),r($o,"class","svelte-1ti8m27"),r(en,"class","svelte-1ti8m27"),r(tn,"class","svelte-1ti8m27"),r(lt,"class","svelte-1ti8m27"),r(an,"class","svelte-1ti8m27"),r(sn,"class","svelte-1ti8m27"),r(ln,"class","svelte-1ti8m27"),r(it,"class","svelte-1ti8m27"),r(rn,"class","svelte-1ti8m27"),r(on,"class","svelte-1ti8m27"),r(nn,"class","svelte-1ti8m27"),r(rt,"class","svelte-1ti8m27"),r(cn,"class","svelte-1ti8m27"),r(un,"class","svelte-1ti8m27"),r(fn,"class","svelte-1ti8m27"),r(ot,"class","svelte-1ti8m27"),r(dn,"class","svelte-1ti8m27"),r(pn,"class","svelte-1ti8m27"),r(hn,"class","svelte-1ti8m27"),r(nt,"class","svelte-1ti8m27"),r(j,"class","svelte-1ti8m27"),r(yt,"class","svelte-1ti8m27"),r(Iu,"class","icon icon-link"),r(La,"aria-hidden","true"),r(La,"tabindex","-1"),r(La,"href","#results"),r(Oa,"id","results"),js(Ms.src,J3="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||r(Ms,"src",J3),r(Ms,"alt","image"),r(Ms,"class","svelte-1ti8m27"),r(Us,"class","svelte-1ti8m27"),r(zu,"class","icon icon-link"),r(Ia,"aria-hidden","true"),r(Ia,"tabindex","-1"),r(Ia,"href","#spacelab"),r(kt,"id","spacelab"),r(kt,"class","svelte-1ti8m27")},m(a,p){f(a,d,p),e(d,g),f(a,m,p),Ba(h,a,p),f(a,v,p),f(a,b,p),e(b,y),e(y,R),e(b,D),f(a,k,p),f(a,E,p),e(E,w),f(a,z,p),f(a,L,p),e(L,P),e(P,q),f(a,S,p),Ba(O,a,p),f(a,A,p),f(a,N,p),e(N,C),f(a,Q,p),f(a,W,p),e(W,F),f(a,B,p),f(a,x,p),e(x,I),f(a,H,p),f(a,X,p),e(X,U),e(U,T),e(T,G),e(G,Wa),e(T,Ws),e(T,_e),e(_e,Fs),e(T,Ep),e(T,Ys),e(Ys,yp),e(X,kp),e(X,ye),e(ye,ke),e(ke,Xs),e(Xs,oc),e(oc,wp),e(ke,Tp),e(ke,Zs),e(Zs,Rp),e(ke,Dp),e(ke,Ks),e(Ks,Sp),e(ye,Ap),e(ye,we),e(we,Vs),e(Vs,nc),e(nc,Op),e(we,Lp),e(we,Qs),e(Qs,Ip),e(we,zp),e(we,Js),e(Js,Pp),e(ye,Np),e(ye,Te),e(Te,$s),e($s,cc),e(cc,Cp),e(Te,xp),e(Te,el),e(el,qp),e(Te,Gp),e(Te,tl),e(tl,Hp),f(a,Gu,p),f(a,al,p),e(al,Up),f(a,Hu,p),f(a,sl,p),e(sl,Mp),f(a,Uu,p),f(a,Fa,p),e(Fa,ll),e(ll,Bp),f(a,Mu,p),f(a,Ya,p),e(Ya,uc),e(uc,jp),e(Ya,Wp),f(a,Bu,p),f(a,Xa,p),e(Xa,fc),e(fc,Fp),e(Xa,Yp),f(a,ju,p),f(a,Za,p),e(Za,dc),e(dc,Xp),e(Za,Zp),f(a,Wu,p),f(a,Ka,p),e(Ka,pc),e(pc,Kp),e(Ka,Vp),f(a,Fu,p),f(a,Tt,p),e(Tt,Rt),e(Rt,hc),e(Tt,Qp),f(a,Yu,p),f(a,Va,p),e(Va,mc),e(mc,Jp),e(Va,$p),f(a,Xu,p),f(a,Re,p),e(Re,eh),e(Re,gc),e(gc,th),e(Re,ah),e(Re,vc),e(vc,sh),e(Re,lh),f(a,Zu,p),f(a,De,p),e(De,il),e(il,_c),e(_c,ih),e(il,rh),e(De,oh),e(De,rl),e(rl,bc),e(bc,nh),e(rl,ch),e(De,uh),e(De,Dt),e(Dt,Ec),e(Ec,fh),e(Dt,dh),e(Dt,ol),e(ol,ph),e(Dt,hh),f(a,Ku,p),f(a,St,p),e(St,At),e(At,yc),e(St,kc),e(kc,mh),f(a,Vu,p),f(a,nl,p),e(nl,gh),f(a,Qu,p),f(a,Se,p),e(Se,cl),e(cl,wc),e(wc,vh),e(cl,_h),e(Se,bh),e(Se,ul),e(ul,Tc),e(Tc,Eh),e(ul,yh),e(Se,kh),e(Se,fl),e(fl,Rc),e(Rc,wh),e(fl,Th),f(a,Ju,p),f(a,Ot,p),e(Ot,Lt),e(Lt,Dc),e(Ot,Sc),e(Sc,Rh),f(a,$u,p),f(a,mt,p),e(mt,dl),e(dl,Ae),e(Ae,pl),e(pl,Ac),e(Ac,Dh),e(Ae,Sh),e(Ae,hl),e(hl,Oc),e(Oc,Ah),e(Ae,Oh),e(Ae,ml),e(ml,Lc),e(Lc,Lh),e(mt,Ih),e(mt,ue),e(ue,Oe),e(Oe,gl),e(gl,Ic),e(Ic,zh),e(Oe,Ph),e(Oe,vl),e(vl,Nh),e(Oe,Ch),e(Oe,_l),e(_l,xh),e(ue,qh),e(ue,Le),e(Le,bl),e(bl,zc),e(zc,Gh),e(Le,Hh),e(Le,El),e(El,Uh),e(Le,Mh),e(Le,yl),e(yl,Bh),e(ue,jh),e(ue,Ie),e(Ie,kl),e(kl,Pc),e(Pc,Wh),e(Ie,Fh),e(Ie,wl),e(wl,Yh),e(Ie,Xh),e(Ie,Tl),e(Tl,Zh),e(ue,Kh),e(ue,ze),e(ze,Rl),e(Rl,Nc),e(Nc,Vh),e(ze,Qh),e(ze,Dl),e(Dl,Jh),e(ze,$h),e(ze,Sl),e(Sl,em),f(a,ef,p),f(a,It,p),e(It,zt),e(zt,Cc),e(It,tm),f(a,tf,p),f(a,gt,p),e(gt,Al),e(Al,Pt),e(Pt,Ol),e(Ol,am),e(Pt,sm),e(Pt,Ll),e(Ll,lm),e(gt,im),e(gt,fe),e(fe,Nt),e(Nt,Il),e(Il,xc),e(xc,rm),e(Nt,om),e(Nt,zl),e(zl,nm),e(fe,cm),e(fe,Ct),e(Ct,Pl),e(Pl,qc),e(qc,um),e(Ct,fm),e(Ct,Nl),e(Nl,dm),e(fe,pm),e(fe,xt),e(xt,Cl),e(Cl,Gc),e(Gc,hm),e(xt,mm),e(xt,xl),e(xl,gm),e(fe,vm),e(fe,qt),e(qt,ql),e(ql,Hc),e(Hc,_m),e(qt,bm),e(qt,Gl),e(Gl,Em),f(a,af,p),f(a,Hl,p),e(Hl,ym),f(a,sf,p),f(a,Gt,p),e(Gt,Ht),e(Ht,Uc),e(Gt,km),f(a,lf,p),f(a,Qa,p),Qa.innerHTML=J5,f(a,rf,p),f(a,Ja,p),Ja.innerHTML=$5,f(a,of,p),f(a,Ut,p),e(Ut,Mt),e(Mt,Mc),e(Ut,wm),f(a,nf,p),f(a,vt,p),e(vt,Ul),e(Ul,Pe),e(Pe,Ml),e(Ml,Tm),e(Pe,Rm),e(Pe,Bl),e(Bl,Dm),e(Pe,Sm),e(Pe,jl),e(jl,Am),e(vt,Om),e(vt,de),e(de,Ne),e(Ne,Wl),e(Wl,Lm),e(Ne,Im),e(Ne,Fl),e(Fl,zm),e(Ne,Pm),e(Ne,Yl),e(Yl,Nm),e(de,Cm),e(de,Ce),e(Ce,Xl),e(Xl,xm),e(Ce,qm),e(Ce,Zl),e(Zl,Gm),e(Ce,Hm),e(Ce,Kl),e(Kl,Um),e(de,Mm),e(de,xe),e(xe,Vl),e(Vl,Bm),e(xe,jm),e(xe,Ql),e(Ql,Wm),e(xe,Fm),e(xe,Jl),e(Jl,Ym),e(de,Xm),e(de,qe),e(qe,$l),e($l,Zm),e(qe,Km),e(qe,ei),e(ei,Vm),e(qe,Qm),e(qe,ti),e(ti,Jm),f(a,cf,p),f(a,Bt,p),e(Bt,jt),e(jt,Bc),e(Bt,$m),f(a,uf,p),f(a,le,p),e(le,ai),e(ai,eg),e(ai,$a),e($a,tg),e(le,ag),e(le,jc),e(jc,sg),e(le,lg),e(le,Wc),e(Wc,ig),e(le,rg),e(le,Fc),e(Fc,og),e(le,ng),e(le,Yc),e(Yc,cg),f(a,ff,p),f(a,Wt,p),e(Wt,Ft),e(Ft,Xc),e(Wt,ug),f(a,df,p),f(a,Yt,p),e(Yt,fg),e(Yt,si),e(si,dg),e(Yt,pg),f(a,pf,p),f(a,pe,p),e(pe,hg),e(pe,li),e(li,mg),e(pe,gg),e(pe,ii),e(ii,vg),e(pe,_g),e(pe,ri),e(ri,bg),e(pe,Eg),f(a,hf,p),f(a,es,p),e(es,oi),e(oi,ni),e(ni,yg),f(a,mf,p),f(a,ci,p),e(ci,kg),f(a,gf,p),f(a,Xt,p),e(Xt,Zt),e(Zt,Zc),e(Xt,wg),f(a,vf,p),f(a,Ge,p),e(Ge,Kc),e(Kc,ts),e(ts,Vc),e(Vc,Tg),e(ts,Rg),e(ts,Dg),e(Ge,Sg),e(Ge,Qc),e(Qc,as),e(as,Jc),e(Jc,Ag),e(as,Og),e(as,Lg),e(Ge,Ig),e(Ge,$c),e($c,ss),e(ss,eu),e(eu,zg),e(ss,Pg),e(ss,Ng),f(a,_f,p),Ba(ls,a,p),f(a,bf,p),f(a,Kt,p),e(Kt,Vt),e(Vt,tu),e(Kt,Cg),f(a,Ef,p),f(a,Qt,p),e(Qt,xg),e(Qt,is),e(is,qg),e(Qt,Gg),f(a,yf,p),f(a,He,p),e(He,Hg),e(He,ui),e(ui,Ug),e(He,Mg),e(He,fi),e(fi,Bg),e(He,jg),f(a,kf,p),f(a,J,p),e(J,au),e(au,di),e(di,Wg),e(di,pi),e(pi,Fg),e(J,Yg),e(J,su),e(su,rs),e(rs,Xg),e(rs,hi),e(hi,Zg),e(rs,Kg),e(J,Vg),e(J,lu),e(lu,Z),e(Z,Qg),e(Z,mi),e(mi,Jg),e(Z,$g),e(Z,gi),e(gi,ev),e(Z,tv),e(Z,vi),e(vi,av),e(Z,sv),e(Z,_i),e(_i,lv),e(Z,iv),e(Z,bi),e(bi,rv),e(Z,ov),e(Z,Ei),e(Ei,nv),e(Z,cv),e(Z,yi),e(yi,uv),e(Z,fv),e(Z,ki),e(ki,dv),e(J,pv),e(J,iu),e(iu,$),e($,hv),e($,wi),e(wi,mv),e($,gv),e($,Ti),e(Ti,vv),e($,_v),e($,Ri),e(Ri,bv),e($,Ev),e($,Di),e(Di,yv),e($,kv),e($,Si),e(Si,wv),e($,Tv),e($,Ai),e(Ai,Rv),e($,Dv),e($,Oi),e(Oi,Sv),e(J,Av),e(J,ru),e(ru,K),e(K,Ov),e(K,Li),e(Li,Lv),e(K,Iv),e(K,Ii),e(Ii,zv),e(K,Pv),e(K,zi),e(zi,Nv),e(K,Cv),e(K,Pi),e(Pi,xv),e(K,qv),e(K,Ni),e(Ni,Gv),e(K,Hv),e(K,Ci),e(Ci,Uv),e(K,Mv),e(K,xi),e(xi,Bv),e(K,jv),e(K,qi),e(qi,Wv),e(J,Fv),e(J,ou),e(ou,Gi),e(Gi,Yv),e(Gi,Hi),e(Hi,Xv),e(J,Zv),e(J,nu),e(nu,Jt),e(Jt,Kv),e(Jt,Ui),e(Ui,Vv),e(Jt,Qv),e(Jt,Mi),e(Mi,Jv),f(a,wf,p),f(a,Ue,p),e(Ue,$v),e(Ue,Bi),e(Bi,e1),e(Ue,t1),e(Ue,ji),e(ji,a1),e(Ue,s1),f(a,Tf,p),Ba(os,a,p),f(a,Rf,p),f(a,$t,p),e($t,ea),e(ea,cu),e($t,l1),f(a,Df,p),f(a,Wi,p),e(Wi,i1),f(a,Sf,p),f(a,he,p),e(he,Fi),e(Fi,ns),e(ns,r1),e(Fi,o1),e(he,n1),e(he,Yi),e(Yi,cs),e(cs,c1),e(Yi,u1),e(he,f1),e(he,Xi),e(Xi,us),e(us,d1),e(Xi,p1),e(he,h1),e(he,Zi),e(Zi,fs),e(fs,m1),e(Zi,g1),f(a,Af,p),f(a,ta,p),e(ta,aa),e(aa,uu),e(ta,v1),f(a,Of,p),f(a,sa,p),e(sa,_1),e(sa,Ki),e(Ki,b1),e(sa,E1),f(a,Lf,p),f(a,ds,p),ds.innerHTML=e0,f(a,If,p),f(a,Me,p),e(Me,y1),e(Me,Vi),e(Vi,k1),e(Me,w1),e(Me,Qi),e(Qi,T1),e(Me,R1),f(a,zf,p),f(a,ps,p),e(ps,D1),e(ps,Ji),e(Ji,S1),f(a,Pf,p),f(a,la,p),e(la,A1),e(la,$i),e($i,O1),e(la,L1),f(a,Nf,p),f(a,ia,p),e(ia,ra),e(ra,fu),e(ia,I1),f(a,Cf,p),f(a,oa,p),e(oa,z1),e(oa,hs),e(hs,P1),e(oa,N1),f(a,xf,p),f(a,ms,p),e(ms,na),e(na,C1),e(na,gs),e(gs,x1),e(na,q1),f(a,qf,p),f(a,ca,p),e(ca,ua),e(ua,du),e(ca,G1),f(a,Gf,p),f(a,fa,p),e(fa,H1),e(fa,er),e(er,U1),e(fa,M1),f(a,Hf,p),f(a,vs,p),vs.innerHTML=t0,f(a,Uf,p),f(a,tr,p),e(tr,B1),f(a,Mf,p),f(a,_s,p),_s.innerHTML=a0,f(a,Bf,p),f(a,Be,p),e(Be,j1),e(Be,ar),e(ar,W1),e(Be,F1),e(Be,sr),e(sr,Y1),e(Be,X1),f(a,jf,p),f(a,je,p),e(je,Z1),e(je,lr),e(lr,K1),e(je,V1),e(je,ir),e(ir,Q1),e(je,J1),f(a,Wf,p),f(a,rr,p),e(rr,$1),f(a,Ff,p),f(a,da,p),e(da,or),e(or,e2),e(or,pu),e(pu,hu),e(hu,t2),e(da,a2),e(da,nr),e(nr,s2),e(nr,mu),e(mu,gu),e(gu,l2),f(a,Yf,p),f(a,cr,p),e(cr,i2),f(a,Xf,p),f(a,bs,p),e(bs,Es),f(a,Zf,p),f(a,pa,p),e(pa,ha),e(ha,vu),e(pa,r2),f(a,Kf,p),f(a,_t,p),e(_t,o2),e(_t,ur),e(ur,n2),e(_t,c2),e(_t,fr),e(fr,u2),f(a,Vf,p),f(a,bt,p),e(bt,dr),e(dr,ie),e(ie,pr),e(pr,f2),e(ie,d2),e(ie,hr),e(hr,p2),e(ie,h2),e(ie,mr),e(mr,m2),e(ie,g2),e(ie,gr),e(gr,v2),e(ie,_2),e(ie,vr),e(vr,b2),e(bt,E2),e(bt,_r),e(_r,re),e(re,br),e(br,y2),e(re,k2),e(re,Er),e(Er,w2),e(re,T2),e(re,yr),e(yr,R2),e(re,D2),e(re,kr),e(kr,S2),e(re,A2),e(re,wr),e(wr,O2),f(a,Qf,p),f(a,Tr,p),e(Tr,L2),f(a,Jf,p),f(a,ys,p),ys.innerHTML=s0,f(a,$f,p),f(a,M,p),e(M,Rr),e(Rr,ks),e(ks,I2),e(ks,Dr),e(Dr,z2),e(ks,P2),e(Rr,N2),e(M,C2),e(M,Sr),e(Sr,ws),e(ws,x2),e(ws,Ar),e(Ar,q2),e(ws,G2),e(Sr,H2),e(M,U2),e(M,Or),e(Or,Ts),e(Ts,M2),e(Ts,Lr),e(Lr,B2),e(Ts,j2),e(Or,W2),e(M,F2),e(M,Ir),e(Ir,Rs),e(Rs,Y2),e(Rs,zr),e(zr,X2),e(Rs,Z2),e(Ir,K2),e(M,V2),e(M,Pr),e(Pr,Ds),e(Ds,Q2),e(Ds,Nr),e(Nr,J2),e(Ds,$2),e(Pr,e_),e(M,t_),e(M,Cr),e(Cr,Ss),e(Ss,a_),e(Ss,xr),e(xr,s_),e(Ss,l_),e(Cr,i_),e(M,r_),e(M,qr),e(qr,As),e(As,o_),e(As,Gr),e(Gr,n_),e(As,c_),e(qr,u_),e(M,f_),e(M,Hr),e(Hr,Os),e(Os,d_),e(Os,Ur),e(Ur,p_),e(Os,h_),e(Hr,m_),e(M,g_),e(M,Mr),e(Mr,Ls),e(Ls,v_),e(Ls,Br),e(Br,__),e(Ls,b_),e(Mr,E_),e(M,y_),e(M,jr),e(jr,Is),e(Is,k_),e(Is,Wr),e(Wr,w_),e(Is,T_),e(jr,R_),e(M,D_),e(M,Fr),e(Fr,zs),e(zs,S_),e(zs,Yr),e(Yr,A_),e(zs,O_),e(Fr,L_),f(a,ed,p),f(a,ma,p),e(ma,ga),e(ga,_u),e(ma,I_),f(a,td,p),f(a,Xr,p),e(Xr,z_),f(a,ad,p),Ba(Ps,a,p),f(a,sd,p),f(a,va,p),e(va,_a),e(_a,bu),e(va,P_),f(a,ld,p),f(a,ba,p),e(ba,N_),e(ba,Ns),e(Ns,C_),e(ba,x_),f(a,id,p),f(a,Ea,p),e(Ea,q_),e(Ea,Zr),e(Zr,G_),e(Ea,H_),f(a,rd,p),f(a,oe,p),e(oe,Kr),e(Kr,U_),e(Kr,od),e(oe,M_),e(oe,Eu),e(Eu,B_),e(oe,j_),e(oe,We),e(We,W_),e(We,Vr),e(Vr,F_),e(We,Y_),e(We,Qr),e(Qr,X_),e(We,Z_),e(We,Jr),e(Jr,K_),e(oe,V_),e(oe,$r),e($r,Q_),e($r,eo),e(eo,J_),e(oe,$_),e(oe,ya),e(ya,eb),e(ya,to),e(to,tb),e(ya,ab),e(ya,ao),e(ao,sb),f(a,nd,p),f(a,Fe,p),e(Fe,lb),e(Fe,so),e(so,ib),e(Fe,rb),e(Fe,lo),e(lo,ob),e(Fe,nb),f(a,cd,p),f(a,me,p),e(me,ka),e(ka,cb),e(ka,io),e(io,ub),e(ka,fb),e(ka,ro),e(ro,db),e(me,pb),e(me,Cs),e(Cs,hb),e(Cs,oo),e(oo,mb),e(Cs,gb),e(me,vb),e(me,yu),e(yu,_b),e(me,bb),e(me,ku),e(ku,Eb),f(a,ud,p),f(a,wa,p),e(wa,Ta),e(Ta,wu),e(wa,yb),f(a,fd,p),f(a,ge,p),e(ge,no),e(no,Tu),e(Tu,kb),e(no,wb),e(ge,Tb),e(ge,co),e(co,Ru),e(Ru,Rb),e(co,Db),e(ge,Sb),e(ge,uo),e(uo,Du),e(Du,Ab),e(uo,Ob),e(ge,Lb),e(ge,fo),e(fo,Su),e(Su,Ib),e(fo,zb),f(a,dd,p),f(a,po,p),e(po,Pb),f(a,pd,p),f(a,xs,p),e(xs,qs),f(a,hd,p),f(a,Ra,p),e(Ra,Da),e(Da,Au),e(Ra,Nb),f(a,md,p),f(a,ho,p),e(ho,Cb),f(a,gd,p),f(a,Ye,p),e(Ye,Gs),e(Gs,xb),e(Gs,mo),e(mo,qb),e(Gs,Gb),e(Ye,Hb),e(Ye,Hs),e(Hs,Ub),e(Hs,go),e(go,Mb),e(Hs,Bb),e(Ye,jb),e(Ye,Ou),e(Ou,Wb),f(a,vd,p),f(a,Et,p),e(Et,vo),e(vo,Xe),e(Xe,_o),e(_o,Fb),e(Xe,Yb),e(Xe,bo),e(bo,Xb),e(Xe,Zb),e(Xe,Eo),e(Eo,Kb),e(Et,Vb),e(Et,ve),e(ve,Ze),e(Ze,yo),e(yo,Qb),e(Ze,Jb),e(Ze,ko),e(ko,$b),e(Ze,eE),e(Ze,wo),e(wo,tE),e(ve,aE),e(ve,Ke),e(Ke,To),e(To,sE),e(Ke,lE),e(Ke,Ro),e(Ro,iE),e(Ke,rE),e(Ke,Do),e(Do,oE),e(ve,nE),e(ve,Ve),e(Ve,So),e(So,cE),e(Ve,uE),e(Ve,Ao),e(Ao,fE),e(Ve,dE),e(Ve,Oo),e(Oo,pE),e(ve,hE),e(ve,Qe),e(Qe,Lo),e(Lo,mE),e(Qe,gE),e(Qe,Io),e(Io,vE),e(Qe,_E),e(Qe,zo),e(zo,bE),f(a,_d,p),f(a,Sa,p),e(Sa,Aa),e(Aa,Lu),e(Sa,EE),f(a,bd,p),f(a,Po,p),e(Po,yE),f(a,Ed,p),f(a,yt,p),e(yt,No),e(No,Je),e(Je,Co),e(Co,kE),e(Je,wE),e(Je,xo),e(xo,TE),e(Je,RE),e(Je,qo),e(qo,DE),e(yt,SE),e(yt,j),e(j,$e),e($e,Go),e(Go,AE),e($e,OE),e($e,Ho),e(Ho,LE),e($e,IE),e($e,Uo),e(Uo,zE),e(j,PE),e(j,et),e(et,Mo),e(Mo,NE),e(et,CE),e(et,Bo),e(Bo,xE),e(et,qE),e(et,jo),e(jo,GE),e(j,HE),e(j,tt),e(tt,Wo),e(Wo,UE),e(tt,ME),e(tt,Fo),e(Fo,BE),e(tt,jE),e(tt,Yo),e(Yo,WE),e(j,FE),e(j,at),e(at,Xo),e(Xo,YE),e(at,XE),e(at,Zo),e(Zo,ZE),e(at,KE),e(at,Ko),e(Ko,VE),e(j,QE),e(j,st),e(st,Vo),e(Vo,JE),e(st,$E),e(st,Qo),e(Qo,ey),e(st,ty),e(st,Jo),e(Jo,ay),e(j,sy),e(j,lt),e(lt,$o),e($o,ly),e(lt,iy),e(lt,en),e(en,ry),e(lt,oy),e(lt,tn),e(tn,ny),e(j,cy),e(j,it),e(it,an),e(an,uy),e(it,fy),e(it,sn),e(sn,dy),e(it,py),e(it,ln),e(ln,hy),e(j,my),e(j,rt),e(rt,rn),e(rn,gy),e(rt,vy),e(rt,on),e(on,_y),e(rt,by),e(rt,nn),e(nn,Ey),e(j,yy),e(j,ot),e(ot,cn),e(cn,ky),e(ot,wy),e(ot,un),e(un,Ty),e(ot,Ry),e(ot,fn),e(fn,Dy),e(j,Sy),e(j,nt),e(nt,dn),e(dn,Ay),e(nt,Oy),e(nt,pn),e(pn,Ly),e(nt,Iy),e(nt,hn),e(hn,zy),f(a,yd,p),f(a,Oa,p),e(Oa,La),e(La,Iu),e(Oa,Py),f(a,kd,p),f(a,mn,p),e(mn,Ny),f(a,wd,p),f(a,gn,p),e(gn,Cy),f(a,Td,p),f(a,Us,p),e(Us,Ms),f(a,Rd,p),f(a,vn,p),e(vn,xy),f(a,Dd,p),f(a,kt,p),e(kt,Ia),e(Ia,zu),e(kt,qy),f(a,Sd,p),be&&be.m(a,p),f(a,Ad,p),Od=!0},p(a,p){Q5&&be.p(a,p)},i(a){Od||(pt(h.$$.fragment,a),pt(O.$$.fragment,a),pt(ls.$$.fragment,a),pt(os.$$.fragment,a),pt(Ps.$$.fragment,a),pt(be),Od=!0)},o(a){ht(h.$$.fragment,a),ht(O.$$.fragment,a),ht(ls.$$.fragment,a),ht(os.$$.fragment,a),ht(Ps.$$.fragment,a),ht(be),Od=!1},d(a){a&&t(d),a&&t(m),ja(h,a),a&&t(v),a&&t(b),a&&t(k),a&&t(E),a&&t(z),a&&t(L),a&&t(S),ja(O,a),a&&t(A),a&&t(N),a&&t(Q),a&&t(W),a&&t(B),a&&t(x),a&&t(H),a&&t(X),a&&t(Gu),a&&t(al),a&&t(Hu),a&&t(sl),a&&t(Uu),a&&t(Fa),a&&t(Mu),a&&t(Ya),a&&t(Bu),a&&t(Xa),a&&t(ju),a&&t(Za),a&&t(Wu),a&&t(Ka),a&&t(Fu),a&&t(Tt),a&&t(Yu),a&&t(Va),a&&t(Xu),a&&t(Re),a&&t(Zu),a&&t(De),a&&t(Ku),a&&t(St),a&&t(Vu),a&&t(nl),a&&t(Qu),a&&t(Se),a&&t(Ju),a&&t(Ot),a&&t($u),a&&t(mt),a&&t(ef),a&&t(It),a&&t(tf),a&&t(gt),a&&t(af),a&&t(Hl),a&&t(sf),a&&t(Gt),a&&t(lf),a&&t(Qa),a&&t(rf),a&&t(Ja),a&&t(of),a&&t(Ut),a&&t(nf),a&&t(vt),a&&t(cf),a&&t(Bt),a&&t(uf),a&&t(le),a&&t(ff),a&&t(Wt),a&&t(df),a&&t(Yt),a&&t(pf),a&&t(pe),a&&t(hf),a&&t(es),a&&t(mf),a&&t(ci),a&&t(gf),a&&t(Xt),a&&t(vf),a&&t(Ge),a&&t(_f),ja(ls,a),a&&t(bf),a&&t(Kt),a&&t(Ef),a&&t(Qt),a&&t(yf),a&&t(He),a&&t(kf),a&&t(J),a&&t(wf),a&&t(Ue),a&&t(Tf),ja(os,a),a&&t(Rf),a&&t($t),a&&t(Df),a&&t(Wi),a&&t(Sf),a&&t(he),a&&t(Af),a&&t(ta),a&&t(Of),a&&t(sa),a&&t(Lf),a&&t(ds),a&&t(If),a&&t(Me),a&&t(zf),a&&t(ps),a&&t(Pf),a&&t(la),a&&t(Nf),a&&t(ia),a&&t(Cf),a&&t(oa),a&&t(xf),a&&t(ms),a&&t(qf),a&&t(ca),a&&t(Gf),a&&t(fa),a&&t(Hf),a&&t(vs),a&&t(Uf),a&&t(tr),a&&t(Mf),a&&t(_s),a&&t(Bf),a&&t(Be),a&&t(jf),a&&t(je),a&&t(Wf),a&&t(rr),a&&t(Ff),a&&t(da),a&&t(Yf),a&&t(cr),a&&t(Xf),a&&t(bs),a&&t(Zf),a&&t(pa),a&&t(Kf),a&&t(_t),a&&t(Vf),a&&t(bt),a&&t(Qf),a&&t(Tr),a&&t(Jf),a&&t(ys),a&&t($f),a&&t(M),a&&t(ed),a&&t(ma),a&&t(td),a&&t(Xr),a&&t(ad),ja(Ps,a),a&&t(sd),a&&t(va),a&&t(ld),a&&t(ba),a&&t(id),a&&t(Ea),a&&t(rd),a&&t(oe),a&&t(nd),a&&t(Fe),a&&t(cd),a&&t(me),a&&t(ud),a&&t(wa),a&&t(fd),a&&t(ge),a&&t(dd),a&&t(po),a&&t(pd),a&&t(xs),a&&t(hd),a&&t(Ra),a&&t(md),a&&t(ho),a&&t(gd),a&&t(Ye),a&&t(vd),a&&t(Et),a&&t(_d),a&&t(Sa),a&&t(bd),a&&t(Po),a&&t(Ed),a&&t(yt),a&&t(yd),a&&t(Oa),a&&t(kd),a&&t(mn),a&&t(wd),a&&t(gn),a&&t(Td),a&&t(Us),a&&t(Rd),a&&t(vn),a&&t(Dd),a&&t(kt),a&&t(Sd),be&&be.d(a),a&&t(Ad)}}}function Y0(_){let d,g;const m=[_[0],K3];let h={$$slots:{default:[F0]},$$scope:{ctx:_}};for(let v=0;v<m.length;v+=1)h=Z3(h,m[v]);return d=new v0({props:h}),{c(){Ua(d.$$.fragment)},l(v){Ma(d.$$.fragment,v)},m(v,b){Ba(d,v,b),g=!0},p(v,[b]){const y=b&1?g0(m,[b&1&&W5(v[0]),b&0&&W5(K3)]):{};b&2&&(y.$$scope={dirty:b,ctx:v}),d.$set(y)},i(v){g||(pt(d.$$.fragment,v),g=!0)},o(v){ht(d.$$.fragment,v),g=!1},d(v){ja(d,v)}}}const K3={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:i6,date:r6,modifiedDate:o6,categories:n6,svg:c6,seoImage:u6,shortDescription:f6,author:d6,spacelab:Q5,id:X0,spacelabDefaultTitle:Z0,spacelabDefaultContent:K0,menu:p6,keywords:h6}=K3;function V0(_,d,g){return _.$$set=m=>{g(0,d=Z3(Z3({},d),F5(m)))},d=F5(d),[d]}class m6 extends vp{constructor(d){super(),_p(this,d,V0,Y0,bp,{})}}export{m6 as default,K3 as metadata};
