import{S as uc,i as pc,s as hc,l as dc,g as n,E as Vv,d as t,v as kb,e as i,t as l,c as o,a as r,h as s,b as d,G as e,j as ze,k as c,m as f,F as Nt,H as os,Y as Db,J as is,f as We,Z as Rb,_ as Tb,$ as Sb,q as ya,o as ka,O as zb,w as rs,x as ls,y as ss,B as ns,C as Qv,z as Ob,A as sb,a1 as nb}from"../../chunks/index-2a82a4a8.js";import{P as Lb}from"../../chunks/_post-dca79525.js";import{g as Ib}from"../../chunks/config-201c2df4.js";import{a as Kv}from"../../chunks/accountStore-3492c591.js";/* empty css                                                                   */import{R as Ab}from"../../chunks/ResponsivePicture-976c1e70.js";import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";/* empty css                                                                   */function Cb(_){let p,g,h,v,m,E,y,D,N,O,S,k,j,M,x,B,I,R;function A(w,L){return typeof w[2].title!="undefined"?xb:Nb}let H=A(_),P=H(_);function _e(w,L){return typeof w[2].description!="undefined"?jb:qb}let se=_e(_),z=se(_),T=typeof _[2].list_description!="undefined"&&cb(_),b=typeof _[2].footer_description!="undefined"&&fb(_);return{c(){p=i("hr"),g=c(),h=i("div"),P.c(),v=c(),m=i("p"),E=i("ion-icon"),y=l("SpaceLab Content"),D=c(),z.c(),N=c(),T&&T.c(),O=c(),b&&b.c(),S=c(),k=i("button"),j=i("ion-icon"),M=c(),x=i("span"),B=l("SpaceLab"),this.h()},l(w){p=o(w,"HR",{}),g=f(w),h=o(w,"DIV",{class:!0});var L=r(h);P.l(L),v=f(L),m=o(L,"P",{class:!0});var V=r(m);E=o(V,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=s(V,"SpaceLab Content"),V.forEach(t),D=f(L),z.l(L),N=f(L),T&&T.l(L),O=f(L),b&&b.l(L),S=f(L),k=o(L,"BUTTON",{class:!0});var $=r(k);j=o($,"ION-ICON",{class:!0,name:!0}),r(j).forEach(t),M=f($),x=o($,"SPAN",{});var Oe=r(x);B=s(Oe,"SpaceLab"),Oe.forEach(t),$.forEach(t),L.forEach(t),this.h()},h(){Nt(E,"class","icon svelte-vjvavh"),Nt(E,"name","lock-closed"),d(m,"class","highlight large svelte-vjvavh"),Nt(j,"class","icon svelte-vjvavh"),Nt(j,"name","planet"),d(k,"class","button subscribe svelte-vjvavh"),d(h,"class","subscribe svelte-vjvavh")},m(w,L){n(w,p,L),n(w,g,L),n(w,h,L),P.m(h,null),e(h,v),e(h,m),e(m,E),e(m,y),e(h,D),z.m(h,null),e(h,N),T&&T.m(h,null),e(h,O),b&&b.m(h,null),e(h,S),e(h,k),e(k,j),e(k,M),e(k,x),e(x,B),I||(R=os(k,"click",_[5]),I=!0)},p(w,L){H===(H=A(w))&&P?P.p(w,L):(P.d(1),P=H(w),P&&(P.c(),P.m(h,v))),se===(se=_e(w))&&z?z.p(w,L):(z.d(1),z=se(w),z&&(z.c(),z.m(h,N))),typeof w[2].list_description!="undefined"?T?T.p(w,L):(T=cb(w),T.c(),T.m(h,O)):T&&(T.d(1),T=null),typeof w[2].footer_description!="undefined"?b?b.p(w,L):(b=fb(w),b.c(),b.m(h,S)):b&&(b.d(1),b=null)},d(w){w&&t(p),w&&t(g),w&&t(h),P.d(),z.d(),T&&T.d(),b&&b.d(),I=!1,R()}}}function Pb(_){let p,g,h,v=_[2].title+"",m,E,y,D,N,O,S,k=_[2].description+"",j,M,x,B,I,R,A,H,P,_e,se,z=typeof _[2].list_description!="undefined"&&db(_),T=typeof _[2].footer_description!="undefined"&&ub(_);return{c(){p=i("hr"),g=c(),h=i("h2"),m=l(v),E=c(),y=i("p"),D=i("ion-icon"),N=l("SpaceLab Content"),O=c(),S=i("p"),j=l(k),M=c(),z&&z.c(),x=c(),T&&T.c(),B=c(),I=i("button"),R=i("ion-icon"),A=c(),H=i("span"),P=l("Download"),this.h()},l(b){p=o(b,"HR",{}),g=f(b),h=o(b,"H2",{class:!0});var w=r(h);m=s(w,v),w.forEach(t),E=f(b),y=o(b,"P",{class:!0});var L=r(y);D=o(L,"ION-ICON",{class:!0,name:!0}),r(D).forEach(t),N=s(L,"SpaceLab Content"),L.forEach(t),O=f(b),S=o(b,"P",{class:!0});var V=r(S);j=s(V,k),V.forEach(t),M=f(b),z&&z.l(b),x=f(b),T&&T.l(b),B=f(b),I=o(b,"BUTTON",{class:!0});var $=r(I);R=o($,"ION-ICON",{class:!0,name:!0}),r(R).forEach(t),A=f($),H=o($,"SPAN",{});var Oe=r(H);P=s(Oe,"Download"),Oe.forEach(t),$.forEach(t),this.h()},h(){d(h,"class","svelte-vjvavh"),Nt(D,"class","icon svelte-vjvavh"),Nt(D,"name","planet-sharp"),d(y,"class","highlight large svelte-vjvavh"),d(S,"class","svelte-vjvavh"),Nt(R,"class","icon svelte-vjvavh"),Nt(R,"name","cloud-download"),d(I,"class","button svelte-vjvavh")},m(b,w){n(b,p,w),n(b,g,w),n(b,h,w),e(h,m),n(b,E,w),n(b,y,w),e(y,D),e(y,N),n(b,O,w),n(b,S,w),e(S,j),n(b,M,w),z&&z.m(b,w),n(b,x,w),T&&T.m(b,w),n(b,B,w),n(b,I,w),e(I,R),e(I,A),e(I,H),e(H,P),_e||(se=os(I,"click",_[4]),_e=!0)},p(b,w){w&4&&v!==(v=b[2].title+"")&&ze(m,v),w&4&&k!==(k=b[2].description+"")&&ze(j,k),typeof b[2].list_description!="undefined"?z?z.p(b,w):(z=db(b),z.c(),z.m(x.parentNode,x)):z&&(z.d(1),z=null),typeof b[2].footer_description!="undefined"?T?T.p(b,w):(T=ub(b),T.c(),T.m(B.parentNode,B)):T&&(T.d(1),T=null)},d(b){b&&t(p),b&&t(g),b&&t(h),b&&t(E),b&&t(y),b&&t(O),b&&t(S),b&&t(M),z&&z.d(b),b&&t(x),T&&T.d(b),b&&t(B),b&&t(I),_e=!1,se()}}}function Nb(_){let p,g;return{c(){p=i("h2"),g=l(_[0]),this.h()},l(h){p=o(h,"H2",{class:!0});var v=r(p);g=s(v,_[0]),v.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(h,v){n(h,p,v),e(p,g)},p(h,v){v&1&&ze(g,h[0])},d(h){h&&t(p)}}}function xb(_){let p,g=_[2].title+"",h;return{c(){p=i("h2"),h=l(g),this.h()},l(v){p=o(v,"H2",{class:!0});var m=r(p);h=s(m,g),m.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(v,m){n(v,p,m),e(p,h)},p(v,m){m&4&&g!==(g=v[2].title+"")&&ze(h,g)},d(v){v&&t(p)}}}function qb(_){let p,g;return{c(){p=i("p"),g=l(_[1]),this.h()},l(h){p=o(h,"P",{class:!0});var v=r(p);g=s(v,_[1]),v.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(h,v){n(h,p,v),e(p,g)},p(h,v){v&2&&ze(g,h[1])},d(h){h&&t(p)}}}function jb(_){let p,g=_[2].description+"",h;return{c(){p=i("p"),h=l(g),this.h()},l(v){p=o(v,"P",{class:!0});var m=r(p);h=s(m,g),m.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(v,m){n(v,p,m),e(p,h)},p(v,m){m&4&&g!==(g=v[2].description+"")&&ze(h,g)},d(v){v&&t(p)}}}function cb(_){let p,g,h=_[2].list_description+"",v;return{c(){p=i("div"),g=i("p"),v=l(h),this.h()},l(m){p=o(m,"DIV",{class:!0});var E=r(p);g=o(E,"P",{class:!0});var y=r(g);v=s(y,h),y.forEach(t),E.forEach(t),this.h()},h(){d(g,"class","svelte-vjvavh"),d(p,"class","list-description svelte-vjvavh")},m(m,E){n(m,p,E),e(p,g),e(g,v)},p(m,E){E&4&&h!==(h=m[2].list_description+"")&&ze(v,h)},d(m){m&&t(p)}}}function fb(_){let p,g=_[2].footer_description+"",h;return{c(){p=i("p"),h=l(g),this.h()},l(v){p=o(v,"P",{class:!0});var m=r(p);h=s(m,g),m.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(v,m){n(v,p,m),e(p,h)},p(v,m){m&4&&g!==(g=v[2].footer_description+"")&&ze(h,g)},d(v){v&&t(p)}}}function db(_){let p,g,h=_[2].list_description+"",v;return{c(){p=i("div"),g=i("p"),v=l(h),this.h()},l(m){p=o(m,"DIV",{class:!0});var E=r(p);g=o(E,"P",{class:!0});var y=r(g);v=s(y,h),y.forEach(t),E.forEach(t),this.h()},h(){d(g,"class","svelte-vjvavh"),d(p,"class","list-description svelte-vjvavh")},m(m,E){n(m,p,E),e(p,g),e(g,v)},p(m,E){E&4&&h!==(h=m[2].list_description+"")&&ze(v,h)},d(m){m&&t(p)}}}function ub(_){let p,g=_[2].footer_description+"",h;return{c(){p=i("p"),h=l(g),this.h()},l(v){p=o(v,"P",{class:!0});var m=r(p);h=s(m,g),m.forEach(t),this.h()},h(){d(p,"class","svelte-vjvavh")},m(v,m){n(v,p,m),e(p,h)},p(v,m){m&4&&g!==(g=v[2].footer_description+"")&&ze(h,g)},d(v){v&&t(p)}}}function Hb(_){let p;function g(m,E){if(typeof m[2]!="undefined"&&typeof m[2].pk!="undefined"&&m[2].success)return Pb;if(!m[2].success)return Cb}let h=g(_),v=h&&h(_);return{c(){v&&v.c(),p=dc()},l(m){v&&v.l(m),p=dc()},m(m,E){v&&v.m(m,E),n(m,p,E)},p(m,[E]){h===(h=g(m))&&v?v.p(m,E):(v&&v.d(1),v=h&&h(m),v&&(v.c(),v.m(p.parentNode,p)))},i:Vv,o:Vv,d(m){v&&v.d(m),m&&t(p)}}}function Ub(_,p,g){let{id:h}=p,{spacelabDefaultTitle:v="Spacelab Content"}=p,{spacelabDefaultContent:m="To access this content, you need a SpaceLab subscription."}=p,E={},y;Kv.subscribe(O=>{y=O}),kb(async()=>{if(typeof(y==null?void 0:y.token)!="undefined"){const O=await fetch(`${Ib().serviceUrl}/education/spacelab/${h}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+y.token},mode:"cors"});if(O.status===401){Kv.set({}),Kv.deleteLocalStorage();return}let S=await O.json();g(2,E=S)}else g(2,E.success=!1,E)});const D=()=>window.open(E.url,"_blank"),N=()=>window.open("/spacelab/","_blank");return _.$$set=O=>{"id"in O&&g(3,h=O.id),"spacelabDefaultTitle"in O&&g(0,v=O.spacelabDefaultTitle),"spacelabDefaultContent"in O&&g(1,m=O.spacelabDefaultContent)},[v,m,E,h,D,N]}class Gb extends uc{constructor(p){super(),pc(this,p,Ub,Hb,hc,{id:3,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const Wb=_=>({}),pb=_=>({});function Mb(_){let p;return{c(){p=l(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(g){p=s(g,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(g,h){n(g,p,h)},d(g){g&&t(p)}}}function Bb(_){let p,g,h,v,m,E,y,D,N,O,S,k,j,M;const x=_[7]["slider-label"],B=Db(x,_,_[6],pb),I=B||Mb();return{c(){p=i("div"),g=i("img"),v=c(),m=i("img"),y=c(),D=i("label"),N=i("span"),I&&I.c(),O=c(),S=i("input"),this.h()},l(R){p=o(R,"DIV",{class:!0,style:!0,"data-testid":!0});var A=r(p);g=o(A,"IMG",{src:!0,alt:!0,class:!0}),v=f(A),m=o(A,"IMG",{src:!0,alt:!0,class:!0}),y=f(A),D=o(A,"LABEL",{class:!0});var H=r(D);N=o(H,"SPAN",{class:!0});var P=r(N);I&&I.l(P),P.forEach(t),O=f(H),S=o(H,"INPUT",{type:!0,min:!0,max:!0,class:!0}),H.forEach(t),A.forEach(t),this.h()},h(){is(g.src,h=_[0])||d(g,"src",h),d(g,"alt",_[1]),d(g,"class","left-img svelte-1po6qlg"),is(m.src,E=_[2])||d(m,"src",E),d(m,"alt",_[3]),d(m,"class","right-img svelte-1po6qlg"),d(N,"class","visually-hidden svelte-1po6qlg"),d(S,"type","range"),d(S,"min","0"),d(S,"max","100"),S.value=_[4],d(S,"class","svelte-1po6qlg"),d(D,"class","svelte-1po6qlg"),d(p,"class","svelte-compare-image-container svelte-1po6qlg"),We(p,"--slider-position",_[4]+"%"),d(p,"data-testid","svelte-compare-image")},m(R,A){n(R,p,A),e(p,g),e(p,v),e(p,m),e(p,y),e(p,D),e(D,N),I&&I.m(N,null),e(D,O),e(D,S),k=!0,j||(M=[os(S,"input",_[5]),os(S,"change",_[5]),os(S,"click",Fb)],j=!0)},p(R,[A]){(!k||A&1&&!is(g.src,h=R[0]))&&d(g,"src",h),(!k||A&2)&&d(g,"alt",R[1]),(!k||A&4&&!is(m.src,E=R[2]))&&d(m,"src",E),(!k||A&8)&&d(m,"alt",R[3]),B&&B.p&&(!k||A&64)&&Rb(B,x,R,R[6],k?Sb(x,R[6],A,Wb):Tb(R[6]),pb),(!k||A&16)&&(S.value=R[4]),(!k||A&16)&&We(p,"--slider-position",R[4]+"%")},i(R){k||(ya(I,R),k=!0)},o(R){ka(I,R),k=!1},d(R){R&&t(p),I&&I.d(R),j=!1,zb(M)}}}function Fb(_){_.target.focus()}function Yb(_,p,g){let{$$slots:h={},$$scope:v}=p,{imageLeftSrc:m=""}=p,{imageLeftAlt:E=""}=p,{imageRightSrc:y=""}=p,{imageRightAlt:D=""}=p,N=50,O=null;function S(k){O&&cancelAnimationFrame(O),O=requestAnimationFrame(()=>{g(4,N=k.target.valueAsNumber)})}return _.$$set=k=>{"imageLeftSrc"in k&&g(0,m=k.imageLeftSrc),"imageLeftAlt"in k&&g(1,E=k.imageLeftAlt),"imageRightSrc"in k&&g(2,y=k.imageRightSrc),"imageRightAlt"in k&&g(3,D=k.imageRightAlt),"$$scope"in k&&g(6,v=k.$$scope)},[m,E,y,D,N,S,v,h]}class Xb extends uc{constructor(p){super(),pc(this,p,Yb,Bb,hc,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function Zb(_){let p;return{c(){p=l(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(g){p=s(g,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(g,h){n(g,p,h)},d(g){g&&t(p)}}}function Kb(_){let p,g,h,v;return g=new Xb({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[Zb]},$$scope:{ctx:_}}}),{c(){p=i("div"),h=i("div"),rs(g.$$.fragment),this.h()},l(m){p=o(m,"DIV",{class:!0});var E=r(p);h=o(E,"DIV",{style:!0});var y=r(h);ls(g.$$.fragment,y),E.forEach(t),this.h()},h(){We(h,"display","contents"),We(h,"--handle-size","2.5rem"),We(h,"--handle-background-color","rgba(0, 0, 0, 0.6)"),We(h,"--handle-background-image",_[4]),We(h,"--handle-border-width","0.125rem"),We(h,"--slider-color","#ffffff"),We(h,"--slider-width","0.125rem"),d(p,"class","image-compare-container svelte-s79nww")},m(m,E){n(m,p,E),e(p,h),ss(g,h,null),v=!0},p(m,[E]){const y={};E&1&&(y.imageLeftSrc=m[0]),E&2&&(y.imageLeftAlt=m[1]),E&4&&(y.imageRightSrc=m[2]),E&8&&(y.imageRightAlt=m[3]),E&32&&(y.$$scope={dirty:E,ctx:m}),g.$set(y)},i(m){v||(ya(g.$$.fragment,m),v=!0)},o(m){ka(g.$$.fragment,m),v=!1},d(m){m&&t(p),ns(g)}}}function Vb(_,p,g){const h=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:v="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=p,{imageLeftAlt:m="left"}=p,{imageRightSrc:E="https://via.placeholder.com/512x512/00aaff/ffffff/"}=p,{imageRightAlt:y="right"}=p;return _.$$set=D=>{"imageLeftSrc"in D&&g(0,v=D.imageLeftSrc),"imageLeftAlt"in D&&g(1,m=D.imageLeftAlt),"imageRightSrc"in D&&g(2,E=D.imageRightSrc),"imageRightAlt"in D&&g(3,y=D.imageRightAlt)},[v,m,E,y,h]}class Qb extends uc{constructor(p){super(),pc(this,p,Vb,Kb,hc,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function Jb(_){let p,g;return p=new Gb({props:{id:t3,spacelabDefaultTitle:a3,spacelabDefaultContent:i3}}),{c(){rs(p.$$.fragment)},l(h){ls(p.$$.fragment,h)},m(h,v){ss(p,h,v),g=!0},p:Vv,i(h){g||(ya(p.$$.fragment,h),g=!0)},o(h){ka(p.$$.fragment,h),g=!1},d(h){ns(p,h)}}}function $b(_){let p,g,h,v,m,E,y,D,N,O,S,k,j,M,x,B,I,R,A,H,P,_e,se,z,T,b,w,L,V,$,Oe,mc,mo,gc,vc,go,_c,Ec,pe,Le,Da,vo,bc,wc,Ra,yc,kc,Ta,Dc,Rc,Ie,Sa,_o,Tc,Sc,za,zc,Oc,Oa,Lc,Ic,Ae,La,Eo,Ac,Cc,Ia,Pc,Nc,Aa,xc,qc,Ce,Ca,bo,jc,Hc,Pa,Uc,Gc,Na,Wc,cs,xa,Mc,fs,qa,Bc,ds,xt,ja,Fc,us,qt,wo,Yc,Xc,ps,jt,yo,Zc,Kc,hs,Ht,ko,Vc,Qc,ms,Ut,Do,Jc,$c,gs,Me,Be,Ro,ef,vs,Fe,tf,To,af,of,_s,Ha,rf,Es,Ua,lf,bs,Pe,So,Gt,zo,sf,nf,Oo,cf,ff,he,Wt,Ga,df,uf,Wa,pf,hf,Mt,Ma,mf,gf,Ba,vf,_f,Bt,Fa,Ef,bf,Ya,wf,yf,Ft,Xa,kf,Df,Za,Rf,ws,Ye,Xe,Lo,Tf,ys,Ze,Sf,Io,zf,Of,ks,ne,Lf,Ao,If,Af,Co,Cf,Pf,Po,Nf,xf,Ds,Yt,Ka,No,qf,Rs,Va,jf,Ts,Xt,Ss,Ke,Ve,xo,Hf,zs,Qe,Uf,Zt,Gf,Wf,Os,Ee,Mf,qo,Bf,Ff,jo,Yf,Xf,Ls,F,Ho,Qa,Zf,Uo,Kf,Vf,Go,Kt,Qf,Wo,Jf,$f,ed,Mo,U,td,Bo,ad,id,Fo,od,rd,Yo,ld,sd,Xo,nd,cd,Zo,fd,dd,Ko,ud,pd,Vo,hd,md,Qo,gd,vd,Jo,Y,_d,$o,Ed,bd,er,wd,yd,tr,kd,Dd,ar,Rd,Td,ir,Sd,zd,or,Od,Ld,rr,Id,Ad,lr,G,Cd,sr,Pd,Nd,nr,xd,qd,cr,jd,Hd,fr,Ud,Gd,dr,Wd,Md,ur,Bd,Fd,pr,Yd,Xd,hr,Zd,Kd,mr,Ja,Vd,gr,Qd,Jd,vr,Je,$d,_r,eu,tu,Er,au,Is,be,iu,br,ou,ru,wr,lu,su,As,$e,et,yr,nu,Cs,$a,cu,Ps,ce,ei,Vt,fu,du,uu,ti,Qt,pu,hu,mu,ai,Jt,gu,vu,_u,ii,$t,Eu,bu,Ns,tt,at,kr,wu,xs,it,yu,Dr,ku,Du,qs,ea,mb=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"filename=%%i"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption_filename=%%~ni.txt"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption=%%~ni"</span>

    rem Extracting the part from the first character to the first comma <span class="token keyword">in</span> the filename
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1,* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!caption!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>

    <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span> <span class="token operator">></span> <span class="token string">"!caption_filename!"</span>
<span class="token punctuation">)</span></code>`,js,we,Ru,Rr,Tu,Su,Tr,zu,Ou,Hs,ta,Lu,Sr,Iu,Us,ot,Au,zr,Cu,Pu,Gs,rt,lt,Or,Nu,Ws,oi,xu,Ms,aa,ri,qu,Bs,st,nt,Lr,ju,Fs,ct,Hu,Ir,Uu,Gu,Ys,ia,gb=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Xs,li,Wu,Zs,oa,vb='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Ks,Q,Mu,Ar,Bu,Fu,Cr,Yu,Xu,Pr,Zu,Ku,Nr,Vu,Qu,xr,Ju,$u,Vs,ye,ep,qr,tp,ap,jr,ip,op,Qs,si,rp,Js,ft,ni,lp,Hr,Ur,sp,np,ci,cp,Gr,Wr,fp,$s,fi,dp,en,di,ra,$v,tn,dt,ut,Mr,up,an,pt,pp,Br,hp,mp,on,Ne,Fr,oe,Yr,gp,vp,Xr,_p,Ep,Zr,bp,wp,Kr,yp,kp,Vr,Dp,Rp,Qr,re,ui,Tp,Sp,pi,zp,Op,hi,Lp,Ip,mi,Ap,Cp,gi,Pp,rn,vi,Np,ln,la,_b=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"5e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,sn,C,_i,sa,xp,Jr,qp,jp,Hp,Up,Ei,na,Gp,$r,Wp,Mp,Bp,Fp,bi,ca,Yp,el,Xp,Zp,Kp,Vp,wi,fa,Qp,tl,Jp,$p,eh,th,yi,da,ah,al,ih,oh,rh,lh,ki,ua,sh,il,nh,ch,fh,dh,Di,pa,uh,ol,ph,hh,mh,gh,Ri,ha,vh,rl,_h,Eh,bh,wh,Ti,ma,yh,ll,kh,Dh,Rh,Th,Si,ga,Sh,sl,zh,Oh,Lh,Ih,zi,va,Ah,nl,Ch,Ph,Nh,nn,ht,mt,cl,xh,cn,Oi,qh,fn,gt,vt,fl,jh,dn,_t,Hh,_a,Uh,Gh,un,Et,Wh,dl,Mh,Bh,pn,te,Li,Fh,ul,Yh,Xh,Ea,Zh,pl,Kh,Vh,Qh,ae,Jh,hl,$h,em,ml,tm,am,gl,im,om,vl,rm,lm,_l,sm,nm,Ii,cm,El,fm,dm,bt,um,bl,pm,hm,wl,mm,hn,ke,gm,yl,vm,_m,kl,Em,bm,mn,fe,W,wm,Dl,ym,km,Rl,Dm,Rm,Tl,Tm,Sm,Sl,zm,Om,zl,Lm,Im,Ol,Am,Cm,Ll,Pm,Nm,Il,xm,qm,J,jm,Al,Hm,Um,Cl,Gm,Wm,Pl,Mm,Bm,Nl,Fm,Ym,xl,Xm,Zm,ql,Km,Vm,jl,Qm,Jm,Hl,$m,gn,wt,yt,Ul,eg,vn,de,Ai,Gl,tg,ag,ig,Ci,Wl,og,rg,lg,Pi,Ml,sg,ng,cg,Ni,Bl,fg,dg,_n,xi,ug,En,kt,Dt,Fl,pg,bn,qi,hg,wn,De,ba,mg,Yl,gg,vg,_g,wa,Eg,Xl,bg,wg,yg,Zl,kg,yn,xe,Kl,qe,Vl,Dg,Rg,Ql,Tg,Sg,Jl,zg,Og,me,je,ji,Lg,Ig,Hi,Ag,Cg,Ui,Pg,Ng,He,Gi,xg,qg,Wi,jg,Hg,Mi,Ug,Gg,Ue,Bi,Wg,Mg,Fi,Bg,Fg,Rt,Yg,$l,Xg,Zg,Kg,Ge,Yi,Vg,Qg,Xi,Jg,$g,Zi,ev,kn,Tt,St,es,tv,Dn,Ki,av,Rn,Vi,iv,Tn,Qi,ov,Sn,zn,On;v=new Ab({props:{smallImage:"https://3ee.s3.amazonaws.com/img/adam_blog_sm.png",largeImage:"https://3ee.s3.amazonaws.com/img/adam_blog.png",alt:"Action Figure with reg images",largeWidth:"968",largeHeight:"512",smallWidth:"484",smallHeight:"256"}}),Xt=new Qb({props:{imageLeftSrc:"https://via.placeholder.com/512x512/ff9900/ffffff/",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://via.placeholder.com/512x512/00aaff/ffffff/",imageRightAlt:"prince adam trained with regularization images."}});let ge=hb&&Jb();return{c(){p=i("p"),g=l("I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),h=c(),rs(v.$$.fragment),m=c(),E=i("h2"),y=i("a"),D=i("span"),N=l("What are Regularization Images?"),O=c(),S=i("p"),k=l("Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model.  To further illustrate: regularization images are extra pictures that are used to help Stable Diffusion learn better."),j=c(),M=i("blockquote"),x=i("p"),B=l("Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),I=c(),R=i("p"),A=l("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),H=c(),P=i("p"),_e=l("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),se=c(),z=i("p"),T=l("In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),b=c(),w=i("table"),L=i("thead"),V=i("tr"),$=i("th"),Oe=l("Aspect"),mc=c(),mo=i("th"),gc=l("Regularization"),vc=c(),go=i("th"),_c=l("No Regularization"),Ec=c(),pe=i("tbody"),Le=i("tr"),Da=i("td"),vo=i("strong"),bc=l("Definition"),wc=c(),Ra=i("td"),yc=l("Defines skateboard class"),kc=c(),Ta=i("td"),Dc=l("No specific class"),Rc=c(),Ie=i("tr"),Sa=i("td"),_o=i("strong"),Tc=l("Example"),Sc=c(),za=i("td"),zc=l("Uses skateboard images"),Oc=c(),Oa=i("td"),Lc=l("No specific images"),Ic=c(),Ae=i("tr"),La=i("td"),Eo=i("strong"),Ac=l("Purpose"),Cc=c(),Ia=i("td"),Pc=l("Prevents drift, focuses on skateboard class"),Nc=c(),Aa=i("td"),xc=l("May drift to unrelated classes"),qc=c(),Ce=i("tr"),Ca=i("td"),bo=i("strong"),jc=l("Overfitting"),Hc=c(),Pa=i("td"),Uc=l("Guards against overfitting"),Gc=c(),Na=i("td"),Wc=l("Higher risk of overfitting"),cs=c(),xa=i("p"),Mc=l("Regularization helps us make sure our models can correctly classify new data points they were not trained on. We call this ability to work well with new data \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),fs=c(),qa=i("p"),Bc=l("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well even with the training data. This happens when we limit our model\u2019s ability too much."),ds=c(),xt=i("blockquote"),ja=i("p"),Fc=l("Imagine a graph of points. We want to find a function that fits those points well. We could choose a simple function, which might not fit the points very well. Or we could choose a very complex function that fits the points perfectly, but it might not work well with new points we haven\u2019t seen before. The key is to find the right balance between simplicity and complexity to achieve the best performance."),us=c(),qt=i("p"),wo=i("strong"),Yc=l("Scenario 1"),Xc=l(": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),ps=c(),jt=i("p"),yo=i("strong"),Zc=l("Solution"),Kc=l(": consider using regularization images to help the model learn more about cat features."),hs=c(),Ht=i("p"),ko=i("strong"),Vc=l("Scenario 2"),Qc=l(": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),ms=c(),Ut=i("p"),Do=i("strong"),Jc=l("Solution"),$c=l(": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),gs=c(),Me=i("h2"),Be=i("a"),Ro=i("span"),ef=l("Divergence"),vs=c(),Fe=i("p"),tf=l("Providing too much data leads to "),To=i("strong"),af=l("divergence"),of=l(". Divergence happens when the model produces random outputs that do not accurately represent the subject\u2019s likeness. This can occur because the model is trying to learn from too many images with inconsistent features, causing it to become confused and produce poor results."),_s=c(),Ha=i("p"),rf=l("To avoid divergence, we need to ensure the model is focusing on the features that are unique and consistent with your subject.  This starts from carefully curating the dataset by selecting high-quality images that accurately represent the object."),Es=c(),Ua=i("p"),lf=l("Training a model to recognize specific objects requires careful consideration of the dataset and the use of regularization techniques to ensure the model is focused on the right features and is not prone to divergence."),bs=c(),Pe=i("table"),So=i("thead"),Gt=i("tr"),zo=i("th"),sf=l("Situation"),nf=c(),Oo=i("th"),cf=l("Outcome"),ff=c(),he=i("tbody"),Wt=i("tr"),Ga=i("td"),df=l("Too many regularization images or inconsistent features"),uf=c(),Wa=i("td"),pf=l("Model performance suffers, leading to inaccurate predictions."),hf=c(),Mt=i("tr"),Ma=i("td"),mf=l("Lack of focus on unique and consistent features"),gf=c(),Ba=i("td"),vf=l("Difficulty learning meaningful patterns, impacting prediction accuracy."),_f=c(),Bt=i("tr"),Fa=i("td"),Ef=l("Need for careful dataset curation"),bf=c(),Ya=i("td"),wf=l("High-quality image selection to avoid confusion and divergence."),yf=c(),Ft=i("tr"),Xa=i("td"),kf=l("Importance of regularization techniques"),Df=c(),Za=i("td"),Rf=l("Proper use ensures model focuses on relevant features for accurate predictions."),ws=c(),Ye=i("h2"),Xe=i("a"),Lo=i("span"),Tf=l("Generating Regularization images"),ys=c(),Ze=i("p"),Sf=l("Regularization images are generated using model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Io=i("code"),zf=l("1boy"),Of=l(")."),ks=c(),ne=i("p"),Lf=l("According to the Dreambooth technique, "),Ao=i("code"),If=l("200"),Af=l(" regularization images per training image.  For example, if you have "),Co=i("code"),Cf=l("16"),Pf=l(" images: "),Po=i("code"),Nf=l("200 * 16 = 3200"),xf=l(" total regularization images.  When training, the math involved for calculating total steps is:"),Ds=c(),Yt=i("blockquote"),Ka=i("p"),No=i("code"),qf=l("repeats * training images >= repeats * regularization images"),Rs=c(),Va=i("p"),jf=l("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),Ts=c(),rs(Xt.$$.fragment),Ss=c(),Ke=i("h4"),Ve=i("a"),xo=i("span"),Hf=l("Generate using Stable Diffusion web UI"),zs=c(),Qe=i("p"),Uf=l("We\u2019re going to use "),Zt=i("a"),Gf=l("Stable Diffusion web UI"),Wf=l(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Os=c(),Ee=i("p"),Mf=l("We\u2019re going to use the "),qo=i("code"),Bf=l("X/Y/Z plot"),Ff=l(" script to use "),jo=i("code"),Yf=l("Prompt Search & Replace"),Xf=l(" to dynamically build a prompt that will generate hundreds of regularization images."),Ls=c(),F=i("ol"),Ho=i("li"),Qa=i("p"),Zf=l("Select the text 2 image tab.  Enter a generic prompt "),Uo=i("code"),Kf=l("princeadam, portrait, looking_at_viewer, forest"),Vf=c(),Go=i("li"),Kt=i("p"),Qf=l("In generation parameters and select the "),Wo=i("code"),Jf=l("X/Y/Z plot"),$f=l(" script."),ed=c(),Mo=i("li"),U=i("p"),td=l("Select the "),Bo=i("code"),ad=l("X"),id=l(" parameter and "),Fo=i("code"),od=l("Prompt SR"),rd=l(" for Prompt Replace.  We\u2019re going to replace "),Yo=i("code"),ld=l("portrait"),sd=l(" with different camera angle tags: "),Xo=i("code"),nd=l("close-up"),cd=l(", "),Zo=i("code"),fd=l("upper_body"),dd=l(", "),Ko=i("code"),ud=l("from_below"),pd=l(", "),Vo=i("code"),hd=l("from_above"),md=l(", "),Qo=i("code"),gd=l("dutch_angle"),vd=c(),Jo=i("li"),Y=i("p"),_d=l("Select the "),$o=i("code"),Ed=l("Y"),bd=l(" parameter and "),er=i("code"),wd=l("Prompt SR"),yd=l(" for Prompt Replace.  Replace "),tr=i("code"),kd=l("looking_at_viewer"),Dd=l(": "),ar=i("code"),Rd=l("looking_away"),Td=l(", "),ir=i("code"),Sd=l("looking_to_the_side"),zd=l(", "),or=i("code"),Od=l("looking_ahead"),Ld=l(", "),rr=i("code"),Id=l("looking_down"),Ad=c(),lr=i("li"),G=i("p"),Cd=l("Select the "),sr=i("code"),Pd=l("Z"),Nd=l(" parameter and "),nr=i("code"),xd=l("Prompt SR"),qd=l(" for Prompt Replace. Replace "),cr=i("code"),jd=l("forest"),Hd=l(" with a vareity of locatinos: "),fr=i("code"),Ud=l("castle"),Gd=l(", "),dr=i("code"),Wd=l("mountain"),Md=l(", "),ur=i("code"),Bd=l("cave"),Fd=l(", "),pr=i("code"),Yd=l("farm"),Xd=l(", "),hr=i("code"),Zd=l("ocean"),Kd=c(),mr=i("li"),Ja=i("p"),Vd=l("Select a fast sampler like "),gr=i("code"),Qd=l("DPM2 KARRAS"),Jd=c(),vr=i("li"),Je=i("p"),$d=l("CFG Scale set to "),_r=i("code"),eu=l("7"),tu=l(" and Steps to "),Er=i("code"),au=l("20"),Is=c(),be=i("p"),iu=l("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),br=i("code"),ou=l("150"),ru=l(" - "),wr=i("code"),lu=l("200"),su=l(" and keep in mind we can add and remove as we try different training settings with different output."),As=c(),$e=i("h4"),et=i("a"),yr=i("span"),nu=l("Download images"),Cs=c(),$a=i("p"),cu=l("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),Ps=c(),ce=i("ul"),ei=i("li"),Vt=i("a"),fu=l("3ee Games regularization images"),du=l(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),uu=c(),ti=i("li"),Qt=i("a"),pu=l("Pre-Rendered Regularization Images"),hu=l(": Includes 1500 regularization images."),mu=c(),ai=i("li"),Jt=i("a"),gu=l("Stable Diffusion 1.5 Regularization Images"),vu=l(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),_u=c(),ii=i("li"),$t=i("a"),Eu=l("Aitrepreneur SDXL image set"),bu=l(": a large image set generated with Stable Diffusion SDXL."),Ns=c(),tt=i("h4"),at=i("a"),kr=i("span"),wu=l("Captioning Regularization images"),xs=c(),it=i("p"),yu=l("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Dr=i("code"),ku=l("txt"),Du=l(" files with a shell script:"),qs=c(),ea=i("pre"),js=c(),we=i("p"),Ru=l("Save this file as "),Rr=i("code"),Tu=l("filename2txt.bat"),Su=l(" and place it into the regularization images directory and run: "),Tr=i("code"),zu=l(".\\filename2txt.bat"),Ou=l(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),Hs=c(),ta=i("p"),Lu=l("Example filename: "),Sr=i("code"),Iu=l("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),Us=c(),ot=i("p"),Au=l("Output: "),zr=i("code"),Cu=l("aburbres,princeadam,1boy,close-up,purple_vest"),Pu=l(" saved in a text file with the same name as image."),Gs=c(),rt=i("h2"),lt=i("a"),Or=i("span"),Nu=l("Training a LoRA"),Ws=c(),oi=i("p"),xu=l("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images."),Ms=c(),aa=i("blockquote"),ri=i("p"),qu=l("Learning how to train a LoRA is a completely different subject all on its own.  Learn more about LoRA training: LINK HERE."),Bs=c(),st=i("h3"),nt=i("a"),Lr=i("span"),ju=l("Directory setup"),Fs=c(),ct=i("p"),Hu=l("In your configuration json, use "),Ir=i("code"),Uu=l("reg_data_dir"),Gu=l(" to point to the directory with your regularization images:"),Ys=c(),ia=i("pre"),Xs=c(),li=i("p"),Wu=l("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Zs=c(),oa=i("pre"),Ks=c(),Q=i("p"),Mu=l("Specify the "),Ar=i("code"),Bu=l("number of iterations"),Fu=l(" so that the number of iterations of training images "),Cr=i("code"),Yu=l("x"),Xu=l(" =  the number of training images "),Pr=i("code"),Zu=l("\u2265"),Ku=l(" the number of iterations of regularization images "),Nr=i("code"),Vu=l("x"),Qu=l(` the number of regularization images .
(The number of data in one epoch is \u201Cnumber of repetitions of training images `),xr=i("code"),Ju=l("x"),$u=l(" number of training images\u201D. If the number of regularization images is more than that, the remaining regularization images will not be used.)"),Vs=c(),ye=i("p"),ep=l("Create folders in the training image folder with the format "),qr=i("code"),tp=l("<repetition count>_<class>"),ap=l(" multiple times, and similarly create folders in the regularization image folder with the format "),jr=i("code"),ip=l("<repetition count>_<class>"),op=l("."),Qs=c(),si=i("p"),rp=l("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Js=c(),ft=i("ul"),ni=i("li"),lp=l("train_data_dir"),Hr=i("ul"),Ur=i("li"),sp=l("10_princeadam"),np=c(),ci=i("li"),cp=l("reg_dir"),Gr=i("ul"),Wr=i("li"),fp=l("1_1boy"),$s=c(),fi=i("p"),dp=l("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),en=c(),di=i("p"),ra=i("img"),tn=c(),dt=i("h3"),ut=i("a"),Mr=i("span"),up=l("Training Settings"),an=c(),pt=i("p"),pp=l("The training setup we\u2019re going to use is:  "),Br=i("code"),hp=l("Number of images * repeats * epoch / batch size = total steps"),mp=l(".  Based on our training data, we have 45 images and going for 4500 steps:"),on=c(),Ne=i("table"),Fr=i("thead"),oe=i("tr"),Yr=i("th"),gp=l("Number of Images"),vp=c(),Xr=i("th"),_p=l("Repeats"),Ep=c(),Zr=i("th"),bp=l("Epochs"),wp=c(),Kr=i("th"),yp=l("Batch Size"),kp=c(),Vr=i("th"),Dp=l("Total Steps"),Rp=c(),Qr=i("tbody"),re=i("tr"),ui=i("td"),Tp=l("45"),Sp=c(),pi=i("td"),zp=l("10"),Op=c(),hi=i("td"),Lp=l("20"),Ip=c(),mi=i("td"),Ap=l("2"),Cp=c(),gi=i("td"),Pp=l("4500"),rn=c(),vi=i("p"),Np=l("Now let\u2019s focus on these training settings:"),ln=c(),la=i("pre"),sn=c(),C=i("ul"),_i=i("li"),sa=i("strong"),xp=l("Learning Rate ("),Jr=i("code"),qp=l("learning_rate"),jp=l(")"),Hp=l(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Up=c(),Ei=i("li"),na=i("strong"),Gp=l("Text Encoder Learning Rate ("),$r=i("code"),Wp=l("text_encoder_lr"),Mp=l(")"),Bp=l(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Fp=c(),bi=i("li"),ca=i("strong"),Yp=l("UNet Learning Rate ("),el=i("code"),Xp=l("unet_lr"),Zp=l(")"),Kp=l(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Vp=c(),wi=i("li"),fa=i("strong"),Qp=l("Learning Rate Scheduler ("),tl=i("code"),Jp=l("lr_scheduler"),$p=l(")"),eh=l(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),th=c(),yi=i("li"),da=i("strong"),ah=l("Number of Cycles in Learning Rate Scheduler ("),al=i("code"),ih=l("lr_scheduler_num_cycles"),oh=l(")"),rh=l(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),lh=c(),ki=i("li"),ua=i("strong"),sh=l("Network Dimension ("),il=i("code"),nh=l("network_dim"),ch=l(")"),fh=l(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),dh=c(),Di=i("li"),pa=i("strong"),uh=l("Network Alpha ("),ol=i("code"),ph=l("network_alpha"),hh=l(")"),mh=l(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),gh=c(),Ri=i("li"),ha=i("strong"),vh=l("Clip Skip ("),rl=i("code"),_h=l("clip_skip"),Eh=l(")"),bh=l(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),wh=c(),Ti=i("li"),ma=i("strong"),yh=l("Max Token Length ("),ll=i("code"),kh=l("max_token_length"),Dh=l(")"),Rh=l(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Th=c(),Si=i("li"),ga=i("strong"),Sh=l("Noise Offset ("),sl=i("code"),zh=l("noise_offset"),Oh=l(")"),Lh=l(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Ih=c(),zi=i("li"),va=i("strong"),Ah=l("Regularization Data Directory ("),nl=i("code"),Ch=l("reg_data_dir"),Ph=l(")"),Nh=l(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),nn=c(),ht=i("h3"),mt=i("a"),cl=i("span"),xh=l("Fine Tuning"),cn=c(),Oi=i("p"),qh=l("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),fn=c(),gt=i("h4"),vt=i("a"),fl=i("span"),jh=l("Workflow with Auto1111 WebUI"),dn=c(),_t=i("p"),Hh=l("We\u2019re going to use "),_a=i("a"),Uh=l("Stable Diffusion web UI"),Gh=l(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),un=c(),Et=i("p"),Wh=l("We\u2019re going to use the "),dl=i("code"),Mh=l("X/Y/Z plot"),Bh=l(" script to compare different epochs."),pn=c(),te=i("ul"),Li=i("li"),Fh=l("Select the text 2 image tab.  Enter a generic prompt "),ul=i("code"),Yh=l("princeadam, portrait, <princeadam0001:0.7>"),Xh=c(),Ea=i("li"),Zh=l("In generation parameters and select the "),pl=i("code"),Kh=l("X/Y/Z plot"),Vh=l(" script."),Qh=c(),ae=i("li"),Jh=l("Select "),hl=i("code"),$h=l("Prompt SR"),em=l(" for Prompt Replace.  We\u2019re going to replace "),ml=i("code"),tm=l("<princeadam0001:0.7>"),am=l(" with different epoch: "),gl=i("code"),im=l("<princeadam0001:0.7>"),om=l(", "),vl=i("code"),rm=l("<princeadam0003:0.7>"),lm=l(", "),_l=i("code"),sm=l("<princeadam0023:0.7>"),nm=c(),Ii=i("li"),cm=l("Select a fast sampler like "),El=i("code"),fm=l("DPM2 KARRAS"),dm=c(),bt=i("li"),um=l("CFG Scale set to "),bl=i("code"),pm=l("7"),hm=l(" and Steps to "),wl=i("code"),mm=l("20"),hn=c(),ke=i("p"),gm=l("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),yl=i("code"),vm=l("network_dim"),_m=l(" and "),kl=i("code"),Em=l("network_alpha"),bm=l("?  Those are the settings that directly control the output strength mentioned earlier."),mn=c(),fe=i("ul"),W=i("li"),wm=l("Select "),Dl=i("code"),ym=l("Prompt SR"),km=l(" for Prompt Replace.  We\u2019re going to replace the weights "),Rl=i("code"),Dm=l("<princeadam12:0.4>"),Rm=l(","),Tl=i("code"),Tm=l("<princeadam12:0.5>"),Sm=l(", "),Sl=i("code"),zm=l("<princeadam12:0.6>"),Om=l(", "),zl=i("code"),Lm=l("<princeadam12:0.7>"),Im=l(", "),Ol=i("code"),Am=l("<princeadam12:0.8>"),Cm=l(", "),Ll=i("code"),Pm=l("<princeadam12:0.9>"),Nm=l(", "),Il=i("code"),xm=l("<princeadam12:1.0>"),qm=c(),J=i("li"),jm=l("Use another "),Al=i("code"),Hm=l("Prompt SR"),Um=l(" to generate a variety of different angles: Select "),Cl=i("code"),Gm=l("Prompt SR"),Wm=l(" for Prompt Replace.  Replace "),Pl=i("code"),Mm=l("upper_body"),Bm=l(" with different camera angles: "),Nl=i("code"),Fm=l("from_below"),Ym=l(", "),xl=i("code"),Xm=l("from_above"),Zm=l(", "),ql=i("code"),Km=l("close_up"),Vm=c(),jl=i("li"),Qm=l("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),Jm=c(),Hl=i("li"),$m=l("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),gn=c(),wt=i("h4"),yt=i("a"),Ul=i("span"),eg=l("Issues to look for"),vn=c(),de=i("ul"),Ai=i("li"),Gl=i("strong"),tg=l("Undercooked:"),ag=l(" Lacks output, adjust unet learning rate or extend training duration."),ig=c(),Ci=i("li"),Wl=i("strong"),og=l("Overcooked:"),rg=l(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),lg=c(),Pi=i("li"),Ml=i("strong"),sg=l("Overfit:"),ng=l(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),cg=c(),Ni=i("li"),Bl=i("strong"),fg=l("Mismatched:"),dg=l(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),_n=c(),xi=i("p"),ug=l("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),En=c(),kt=i("h4"),Dt=i("a"),Fl=i("span"),pg=l("Troubleshooting"),bn=c(),qi=i("p"),hg=l("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),wn=c(),De=i("ul"),ba=i("li"),mg=l("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Yl=i("code"),gg=l("200"),vg=l(" regularization images per training image."),_g=c(),wa=i("li"),Eg=l("Repeats of regularization images, but may overfit more.  Increasing the "),Xl=i("code"),bg=l("repetition_count"),wg=l(" will cycle through the images more but the results may have results that overfit the model."),yg=c(),Zl=i("li"),kg=l("Create more regularization images without increasing repeats will help with the overfitting."),yn=c(),xe=i("table"),Kl=i("thead"),qe=i("tr"),Vl=i("th"),Dg=l("Issue"),Rg=c(),Ql=i("th"),Tg=l("Situation"),Sg=c(),Jl=i("th"),zg=l("Recommendation"),Og=c(),me=i("tbody"),je=i("tr"),ji=i("td"),Lg=l("Varying quality"),Ig=c(),Hi=i("td"),Ag=l("Results differ from expectations"),Cg=c(),Ui=i("td"),Pg=l("Evaluate the quality and quantity of regularization images. Adjust the number and selection and check for better results."),Ng=c(),He=i("tr"),Gi=i("td"),xg=l("Inadequate regularization for input data"),qg=c(),Wi=i("td"),jg=l("Lower input images, less regularization needed"),Hg=c(),Mi=i("td"),Ug=l("Consider reducing the number of input images or increasing the quantity and diversity of regularization images."),Gg=c(),Ue=i("tr"),Bi=i("td"),Wg=l("Overfitting due to repetition"),Mg=c(),Fi=i("td"),Bg=l("Repeats of regularization images, risk of overfitting"),Fg=c(),Rt=i("td"),Yg=l("Adjust the "),$l=i("code"),Xg=l("repetition_count"),Zg=l(" to balance cycling through images without overfitting. Monitor results for improvements."),Kg=c(),Ge=i("tr"),Yi=i("td"),Vg=l("Mitigate overfitting while increasing diversity"),Qg=c(),Xi=i("td"),Jg=l("Create more regularization images without repeats"),$g=c(),Zi=i("td"),ev=l("Generate additional regularization images without increasing repetitions. Enhance model adaptability without overfitting."),kn=c(),Tt=i("h3"),St=i("a"),es=i("span"),tv=l("Results"),Dn=c(),Ki=i("p"),av=l("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),Rn=c(),Vi=i("p"),iv=l("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),Tn=c(),Qi=i("p"),ov=l("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),Sn=c(),ge&&ge.c(),zn=dc(),this.h()},l(a){p=o(a,"P",{});var u=r(p);g=s(u,"I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),u.forEach(t),h=f(a),ls(v.$$.fragment,a),m=f(a),E=o(a,"H2",{id:!0});var rv=r(E);y=o(rv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var e_=r(y);D=o(e_,"SPAN",{class:!0}),r(D).forEach(t),e_.forEach(t),N=s(rv,"What are Regularization Images?"),rv.forEach(t),O=f(a),S=o(a,"P",{});var t_=r(S);k=s(t_,"Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model.  To further illustrate: regularization images are extra pictures that are used to help Stable Diffusion learn better."),t_.forEach(t),j=f(a),M=o(a,"BLOCKQUOTE",{class:!0});var a_=r(M);x=o(a_,"P",{class:!0});var i_=r(x);B=s(i_,"Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),i_.forEach(t),a_.forEach(t),I=f(a),R=o(a,"P",{});var o_=r(R);A=s(o_,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),o_.forEach(t),H=f(a),P=o(a,"P",{});var r_=r(P);_e=s(r_,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),r_.forEach(t),se=f(a),z=o(a,"P",{});var l_=r(z);T=s(l_,"In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),l_.forEach(t),b=f(a),w=o(a,"TABLE",{class:!0});var Ln=r(w);L=o(Ln,"THEAD",{});var s_=r(L);V=o(s_,"TR",{});var Ji=r(V);$=o(Ji,"TH",{});var n_=r($);Oe=s(n_,"Aspect"),n_.forEach(t),mc=f(Ji),mo=o(Ji,"TH",{});var c_=r(mo);gc=s(c_,"Regularization"),c_.forEach(t),vc=f(Ji),go=o(Ji,"TH",{});var f_=r(go);_c=s(f_,"No Regularization"),f_.forEach(t),Ji.forEach(t),s_.forEach(t),Ec=f(Ln),pe=o(Ln,"TBODY",{});var zt=r(pe);Le=o(zt,"TR",{});var $i=r(Le);Da=o($i,"TD",{class:!0});var d_=r(Da);vo=o(d_,"STRONG",{});var u_=r(vo);bc=s(u_,"Definition"),u_.forEach(t),d_.forEach(t),wc=f($i),Ra=o($i,"TD",{class:!0});var p_=r(Ra);yc=s(p_,"Defines skateboard class"),p_.forEach(t),kc=f($i),Ta=o($i,"TD",{class:!0});var h_=r(Ta);Dc=s(h_,"No specific class"),h_.forEach(t),$i.forEach(t),Rc=f(zt),Ie=o(zt,"TR",{});var eo=r(Ie);Sa=o(eo,"TD",{class:!0});var m_=r(Sa);_o=o(m_,"STRONG",{});var g_=r(_o);Tc=s(g_,"Example"),g_.forEach(t),m_.forEach(t),Sc=f(eo),za=o(eo,"TD",{class:!0});var v_=r(za);zc=s(v_,"Uses skateboard images"),v_.forEach(t),Oc=f(eo),Oa=o(eo,"TD",{class:!0});var __=r(Oa);Lc=s(__,"No specific images"),__.forEach(t),eo.forEach(t),Ic=f(zt),Ae=o(zt,"TR",{});var to=r(Ae);La=o(to,"TD",{class:!0});var E_=r(La);Eo=o(E_,"STRONG",{});var b_=r(Eo);Ac=s(b_,"Purpose"),b_.forEach(t),E_.forEach(t),Cc=f(to),Ia=o(to,"TD",{class:!0});var w_=r(Ia);Pc=s(w_,"Prevents drift, focuses on skateboard class"),w_.forEach(t),Nc=f(to),Aa=o(to,"TD",{class:!0});var y_=r(Aa);xc=s(y_,"May drift to unrelated classes"),y_.forEach(t),to.forEach(t),qc=f(zt),Ce=o(zt,"TR",{});var ao=r(Ce);Ca=o(ao,"TD",{class:!0});var k_=r(Ca);bo=o(k_,"STRONG",{});var D_=r(bo);jc=s(D_,"Overfitting"),D_.forEach(t),k_.forEach(t),Hc=f(ao),Pa=o(ao,"TD",{class:!0});var R_=r(Pa);Uc=s(R_,"Guards against overfitting"),R_.forEach(t),Gc=f(ao),Na=o(ao,"TD",{class:!0});var T_=r(Na);Wc=s(T_,"Higher risk of overfitting"),T_.forEach(t),ao.forEach(t),zt.forEach(t),Ln.forEach(t),cs=f(a),xa=o(a,"P",{});var S_=r(xa);Mc=s(S_,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. We call this ability to work well with new data \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),S_.forEach(t),fs=f(a),qa=o(a,"P",{});var z_=r(qa);Bc=s(z_,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well even with the training data. This happens when we limit our model\u2019s ability too much."),z_.forEach(t),ds=f(a),xt=o(a,"BLOCKQUOTE",{class:!0});var O_=r(xt);ja=o(O_,"P",{class:!0});var L_=r(ja);Fc=s(L_,"Imagine a graph of points. We want to find a function that fits those points well. We could choose a simple function, which might not fit the points very well. Or we could choose a very complex function that fits the points perfectly, but it might not work well with new points we haven\u2019t seen before. The key is to find the right balance between simplicity and complexity to achieve the best performance."),L_.forEach(t),O_.forEach(t),us=f(a),qt=o(a,"P",{});var lv=r(qt);wo=o(lv,"STRONG",{});var I_=r(wo);Yc=s(I_,"Scenario 1"),I_.forEach(t),Xc=s(lv,": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),lv.forEach(t),ps=f(a),jt=o(a,"P",{});var sv=r(jt);yo=o(sv,"STRONG",{});var A_=r(yo);Zc=s(A_,"Solution"),A_.forEach(t),Kc=s(sv,": consider using regularization images to help the model learn more about cat features."),sv.forEach(t),hs=f(a),Ht=o(a,"P",{});var nv=r(Ht);ko=o(nv,"STRONG",{});var C_=r(ko);Vc=s(C_,"Scenario 2"),C_.forEach(t),Qc=s(nv,": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),nv.forEach(t),ms=f(a),Ut=o(a,"P",{});var cv=r(Ut);Do=o(cv,"STRONG",{});var P_=r(Do);Jc=s(P_,"Solution"),P_.forEach(t),$c=s(cv,": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),cv.forEach(t),gs=f(a),Me=o(a,"H2",{id:!0});var fv=r(Me);Be=o(fv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var N_=r(Be);Ro=o(N_,"SPAN",{class:!0}),r(Ro).forEach(t),N_.forEach(t),ef=s(fv,"Divergence"),fv.forEach(t),vs=f(a),Fe=o(a,"P",{});var In=r(Fe);tf=s(In,"Providing too much data leads to "),To=o(In,"STRONG",{});var x_=r(To);af=s(x_,"divergence"),x_.forEach(t),of=s(In,". Divergence happens when the model produces random outputs that do not accurately represent the subject\u2019s likeness. This can occur because the model is trying to learn from too many images with inconsistent features, causing it to become confused and produce poor results."),In.forEach(t),_s=f(a),Ha=o(a,"P",{});var q_=r(Ha);rf=s(q_,"To avoid divergence, we need to ensure the model is focusing on the features that are unique and consistent with your subject.  This starts from carefully curating the dataset by selecting high-quality images that accurately represent the object."),q_.forEach(t),Es=f(a),Ua=o(a,"P",{});var j_=r(Ua);lf=s(j_,"Training a model to recognize specific objects requires careful consideration of the dataset and the use of regularization techniques to ensure the model is focused on the right features and is not prone to divergence."),j_.forEach(t),bs=f(a),Pe=o(a,"TABLE",{class:!0});var An=r(Pe);So=o(An,"THEAD",{});var H_=r(So);Gt=o(H_,"TR",{});var Cn=r(Gt);zo=o(Cn,"TH",{});var U_=r(zo);sf=s(U_,"Situation"),U_.forEach(t),nf=f(Cn),Oo=o(Cn,"TH",{});var G_=r(Oo);cf=s(G_,"Outcome"),G_.forEach(t),Cn.forEach(t),H_.forEach(t),ff=f(An),he=o(An,"TBODY",{});var Ot=r(he);Wt=o(Ot,"TR",{});var Pn=r(Wt);Ga=o(Pn,"TD",{class:!0});var W_=r(Ga);df=s(W_,"Too many regularization images or inconsistent features"),W_.forEach(t),uf=f(Pn),Wa=o(Pn,"TD",{class:!0});var M_=r(Wa);pf=s(M_,"Model performance suffers, leading to inaccurate predictions."),M_.forEach(t),Pn.forEach(t),hf=f(Ot),Mt=o(Ot,"TR",{});var Nn=r(Mt);Ma=o(Nn,"TD",{class:!0});var B_=r(Ma);mf=s(B_,"Lack of focus on unique and consistent features"),B_.forEach(t),gf=f(Nn),Ba=o(Nn,"TD",{class:!0});var F_=r(Ba);vf=s(F_,"Difficulty learning meaningful patterns, impacting prediction accuracy."),F_.forEach(t),Nn.forEach(t),_f=f(Ot),Bt=o(Ot,"TR",{});var xn=r(Bt);Fa=o(xn,"TD",{class:!0});var Y_=r(Fa);Ef=s(Y_,"Need for careful dataset curation"),Y_.forEach(t),bf=f(xn),Ya=o(xn,"TD",{class:!0});var X_=r(Ya);wf=s(X_,"High-quality image selection to avoid confusion and divergence."),X_.forEach(t),xn.forEach(t),yf=f(Ot),Ft=o(Ot,"TR",{});var qn=r(Ft);Xa=o(qn,"TD",{class:!0});var Z_=r(Xa);kf=s(Z_,"Importance of regularization techniques"),Z_.forEach(t),Df=f(qn),Za=o(qn,"TD",{class:!0});var K_=r(Za);Rf=s(K_,"Proper use ensures model focuses on relevant features for accurate predictions."),K_.forEach(t),qn.forEach(t),Ot.forEach(t),An.forEach(t),ws=f(a),Ye=o(a,"H2",{id:!0});var dv=r(Ye);Xe=o(dv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var V_=r(Xe);Lo=o(V_,"SPAN",{class:!0}),r(Lo).forEach(t),V_.forEach(t),Tf=s(dv,"Generating Regularization images"),dv.forEach(t),ys=f(a),Ze=o(a,"P",{});var jn=r(Ze);Sf=s(jn,"Regularization images are generated using model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),Io=o(jn,"CODE",{});var Q_=r(Io);zf=s(Q_,"1boy"),Q_.forEach(t),Of=s(jn,")."),jn.forEach(t),ks=f(a),ne=o(a,"P",{});var Lt=r(ne);Lf=s(Lt,"According to the Dreambooth technique, "),Ao=o(Lt,"CODE",{});var J_=r(Ao);If=s(J_,"200"),J_.forEach(t),Af=s(Lt," regularization images per training image.  For example, if you have "),Co=o(Lt,"CODE",{});var $_=r(Co);Cf=s($_,"16"),$_.forEach(t),Pf=s(Lt," images: "),Po=o(Lt,"CODE",{});var e1=r(Po);Nf=s(e1,"200 * 16 = 3200"),e1.forEach(t),xf=s(Lt," total regularization images.  When training, the math involved for calculating total steps is:"),Lt.forEach(t),Ds=f(a),Yt=o(a,"BLOCKQUOTE",{class:!0});var t1=r(Yt);Ka=o(t1,"P",{class:!0});var a1=r(Ka);No=o(a1,"CODE",{});var i1=r(No);qf=s(i1,"repeats * training images >= repeats * regularization images"),i1.forEach(t),a1.forEach(t),t1.forEach(t),Rs=f(a),Va=o(a,"P",{});var o1=r(Va);jf=s(o1,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),o1.forEach(t),Ts=f(a),ls(Xt.$$.fragment,a),Ss=f(a),Ke=o(a,"H4",{id:!0});var uv=r(Ke);Ve=o(uv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r1=r(Ve);xo=o(r1,"SPAN",{class:!0}),r(xo).forEach(t),r1.forEach(t),Hf=s(uv,"Generate using Stable Diffusion web UI"),uv.forEach(t),zs=f(a),Qe=o(a,"P",{});var Hn=r(Qe);Uf=s(Hn,"We\u2019re going to use "),Zt=o(Hn,"A",{href:!0,rel:!0});var l1=r(Zt);Gf=s(l1,"Stable Diffusion web UI"),l1.forEach(t),Wf=s(Hn," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Hn.forEach(t),Os=f(a),Ee=o(a,"P",{});var io=r(Ee);Mf=s(io,"We\u2019re going to use the "),qo=o(io,"CODE",{});var s1=r(qo);Bf=s(s1,"X/Y/Z plot"),s1.forEach(t),Ff=s(io," script to use "),jo=o(io,"CODE",{});var n1=r(jo);Yf=s(n1,"Prompt Search & Replace"),n1.forEach(t),Xf=s(io," to dynamically build a prompt that will generate hundreds of regularization images."),io.forEach(t),Ls=f(a),F=o(a,"OL",{});var ie=r(F);Ho=o(ie,"LI",{});var c1=r(Ho);Qa=o(c1,"P",{});var pv=r(Qa);Zf=s(pv,"Select the text 2 image tab.  Enter a generic prompt "),Uo=o(pv,"CODE",{});var f1=r(Uo);Kf=s(f1,"princeadam, portrait, looking_at_viewer, forest"),f1.forEach(t),pv.forEach(t),c1.forEach(t),Vf=f(ie),Go=o(ie,"LI",{});var d1=r(Go);Kt=o(d1,"P",{});var Un=r(Kt);Qf=s(Un,"In generation parameters and select the "),Wo=o(Un,"CODE",{});var u1=r(Wo);Jf=s(u1,"X/Y/Z plot"),u1.forEach(t),$f=s(Un," script."),Un.forEach(t),d1.forEach(t),ed=f(ie),Mo=o(ie,"LI",{});var p1=r(Mo);U=o(p1,"P",{});var X=r(U);td=s(X,"Select the "),Bo=o(X,"CODE",{});var h1=r(Bo);ad=s(h1,"X"),h1.forEach(t),id=s(X," parameter and "),Fo=o(X,"CODE",{});var m1=r(Fo);od=s(m1,"Prompt SR"),m1.forEach(t),rd=s(X," for Prompt Replace.  We\u2019re going to replace "),Yo=o(X,"CODE",{});var g1=r(Yo);ld=s(g1,"portrait"),g1.forEach(t),sd=s(X," with different camera angle tags: "),Xo=o(X,"CODE",{});var v1=r(Xo);nd=s(v1,"close-up"),v1.forEach(t),cd=s(X,", "),Zo=o(X,"CODE",{});var _1=r(Zo);fd=s(_1,"upper_body"),_1.forEach(t),dd=s(X,", "),Ko=o(X,"CODE",{});var E1=r(Ko);ud=s(E1,"from_below"),E1.forEach(t),pd=s(X,", "),Vo=o(X,"CODE",{});var b1=r(Vo);hd=s(b1,"from_above"),b1.forEach(t),md=s(X,", "),Qo=o(X,"CODE",{});var w1=r(Qo);gd=s(w1,"dutch_angle"),w1.forEach(t),X.forEach(t),p1.forEach(t),vd=f(ie),Jo=o(ie,"LI",{});var y1=r(Jo);Y=o(y1,"P",{});var ee=r(Y);_d=s(ee,"Select the "),$o=o(ee,"CODE",{});var k1=r($o);Ed=s(k1,"Y"),k1.forEach(t),bd=s(ee," parameter and "),er=o(ee,"CODE",{});var D1=r(er);wd=s(D1,"Prompt SR"),D1.forEach(t),yd=s(ee," for Prompt Replace.  Replace "),tr=o(ee,"CODE",{});var R1=r(tr);kd=s(R1,"looking_at_viewer"),R1.forEach(t),Dd=s(ee,": "),ar=o(ee,"CODE",{});var T1=r(ar);Rd=s(T1,"looking_away"),T1.forEach(t),Td=s(ee,", "),ir=o(ee,"CODE",{});var S1=r(ir);Sd=s(S1,"looking_to_the_side"),S1.forEach(t),zd=s(ee,", "),or=o(ee,"CODE",{});var z1=r(or);Od=s(z1,"looking_ahead"),z1.forEach(t),Ld=s(ee,", "),rr=o(ee,"CODE",{});var O1=r(rr);Id=s(O1,"looking_down"),O1.forEach(t),ee.forEach(t),y1.forEach(t),Ad=f(ie),lr=o(ie,"LI",{});var L1=r(lr);G=o(L1,"P",{});var Z=r(G);Cd=s(Z,"Select the "),sr=o(Z,"CODE",{});var I1=r(sr);Pd=s(I1,"Z"),I1.forEach(t),Nd=s(Z," parameter and "),nr=o(Z,"CODE",{});var A1=r(nr);xd=s(A1,"Prompt SR"),A1.forEach(t),qd=s(Z," for Prompt Replace. Replace "),cr=o(Z,"CODE",{});var C1=r(cr);jd=s(C1,"forest"),C1.forEach(t),Hd=s(Z," with a vareity of locatinos: "),fr=o(Z,"CODE",{});var P1=r(fr);Ud=s(P1,"castle"),P1.forEach(t),Gd=s(Z,", "),dr=o(Z,"CODE",{});var N1=r(dr);Wd=s(N1,"mountain"),N1.forEach(t),Md=s(Z,", "),ur=o(Z,"CODE",{});var x1=r(ur);Bd=s(x1,"cave"),x1.forEach(t),Fd=s(Z,", "),pr=o(Z,"CODE",{});var q1=r(pr);Yd=s(q1,"farm"),q1.forEach(t),Xd=s(Z,", "),hr=o(Z,"CODE",{});var j1=r(hr);Zd=s(j1,"ocean"),j1.forEach(t),Z.forEach(t),L1.forEach(t),Kd=f(ie),mr=o(ie,"LI",{});var H1=r(mr);Ja=o(H1,"P",{});var hv=r(Ja);Vd=s(hv,"Select a fast sampler like "),gr=o(hv,"CODE",{});var U1=r(gr);Qd=s(U1,"DPM2 KARRAS"),U1.forEach(t),hv.forEach(t),H1.forEach(t),Jd=f(ie),vr=o(ie,"LI",{});var G1=r(vr);Je=o(G1,"P",{});var ts=r(Je);$d=s(ts,"CFG Scale set to "),_r=o(ts,"CODE",{});var W1=r(_r);eu=s(W1,"7"),W1.forEach(t),tu=s(ts," and Steps to "),Er=o(ts,"CODE",{});var M1=r(Er);au=s(M1,"20"),M1.forEach(t),ts.forEach(t),G1.forEach(t),ie.forEach(t),Is=f(a),be=o(a,"P",{});var oo=r(be);iu=s(oo,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),br=o(oo,"CODE",{});var B1=r(br);ou=s(B1,"150"),B1.forEach(t),ru=s(oo," - "),wr=o(oo,"CODE",{});var F1=r(wr);lu=s(F1,"200"),F1.forEach(t),su=s(oo," and keep in mind we can add and remove as we try different training settings with different output."),oo.forEach(t),As=f(a),$e=o(a,"H4",{id:!0});var mv=r($e);et=o(mv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Y1=r(et);yr=o(Y1,"SPAN",{class:!0}),r(yr).forEach(t),Y1.forEach(t),nu=s(mv,"Download images"),mv.forEach(t),Cs=f(a),$a=o(a,"P",{});var X1=r($a);cu=s(X1,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),X1.forEach(t),Ps=f(a),ce=o(a,"UL",{});var It=r(ce);ei=o(It,"LI",{});var gv=r(ei);Vt=o(gv,"A",{href:!0,rel:!0});var Z1=r(Vt);fu=s(Z1,"3ee Games regularization images"),Z1.forEach(t),du=s(gv,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),gv.forEach(t),uu=f(It),ti=o(It,"LI",{});var vv=r(ti);Qt=o(vv,"A",{href:!0,rel:!0});var K1=r(Qt);pu=s(K1,"Pre-Rendered Regularization Images"),K1.forEach(t),hu=s(vv,": Includes 1500 regularization images."),vv.forEach(t),mu=f(It),ai=o(It,"LI",{});var _v=r(ai);Jt=o(_v,"A",{href:!0,rel:!0});var V1=r(Jt);gu=s(V1,"Stable Diffusion 1.5 Regularization Images"),V1.forEach(t),vu=s(_v,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),_v.forEach(t),_u=f(It),ii=o(It,"LI",{});var Ev=r(ii);$t=o(Ev,"A",{href:!0,rel:!0});var Q1=r($t);Eu=s(Q1,"Aitrepreneur SDXL image set"),Q1.forEach(t),bu=s(Ev,": a large image set generated with Stable Diffusion SDXL."),Ev.forEach(t),It.forEach(t),Ns=f(a),tt=o(a,"H4",{id:!0});var bv=r(tt);at=o(bv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var J1=r(at);kr=o(J1,"SPAN",{class:!0}),r(kr).forEach(t),J1.forEach(t),wu=s(bv,"Captioning Regularization images"),bv.forEach(t),xs=f(a),it=o(a,"P",{});var Gn=r(it);yu=s(Gn,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Dr=o(Gn,"CODE",{});var $1=r(Dr);ku=s($1,"txt"),$1.forEach(t),Du=s(Gn," files with a shell script:"),Gn.forEach(t),qs=f(a),ea=o(a,"PRE",{class:!0});var Eb=r(ea);Eb.forEach(t),js=f(a),we=o(a,"P",{});var ro=r(we);Ru=s(ro,"Save this file as "),Rr=o(ro,"CODE",{});var e2=r(Rr);Tu=s(e2,"filename2txt.bat"),e2.forEach(t),Su=s(ro," and place it into the regularization images directory and run: "),Tr=o(ro,"CODE",{});var t2=r(Tr);zu=s(t2,".\\filename2txt.bat"),t2.forEach(t),Ou=s(ro,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),ro.forEach(t),Hs=f(a),ta=o(a,"P",{});var wv=r(ta);Lu=s(wv,"Example filename: "),Sr=o(wv,"CODE",{});var a2=r(Sr);Iu=s(a2,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),a2.forEach(t),wv.forEach(t),Us=f(a),ot=o(a,"P",{});var Wn=r(ot);Au=s(Wn,"Output: "),zr=o(Wn,"CODE",{});var i2=r(zr);Cu=s(i2,"aburbres,princeadam,1boy,close-up,purple_vest"),i2.forEach(t),Pu=s(Wn," saved in a text file with the same name as image."),Wn.forEach(t),Gs=f(a),rt=o(a,"H2",{id:!0});var yv=r(rt);lt=o(yv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var o2=r(lt);Or=o(o2,"SPAN",{class:!0}),r(Or).forEach(t),o2.forEach(t),Nu=s(yv,"Training a LoRA"),yv.forEach(t),Ws=f(a),oi=o(a,"P",{});var r2=r(oi);xu=s(r2,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images."),r2.forEach(t),Ms=f(a),aa=o(a,"BLOCKQUOTE",{class:!0});var l2=r(aa);ri=o(l2,"P",{class:!0});var s2=r(ri);qu=s(s2,"Learning how to train a LoRA is a completely different subject all on its own.  Learn more about LoRA training: LINK HERE."),s2.forEach(t),l2.forEach(t),Bs=f(a),st=o(a,"H3",{id:!0});var kv=r(st);nt=o(kv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var n2=r(nt);Lr=o(n2,"SPAN",{class:!0}),r(Lr).forEach(t),n2.forEach(t),ju=s(kv,"Directory setup"),kv.forEach(t),Fs=f(a),ct=o(a,"P",{});var Mn=r(ct);Hu=s(Mn,"In your configuration json, use "),Ir=o(Mn,"CODE",{});var c2=r(Ir);Uu=s(c2,"reg_data_dir"),c2.forEach(t),Gu=s(Mn," to point to the directory with your regularization images:"),Mn.forEach(t),Ys=f(a),ia=o(a,"PRE",{class:!0});var bb=r(ia);bb.forEach(t),Xs=f(a),li=o(a,"P",{});var f2=r(li);Wu=s(f2,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),f2.forEach(t),Zs=f(a),oa=o(a,"PRE",{class:!0});var wb=r(oa);wb.forEach(t),Ks=f(a),Q=o(a,"P",{});var ue=r(Q);Mu=s(ue,"Specify the "),Ar=o(ue,"CODE",{});var d2=r(Ar);Bu=s(d2,"number of iterations"),d2.forEach(t),Fu=s(ue," so that the number of iterations of training images "),Cr=o(ue,"CODE",{});var u2=r(Cr);Yu=s(u2,"x"),u2.forEach(t),Xu=s(ue," =  the number of training images "),Pr=o(ue,"CODE",{});var p2=r(Pr);Zu=s(p2,"\u2265"),p2.forEach(t),Ku=s(ue," the number of iterations of regularization images "),Nr=o(ue,"CODE",{});var h2=r(Nr);Vu=s(h2,"x"),h2.forEach(t),Qu=s(ue,` the number of regularization images .
(The number of data in one epoch is \u201Cnumber of repetitions of training images `),xr=o(ue,"CODE",{});var m2=r(xr);Ju=s(m2,"x"),m2.forEach(t),$u=s(ue," number of training images\u201D. If the number of regularization images is more than that, the remaining regularization images will not be used.)"),ue.forEach(t),Vs=f(a),ye=o(a,"P",{});var lo=r(ye);ep=s(lo,"Create folders in the training image folder with the format "),qr=o(lo,"CODE",{});var g2=r(qr);tp=s(g2,"<repetition count>_<class>"),g2.forEach(t),ap=s(lo," multiple times, and similarly create folders in the regularization image folder with the format "),jr=o(lo,"CODE",{});var v2=r(jr);ip=s(v2,"<repetition count>_<class>"),v2.forEach(t),op=s(lo,"."),lo.forEach(t),Qs=f(a),si=o(a,"P",{});var _2=r(si);rp=s(_2,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),_2.forEach(t),Js=f(a),ft=o(a,"UL",{});var Bn=r(ft);ni=o(Bn,"LI",{});var Dv=r(ni);lp=s(Dv,"train_data_dir"),Hr=o(Dv,"UL",{});var E2=r(Hr);Ur=o(E2,"LI",{});var b2=r(Ur);sp=s(b2,"10_princeadam"),b2.forEach(t),E2.forEach(t),Dv.forEach(t),np=f(Bn),ci=o(Bn,"LI",{});var Rv=r(ci);cp=s(Rv,"reg_dir"),Gr=o(Rv,"UL",{});var w2=r(Gr);Wr=o(w2,"LI",{});var y2=r(Wr);fp=s(y2,"1_1boy"),y2.forEach(t),w2.forEach(t),Rv.forEach(t),Bn.forEach(t),$s=f(a),fi=o(a,"P",{});var k2=r(fi);dp=s(k2,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),k2.forEach(t),en=f(a),di=o(a,"P",{});var D2=r(di);ra=o(D2,"IMG",{src:!0,alt:!0,class:!0}),D2.forEach(t),tn=f(a),dt=o(a,"H3",{id:!0});var Tv=r(dt);ut=o(Tv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var R2=r(ut);Mr=o(R2,"SPAN",{class:!0}),r(Mr).forEach(t),R2.forEach(t),up=s(Tv,"Training Settings"),Tv.forEach(t),an=f(a),pt=o(a,"P",{});var Fn=r(pt);pp=s(Fn,"The training setup we\u2019re going to use is:  "),Br=o(Fn,"CODE",{});var T2=r(Br);hp=s(T2,"Number of images * repeats * epoch / batch size = total steps"),T2.forEach(t),mp=s(Fn,".  Based on our training data, we have 45 images and going for 4500 steps:"),Fn.forEach(t),on=f(a),Ne=o(a,"TABLE",{class:!0});var Yn=r(Ne);Fr=o(Yn,"THEAD",{});var S2=r(Fr);oe=o(S2,"TR",{});var Re=r(oe);Yr=o(Re,"TH",{});var z2=r(Yr);gp=s(z2,"Number of Images"),z2.forEach(t),vp=f(Re),Xr=o(Re,"TH",{});var O2=r(Xr);_p=s(O2,"Repeats"),O2.forEach(t),Ep=f(Re),Zr=o(Re,"TH",{});var L2=r(Zr);bp=s(L2,"Epochs"),L2.forEach(t),wp=f(Re),Kr=o(Re,"TH",{});var I2=r(Kr);yp=s(I2,"Batch Size"),I2.forEach(t),kp=f(Re),Vr=o(Re,"TH",{});var A2=r(Vr);Dp=s(A2,"Total Steps"),A2.forEach(t),Re.forEach(t),S2.forEach(t),Rp=f(Yn),Qr=o(Yn,"TBODY",{});var C2=r(Qr);re=o(C2,"TR",{});var Te=r(re);ui=o(Te,"TD",{class:!0});var P2=r(ui);Tp=s(P2,"45"),P2.forEach(t),Sp=f(Te),pi=o(Te,"TD",{class:!0});var N2=r(pi);zp=s(N2,"10"),N2.forEach(t),Op=f(Te),hi=o(Te,"TD",{class:!0});var x2=r(hi);Lp=s(x2,"20"),x2.forEach(t),Ip=f(Te),mi=o(Te,"TD",{class:!0});var q2=r(mi);Ap=s(q2,"2"),q2.forEach(t),Cp=f(Te),gi=o(Te,"TD",{class:!0});var j2=r(gi);Pp=s(j2,"4500"),j2.forEach(t),Te.forEach(t),C2.forEach(t),Yn.forEach(t),rn=f(a),vi=o(a,"P",{});var H2=r(vi);Np=s(H2,"Now let\u2019s focus on these training settings:"),H2.forEach(t),ln=f(a),la=o(a,"PRE",{class:!0});var yb=r(la);yb.forEach(t),sn=f(a),C=o(a,"UL",{});var q=r(C);_i=o(q,"LI",{});var Sv=r(_i);sa=o(Sv,"STRONG",{});var Xn=r(sa);xp=s(Xn,"Learning Rate ("),Jr=o(Xn,"CODE",{});var U2=r(Jr);qp=s(U2,"learning_rate"),U2.forEach(t),jp=s(Xn,")"),Xn.forEach(t),Hp=s(Sv,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Sv.forEach(t),Up=f(q),Ei=o(q,"LI",{});var zv=r(Ei);na=o(zv,"STRONG",{});var Zn=r(na);Gp=s(Zn,"Text Encoder Learning Rate ("),$r=o(Zn,"CODE",{});var G2=r($r);Wp=s(G2,"text_encoder_lr"),G2.forEach(t),Mp=s(Zn,")"),Zn.forEach(t),Bp=s(zv,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),zv.forEach(t),Fp=f(q),bi=o(q,"LI",{});var Ov=r(bi);ca=o(Ov,"STRONG",{});var Kn=r(ca);Yp=s(Kn,"UNet Learning Rate ("),el=o(Kn,"CODE",{});var W2=r(el);Xp=s(W2,"unet_lr"),W2.forEach(t),Zp=s(Kn,")"),Kn.forEach(t),Kp=s(Ov,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Ov.forEach(t),Vp=f(q),wi=o(q,"LI",{});var Lv=r(wi);fa=o(Lv,"STRONG",{});var Vn=r(fa);Qp=s(Vn,"Learning Rate Scheduler ("),tl=o(Vn,"CODE",{});var M2=r(tl);Jp=s(M2,"lr_scheduler"),M2.forEach(t),$p=s(Vn,")"),Vn.forEach(t),eh=s(Lv,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Lv.forEach(t),th=f(q),yi=o(q,"LI",{});var Iv=r(yi);da=o(Iv,"STRONG",{});var Qn=r(da);ah=s(Qn,"Number of Cycles in Learning Rate Scheduler ("),al=o(Qn,"CODE",{});var B2=r(al);ih=s(B2,"lr_scheduler_num_cycles"),B2.forEach(t),oh=s(Qn,")"),Qn.forEach(t),rh=s(Iv,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Iv.forEach(t),lh=f(q),ki=o(q,"LI",{});var Av=r(ki);ua=o(Av,"STRONG",{});var Jn=r(ua);sh=s(Jn,"Network Dimension ("),il=o(Jn,"CODE",{});var F2=r(il);nh=s(F2,"network_dim"),F2.forEach(t),ch=s(Jn,")"),Jn.forEach(t),fh=s(Av,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Av.forEach(t),dh=f(q),Di=o(q,"LI",{});var Cv=r(Di);pa=o(Cv,"STRONG",{});var $n=r(pa);uh=s($n,"Network Alpha ("),ol=o($n,"CODE",{});var Y2=r(ol);ph=s(Y2,"network_alpha"),Y2.forEach(t),hh=s($n,")"),$n.forEach(t),mh=s(Cv,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Cv.forEach(t),gh=f(q),Ri=o(q,"LI",{});var Pv=r(Ri);ha=o(Pv,"STRONG",{});var ec=r(ha);vh=s(ec,"Clip Skip ("),rl=o(ec,"CODE",{});var X2=r(rl);_h=s(X2,"clip_skip"),X2.forEach(t),Eh=s(ec,")"),ec.forEach(t),bh=s(Pv,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Pv.forEach(t),wh=f(q),Ti=o(q,"LI",{});var Nv=r(Ti);ma=o(Nv,"STRONG",{});var tc=r(ma);yh=s(tc,"Max Token Length ("),ll=o(tc,"CODE",{});var Z2=r(ll);kh=s(Z2,"max_token_length"),Z2.forEach(t),Dh=s(tc,")"),tc.forEach(t),Rh=s(Nv,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),Nv.forEach(t),Th=f(q),Si=o(q,"LI",{});var xv=r(Si);ga=o(xv,"STRONG",{});var ac=r(ga);Sh=s(ac,"Noise Offset ("),sl=o(ac,"CODE",{});var K2=r(sl);zh=s(K2,"noise_offset"),K2.forEach(t),Oh=s(ac,")"),ac.forEach(t),Lh=s(xv,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),xv.forEach(t),Ih=f(q),zi=o(q,"LI",{});var qv=r(zi);va=o(qv,"STRONG",{});var ic=r(va);Ah=s(ic,"Regularization Data Directory ("),nl=o(ic,"CODE",{});var V2=r(nl);Ch=s(V2,"reg_data_dir"),V2.forEach(t),Ph=s(ic,")"),ic.forEach(t),Nh=s(qv,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),qv.forEach(t),q.forEach(t),nn=f(a),ht=o(a,"H3",{id:!0});var jv=r(ht);mt=o(jv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Q2=r(mt);cl=o(Q2,"SPAN",{class:!0}),r(cl).forEach(t),Q2.forEach(t),xh=s(jv,"Fine Tuning"),jv.forEach(t),cn=f(a),Oi=o(a,"P",{});var J2=r(Oi);qh=s(J2,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),J2.forEach(t),fn=f(a),gt=o(a,"H4",{id:!0});var Hv=r(gt);vt=o(Hv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var $2=r(vt);fl=o($2,"SPAN",{class:!0}),r(fl).forEach(t),$2.forEach(t),jh=s(Hv,"Workflow with Auto1111 WebUI"),Hv.forEach(t),dn=f(a),_t=o(a,"P",{});var oc=r(_t);Hh=s(oc,"We\u2019re going to use "),_a=o(oc,"A",{href:!0,rel:!0});var eE=r(_a);Uh=s(eE,"Stable Diffusion web UI"),eE.forEach(t),Gh=s(oc," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),oc.forEach(t),un=f(a),Et=o(a,"P",{});var rc=r(Et);Wh=s(rc,"We\u2019re going to use the "),dl=o(rc,"CODE",{});var tE=r(dl);Mh=s(tE,"X/Y/Z plot"),tE.forEach(t),Bh=s(rc," script to compare different epochs."),rc.forEach(t),pn=f(a),te=o(a,"UL",{});var Se=r(te);Li=o(Se,"LI",{});var Uv=r(Li);Fh=s(Uv,"Select the text 2 image tab.  Enter a generic prompt "),ul=o(Uv,"CODE",{});var aE=r(ul);Yh=s(aE,"princeadam, portrait, <princeadam0001:0.7>"),aE.forEach(t),Uv.forEach(t),Xh=f(Se),Ea=o(Se,"LI",{});var lc=r(Ea);Zh=s(lc,"In generation parameters and select the "),pl=o(lc,"CODE",{});var iE=r(pl);Kh=s(iE,"X/Y/Z plot"),iE.forEach(t),Vh=s(lc," script."),lc.forEach(t),Qh=f(Se),ae=o(Se,"LI",{});var ve=r(ae);Jh=s(ve,"Select "),hl=o(ve,"CODE",{});var oE=r(hl);$h=s(oE,"Prompt SR"),oE.forEach(t),em=s(ve," for Prompt Replace.  We\u2019re going to replace "),ml=o(ve,"CODE",{});var rE=r(ml);tm=s(rE,"<princeadam0001:0.7>"),rE.forEach(t),am=s(ve," with different epoch: "),gl=o(ve,"CODE",{});var lE=r(gl);im=s(lE,"<princeadam0001:0.7>"),lE.forEach(t),om=s(ve,", "),vl=o(ve,"CODE",{});var sE=r(vl);rm=s(sE,"<princeadam0003:0.7>"),sE.forEach(t),lm=s(ve,", "),_l=o(ve,"CODE",{});var nE=r(_l);sm=s(nE,"<princeadam0023:0.7>"),nE.forEach(t),ve.forEach(t),nm=f(Se),Ii=o(Se,"LI",{});var Gv=r(Ii);cm=s(Gv,"Select a fast sampler like "),El=o(Gv,"CODE",{});var cE=r(El);fm=s(cE,"DPM2 KARRAS"),cE.forEach(t),Gv.forEach(t),dm=f(Se),bt=o(Se,"LI",{});var as=r(bt);um=s(as,"CFG Scale set to "),bl=o(as,"CODE",{});var fE=r(bl);pm=s(fE,"7"),fE.forEach(t),hm=s(as," and Steps to "),wl=o(as,"CODE",{});var dE=r(wl);mm=s(dE,"20"),dE.forEach(t),as.forEach(t),Se.forEach(t),hn=f(a),ke=o(a,"P",{});var so=r(ke);gm=s(so,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),yl=o(so,"CODE",{});var uE=r(yl);vm=s(uE,"network_dim"),uE.forEach(t),_m=s(so," and "),kl=o(so,"CODE",{});var pE=r(kl);Em=s(pE,"network_alpha"),pE.forEach(t),bm=s(so,"?  Those are the settings that directly control the output strength mentioned earlier."),so.forEach(t),mn=f(a),fe=o(a,"UL",{});var At=r(fe);W=o(At,"LI",{});var K=r(W);wm=s(K,"Select "),Dl=o(K,"CODE",{});var hE=r(Dl);ym=s(hE,"Prompt SR"),hE.forEach(t),km=s(K," for Prompt Replace.  We\u2019re going to replace the weights "),Rl=o(K,"CODE",{});var mE=r(Rl);Dm=s(mE,"<princeadam12:0.4>"),mE.forEach(t),Rm=s(K,","),Tl=o(K,"CODE",{});var gE=r(Tl);Tm=s(gE,"<princeadam12:0.5>"),gE.forEach(t),Sm=s(K,", "),Sl=o(K,"CODE",{});var vE=r(Sl);zm=s(vE,"<princeadam12:0.6>"),vE.forEach(t),Om=s(K,", "),zl=o(K,"CODE",{});var _E=r(zl);Lm=s(_E,"<princeadam12:0.7>"),_E.forEach(t),Im=s(K,", "),Ol=o(K,"CODE",{});var EE=r(Ol);Am=s(EE,"<princeadam12:0.8>"),EE.forEach(t),Cm=s(K,", "),Ll=o(K,"CODE",{});var bE=r(Ll);Pm=s(bE,"<princeadam12:0.9>"),bE.forEach(t),Nm=s(K,", "),Il=o(K,"CODE",{});var wE=r(Il);xm=s(wE,"<princeadam12:1.0>"),wE.forEach(t),K.forEach(t),qm=f(At),J=o(At,"LI",{});var le=r(J);jm=s(le,"Use another "),Al=o(le,"CODE",{});var yE=r(Al);Hm=s(yE,"Prompt SR"),yE.forEach(t),Um=s(le," to generate a variety of different angles: Select "),Cl=o(le,"CODE",{});var kE=r(Cl);Gm=s(kE,"Prompt SR"),kE.forEach(t),Wm=s(le," for Prompt Replace.  Replace "),Pl=o(le,"CODE",{});var DE=r(Pl);Mm=s(DE,"upper_body"),DE.forEach(t),Bm=s(le," with different camera angles: "),Nl=o(le,"CODE",{});var RE=r(Nl);Fm=s(RE,"from_below"),RE.forEach(t),Ym=s(le,", "),xl=o(le,"CODE",{});var TE=r(xl);Xm=s(TE,"from_above"),TE.forEach(t),Zm=s(le,", "),ql=o(le,"CODE",{});var SE=r(ql);Km=s(SE,"close_up"),SE.forEach(t),le.forEach(t),Vm=f(At),jl=o(At,"LI",{});var zE=r(jl);Qm=s(zE,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),zE.forEach(t),Jm=f(At),Hl=o(At,"LI",{});var OE=r(Hl);$m=s(OE,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),OE.forEach(t),At.forEach(t),gn=f(a),wt=o(a,"H4",{id:!0});var Wv=r(wt);yt=o(Wv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var LE=r(yt);Ul=o(LE,"SPAN",{class:!0}),r(Ul).forEach(t),LE.forEach(t),eg=s(Wv,"Issues to look for"),Wv.forEach(t),vn=f(a),de=o(a,"UL",{});var Ct=r(de);Ai=o(Ct,"LI",{});var Mv=r(Ai);Gl=o(Mv,"STRONG",{});var IE=r(Gl);tg=s(IE,"Undercooked:"),IE.forEach(t),ag=s(Mv," Lacks output, adjust unet learning rate or extend training duration."),Mv.forEach(t),ig=f(Ct),Ci=o(Ct,"LI",{});var Bv=r(Ci);Wl=o(Bv,"STRONG",{});var AE=r(Wl);og=s(AE,"Overcooked:"),AE.forEach(t),rg=s(Bv," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Bv.forEach(t),lg=f(Ct),Pi=o(Ct,"LI",{});var Fv=r(Pi);Ml=o(Fv,"STRONG",{});var CE=r(Ml);sg=s(CE,"Overfit:"),CE.forEach(t),ng=s(Fv," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),Fv.forEach(t),cg=f(Ct),Ni=o(Ct,"LI",{});var Yv=r(Ni);Bl=o(Yv,"STRONG",{});var PE=r(Bl);fg=s(PE,"Mismatched:"),PE.forEach(t),dg=s(Yv," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Yv.forEach(t),Ct.forEach(t),_n=f(a),xi=o(a,"P",{});var NE=r(xi);ug=s(NE,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),NE.forEach(t),En=f(a),kt=o(a,"H4",{id:!0});var Xv=r(kt);Dt=o(Xv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xE=r(Dt);Fl=o(xE,"SPAN",{class:!0}),r(Fl).forEach(t),xE.forEach(t),pg=s(Xv,"Troubleshooting"),Xv.forEach(t),bn=f(a),qi=o(a,"P",{});var qE=r(qi);hg=s(qE,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),qE.forEach(t),wn=f(a),De=o(a,"UL",{});var no=r(De);ba=o(no,"LI",{});var sc=r(ba);mg=s(sc,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Yl=o(sc,"CODE",{});var jE=r(Yl);gg=s(jE,"200"),jE.forEach(t),vg=s(sc," regularization images per training image."),sc.forEach(t),_g=f(no),wa=o(no,"LI",{});var nc=r(wa);Eg=s(nc,"Repeats of regularization images, but may overfit more.  Increasing the "),Xl=o(nc,"CODE",{});var HE=r(Xl);bg=s(HE,"repetition_count"),HE.forEach(t),wg=s(nc," will cycle through the images more but the results may have results that overfit the model."),nc.forEach(t),yg=f(no),Zl=o(no,"LI",{});var UE=r(Zl);kg=s(UE,"Create more regularization images without increasing repeats will help with the overfitting."),UE.forEach(t),no.forEach(t),yn=f(a),xe=o(a,"TABLE",{class:!0});var cc=r(xe);Kl=o(cc,"THEAD",{});var GE=r(Kl);qe=o(GE,"TR",{});var co=r(qe);Vl=o(co,"TH",{});var WE=r(Vl);Dg=s(WE,"Issue"),WE.forEach(t),Rg=f(co),Ql=o(co,"TH",{});var ME=r(Ql);Tg=s(ME,"Situation"),ME.forEach(t),Sg=f(co),Jl=o(co,"TH",{});var BE=r(Jl);zg=s(BE,"Recommendation"),BE.forEach(t),co.forEach(t),GE.forEach(t),Og=f(cc),me=o(cc,"TBODY",{});var Pt=r(me);je=o(Pt,"TR",{});var fo=r(je);ji=o(fo,"TD",{class:!0});var FE=r(ji);Lg=s(FE,"Varying quality"),FE.forEach(t),Ig=f(fo),Hi=o(fo,"TD",{class:!0});var YE=r(Hi);Ag=s(YE,"Results differ from expectations"),YE.forEach(t),Cg=f(fo),Ui=o(fo,"TD",{class:!0});var XE=r(Ui);Pg=s(XE,"Evaluate the quality and quantity of regularization images. Adjust the number and selection and check for better results."),XE.forEach(t),fo.forEach(t),Ng=f(Pt),He=o(Pt,"TR",{});var uo=r(He);Gi=o(uo,"TD",{class:!0});var ZE=r(Gi);xg=s(ZE,"Inadequate regularization for input data"),ZE.forEach(t),qg=f(uo),Wi=o(uo,"TD",{class:!0});var KE=r(Wi);jg=s(KE,"Lower input images, less regularization needed"),KE.forEach(t),Hg=f(uo),Mi=o(uo,"TD",{class:!0});var VE=r(Mi);Ug=s(VE,"Consider reducing the number of input images or increasing the quantity and diversity of regularization images."),VE.forEach(t),uo.forEach(t),Gg=f(Pt),Ue=o(Pt,"TR",{});var po=r(Ue);Bi=o(po,"TD",{class:!0});var QE=r(Bi);Wg=s(QE,"Overfitting due to repetition"),QE.forEach(t),Mg=f(po),Fi=o(po,"TD",{class:!0});var JE=r(Fi);Bg=s(JE,"Repeats of regularization images, risk of overfitting"),JE.forEach(t),Fg=f(po),Rt=o(po,"TD",{class:!0});var fc=r(Rt);Yg=s(fc,"Adjust the "),$l=o(fc,"CODE",{});var $E=r($l);Xg=s($E,"repetition_count"),$E.forEach(t),Zg=s(fc," to balance cycling through images without overfitting. Monitor results for improvements."),fc.forEach(t),po.forEach(t),Kg=f(Pt),Ge=o(Pt,"TR",{});var ho=r(Ge);Yi=o(ho,"TD",{class:!0});var eb=r(Yi);Vg=s(eb,"Mitigate overfitting while increasing diversity"),eb.forEach(t),Qg=f(ho),Xi=o(ho,"TD",{class:!0});var tb=r(Xi);Jg=s(tb,"Create more regularization images without repeats"),tb.forEach(t),$g=f(ho),Zi=o(ho,"TD",{class:!0});var ab=r(Zi);ev=s(ab,"Generate additional regularization images without increasing repetitions. Enhance model adaptability without overfitting."),ab.forEach(t),ho.forEach(t),Pt.forEach(t),cc.forEach(t),kn=f(a),Tt=o(a,"H3",{id:!0});var Zv=r(Tt);St=o(Zv,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ib=r(St);es=o(ib,"SPAN",{class:!0}),r(es).forEach(t),ib.forEach(t),tv=s(Zv,"Results"),Zv.forEach(t),Dn=f(a),Ki=o(a,"P",{});var ob=r(Ki);av=s(ob,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),ob.forEach(t),Rn=f(a),Vi=o(a,"P",{});var rb=r(Vi);iv=s(rb,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),rb.forEach(t),Tn=f(a),Qi=o(a,"P",{});var lb=r(Qi);ov=s(lb,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),lb.forEach(t),Sn=f(a),ge&&ge.l(a),zn=dc(),this.h()},h(){d(D,"class","icon icon-link"),d(y,"aria-hidden","true"),d(y,"tabindex","-1"),d(y,"href","#what-are-regularization-images"),d(E,"id","what-are-regularization-images"),d(x,"class","svelte-1tmcg3d"),d(M,"class","svelte-1tmcg3d"),d(Da,"class","svelte-1tmcg3d"),d(Ra,"class","svelte-1tmcg3d"),d(Ta,"class","svelte-1tmcg3d"),d(Sa,"class","svelte-1tmcg3d"),d(za,"class","svelte-1tmcg3d"),d(Oa,"class","svelte-1tmcg3d"),d(La,"class","svelte-1tmcg3d"),d(Ia,"class","svelte-1tmcg3d"),d(Aa,"class","svelte-1tmcg3d"),d(Ca,"class","svelte-1tmcg3d"),d(Pa,"class","svelte-1tmcg3d"),d(Na,"class","svelte-1tmcg3d"),d(w,"class","svelte-1tmcg3d"),d(ja,"class","svelte-1tmcg3d"),d(xt,"class","svelte-1tmcg3d"),d(Ro,"class","icon icon-link"),d(Be,"aria-hidden","true"),d(Be,"tabindex","-1"),d(Be,"href","#divergence"),d(Me,"id","divergence"),d(Ga,"class","svelte-1tmcg3d"),d(Wa,"class","svelte-1tmcg3d"),d(Ma,"class","svelte-1tmcg3d"),d(Ba,"class","svelte-1tmcg3d"),d(Fa,"class","svelte-1tmcg3d"),d(Ya,"class","svelte-1tmcg3d"),d(Xa,"class","svelte-1tmcg3d"),d(Za,"class","svelte-1tmcg3d"),d(Pe,"class","svelte-1tmcg3d"),d(Lo,"class","icon icon-link"),d(Xe,"aria-hidden","true"),d(Xe,"tabindex","-1"),d(Xe,"href","#generating-regularization-images"),d(Ye,"id","generating-regularization-images"),d(Ka,"class","svelte-1tmcg3d"),d(Yt,"class","svelte-1tmcg3d"),d(xo,"class","icon icon-link"),d(Ve,"aria-hidden","true"),d(Ve,"tabindex","-1"),d(Ve,"href","#generate-using-stable-diffusion-web-ui"),d(Ke,"id","generate-using-stable-diffusion-web-ui"),d(Zt,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),d(Zt,"rel","nofollow"),d(yr,"class","icon icon-link"),d(et,"aria-hidden","true"),d(et,"tabindex","-1"),d(et,"href","#download-images"),d($e,"id","download-images"),d(Vt,"href","https://huggingface.co/3ee"),d(Vt,"rel","nofollow"),d(Qt,"href","https://github.com/Luehrsen/sd_regularization_images"),d(Qt,"rel","nofollow"),d(Jt,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),d(Jt,"rel","nofollow"),d($t,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),d($t,"rel","nofollow"),d(kr,"class","icon icon-link"),d(at,"aria-hidden","true"),d(at,"tabindex","-1"),d(at,"href","#captioning-regularization-images"),d(tt,"id","captioning-regularization-images"),d(ea,"class","language-shell"),d(Or,"class","icon icon-link"),d(lt,"aria-hidden","true"),d(lt,"tabindex","-1"),d(lt,"href","#training-a-lora"),d(rt,"id","training-a-lora"),d(ri,"class","svelte-1tmcg3d"),d(aa,"class","svelte-1tmcg3d"),d(Lr,"class","icon icon-link"),d(nt,"aria-hidden","true"),d(nt,"tabindex","-1"),d(nt,"href","#directory-setup"),d(st,"id","directory-setup"),d(ia,"class","language-json"),d(oa,"class","language-xml"),is(ra.src,$v="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||d(ra,"src",$v),d(ra,"alt","image"),d(ra,"class","svelte-1tmcg3d"),d(Mr,"class","icon icon-link"),d(ut,"aria-hidden","true"),d(ut,"tabindex","-1"),d(ut,"href","#training-settings"),d(dt,"id","training-settings"),d(ui,"class","svelte-1tmcg3d"),d(pi,"class","svelte-1tmcg3d"),d(hi,"class","svelte-1tmcg3d"),d(mi,"class","svelte-1tmcg3d"),d(gi,"class","svelte-1tmcg3d"),d(Ne,"class","svelte-1tmcg3d"),d(la,"class","language-json"),d(cl,"class","icon icon-link"),d(mt,"aria-hidden","true"),d(mt,"tabindex","-1"),d(mt,"href","#fine-tuning"),d(ht,"id","fine-tuning"),d(fl,"class","icon icon-link"),d(vt,"aria-hidden","true"),d(vt,"tabindex","-1"),d(vt,"href","#workflow-with-auto1111-webui"),d(gt,"id","workflow-with-auto1111-webui"),d(_a,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),d(_a,"rel","nofollow"),d(Ul,"class","icon icon-link"),d(yt,"aria-hidden","true"),d(yt,"tabindex","-1"),d(yt,"href","#issues-to-look-for"),d(wt,"id","issues-to-look-for"),d(Fl,"class","icon icon-link"),d(Dt,"aria-hidden","true"),d(Dt,"tabindex","-1"),d(Dt,"href","#troubleshooting"),d(kt,"id","troubleshooting"),d(ji,"class","svelte-1tmcg3d"),d(Hi,"class","svelte-1tmcg3d"),d(Ui,"class","svelte-1tmcg3d"),d(Gi,"class","svelte-1tmcg3d"),d(Wi,"class","svelte-1tmcg3d"),d(Mi,"class","svelte-1tmcg3d"),d(Bi,"class","svelte-1tmcg3d"),d(Fi,"class","svelte-1tmcg3d"),d(Rt,"class","svelte-1tmcg3d"),d(Yi,"class","svelte-1tmcg3d"),d(Xi,"class","svelte-1tmcg3d"),d(Zi,"class","svelte-1tmcg3d"),d(xe,"class","svelte-1tmcg3d"),d(es,"class","icon icon-link"),d(St,"aria-hidden","true"),d(St,"tabindex","-1"),d(St,"href","#results"),d(Tt,"id","results")},m(a,u){n(a,p,u),e(p,g),n(a,h,u),ss(v,a,u),n(a,m,u),n(a,E,u),e(E,y),e(y,D),e(E,N),n(a,O,u),n(a,S,u),e(S,k),n(a,j,u),n(a,M,u),e(M,x),e(x,B),n(a,I,u),n(a,R,u),e(R,A),n(a,H,u),n(a,P,u),e(P,_e),n(a,se,u),n(a,z,u),e(z,T),n(a,b,u),n(a,w,u),e(w,L),e(L,V),e(V,$),e($,Oe),e(V,mc),e(V,mo),e(mo,gc),e(V,vc),e(V,go),e(go,_c),e(w,Ec),e(w,pe),e(pe,Le),e(Le,Da),e(Da,vo),e(vo,bc),e(Le,wc),e(Le,Ra),e(Ra,yc),e(Le,kc),e(Le,Ta),e(Ta,Dc),e(pe,Rc),e(pe,Ie),e(Ie,Sa),e(Sa,_o),e(_o,Tc),e(Ie,Sc),e(Ie,za),e(za,zc),e(Ie,Oc),e(Ie,Oa),e(Oa,Lc),e(pe,Ic),e(pe,Ae),e(Ae,La),e(La,Eo),e(Eo,Ac),e(Ae,Cc),e(Ae,Ia),e(Ia,Pc),e(Ae,Nc),e(Ae,Aa),e(Aa,xc),e(pe,qc),e(pe,Ce),e(Ce,Ca),e(Ca,bo),e(bo,jc),e(Ce,Hc),e(Ce,Pa),e(Pa,Uc),e(Ce,Gc),e(Ce,Na),e(Na,Wc),n(a,cs,u),n(a,xa,u),e(xa,Mc),n(a,fs,u),n(a,qa,u),e(qa,Bc),n(a,ds,u),n(a,xt,u),e(xt,ja),e(ja,Fc),n(a,us,u),n(a,qt,u),e(qt,wo),e(wo,Yc),e(qt,Xc),n(a,ps,u),n(a,jt,u),e(jt,yo),e(yo,Zc),e(jt,Kc),n(a,hs,u),n(a,Ht,u),e(Ht,ko),e(ko,Vc),e(Ht,Qc),n(a,ms,u),n(a,Ut,u),e(Ut,Do),e(Do,Jc),e(Ut,$c),n(a,gs,u),n(a,Me,u),e(Me,Be),e(Be,Ro),e(Me,ef),n(a,vs,u),n(a,Fe,u),e(Fe,tf),e(Fe,To),e(To,af),e(Fe,of),n(a,_s,u),n(a,Ha,u),e(Ha,rf),n(a,Es,u),n(a,Ua,u),e(Ua,lf),n(a,bs,u),n(a,Pe,u),e(Pe,So),e(So,Gt),e(Gt,zo),e(zo,sf),e(Gt,nf),e(Gt,Oo),e(Oo,cf),e(Pe,ff),e(Pe,he),e(he,Wt),e(Wt,Ga),e(Ga,df),e(Wt,uf),e(Wt,Wa),e(Wa,pf),e(he,hf),e(he,Mt),e(Mt,Ma),e(Ma,mf),e(Mt,gf),e(Mt,Ba),e(Ba,vf),e(he,_f),e(he,Bt),e(Bt,Fa),e(Fa,Ef),e(Bt,bf),e(Bt,Ya),e(Ya,wf),e(he,yf),e(he,Ft),e(Ft,Xa),e(Xa,kf),e(Ft,Df),e(Ft,Za),e(Za,Rf),n(a,ws,u),n(a,Ye,u),e(Ye,Xe),e(Xe,Lo),e(Ye,Tf),n(a,ys,u),n(a,Ze,u),e(Ze,Sf),e(Ze,Io),e(Io,zf),e(Ze,Of),n(a,ks,u),n(a,ne,u),e(ne,Lf),e(ne,Ao),e(Ao,If),e(ne,Af),e(ne,Co),e(Co,Cf),e(ne,Pf),e(ne,Po),e(Po,Nf),e(ne,xf),n(a,Ds,u),n(a,Yt,u),e(Yt,Ka),e(Ka,No),e(No,qf),n(a,Rs,u),n(a,Va,u),e(Va,jf),n(a,Ts,u),ss(Xt,a,u),n(a,Ss,u),n(a,Ke,u),e(Ke,Ve),e(Ve,xo),e(Ke,Hf),n(a,zs,u),n(a,Qe,u),e(Qe,Uf),e(Qe,Zt),e(Zt,Gf),e(Qe,Wf),n(a,Os,u),n(a,Ee,u),e(Ee,Mf),e(Ee,qo),e(qo,Bf),e(Ee,Ff),e(Ee,jo),e(jo,Yf),e(Ee,Xf),n(a,Ls,u),n(a,F,u),e(F,Ho),e(Ho,Qa),e(Qa,Zf),e(Qa,Uo),e(Uo,Kf),e(F,Vf),e(F,Go),e(Go,Kt),e(Kt,Qf),e(Kt,Wo),e(Wo,Jf),e(Kt,$f),e(F,ed),e(F,Mo),e(Mo,U),e(U,td),e(U,Bo),e(Bo,ad),e(U,id),e(U,Fo),e(Fo,od),e(U,rd),e(U,Yo),e(Yo,ld),e(U,sd),e(U,Xo),e(Xo,nd),e(U,cd),e(U,Zo),e(Zo,fd),e(U,dd),e(U,Ko),e(Ko,ud),e(U,pd),e(U,Vo),e(Vo,hd),e(U,md),e(U,Qo),e(Qo,gd),e(F,vd),e(F,Jo),e(Jo,Y),e(Y,_d),e(Y,$o),e($o,Ed),e(Y,bd),e(Y,er),e(er,wd),e(Y,yd),e(Y,tr),e(tr,kd),e(Y,Dd),e(Y,ar),e(ar,Rd),e(Y,Td),e(Y,ir),e(ir,Sd),e(Y,zd),e(Y,or),e(or,Od),e(Y,Ld),e(Y,rr),e(rr,Id),e(F,Ad),e(F,lr),e(lr,G),e(G,Cd),e(G,sr),e(sr,Pd),e(G,Nd),e(G,nr),e(nr,xd),e(G,qd),e(G,cr),e(cr,jd),e(G,Hd),e(G,fr),e(fr,Ud),e(G,Gd),e(G,dr),e(dr,Wd),e(G,Md),e(G,ur),e(ur,Bd),e(G,Fd),e(G,pr),e(pr,Yd),e(G,Xd),e(G,hr),e(hr,Zd),e(F,Kd),e(F,mr),e(mr,Ja),e(Ja,Vd),e(Ja,gr),e(gr,Qd),e(F,Jd),e(F,vr),e(vr,Je),e(Je,$d),e(Je,_r),e(_r,eu),e(Je,tu),e(Je,Er),e(Er,au),n(a,Is,u),n(a,be,u),e(be,iu),e(be,br),e(br,ou),e(be,ru),e(be,wr),e(wr,lu),e(be,su),n(a,As,u),n(a,$e,u),e($e,et),e(et,yr),e($e,nu),n(a,Cs,u),n(a,$a,u),e($a,cu),n(a,Ps,u),n(a,ce,u),e(ce,ei),e(ei,Vt),e(Vt,fu),e(ei,du),e(ce,uu),e(ce,ti),e(ti,Qt),e(Qt,pu),e(ti,hu),e(ce,mu),e(ce,ai),e(ai,Jt),e(Jt,gu),e(ai,vu),e(ce,_u),e(ce,ii),e(ii,$t),e($t,Eu),e(ii,bu),n(a,Ns,u),n(a,tt,u),e(tt,at),e(at,kr),e(tt,wu),n(a,xs,u),n(a,it,u),e(it,yu),e(it,Dr),e(Dr,ku),e(it,Du),n(a,qs,u),n(a,ea,u),ea.innerHTML=mb,n(a,js,u),n(a,we,u),e(we,Ru),e(we,Rr),e(Rr,Tu),e(we,Su),e(we,Tr),e(Tr,zu),e(we,Ou),n(a,Hs,u),n(a,ta,u),e(ta,Lu),e(ta,Sr),e(Sr,Iu),n(a,Us,u),n(a,ot,u),e(ot,Au),e(ot,zr),e(zr,Cu),e(ot,Pu),n(a,Gs,u),n(a,rt,u),e(rt,lt),e(lt,Or),e(rt,Nu),n(a,Ws,u),n(a,oi,u),e(oi,xu),n(a,Ms,u),n(a,aa,u),e(aa,ri),e(ri,qu),n(a,Bs,u),n(a,st,u),e(st,nt),e(nt,Lr),e(st,ju),n(a,Fs,u),n(a,ct,u),e(ct,Hu),e(ct,Ir),e(Ir,Uu),e(ct,Gu),n(a,Ys,u),n(a,ia,u),ia.innerHTML=gb,n(a,Xs,u),n(a,li,u),e(li,Wu),n(a,Zs,u),n(a,oa,u),oa.innerHTML=vb,n(a,Ks,u),n(a,Q,u),e(Q,Mu),e(Q,Ar),e(Ar,Bu),e(Q,Fu),e(Q,Cr),e(Cr,Yu),e(Q,Xu),e(Q,Pr),e(Pr,Zu),e(Q,Ku),e(Q,Nr),e(Nr,Vu),e(Q,Qu),e(Q,xr),e(xr,Ju),e(Q,$u),n(a,Vs,u),n(a,ye,u),e(ye,ep),e(ye,qr),e(qr,tp),e(ye,ap),e(ye,jr),e(jr,ip),e(ye,op),n(a,Qs,u),n(a,si,u),e(si,rp),n(a,Js,u),n(a,ft,u),e(ft,ni),e(ni,lp),e(ni,Hr),e(Hr,Ur),e(Ur,sp),e(ft,np),e(ft,ci),e(ci,cp),e(ci,Gr),e(Gr,Wr),e(Wr,fp),n(a,$s,u),n(a,fi,u),e(fi,dp),n(a,en,u),n(a,di,u),e(di,ra),n(a,tn,u),n(a,dt,u),e(dt,ut),e(ut,Mr),e(dt,up),n(a,an,u),n(a,pt,u),e(pt,pp),e(pt,Br),e(Br,hp),e(pt,mp),n(a,on,u),n(a,Ne,u),e(Ne,Fr),e(Fr,oe),e(oe,Yr),e(Yr,gp),e(oe,vp),e(oe,Xr),e(Xr,_p),e(oe,Ep),e(oe,Zr),e(Zr,bp),e(oe,wp),e(oe,Kr),e(Kr,yp),e(oe,kp),e(oe,Vr),e(Vr,Dp),e(Ne,Rp),e(Ne,Qr),e(Qr,re),e(re,ui),e(ui,Tp),e(re,Sp),e(re,pi),e(pi,zp),e(re,Op),e(re,hi),e(hi,Lp),e(re,Ip),e(re,mi),e(mi,Ap),e(re,Cp),e(re,gi),e(gi,Pp),n(a,rn,u),n(a,vi,u),e(vi,Np),n(a,ln,u),n(a,la,u),la.innerHTML=_b,n(a,sn,u),n(a,C,u),e(C,_i),e(_i,sa),e(sa,xp),e(sa,Jr),e(Jr,qp),e(sa,jp),e(_i,Hp),e(C,Up),e(C,Ei),e(Ei,na),e(na,Gp),e(na,$r),e($r,Wp),e(na,Mp),e(Ei,Bp),e(C,Fp),e(C,bi),e(bi,ca),e(ca,Yp),e(ca,el),e(el,Xp),e(ca,Zp),e(bi,Kp),e(C,Vp),e(C,wi),e(wi,fa),e(fa,Qp),e(fa,tl),e(tl,Jp),e(fa,$p),e(wi,eh),e(C,th),e(C,yi),e(yi,da),e(da,ah),e(da,al),e(al,ih),e(da,oh),e(yi,rh),e(C,lh),e(C,ki),e(ki,ua),e(ua,sh),e(ua,il),e(il,nh),e(ua,ch),e(ki,fh),e(C,dh),e(C,Di),e(Di,pa),e(pa,uh),e(pa,ol),e(ol,ph),e(pa,hh),e(Di,mh),e(C,gh),e(C,Ri),e(Ri,ha),e(ha,vh),e(ha,rl),e(rl,_h),e(ha,Eh),e(Ri,bh),e(C,wh),e(C,Ti),e(Ti,ma),e(ma,yh),e(ma,ll),e(ll,kh),e(ma,Dh),e(Ti,Rh),e(C,Th),e(C,Si),e(Si,ga),e(ga,Sh),e(ga,sl),e(sl,zh),e(ga,Oh),e(Si,Lh),e(C,Ih),e(C,zi),e(zi,va),e(va,Ah),e(va,nl),e(nl,Ch),e(va,Ph),e(zi,Nh),n(a,nn,u),n(a,ht,u),e(ht,mt),e(mt,cl),e(ht,xh),n(a,cn,u),n(a,Oi,u),e(Oi,qh),n(a,fn,u),n(a,gt,u),e(gt,vt),e(vt,fl),e(gt,jh),n(a,dn,u),n(a,_t,u),e(_t,Hh),e(_t,_a),e(_a,Uh),e(_t,Gh),n(a,un,u),n(a,Et,u),e(Et,Wh),e(Et,dl),e(dl,Mh),e(Et,Bh),n(a,pn,u),n(a,te,u),e(te,Li),e(Li,Fh),e(Li,ul),e(ul,Yh),e(te,Xh),e(te,Ea),e(Ea,Zh),e(Ea,pl),e(pl,Kh),e(Ea,Vh),e(te,Qh),e(te,ae),e(ae,Jh),e(ae,hl),e(hl,$h),e(ae,em),e(ae,ml),e(ml,tm),e(ae,am),e(ae,gl),e(gl,im),e(ae,om),e(ae,vl),e(vl,rm),e(ae,lm),e(ae,_l),e(_l,sm),e(te,nm),e(te,Ii),e(Ii,cm),e(Ii,El),e(El,fm),e(te,dm),e(te,bt),e(bt,um),e(bt,bl),e(bl,pm),e(bt,hm),e(bt,wl),e(wl,mm),n(a,hn,u),n(a,ke,u),e(ke,gm),e(ke,yl),e(yl,vm),e(ke,_m),e(ke,kl),e(kl,Em),e(ke,bm),n(a,mn,u),n(a,fe,u),e(fe,W),e(W,wm),e(W,Dl),e(Dl,ym),e(W,km),e(W,Rl),e(Rl,Dm),e(W,Rm),e(W,Tl),e(Tl,Tm),e(W,Sm),e(W,Sl),e(Sl,zm),e(W,Om),e(W,zl),e(zl,Lm),e(W,Im),e(W,Ol),e(Ol,Am),e(W,Cm),e(W,Ll),e(Ll,Pm),e(W,Nm),e(W,Il),e(Il,xm),e(fe,qm),e(fe,J),e(J,jm),e(J,Al),e(Al,Hm),e(J,Um),e(J,Cl),e(Cl,Gm),e(J,Wm),e(J,Pl),e(Pl,Mm),e(J,Bm),e(J,Nl),e(Nl,Fm),e(J,Ym),e(J,xl),e(xl,Xm),e(J,Zm),e(J,ql),e(ql,Km),e(fe,Vm),e(fe,jl),e(jl,Qm),e(fe,Jm),e(fe,Hl),e(Hl,$m),n(a,gn,u),n(a,wt,u),e(wt,yt),e(yt,Ul),e(wt,eg),n(a,vn,u),n(a,de,u),e(de,Ai),e(Ai,Gl),e(Gl,tg),e(Ai,ag),e(de,ig),e(de,Ci),e(Ci,Wl),e(Wl,og),e(Ci,rg),e(de,lg),e(de,Pi),e(Pi,Ml),e(Ml,sg),e(Pi,ng),e(de,cg),e(de,Ni),e(Ni,Bl),e(Bl,fg),e(Ni,dg),n(a,_n,u),n(a,xi,u),e(xi,ug),n(a,En,u),n(a,kt,u),e(kt,Dt),e(Dt,Fl),e(kt,pg),n(a,bn,u),n(a,qi,u),e(qi,hg),n(a,wn,u),n(a,De,u),e(De,ba),e(ba,mg),e(ba,Yl),e(Yl,gg),e(ba,vg),e(De,_g),e(De,wa),e(wa,Eg),e(wa,Xl),e(Xl,bg),e(wa,wg),e(De,yg),e(De,Zl),e(Zl,kg),n(a,yn,u),n(a,xe,u),e(xe,Kl),e(Kl,qe),e(qe,Vl),e(Vl,Dg),e(qe,Rg),e(qe,Ql),e(Ql,Tg),e(qe,Sg),e(qe,Jl),e(Jl,zg),e(xe,Og),e(xe,me),e(me,je),e(je,ji),e(ji,Lg),e(je,Ig),e(je,Hi),e(Hi,Ag),e(je,Cg),e(je,Ui),e(Ui,Pg),e(me,Ng),e(me,He),e(He,Gi),e(Gi,xg),e(He,qg),e(He,Wi),e(Wi,jg),e(He,Hg),e(He,Mi),e(Mi,Ug),e(me,Gg),e(me,Ue),e(Ue,Bi),e(Bi,Wg),e(Ue,Mg),e(Ue,Fi),e(Fi,Bg),e(Ue,Fg),e(Ue,Rt),e(Rt,Yg),e(Rt,$l),e($l,Xg),e(Rt,Zg),e(me,Kg),e(me,Ge),e(Ge,Yi),e(Yi,Vg),e(Ge,Qg),e(Ge,Xi),e(Xi,Jg),e(Ge,$g),e(Ge,Zi),e(Zi,ev),n(a,kn,u),n(a,Tt,u),e(Tt,St),e(St,es),e(Tt,tv),n(a,Dn,u),n(a,Ki,u),e(Ki,av),n(a,Rn,u),n(a,Vi,u),e(Vi,iv),n(a,Tn,u),n(a,Qi,u),e(Qi,ov),n(a,Sn,u),ge&&ge.m(a,u),n(a,zn,u),On=!0},p(a,u){hb&&ge.p(a,u)},i(a){On||(ya(v.$$.fragment,a),ya(Xt.$$.fragment,a),ya(ge),On=!0)},o(a){ka(v.$$.fragment,a),ka(Xt.$$.fragment,a),ka(ge),On=!1},d(a){a&&t(p),a&&t(h),ns(v,a),a&&t(m),a&&t(E),a&&t(O),a&&t(S),a&&t(j),a&&t(M),a&&t(I),a&&t(R),a&&t(H),a&&t(P),a&&t(se),a&&t(z),a&&t(b),a&&t(w),a&&t(cs),a&&t(xa),a&&t(fs),a&&t(qa),a&&t(ds),a&&t(xt),a&&t(us),a&&t(qt),a&&t(ps),a&&t(jt),a&&t(hs),a&&t(Ht),a&&t(ms),a&&t(Ut),a&&t(gs),a&&t(Me),a&&t(vs),a&&t(Fe),a&&t(_s),a&&t(Ha),a&&t(Es),a&&t(Ua),a&&t(bs),a&&t(Pe),a&&t(ws),a&&t(Ye),a&&t(ys),a&&t(Ze),a&&t(ks),a&&t(ne),a&&t(Ds),a&&t(Yt),a&&t(Rs),a&&t(Va),a&&t(Ts),ns(Xt,a),a&&t(Ss),a&&t(Ke),a&&t(zs),a&&t(Qe),a&&t(Os),a&&t(Ee),a&&t(Ls),a&&t(F),a&&t(Is),a&&t(be),a&&t(As),a&&t($e),a&&t(Cs),a&&t($a),a&&t(Ps),a&&t(ce),a&&t(Ns),a&&t(tt),a&&t(xs),a&&t(it),a&&t(qs),a&&t(ea),a&&t(js),a&&t(we),a&&t(Hs),a&&t(ta),a&&t(Us),a&&t(ot),a&&t(Gs),a&&t(rt),a&&t(Ws),a&&t(oi),a&&t(Ms),a&&t(aa),a&&t(Bs),a&&t(st),a&&t(Fs),a&&t(ct),a&&t(Ys),a&&t(ia),a&&t(Xs),a&&t(li),a&&t(Zs),a&&t(oa),a&&t(Ks),a&&t(Q),a&&t(Vs),a&&t(ye),a&&t(Qs),a&&t(si),a&&t(Js),a&&t(ft),a&&t($s),a&&t(fi),a&&t(en),a&&t(di),a&&t(tn),a&&t(dt),a&&t(an),a&&t(pt),a&&t(on),a&&t(Ne),a&&t(rn),a&&t(vi),a&&t(ln),a&&t(la),a&&t(sn),a&&t(C),a&&t(nn),a&&t(ht),a&&t(cn),a&&t(Oi),a&&t(fn),a&&t(gt),a&&t(dn),a&&t(_t),a&&t(un),a&&t(Et),a&&t(pn),a&&t(te),a&&t(hn),a&&t(ke),a&&t(mn),a&&t(fe),a&&t(gn),a&&t(wt),a&&t(vn),a&&t(de),a&&t(_n),a&&t(xi),a&&t(En),a&&t(kt),a&&t(bn),a&&t(qi),a&&t(wn),a&&t(De),a&&t(yn),a&&t(xe),a&&t(kn),a&&t(Tt),a&&t(Dn),a&&t(Ki),a&&t(Rn),a&&t(Vi),a&&t(Tn),a&&t(Qi),a&&t(Sn),ge&&ge.d(a),a&&t(zn)}}}function e3(_){let p,g;const h=[_[0],Jv];let v={$$slots:{default:[$b]},$$scope:{ctx:_}};for(let m=0;m<h.length;m+=1)v=Qv(v,h[m]);return p=new Lb({props:v}),{c(){rs(p.$$.fragment)},l(m){ls(p.$$.fragment,m)},m(m,E){ss(p,m,E),g=!0},p(m,[E]){const y=E&1?Ob(h,[E&1&&sb(m[0]),E&0&&sb(Jv)]):{};E&2&&(y.$$scope={dirty:E,ctx:m}),p.$set(y)},i(m){g||(ya(p.$$.fragment,m),g=!0)},o(m){ka(p.$$.fragment,m),g=!1},d(m){ns(p,m)}}}const Jv={title:"Action Figure Art",date:"2023-04-17",modifiedDate:"2023-04-17",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Check out Ornamental Santa Diffusion, a model that uses stable diffusion to generate Santa Claus.",author:"Ryan Sadwick",spacelab:!0,id:4,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription."},{title:m3,date:g3,modifiedDate:v3,categories:_3,svg:E3,seoImage:b3,shortDescription:w3,author:y3,spacelab:hb,id:t3,spacelabDefaultTitle:a3,spacelabDefaultContent:i3}=Jv;function o3(_,p,g){return _.$$set=h=>{g(0,p=Qv(Qv({},p),nb(h)))},p=nb(p),[p]}class k3 extends uc{constructor(p){super(),pc(this,p,o3,e3,hc,{})}}export{k3 as default,Jv as metadata};
