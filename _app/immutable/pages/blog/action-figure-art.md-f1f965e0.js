import{S as hm,i as gm,s as mm,l as Wu,g as p,E as $w,d as t,v as zD,e as a,t as o,c as l,a as r,h as n,b as i,G as e,j as ce,k as c,m as u,F as ee,H as Re,N as aD,Y as ND,J as Wl,f as Ht,Z as CD,_ as GD,$ as HD,q as Rt,o as St,O as qD,w as Ra,x as Sa,y as Da,B as Aa,C as e5,z as UD,A as lD,a1 as rD}from"../../chunks/index-2a82a4a8.js";import{P as MD}from"../../chunks/_post-913f18eb.js";import{g as Zw}from"../../chunks/config-201c2df4.js";import{a as Qw}from"../../chunks/accountStore-3492c591.js";import{R as BD}from"../../chunks/ResponsivePicture-526d3695.js";import"../../chunks/Player-9202028c.js";import"../../chunks/menuContextStore-c2e700c4.js";import"../../chunks/index-16dda89e.js";function WD(_){let f,m,g,h,v,k,b,T,R,x,E,y,O,L,P,G,S,A;function D(I,q){return typeof I[2].title!="undefined"?YD:FD}let z=D(_),N=z(_);function Q(I,q){return typeof I[2].description!="undefined"?KD:VD}let j=Q(_),F=j(_),B=typeof _[2].list_description!="undefined"&&iD(_),C=typeof _[2].footer_description!="undefined"&&oD(_);return{c(){f=a("hr"),m=c(),g=a("div"),N.c(),h=c(),v=a("p"),k=a("ion-icon"),b=o("SpaceLab Content"),T=c(),F.c(),R=c(),B&&B.c(),x=c(),C&&C.c(),E=c(),y=a("button"),O=a("ion-icon"),L=c(),P=a("span"),G=o("SpaceLab"),this.h()},l(I){f=l(I,"HR",{}),m=u(I),g=l(I,"DIV",{class:!0});var q=r(g);N.l(q),h=u(q),v=l(q,"P",{class:!0});var V=r(v);k=l(V,"ION-ICON",{class:!0,name:!0}),r(k).forEach(t),b=n(V,"SpaceLab Content"),V.forEach(t),T=u(q),F.l(q),R=u(q),B&&B.l(q),x=u(q),C&&C.l(q),E=u(q),y=l(q,"BUTTON",{class:!0});var U=r(y);O=l(U,"ION-ICON",{class:!0,name:!0}),r(O).forEach(t),L=u(U),P=l(U,"SPAN",{});var w=r(P);G=n(w,"SpaceLab"),w.forEach(t),U.forEach(t),q.forEach(t),this.h()},h(){ee(k,"class","icon svelte-s12rf8"),ee(k,"name","lock-closed"),i(v,"class","highlight large svelte-s12rf8"),ee(O,"class","icon svelte-s12rf8"),ee(O,"name","planet"),i(y,"class","button subscribe svelte-s12rf8"),i(g,"class","subscribe svelte-s12rf8")},m(I,q){p(I,f,q),p(I,m,q),p(I,g,q),N.m(g,null),e(g,h),e(g,v),e(v,k),e(v,b),e(g,T),F.m(g,null),e(g,R),B&&B.m(g,null),e(g,x),C&&C.m(g,null),e(g,E),e(g,y),e(y,O),e(y,L),e(y,P),e(P,G),S||(A=Re(y,"click",_[15]),S=!0)},p(I,q){z===(z=D(I))&&N?N.p(I,q):(N.d(1),N=z(I),N&&(N.c(),N.m(g,h))),j===(j=Q(I))&&F?F.p(I,q):(F.d(1),F=j(I),F&&(F.c(),F.m(g,R))),typeof I[2].list_description!="undefined"?B?B.p(I,q):(B=iD(I),B.c(),B.m(g,x)):B&&(B.d(1),B=null),typeof I[2].footer_description!="undefined"?C?C.p(I,q):(C=oD(I),C.c(),C.m(g,E)):C&&(C.d(1),C=null)},d(I){I&&t(f),I&&t(m),I&&t(g),N.d(),F.d(),B&&B.d(),C&&C.d(),S=!1,A()}}}function jD(_){let f,m,g,h=_[2].title+"",v,k,b,T,R,x,E,y=_[2].description+"",O,L,P,G,S,A,D,z,N,Q,j,F,B,C=typeof _[2].list_description!="undefined"&&nD(_),I=typeof _[2].footer_description!="undefined"&&cD(_);function q(w,H){if(w[2].github_private_repo&&w[2].github_state==="LOG_EXISTS")return QD;if(w[2].github_private_repo&&w[2].github_state==="NO_LOGS")return ZD;if(w[2].github_private_repo&&w[2].github_state==="NO_GITHUB_USERNAME")return XD}let V=q(_),U=V&&V(_);return{c(){f=a("hr"),m=c(),g=a("h2"),v=o(h),k=c(),b=a("p"),T=a("ion-icon"),R=o("SpaceLab Content"),x=c(),E=a("p"),O=o(y),L=c(),C&&C.c(),P=c(),I&&I.c(),G=c(),S=a("button"),A=a("ion-icon"),D=c(),z=a("span"),N=o("Download"),Q=c(),U&&U.c(),j=Wu(),this.h()},l(w){f=l(w,"HR",{}),m=u(w),g=l(w,"H2",{class:!0});var H=r(g);v=n(H,h),H.forEach(t),k=u(w),b=l(w,"P",{class:!0});var La=r(b);T=l(La,"ION-ICON",{class:!0,name:!0}),r(T).forEach(t),R=n(La,"SpaceLab Content"),La.forEach(t),x=u(w),E=l(w,"P",{class:!0});var jl=r(E);O=n(jl,y),jl.forEach(t),L=u(w),C&&C.l(w),P=u(w),I&&I.l(w),G=u(w),S=l(w,"BUTTON",{class:!0});var we=r(S);A=l(we,"ION-ICON",{class:!0,name:!0}),r(A).forEach(t),D=u(we),z=l(we,"SPAN",{});var Fl=r(z);N=n(Fl,"Download"),Fl.forEach(t),we.forEach(t),Q=u(w),U&&U.l(w),j=Wu(),this.h()},h(){i(g,"class","svelte-s12rf8"),ee(T,"class","icon svelte-s12rf8"),ee(T,"name","planet-sharp"),i(b,"class","highlight large svelte-s12rf8"),i(E,"class","svelte-s12rf8"),ee(A,"class","icon svelte-s12rf8"),ee(A,"name","cloud-download"),i(S,"class","button svelte-s12rf8")},m(w,H){p(w,f,H),p(w,m,H),p(w,g,H),e(g,v),p(w,k,H),p(w,b,H),e(b,T),e(b,R),p(w,x,H),p(w,E,H),e(E,O),p(w,L,H),C&&C.m(w,H),p(w,P,H),I&&I.m(w,H),p(w,G,H),p(w,S,H),e(S,A),e(S,D),e(S,z),e(z,N),p(w,Q,H),U&&U.m(w,H),p(w,j,H),F||(B=Re(S,"click",_[10]),F=!0)},p(w,H){H&4&&h!==(h=w[2].title+"")&&ce(v,h),H&4&&y!==(y=w[2].description+"")&&ce(O,y),typeof w[2].list_description!="undefined"?C?C.p(w,H):(C=nD(w),C.c(),C.m(P.parentNode,P)):C&&(C.d(1),C=null),typeof w[2].footer_description!="undefined"?I?I.p(w,H):(I=cD(w),I.c(),I.m(G.parentNode,G)):I&&(I.d(1),I=null),V===(V=q(w))&&U?U.p(w,H):(U&&U.d(1),U=V&&V(w),U&&(U.c(),U.m(j.parentNode,j)))},d(w){w&&t(f),w&&t(m),w&&t(g),w&&t(k),w&&t(b),w&&t(x),w&&t(E),w&&t(L),C&&C.d(w),w&&t(P),I&&I.d(w),w&&t(G),w&&t(S),w&&t(Q),U&&U.d(w),w&&t(j),F=!1,B()}}}function FD(_){let f,m;return{c(){f=a("h2"),m=o(_[0]),this.h()},l(g){f=l(g,"H2",{class:!0});var h=r(f);m=n(h,_[0]),h.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(g,h){p(g,f,h),e(f,m)},p(g,h){h&1&&ce(m,g[0])},d(g){g&&t(f)}}}function YD(_){let f,m=_[2].title+"",g;return{c(){f=a("h2"),g=o(m),this.h()},l(h){f=l(h,"H2",{class:!0});var v=r(f);g=n(v,m),v.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,v){p(h,f,v),e(f,g)},p(h,v){v&4&&m!==(m=h[2].title+"")&&ce(g,m)},d(h){h&&t(f)}}}function VD(_){let f,m;return{c(){f=a("p"),m=o(_[1]),this.h()},l(g){f=l(g,"P",{class:!0});var h=r(f);m=n(h,_[1]),h.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(g,h){p(g,f,h),e(f,m)},p(g,h){h&2&&ce(m,g[1])},d(g){g&&t(f)}}}function KD(_){let f,m=_[2].description+"",g;return{c(){f=a("p"),g=o(m),this.h()},l(h){f=l(h,"P",{class:!0});var v=r(f);g=n(v,m),v.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,v){p(h,f,v),e(f,g)},p(h,v){v&4&&m!==(m=h[2].description+"")&&ce(g,m)},d(h){h&&t(f)}}}function iD(_){let f,m,g=_[2].list_description+"",h;return{c(){f=a("div"),m=a("p"),h=o(g),this.h()},l(v){f=l(v,"DIV",{class:!0});var k=r(f);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(f,"class","list-description svelte-s12rf8")},m(v,k){p(v,f,k),e(f,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(f)}}}function oD(_){let f,m=_[2].footer_description+"",g;return{c(){f=a("p"),g=o(m),this.h()},l(h){f=l(h,"P",{class:!0});var v=r(f);g=n(v,m),v.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,v){p(h,f,v),e(f,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(f)}}}function nD(_){let f,m,g=_[2].list_description+"",h;return{c(){f=a("div"),m=a("p"),h=o(g),this.h()},l(v){f=l(v,"DIV",{class:!0});var k=r(f);m=l(k,"P",{class:!0});var b=r(m);h=n(b,g),b.forEach(t),k.forEach(t),this.h()},h(){i(m,"class","svelte-s12rf8"),i(f,"class","list-description svelte-s12rf8")},m(v,k){p(v,f,k),e(f,m),e(m,h)},p(v,k){k&4&&g!==(g=v[2].list_description+"")&&ce(h,g)},d(v){v&&t(f)}}}function cD(_){let f,m=_[2].footer_description+"",g;return{c(){f=a("p"),g=o(m),this.h()},l(h){f=l(h,"P",{class:!0});var v=r(f);g=n(v,m),v.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(h,v){p(h,f,v),e(f,g)},p(h,v){v&4&&m!==(m=h[2].footer_description+"")&&ce(g,m)},d(h){h&&t(f)}}}function XD(_){let f,m,g,h,v,k;function b(x,E){return x[5]?$D:JD}let T=b(_),R=T(_);return{c(){f=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),R.c(),this.h()},l(x){f=l(x,"H2",{class:!0});var E=r(f);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{class:!0});var y=r(h);R.l(y),y.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(h,"class","request-permission svelte-s12rf8")},m(x,E){p(x,f,E),e(f,m),p(x,g,E),p(x,h,E),R.m(h,null),v||(k=Re(h,"submit",_[8]),v=!0)},p(x,E){T===(T=b(x))&&R?R.p(x,E):(R.d(1),R=T(x),R&&(R.c(),R.m(h,null)))},d(x){x&&t(f),x&&t(g),x&&t(h),R.d(),v=!1,k()}}}function ZD(_){let f,m,g,h,v,k;function b(x,E){return x[5]?t9:e9}let T=b(_),R=T(_);return{c(){f=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("form"),R.c(),this.h()},l(x){f=l(x,"H2",{class:!0});var E=r(f);m=n(E,"Private GitHub Access"),E.forEach(t),g=u(x),h=l(x,"FORM",{});var y=r(h);R.l(y),y.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8")},m(x,E){p(x,f,E),e(f,m),p(x,g,E),p(x,h,E),R.m(h,null),v||(k=Re(h,"submit",_[7]),v=!0)},p(x,E){T===(T=b(x))&&R?R.p(x,E):(R.d(1),R=T(x),R&&(R.c(),R.m(h,null)))},d(x){x&&t(f),x&&t(g),x&&t(h),R.d(),v=!1,k()}}}function QD(_){var A;let f,m,g,h,v,k,b=((A=_[6].profile)==null?void 0:A.githubUsername)+"",T,R,x,E,y,O,L,P,G,S;return{c(){f=a("h2"),m=o("Private GitHub Access"),g=c(),h=a("p"),v=o("Your GitHub account "),k=a("span"),T=o(b),R=o(` is
			linked to this content.`),x=c(),E=a("button"),y=a("ion-icon"),O=c(),L=a("span"),P=o("Open Repository"),this.h()},l(D){f=l(D,"H2",{class:!0});var z=r(f);m=n(z,"Private GitHub Access"),z.forEach(t),g=u(D),h=l(D,"P",{class:!0});var N=r(h);v=n(N,"Your GitHub account "),k=l(N,"SPAN",{class:!0});var Q=r(k);T=n(Q,b),Q.forEach(t),R=n(N,` is
			linked to this content.`),N.forEach(t),x=u(D),E=l(D,"BUTTON",{class:!0});var j=r(E);y=l(j,"ION-ICON",{class:!0,name:!0}),r(y).forEach(t),O=u(j),L=l(j,"SPAN",{});var F=r(L);P=n(F,"Open Repository"),F.forEach(t),j.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(k,"class","highlight svelte-s12rf8"),i(h,"class","svelte-s12rf8"),ee(y,"class","icon svelte-s12rf8"),ee(y,"name","rocket-sharp"),i(E,"class","svelte-s12rf8")},m(D,z){p(D,f,z),e(f,m),p(D,g,z),p(D,h,z),e(h,v),e(h,k),e(k,T),e(h,R),p(D,x,z),p(D,E,z),e(E,y),e(E,O),e(E,L),e(L,P),G||(S=Re(E,"click",_[11]),G=!0)},p(D,z){var N;z&64&&b!==(b=((N=D[6].profile)==null?void 0:N.githubUsername)+"")&&ce(T,b)},d(D){D&&t(f),D&&t(g),D&&t(h),D&&t(x),D&&t(E),G=!1,S()}}}function JD(_){let f,m,g,h,v,k,b,T,R,x,E,y,O,L,P,G;return{c(){f=a("p"),m=o(`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),g=c(),h=a("label"),v=o("Github username:"),k=c(),b=a("input"),R=c(),x=a("button"),E=a("ion-icon"),y=c(),O=a("span"),L=o("Request Permission"),this.h()},l(S){f=l(S,"P",{class:!0});var A=r(f);m=n(A,`This content can grant access to a private GitHub repository. Enter your GitHub username to
				request access to this repository.`),A.forEach(t),g=u(S),h=l(S,"LABEL",{for:!0});var D=r(h);v=n(D,"Github username:"),D.forEach(t),k=u(S),b=l(S,"INPUT",{name:!0,id:!0,placeholder:!0,type:!0,class:!0}),R=u(S),x=l(S,"BUTTON",{class:!0});var z=r(x);E=l(z,"ION-ICON",{class:!0,name:!0}),r(E).forEach(t),y=u(z),O=l(z,"SPAN",{});var N=r(O);L=n(N,"Request Permission"),N.forEach(t),z.forEach(t),this.h()},h(){i(f,"class","svelte-s12rf8"),i(h,"for","username"),i(b,"name","username"),i(b,"id","username"),i(b,"placeholder","enter a username"),i(b,"type","text"),b.required="true",i(b,"class",T=_[4]?"validation-error":""),ee(E,"class","icon svelte-s12rf8"),ee(E,"name","rocket-sharp"),i(x,"class","svelte-s12rf8")},m(S,A){p(S,f,A),e(f,m),p(S,g,A),p(S,h,A),e(h,v),p(S,k,A),p(S,b,A),aD(b,_[3]),p(S,R,A),p(S,x,A),e(x,E),e(x,y),e(x,O),e(O,L),P||(G=Re(b,"input",_[14]),P=!0)},p(S,A){A&16&&T!==(T=S[4]?"validation-error":"")&&i(b,"class",T),A&8&&b.value!==S[3]&&aD(b,S[3])},d(S){S&&t(f),S&&t(g),S&&t(h),S&&t(k),S&&t(b),S&&t(R),S&&t(x),P=!1,G()}}}function $D(_){let f,m,g,h,v,k,b,T,R,x;return{c(){f=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),T=o("Open Repository"),this.h()},l(E){f=l(E,"P",{class:!0});var y=r(f);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var O=r(h);v=l(O,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(O),b=l(O,"SPAN",{});var L=r(b);T=n(L,"Open Repository"),L.forEach(t),O.forEach(t),this.h()},h(){i(f,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){p(E,f,y),e(f,m),p(E,g,y),p(E,h,y),e(h,v),e(h,k),e(h,b),e(b,T),R||(x=Re(h,"click",_[13]),R=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(f),E&&t(g),E&&t(h),R=!1,x()}}}function e9(_){var O;let f,m,g,h=((O=_[6].profile)==null?void 0:O.githubUsername)+"",v,k,b,T,R,x,E,y;return{c(){f=a("p"),m=o("This content can grant access to a private GitHub repository. Allow "),g=a("span"),v=o(h),k=o(" access to this repo?"),b=c(),T=a("button"),R=a("ion-icon"),x=c(),E=a("span"),y=o("Request Permission"),this.h()},l(L){f=l(L,"P",{class:!0});var P=r(f);m=n(P,"This content can grant access to a private GitHub repository. Allow "),g=l(P,"SPAN",{class:!0});var G=r(g);v=n(G,h),G.forEach(t),k=n(P," access to this repo?"),P.forEach(t),b=u(L),T=l(L,"BUTTON",{class:!0});var S=r(T);R=l(S,"ION-ICON",{class:!0,name:!0}),r(R).forEach(t),x=u(S),E=l(S,"SPAN",{});var A=r(E);y=n(A,"Request Permission"),A.forEach(t),S.forEach(t),this.h()},h(){i(g,"class","highlight svelte-s12rf8"),i(f,"class","svelte-s12rf8"),ee(R,"class","icon svelte-s12rf8"),ee(R,"name","rocket-sharp"),i(T,"class","svelte-s12rf8")},m(L,P){p(L,f,P),e(f,m),e(f,g),e(g,v),e(f,k),p(L,b,P),p(L,T,P),e(T,R),e(T,x),e(T,E),e(E,y)},p(L,P){var G;P&64&&h!==(h=((G=L[6].profile)==null?void 0:G.githubUsername)+"")&&ce(v,h)},d(L){L&&t(f),L&&t(b),L&&t(T)}}}function t9(_){let f,m,g,h,v,k,b,T,R,x;return{c(){f=a("p"),m=o(_[5]),g=c(),h=a("button"),v=a("ion-icon"),k=c(),b=a("span"),T=o("Open Repository"),this.h()},l(E){f=l(E,"P",{class:!0});var y=r(f);m=n(y,_[5]),y.forEach(t),g=u(E),h=l(E,"BUTTON",{class:!0});var O=r(h);v=l(O,"ION-ICON",{class:!0,name:!0}),r(v).forEach(t),k=u(O),b=l(O,"SPAN",{});var L=r(b);T=n(L,"Open Repository"),L.forEach(t),O.forEach(t),this.h()},h(){i(f,"class","feedback svelte-s12rf8"),ee(v,"class","icon svelte-s12rf8"),ee(v,"name","rocket-sharp"),i(h,"class","svelte-s12rf8")},m(E,y){p(E,f,y),e(f,m),p(E,g,y),p(E,h,y),e(h,v),e(h,k),e(h,b),e(b,T),R||(x=Re(h,"click",_[12]),R=!0)},p(E,y){y&32&&ce(m,E[5])},d(E){E&&t(f),E&&t(g),E&&t(h),R=!1,x()}}}function s9(_){let f;function m(v,k){return typeof v[2]!="undefined"&&typeof v[2].pk!="undefined"?jD:WD}let g=m(_),h=g(_);return{c(){h.c(),f=Wu()},l(v){h.l(v),f=Wu()},m(v,k){h.m(v,k),p(v,f,k)},p(v,[k]){g===(g=m(v))&&h?h.p(v,k):(h.d(1),h=g(v),h&&(h.c(),h.m(f.parentNode,f)))},i:$w,o:$w,d(v){h.d(v),v&&t(f)}}}function Jw(_){window.open(_,"_blank")||window.location.replace(_)}function a9(_,f,m){let{id:g}=f,{spacelabDefaultTitle:h="Spacelab Content"}=f,{spacelabDefaultContent:v="To access this content, you need a SpaceLab subscription."}=f,k={},b="",T=!1,R="",x;Qw.subscribe(D=>{m(6,x=D)}),zD(async()=>{if(typeof(x==null?void 0:x.token)!="undefined"){const D=await fetch(`${Zw().serviceUrl}/education/spacelab/${g}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors"});if(D.status===401){Qw.set({}),Qw.deleteLocalStorage();return}let z=await D.json();m(2,k=z)}else m(2,k.success=!1,k)});async function E(D){D.preventDefault();const z={};try{const N=await fetch(`${Zw().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(z)});if(N.ok)m(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await N.json();m(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),m(5,R="An unexpected error occurred. Please try again later.")}}async function y(D){if(D.preventDefault(),!b.trim()){m(4,T=!0),m(5,R="Please enter a valid GitHub username.");return}m(4,T=!1);const z={github_username:b};try{const N=await fetch(`${Zw().serviceUrl}/account/grant-github-access/`,{method:"POST",headers:{"Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+x.token},mode:"cors",body:JSON.stringify(z)});if(N.ok)m(5,R="Access request sent successfully! Please check your GitHub account for access.");else{const Q=await N.json();m(5,R=Q.message||"An error occurred while requesting access. Please try again.")}}catch(N){console.error("Error while sending GitHub access request:",N),m(5,R="An unexpected error occurred. Please try again later.")}}const O=()=>window.open(k.url,"_blank"),L=()=>Jw(`https://github.com/${k.github_repo_name}`),P=()=>Jw(`https://github.com/${k.github_repo_name}`),G=()=>Jw(`https://github.com/${k.github_repo_name}`);function S(){b=this.value,m(3,b)}const A=()=>window.open("/spacelab/","_blank");return _.$$set=D=>{"id"in D&&m(9,g=D.id),"spacelabDefaultTitle"in D&&m(0,h=D.spacelabDefaultTitle),"spacelabDefaultContent"in D&&m(1,v=D.spacelabDefaultContent)},[h,v,k,b,T,R,x,E,y,g,O,L,P,G,S,A]}class l9 extends hm{constructor(f){super(),gm(this,f,a9,s9,mm,{id:9,spacelabDefaultTitle:0,spacelabDefaultContent:1})}}const r9=_=>({}),uD=_=>({});function i9(_){let f;return{c(){f=o(`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},l(m){f=n(m,`Set the visibility of one image over the other. 0 is full visibility of
        the second image and 100 is full visibility of the first image. Any
        amount in-between is a left/right cutoff at the percentage of the
        slider.`)},m(m,g){p(m,f,g)},d(m){m&&t(f)}}}function o9(_){let f,m,g,h,v,k,b,T,R,x,E,y,O,L;const P=_[7]["slider-label"],G=ND(P,_,_[6],uD),S=G||i9();return{c(){f=a("div"),m=a("img"),h=c(),v=a("img"),b=c(),T=a("label"),R=a("span"),S&&S.c(),x=c(),E=a("input"),this.h()},l(A){f=l(A,"DIV",{class:!0,style:!0,"data-testid":!0});var D=r(f);m=l(D,"IMG",{src:!0,alt:!0,class:!0}),h=u(D),v=l(D,"IMG",{src:!0,alt:!0,class:!0}),b=u(D),T=l(D,"LABEL",{class:!0});var z=r(T);R=l(z,"SPAN",{class:!0});var N=r(R);S&&S.l(N),N.forEach(t),x=u(z),E=l(z,"INPUT",{type:!0,min:!0,max:!0,class:!0}),z.forEach(t),D.forEach(t),this.h()},h(){Wl(m.src,g=_[0])||i(m,"src",g),i(m,"alt",_[1]),i(m,"class","left-img svelte-1po6qlg"),Wl(v.src,k=_[2])||i(v,"src",k),i(v,"alt",_[3]),i(v,"class","right-img svelte-1po6qlg"),i(R,"class","visually-hidden svelte-1po6qlg"),i(E,"type","range"),i(E,"min","0"),i(E,"max","100"),E.value=_[4],i(E,"class","svelte-1po6qlg"),i(T,"class","svelte-1po6qlg"),i(f,"class","svelte-compare-image-container svelte-1po6qlg"),Ht(f,"--slider-position",_[4]+"%"),i(f,"data-testid","svelte-compare-image")},m(A,D){p(A,f,D),e(f,m),e(f,h),e(f,v),e(f,b),e(f,T),e(T,R),S&&S.m(R,null),e(T,x),e(T,E),y=!0,O||(L=[Re(E,"input",_[5]),Re(E,"change",_[5]),Re(E,"click",n9)],O=!0)},p(A,[D]){(!y||D&1&&!Wl(m.src,g=A[0]))&&i(m,"src",g),(!y||D&2)&&i(m,"alt",A[1]),(!y||D&4&&!Wl(v.src,k=A[2]))&&i(v,"src",k),(!y||D&8)&&i(v,"alt",A[3]),G&&G.p&&(!y||D&64)&&CD(G,P,A,A[6],y?HD(P,A[6],D,r9):GD(A[6]),uD),(!y||D&16)&&(E.value=A[4]),(!y||D&16)&&Ht(f,"--slider-position",A[4]+"%")},i(A){y||(Rt(S,A),y=!0)},o(A){St(S,A),y=!1},d(A){A&&t(f),S&&S.d(A),O=!1,qD(L)}}}function n9(_){_.target.focus()}function c9(_,f,m){let{$$slots:g={},$$scope:h}=f,{imageLeftSrc:v=""}=f,{imageLeftAlt:k=""}=f,{imageRightSrc:b=""}=f,{imageRightAlt:T=""}=f,R=50,x=null;function E(y){x&&cancelAnimationFrame(x),x=requestAnimationFrame(()=>{m(4,R=y.target.valueAsNumber)})}return _.$$set=y=>{"imageLeftSrc"in y&&m(0,v=y.imageLeftSrc),"imageLeftAlt"in y&&m(1,k=y.imageLeftAlt),"imageRightSrc"in y&&m(2,b=y.imageRightSrc),"imageRightAlt"in y&&m(3,T=y.imageRightAlt),"$$scope"in y&&m(6,h=y.$$scope)},[v,k,b,T,R,E,h,g]}class u9 extends hm{constructor(f){super(),gm(this,f,c9,o9,mm,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function p9(_){let f;return{c(){f=o(`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},l(m){f=n(m,`Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.`)},m(m,g){p(m,f,g)},d(m){m&&t(f)}}}function d9(_){let f,m,g,h;return m=new u9({props:{imageLeftSrc:_[0],imageLeftAlt:_[1],imageRightSrc:_[2],imageRightAlt:_[3],$$slots:{"slider-label":[p9]},$$scope:{ctx:_}}}),{c(){f=a("div"),g=a("div"),Ra(m.$$.fragment),this.h()},l(v){f=l(v,"DIV",{class:!0});var k=r(f);g=l(k,"DIV",{style:!0});var b=r(g);Sa(m.$$.fragment,b),k.forEach(t),this.h()},h(){Ht(g,"display","contents"),Ht(g,"--handle-size","2.5rem"),Ht(g,"--handle-background-color","rgba(0, 0, 0, 0.6)"),Ht(g,"--handle-background-image",_[4]),Ht(g,"--handle-border-width","0.125rem"),Ht(g,"--slider-color","#ffffff"),Ht(g,"--slider-width","0.125rem"),i(f,"class","image-compare-container svelte-s79nww")},m(v,k){p(v,f,k),e(f,g),Da(m,g,null),h=!0},p(v,[k]){const b={};k&1&&(b.imageLeftSrc=v[0]),k&2&&(b.imageLeftAlt=v[1]),k&4&&(b.imageRightSrc=v[2]),k&8&&(b.imageRightAlt=v[3]),k&32&&(b.$$scope={dirty:k,ctx:v}),m.$set(b)},i(v){h||(Rt(m.$$.fragment,v),h=!0)},o(v){St(m.$$.fragment,v),h=!1},d(v){v&&t(f),Aa(m)}}}function f9(_,f,m){const g=`url('data:image/svg+xml;utf8,<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>')`;let{imageLeftSrc:h="https://via.placeholder.com/512x512/ffaa00/ffffff/"}=f,{imageLeftAlt:v="left"}=f,{imageRightSrc:k="https://via.placeholder.com/512x512/00aaff/ffffff/"}=f,{imageRightAlt:b="right"}=f;return _.$$set=T=>{"imageLeftSrc"in T&&m(0,h=T.imageLeftSrc),"imageLeftAlt"in T&&m(1,v=T.imageLeftAlt),"imageRightSrc"in T&&m(2,k=T.imageRightSrc),"imageRightAlt"in T&&m(3,b=T.imageRightAlt)},[h,v,k,b,g]}class fm extends hm{constructor(f){super(),gm(this,f,f9,d9,mm,{imageLeftSrc:0,imageLeftAlt:1,imageRightSrc:2,imageRightAlt:3})}}function h9(_){let f,m;return f=new l9({props:{id:v9,spacelabDefaultTitle:_9,spacelabDefaultContent:k9}}),{c(){Ra(f.$$.fragment)},l(g){Sa(f.$$.fragment,g)},m(g,h){Da(f,g,h),m=!0},p:$w,i(g){m||(Rt(f.$$.fragment,g),m=!0)},o(g){St(f.$$.fragment,g),m=!1},d(g){Aa(f,g)}}}function g9(_){let f,m,g,h,v,k,b,T,R,x,E,y,O,L,P,G,S,A,D,z,N,Q,j,F,B,C,I,q,V,U,w,H,La,jl,we,Fl,vm,Yl,_m,km,Se,De,Vl,ju,Em,bm,Kl,xm,ym,Xl,wm,Tm,Ae,Zl,Fu,Rm,Sm,Ql,Dm,Am,Jl,Lm,Im,Le,$l,Yu,Om,Pm,er,zm,Nm,tr,Cm,Kd,sr,Gm,Xd,ar,Hm,Zd,Ia,lr,qm,Qd,Oa,Vu,Um,Mm,Jd,Pa,Ku,Bm,Wm,$d,za,Xu,jm,Fm,ef,Na,Zu,Ym,Vm,tf,qt,Ut,Qu,Km,sf,Ca,Ju,Xm,Zm,af,Ie,Qm,$u,Jm,$m,ep,ev,tv,lf,Oe,rr,tp,sv,av,lv,ir,sp,rv,iv,ov,Mt,ap,nv,cv,or,uv,pv,rf,Ga,nr,dv,of,Bt,Wt,lp,rp,fv,nf,cr,hv,cf,Pe,ur,ip,gv,mv,vv,pr,op,_v,kv,Ev,dr,np,bv,xv,uf,jt,Ft,cp,up,yv,pf,Dt,fr,ze,hr,pp,wv,Tv,gr,dp,Rv,Sv,mr,fp,Dv,Av,pe,Ne,vr,hp,Lv,Iv,_r,Ov,Pv,kr,zv,Nv,Ce,Er,gp,Cv,Gv,br,Hv,qv,xr,Uv,Mv,Ge,yr,mp,Bv,Wv,wr,jv,Fv,Tr,Yv,Vv,He,Rr,vp,Kv,Xv,Sr,Zv,Qv,Dr,Jv,df,Yt,Vt,_p,$v,ff,At,Ar,Kt,Lr,e2,t2,Ir,s2,a2,de,Xt,Or,kp,l2,r2,Pr,i2,o2,Zt,zr,Ep,n2,c2,Nr,u2,p2,Qt,Cr,bp,d2,f2,Gr,h2,g2,Jt,Hr,xp,m2,v2,qr,_2,hf,Ur,k2,gf,$t,es,yp,E2,mf,Ha,dD=`<code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code>`,vf,qa,fD=`<code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code>`,_f,ts,ss,wp,b2,kf,Lt,Mr,qe,Br,x2,y2,Wr,w2,T2,jr,R2,S2,fe,Ue,Fr,D2,A2,Yr,L2,I2,Vr,O2,P2,Me,Kr,z2,N2,Xr,C2,G2,Zr,H2,q2,Be,Qr,U2,M2,Jr,B2,W2,$r,j2,F2,We,ei,Y2,V2,ti,K2,X2,si,Z2,Ef,bf,xf,as,ls,Tp,Q2,yf,rs,J2,Ua,$2,e_,wf,is,os,Rp,t_,Tf,ns,s_,Ma,a_,l_,Rf,Ba,hD=`<code class="language-bash"><span class="token comment"># Install TensorBoard</span>
pip <span class="token function">install</span> tensorboard

<span class="token comment"># Start TensorBoard (point to your log directory)</span>
tensorboard --logdir<span class="token operator">=</span>./logs</code>`,Sf,cs,us,Sp,r_,Df,je,Dp,i_,o_,Ap,n_,c_,Lp,u_,Af,ps,ds,Ip,p_,Lf,Fe,Op,d_,f_,Pp,h_,g_,zp,m_,If,fs,hs,Np,v_,Of,Wa,Cp,__,k_,Pf,ja,gD=`<code class="language-json"> <span class="token punctuation">&#123;</span>
  <span class="token property">"validation_frequency"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">"num_validation_images"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
  <span class="token property">"validation_prompts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"photo of 1boy"</span><span class="token punctuation">,</span>
    <span class="token string">"portrait of a person"</span><span class="token punctuation">,</span>
    <span class="token string">"full body shot"</span><span class="token punctuation">,</span>
    <span class="token string">"close-up face"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span></code>`,zf,gs,ms,Gp,E_,Nf,Ye,Hp,b_,x_,qp,y_,w_,Up,T_,Cf,Fa,ai,R_,Gf,vs,_s,Mp,S_,Hf,Ya,Bp,D_,A_,qf,li,L_,Uf,Ve,Va,I_,ri,O_,P_,z_,Wp,N_,C_,jp,G_,Mf,Ka,ii,H_,Bf,ks,Es,Fp,q_,Wf,Xa,Yp,U_,M_,jf,Za,mD=`<code class="language-python"><span class="token comment"># example in pytorch</span>
scaler <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>GradScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

scaler<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>optimizer<span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Ff,oi,B_,Yf,Ke,Vp,W_,j_,Kp,F_,Y_,Xp,V_,Vf,Qa,ni,K_,Kf,bs,xs,Zp,X_,Xf,ys,Z_,Qp,Q_,J_,Zf,Ja,vD=`<code class="language-yml"><span class="token key atrule">Text Encoder</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>6 to 5e<span class="token punctuation">-</span><span class="token number">6</span>
<span class="token key atrule">UNet</span><span class="token punctuation">:</span> 1e<span class="token punctuation">-</span>5 to 5e<span class="token punctuation">-</span><span class="token number">5</span></code>`,Qf,$a,_D=`<code class="language-python"><span class="token comment"># Cosine Annealing Example</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>
    optimizer<span class="token punctuation">,</span>
    T_max<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># Number of iterations per cycle</span>
    eta_min<span class="token operator">=</span><span class="token number">1e-7</span>  <span class="token comment"># Minimum learning rate</span>
<span class="token punctuation">)</span></code>`,Jf,el,Jp,$_,e1,$f,Xe,$p,t1,s1,ed,a1,l1,td,r1,eh,It,ci,he,ui,i1,o1,pi,n1,c1,di,u1,p1,fi,d1,f1,le,ge,hi,h1,g1,gi,m1,v1,mi,_1,k1,vi,E1,b1,me,_i,x1,y1,ki,w1,T1,Ei,R1,S1,bi,D1,A1,ve,xi,L1,I1,yi,O1,P1,ws,z1,sd,N1,C1,G1,Ze,H1,wi,q1,U1,Ti,M1,B1,W1,_e,Ri,j1,F1,Si,Y1,V1,Di,K1,X1,Ai,Z1,Q1,ke,Li,J1,$1,Ii,ek,tk,Oi,sk,ak,Pi,lk,th,sh,ah,Ts,Rs,ad,rk,lh,Ss,ik,zi,ok,nk,rh,ue,ck,Ni,uk,pk,Ci,dk,fk,Gi,hk,gk,Hi,mk,ih,qi,vk,oh,Ds,As,ld,_k,nh,Qe,rd,tl,id,kk,Ek,bk,xk,od,sl,nd,yk,wk,Tk,Rk,cd,al,ud,Sk,Dk,Ak,ch,ll,uh,Ls,Is,pd,Lk,ph,Os,Ik,rl,Ok,Pk,dh,Je,zk,Ui,Nk,Ck,Mi,Gk,Hk,fh,J,dd,Bi,qk,Wi,Uk,Mk,fd,il,Bk,ji,Wk,jk,Fk,hd,K,Yk,Fi,Vk,Kk,Yi,Xk,Zk,Vi,Qk,Jk,Ki,$k,eE,Xi,tE,sE,Zi,aE,lE,Qi,rE,iE,Ji,oE,nE,gd,$,cE,$i,uE,pE,eo,dE,fE,to,hE,gE,so,mE,vE,ao,_E,kE,lo,EE,bE,ro,xE,yE,md,X,wE,io,TE,RE,oo,SE,DE,no,AE,LE,co,IE,OE,uo,PE,zE,po,NE,CE,fo,GE,HE,ho,qE,UE,vd,go,ME,mo,BE,WE,_d,Ps,jE,vo,FE,YE,_o,VE,hh,$e,KE,ko,XE,ZE,Eo,QE,JE,gh,ol,mh,zs,Ns,kd,$E,vh,bo,eb,_h,Ee,xo,nl,tb,sb,ab,yo,cl,lb,rb,ib,wo,ul,ob,nb,cb,To,pl,ub,pb,kh,Cs,Gs,Ed,db,Eh,Hs,fb,Ro,hb,gb,bh,dl,kD=`<code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code>`,xh,et,mb,So,vb,_b,Do,kb,Eb,yh,fl,bb,Ao,xb,wh,qs,yb,Lo,wb,Tb,Th,Us,Ms,bd,Rb,Rh,Bs,Sb,hl,Db,Ab,Sh,gl,Ws,Lb,ml,Ib,Ob,Dh,js,Fs,xd,Pb,Ah,Ys,zb,Io,Nb,Cb,Lh,vl,ED=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,Ih,Oo,Gb,Oh,_l,bD='<code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code>',Ph,tt,Hb,Po,qb,Ub,zo,Mb,Bb,zh,st,Wb,No,jb,Fb,Co,Yb,Vb,Nh,Go,Kb,Ch,Vs,Ho,Xb,yd,wd,Zb,Qb,qo,Jb,Td,Rd,$b,Gh,Uo,ex,Hh,kl,El,s5,qh,Ks,Xs,Sd,tx,Uh,Ot,sx,Mo,ax,lx,Bo,rx,Mh,Pt,Wo,re,jo,ix,ox,Fo,nx,cx,Yo,ux,px,Vo,dx,fx,Ko,hx,gx,Xo,ie,Zo,mx,vx,Qo,_x,kx,Jo,Ex,bx,$o,xx,yx,en,wx,Bh,tn,Tx,Wh,bl,xD=`<code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code>`,jh,M,sn,xl,Rx,an,Sx,Dx,Ax,Lx,ln,yl,Ix,rn,Ox,Px,zx,Nx,on,wl,Cx,nn,Gx,Hx,qx,Ux,cn,Tl,Mx,un,Bx,Wx,jx,Fx,pn,Rl,Yx,dn,Vx,Kx,Xx,Zx,fn,Sl,Qx,hn,Jx,$x,ey,ty,gn,Dl,sy,mn,ay,ly,ry,iy,vn,Al,oy,_n,ny,cy,uy,py,kn,Ll,dy,En,fy,hy,gy,my,bn,Il,vy,xn,_y,ky,Ey,by,yn,Ol,xy,wn,yy,wy,Ty,Fh,Zs,Qs,Dd,Ry,Yh,Tn,Sy,Vh,Pl,Kh,Js,$s,Ad,Dy,Xh,ea,Ay,zl,Ly,Iy,Zh,ta,Oy,Rn,Py,zy,Qh,oe,Sn,Ny,Jh,Cy,Ld,Gy,Hy,at,qy,Dn,Uy,My,An,By,Wy,Ln,jy,Fy,In,Yy,On,Vy,Ky,sa,Xy,Pn,Zy,Qy,zn,Jy,$h,lt,$y,Nn,e3,t3,Cn,s3,a3,eg,be,aa,l3,Gn,r3,i3,Hn,o3,n3,Nl,c3,qn,u3,p3,d3,Id,f3,h3,Od,g3,tg,la,ra,Pd,m3,sg,xe,Un,zd,v3,_3,k3,Mn,Nd,E3,b3,x3,Bn,Cd,y3,w3,T3,Wn,Gd,R3,S3,ag,jn,D3,lg,Cl,Gl,a5,rg,ia,oa,Hd,A3,ig,Fn,L3,og,rt,Hl,I3,Yn,O3,P3,z3,ql,N3,Vn,C3,G3,H3,qd,q3,ng,zt,Kn,it,Xn,U3,M3,Zn,B3,W3,Qn,j3,F3,ye,ot,Jn,Y3,V3,$n,K3,X3,ec,Z3,Q3,nt,tc,J3,$3,sc,e4,t4,ac,s4,a4,ct,lc,l4,r4,rc,i4,o4,ic,n4,c4,ut,oc,u4,p4,nc,d4,f4,cc,h4,cg,na,ca,Ud,g4,ug,uc,m4,pg,Nt,pc,pt,dc,v4,_4,fc,k4,E4,hc,b4,x4,W,dt,gc,y4,w4,mc,T4,R4,vc,S4,D4,ft,_c,A4,L4,kc,I4,O4,Ec,P4,z4,ht,bc,N4,C4,xc,G4,H4,yc,q4,U4,gt,wc,M4,B4,Tc,W4,j4,Rc,F4,Y4,mt,Sc,V4,K4,Dc,X4,Z4,Ac,Q4,J4,vt,Lc,$4,e0,Ic,t0,s0,Oc,a0,l0,_t,Pc,r0,i0,zc,o0,n0,Nc,c0,u0,kt,Cc,p0,d0,Gc,f0,h0,Hc,g0,m0,Et,qc,v0,_0,Uc,k0,E0,Mc,b0,x0,bt,Bc,y0,w0,Wc,T0,R0,jc,S0,dg,ua,pa,Md,D0,fg,Fc,A0,hg,Yc,L0,gg,Ul,Ml,l5,mg,Vc,I0,vg,Ct,da,Bd,O0,_g,kg,Eg;h=new BD({props:{smallImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png",largeImage:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png",alt:"Action Figure with reg images",largeWidth:"968",largeHeight:"512",smallWidth:"484",smallHeight:"256"}}),A=new fm({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png",imageRightAlt:"prince adam trained with regularization images."}}),ll=new fm({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png",imageRightAlt:"prince adam trained with regularization images."}}),ol=new fm({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png",imageRightAlt:"prince adam trained with regularization images."}}),Pl=new fm({props:{imageLeftSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png",imageLeftAlt:"prince adam without reg",imageRightSrc:"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png",imageRightAlt:"prince adam trained with regularization images."}});let Te=pD&&h9();return{c(){f=a("p"),m=o("I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),g=c(),Ra(h.$$.fragment),v=c(),k=a("h2"),b=a("a"),T=a("span"),R=o("What are Regularization Images?"),x=c(),E=a("p"),y=o("Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),O=c(),L=a("blockquote"),P=a("p"),G=o("\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),S=c(),Ra(A.$$.fragment),D=c(),z=a("p"),N=o("By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),Q=c(),j=a("p"),F=o("Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),B=c(),C=a("p"),I=o("In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),q=c(),V=a("table"),U=a("thead"),w=a("tr"),H=a("th"),La=o("Aspect"),jl=c(),we=a("th"),Fl=o("Regularization"),vm=c(),Yl=a("th"),_m=o("No Regularization"),km=c(),Se=a("tbody"),De=a("tr"),Vl=a("td"),ju=a("strong"),Em=o("Class Definition"),bm=c(),Kl=a("td"),xm=o("Explicit class anchoring"),ym=c(),Xl=a("td"),wm=o("Implicit class learning"),Tm=c(),Ae=a("tr"),Zl=a("td"),Fu=a("strong"),Rm=o("Failure Modes"),Sm=c(),Ql=a("td"),Dm=o("Underfitting if overdone"),Am=c(),Jl=a("td"),Lm=o("Overfitting/drift"),Im=c(),Le=a("tr"),$l=a("td"),Yu=a("strong"),Om=o("Data Efficiency"),Pm=c(),er=a("td"),zm=o("Better generalization"),Nm=c(),tr=a("td"),Cm=o("Requires more data"),Kd=c(),sr=a("p"),Gm=o("Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),Xd=c(),ar=a("p"),Hm=o("Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),Zd=c(),Ia=a("blockquote"),lr=a("p"),qm=o("\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),Qd=c(),Oa=a("p"),Vu=a("strong"),Um=o("Scenario 1"),Mm=o(": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),Jd=c(),Pa=a("p"),Ku=a("strong"),Bm=o("Solution"),Wm=o(": consider using regularization images to help the model learn more about cat features."),$d=c(),za=a("p"),Xu=a("strong"),jm=o("Scenario 2"),Fm=o(": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),ef=c(),Na=a("p"),Zu=a("strong"),Ym=o("Solution"),Vm=o(": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),tf=c(),qt=a("h2"),Ut=a("a"),Qu=a("span"),Km=o("Divergence"),sf=c(),Ca=a("p"),Ju=a("strong"),Xm=o("Divergence"),Zm=o(" occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),af=c(),Ie=a("p"),Qm=o("Preventing divergence starts with "),$u=a("strong"),Jm=o("careful dataset curation"),$m=o("\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),ep=a("strong"),ev=o("regularization techniques"),tv=o(" can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),lf=c(),Oe=a("ul"),rr=a("li"),tp=a("strong"),sv=o("Chaotic outputs"),av=o(" The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),lv=c(),ir=a("li"),sp=a("strong"),rv=o("Exploding gradients"),iv=o(" During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),ov=c(),Mt=a("li"),ap=a("strong"),nv=o("Loss value instability (NaN/infinity values)"),cv=o(" The training loss fluctuates wildly, sometimes becoming "),or=a("code"),uv=o("NaN"),pv=o(" (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),rf=c(),Ga=a("blockquote"),nr=a("p"),dv=o("\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),of=c(),Bt=a("h2"),Wt=a("a"),lp=a("span"),rp=a("strong"),fv=o("Overfitting"),nf=c(),cr=a("p"),hv=o("Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),cf=c(),Pe=a("ul"),ur=a("li"),ip=a("strong"),gv=o("Perfectly replicates training samples"),mv=o(" The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),vv=c(),pr=a("li"),op=a("strong"),_v=o("Fails to generalize to new inputs"),kv=o(" The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),Ev=c(),dr=a("li"),np=a("strong"),bv=o("Shows excellent training loss but poor validation loss"),xv=o(" The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),uf=c(),jt=a("h3"),Ft=a("a"),cp=a("span"),up=a("strong"),yv=o("Key Differences"),pf=c(),Dt=a("table"),fr=a("thead"),ze=a("tr"),hr=a("th"),pp=a("strong"),wv=o("Aspect"),Tv=c(),gr=a("th"),dp=a("strong"),Rv=o("Divergence"),Sv=c(),mr=a("th"),fp=a("strong"),Dv=o("Overfitting"),Av=c(),pe=a("tbody"),Ne=a("tr"),vr=a("td"),hp=a("strong"),Lv=o("Cause"),Iv=c(),_r=a("td"),Ov=o("Excessive learning rate"),Pv=c(),kr=a("td"),zv=o("Insufficient regularization"),Nv=c(),Ce=a("tr"),Er=a("td"),gp=a("strong"),Cv=o("Loss Behavior"),Gv=c(),br=a("td"),Hv=o("Sudden spikes/NaN values"),qv=c(),xr=a("td"),Uv=o("Steady decrease then rise"),Mv=c(),Ge=a("tr"),yr=a("td"),mp=a("strong"),Bv=o("Output Quality"),Wv=c(),wr=a("td"),jv=o("Random noise/artifacts"),Fv=c(),Tr=a("td"),Yv=o("Overly detailed replicas"),Vv=c(),He=a("tr"),Rr=a("td"),vp=a("strong"),Kv=o("Recovery"),Xv=c(),Sr=a("td"),Zv=o("Requires restart"),Qv=c(),Dr=a("td"),Jv=o("Early stopping works"),df=c(),Yt=a("h3"),Vt=a("a"),_p=a("span"),$v=o("Preventing Divergence"),ff=c(),At=a("table"),Ar=a("thead"),Kt=a("tr"),Lr=a("th"),e2=o("Situation"),t2=c(),Ir=a("th"),s2=o("Outcome"),a2=c(),de=a("tbody"),Xt=a("tr"),Or=a("td"),kp=a("strong"),l2=o("Excessive or inconsistent data"),r2=c(),Pr=a("td"),i2=o("Model struggles to learn and produces unreliable predictions."),o2=c(),Zt=a("tr"),zr=a("td"),Ep=a("strong"),n2=o("Lack of unique and consistent features"),c2=c(),Nr=a("td"),u2=o("Poor generalization, leading to inaccurate or meaningless outputs."),p2=c(),Qt=a("tr"),Cr=a("td"),bp=a("strong"),d2=o("Carefully curated datasets"),f2=c(),Gr=a("td"),h2=o("Improved learning by ensuring the model sees only relevant, high-quality data."),g2=c(),Jt=a("tr"),Hr=a("td"),xp=a("strong"),m2=o("Effective use of regularization techniques"),v2=c(),qr=a("td"),_2=o("Helps maintain focus on essential features and prevents instability."),hf=c(),Ur=a("p"),k2=o("By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),gf=c(),$t=a("h3"),es=a("a"),yp=a("span"),E2=o("Implementing these Strategies"),mf=c(),Ha=a("pre"),vf=c(),qa=a("pre"),_f=c(),ts=a("h3"),ss=a("a"),wp=a("span"),b2=o("Data Considerations"),kf=c(),Lt=a("table"),Mr=a("thead"),qe=a("tr"),Br=a("th"),x2=o("Situation"),y2=c(),Wr=a("th"),w2=o("Actual Risk"),T2=c(),jr=a("th"),R2=o("Solution"),S2=c(),fe=a("tbody"),Ue=a("tr"),Fr=a("td"),D2=o("High LR + small batch size"),A2=c(),Yr=a("td"),L2=o("Divergence"),I2=c(),Vr=a("td"),O2=o("Lower LR, increase batch size"),P2=c(),Me=a("tr"),Kr=a("td"),z2=o("Inconsistent features"),N2=c(),Xr=a("td"),C2=o("Overfitting"),G2=c(),Zr=a("td"),H2=o("Improve dataset consistency"),q2=c(),Be=a("tr"),Qr=a("td"),U2=o("Insufficient reg images"),M2=c(),Jr=a("td"),B2=o("Class leakage"),W2=c(),$r=a("td"),j2=o("Add 100-300 class images"),F2=c(),We=a("tr"),ei=a("td"),Y2=o("High variance in training data"),V2=c(),ti=a("td"),K2=o("Mode collapse"),X2=c(),si=a("td"),Z2=o("Curate focused dataset"),Ef=c(),bf=a("hr"),xf=c(),as=a("h2"),ls=a("a"),Tp=a("span"),Q2=o("Monitoring Tips"),yf=c(),rs=a("p"),J2=o("Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ua=a("a"),$2=o("kohya-ss/sd-scripts"),e_=o(".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),wf=c(),is=a("h3"),os=a("a"),Rp=a("span"),t_=o("Track loss curves"),Tf=c(),ns=a("p"),s_=o("Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Ma=a("a"),a_=o("TensorBoard"),l_=o(" to create these graphs."),Rf=c(),Ba=a("pre"),Sf=c(),cs=a("h4"),us=a("a"),Sp=a("span"),r_=o("What to Monitor:"),Df=c(),je=a("ul"),Dp=a("li"),i_=o("Training Loss: Should decrease steadily but not too quickly."),o_=c(),Ap=a("li"),n_=o("Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),c_=c(),Lp=a("li"),u_=o("Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),Af=c(),ps=a("h4"),ds=a("a"),Ip=a("span"),p_=o("Warning Signs:"),Lf=c(),Fe=a("ul"),Op=a("li"),d_=o("Sudden spikes in loss \u2192 Likely divergence."),f_=c(),Pp=a("li"),h_=o("Loss plateauing too early \u2192 Learning rate may be too low."),g_=c(),zp=a("li"),m_=o("Validation loss increasing while training loss decreases \u2192 Overfitting."),If=c(),fs=a("h3"),hs=a("a"),Np=a("span"),v_=o("Generate validation images every 100 steps"),Of=c(),Wa=a("p"),Cp=a("strong"),__=o("Why It Matters"),k_=o(" : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),Pf=c(),ja=a("pre"),zf=c(),gs=a("h4"),ms=a("a"),Gp=a("span"),E_=o("What to Look For:"),Nf=c(),Ye=a("ul"),Hp=a("li"),b_=o("Consistency: Outputs should align with the training data style."),x_=c(),qp=a("li"),y_=o("Artifacts: Check for distortions, noise, or unnatural features."),w_=c(),Up=a("li"),T_=o("Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),Cf=c(),Fa=a("blockquote"),ai=a("p"),R_=o("\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),Gf=c(),vs=a("h4"),_s=a("a"),Mp=a("span"),S_=o("Use Gradient Clipping"),Hf=c(),Ya=a("p"),Bp=a("strong"),D_=o("Why It Matters"),A_=o(": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),qf=c(),li=a("p"),L_=o("Key Insights:"),Uf=c(),Ve=a("ul"),Va=a("li"),I_=o("Gradient Norm "),ri=a("code"),O_=o("<"),P_=o(" than 0.1: Training may stall due to tiny updates."),z_=c(),Wp=a("li"),N_=o("Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),C_=c(),jp=a("li"),G_=o("Ideal Range: 0.1 to 2.0 for stable training."),Mf=c(),Ka=a("blockquote"),ii=a("p"),H_=o("\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),Bf=c(),ks=a("h4"),Es=a("a"),Fp=a("span"),q_=o("Enable Mixed Precision Training"),Wf=c(),Xa=a("p"),Yp=a("strong"),U_=o("Why It Matters"),M_=o(": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),jf=c(),Za=a("pre"),Ff=c(),oi=a("p"),B_=o("Benefits:"),Yf=c(),Ke=a("ul"),Vp=a("li"),W_=o("2-3x Faster Training: Leverages GPU tensor cores."),j_=c(),Kp=a("li"),F_=o("50% Less VRAM Usage: Allows larger batch sizes or models."),Y_=c(),Xp=a("li"),V_=o("Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),Vf=c(),Qa=a("blockquote"),ni=a("p"),K_=o("\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),Kf=c(),bs=a("h4"),xs=a("a"),Zp=a("span"),X_=o("Start with Conservative Learning Rates"),Xf=c(),ys=a("p"),Z_=o("Start off with 1e-5 to 1e-6.  "),Qp=a("strong"),Q_=o("Why It Matters"),J_=o(": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Zf=c(),Ja=a("pre"),Qf=c(),$a=a("pre"),Jf=c(),el=a("p"),Jp=a("strong"),$_=o("Warning Signs"),e1=o(":"),$f=c(),Xe=a("ul"),$p=a("li"),t1=o("Loss Spikes: Learning rate is too high."),s1=c(),ed=a("li"),a1=o("Slow Convergence: Learning rate is too low."),l1=c(),td=a("li"),r1=o("Oscillating Loss: Poor scheduling or unstable gradients."),eh=c(),It=a("table"),ci=a("thead"),he=a("tr"),ui=a("th"),i1=o("Practice"),o1=c(),pi=a("th"),n1=o("Key Benefit"),c1=c(),di=a("th"),u1=o("Tool/Setting"),p1=c(),fi=a("th"),d1=o("Warning Signs"),f1=c(),le=a("tbody"),ge=a("tr"),hi=a("td"),h1=o("Track Loss Curves"),g1=c(),gi=a("td"),m1=o("Detect overfitting/divergence early"),v1=c(),mi=a("td"),_1=o("TensorBoard, Weights & Biases"),k1=c(),vi=a("td"),E1=o("Spikes, plateaus, growing gaps"),b1=c(),me=a("tr"),_i=a("td"),x1=o("Generate Validation Images"),y1=c(),ki=a("td"),w1=o("Visualize model progress"),T1=c(),Ei=a("td"),R1=o("Fixed prompts/seeds"),S1=c(),bi=a("td"),D1=o("Artifacts, mode collapse"),A1=c(),ve=a("tr"),xi=a("td"),L1=o("Gradient Clipping"),I1=c(),yi=a("td"),O1=o("Prevent exploding gradients"),P1=c(),ws=a("td"),z1=o("clip"),sd=a("em"),N1=o("grad_norm"),C1=o(" (1.0-2.0)"),G1=c(),Ze=a("td"),H1=o("Norm "),wi=a("code"),q1=o(">"),U1=o(" 10.0 or "),Ti=a("code"),M1=o("<"),B1=o(" 0.1"),W1=c(),_e=a("tr"),Ri=a("td"),j1=o("Mixed Precision Training"),F1=c(),Si=a("td"),Y1=o("Faster training, lower VRAM usage"),V1=c(),Di=a("td"),K1=o("PyTorch AMP (torch.cuda.amp)"),X1=c(),Ai=a("td"),Z1=o("NaN values (disable if unstable)"),Q1=c(),ke=a("tr"),Li=a("td"),J1=o("Conservative Learning Rates"),$1=c(),Ii=a("td"),ek=o("Stable training, avoid divergence"),tk=c(),Oi=a("td"),sk=o("Start at 1e-5 to 1e-6, use scheduler"),ak=c(),Pi=a("td"),lk=o("Spikes, slow convergence"),th=c(),sh=a("hr"),ah=c(),Ts=a("h2"),Rs=a("a"),ad=a("span"),rk=o("Generating Regularization images"),lh=c(),Ss=a("p"),ik=o("Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),zi=a("code"),ok=o("1boy"),nk=o(")."),rh=c(),ue=a("p"),ck=o("According to the Dreambooth technique, "),Ni=a("code"),uk=o("200"),pk=o(" regularization images per training image.  For example, if you have "),Ci=a("code"),dk=o("16"),fk=o(" images: "),Gi=a("code"),hk=o("200 * 16 = 3200"),gk=o(" total regularization images.  When training, the math involved for calculating total steps is: "),Hi=a("code"),mk=o("repeats * training images >= repeats * regularization images"),ih=c(),qi=a("p"),vk=o("The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),oh=c(),Ds=a("h4"),As=a("a"),ld=a("span"),_k=o("Important considerations"),nh=c(),Qe=a("ol"),rd=a("li"),tl=a("p"),id=a("strong"),kk=o("Use the same base model for regularization images and training"),Ek=a("br"),bk=o(`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),xk=c(),od=a("li"),sl=a("p"),nd=a("strong"),yk=o("Maintain consistent class representation"),wk=a("br"),Tk=o(`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Rk=c(),cd=a("li"),al=a("p"),ud=a("strong"),Sk=o("Match output resolution to training data"),Dk=a("br"),Ak=o(`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),ch=c(),Ra(ll.$$.fragment),uh=c(),Ls=a("h4"),Is=a("a"),pd=a("span"),Lk=o("Generate using Stable Diffusion web UI"),ph=c(),Os=a("p"),Ik=o("We\u2019re going to use "),rl=a("a"),Ok=o("Stable Diffusion web UI"),Pk=o(" to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),dh=c(),Je=a("p"),zk=o("We\u2019re going to use the "),Ui=a("code"),Nk=o("X/Y/Z plot"),Ck=o(" script to use "),Mi=a("code"),Gk=o("Prompt Search & Replace"),Hk=o(" to dynamically build a prompt that will generate hundreds of regularization images."),fh=c(),J=a("ol"),dd=a("li"),Bi=a("p"),qk=o("Select the text 2 image tab.  Enter a generic prompt "),Wi=a("code"),Uk=o("princeadam, portrait, looking_at_viewer, forest"),Mk=c(),fd=a("li"),il=a("p"),Bk=o("In generation parameters and select the "),ji=a("code"),Wk=o("X/Y/Z plot"),jk=o(" script."),Fk=c(),hd=a("li"),K=a("p"),Yk=o("Select the "),Fi=a("code"),Vk=o("X"),Kk=o(" parameter and "),Yi=a("code"),Xk=o("Prompt SR"),Zk=o(" for Prompt Replace.  We\u2019re going to replace "),Vi=a("code"),Qk=o("portrait"),Jk=o(" with different camera angle tags: "),Ki=a("code"),$k=o("close-up"),eE=o(", "),Xi=a("code"),tE=o("upper_body"),sE=o(", "),Zi=a("code"),aE=o("from_below"),lE=o(", "),Qi=a("code"),rE=o("from_above"),iE=o(", "),Ji=a("code"),oE=o("dutch_angle"),nE=c(),gd=a("li"),$=a("p"),cE=o("Select the "),$i=a("code"),uE=o("Y"),pE=o(" parameter and "),eo=a("code"),dE=o("Prompt SR"),fE=o(" for Prompt Replace.  Replace "),to=a("code"),hE=o("looking_at_viewer"),gE=o(": "),so=a("code"),mE=o("looking_away"),vE=o(", "),ao=a("code"),_E=o("looking_to_the_side"),kE=o(", "),lo=a("code"),EE=o("looking_ahead"),bE=o(", "),ro=a("code"),xE=o("looking_down"),yE=c(),md=a("li"),X=a("p"),wE=o("Select the "),io=a("code"),TE=o("Z"),RE=o(" parameter and "),oo=a("code"),SE=o("Prompt SR"),DE=o(" for Prompt Replace. Replace "),no=a("code"),AE=o("forest"),LE=o(" with a vareity of locatinos: "),co=a("code"),IE=o("castle"),OE=o(", "),uo=a("code"),PE=o("mountain"),zE=o(", "),po=a("code"),NE=o("cave"),CE=o(", "),fo=a("code"),GE=o("farm"),HE=o(", "),ho=a("code"),qE=o("ocean"),UE=c(),vd=a("li"),go=a("p"),ME=o("Select a fast sampler like "),mo=a("code"),BE=o("DPM2 KARRAS"),WE=c(),_d=a("li"),Ps=a("p"),jE=o("CFG Scale set to "),vo=a("code"),FE=o("7"),YE=o(" and Steps to "),_o=a("code"),VE=o("20"),hh=c(),$e=a("p"),KE=o("After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),ko=a("code"),XE=o("150"),ZE=o(" - "),Eo=a("code"),QE=o("200"),JE=o(" and keep in mind we can add and remove as we try different training settings with different output."),gh=c(),Ra(ol.$$.fragment),mh=c(),zs=a("h4"),Ns=a("a"),kd=a("span"),$E=o("Download images"),vh=c(),bo=a("p"),eb=o("If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),_h=c(),Ee=a("ul"),xo=a("li"),nl=a("a"),tb=o("3ee Games regularization images"),sb=o(": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),ab=c(),yo=a("li"),cl=a("a"),lb=o("Pre-Rendered Regularization Images"),rb=o(": Includes 1500 regularization images."),ib=c(),wo=a("li"),ul=a("a"),ob=o("Stable Diffusion 1.5 Regularization Images"),nb=o(": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),cb=c(),To=a("li"),pl=a("a"),ub=o("Aitrepreneur SDXL image set"),pb=o(": a large image set generated with Stable Diffusion SDXL."),kh=c(),Cs=a("h4"),Gs=a("a"),Ed=a("span"),db=o("Captioning Regularization images"),Eh=c(),Hs=a("p"),fb=o("While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Ro=a("code"),hb=o("txt"),gb=o(" files with a shell script:"),bh=c(),dl=a("pre"),xh=c(),et=a("p"),mb=o("Save this file as "),So=a("code"),vb=o("filename2txt.bat"),_b=o(" and place it into the regularization images directory and run: "),Do=a("code"),kb=o(".\\filename2txt.bat"),Eb=o(".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),yh=c(),fl=a("p"),bb=o("Example filename: "),Ao=a("code"),xb=o("18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),wh=c(),qs=a("p"),yb=o("Output: "),Lo=a("code"),wb=o("aburbres,princeadam,1boy,close-up,purple_vest"),Tb=o(" saved in a text file with the same name as image."),Th=c(),Us=a("h2"),Ms=a("a"),bd=a("span"),Rb=o("Training a LoRA"),Rh=c(),Bs=a("p"),Sb=o("Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),hl=a("a"),Db=o("kohya-ss/sd-scripts"),Ab=o("."),Sh=c(),gl=a("blockquote"),Ws=a("p"),Lb=o("\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ml=a("a"),Ib=o("Kohya SD script documentation"),Ob=o("."),Dh=c(),js=a("h3"),Fs=a("a"),xd=a("span"),Pb=o("Directory setup"),Ah=c(),Ys=a("p"),zb=o("In your configuration json, use "),Io=a("code"),Nb=o("reg_data_dir"),Cb=o(" to point to the directory with your regularization images:"),Lh=c(),vl=a("pre"),Ih=c(),Oo=a("p"),Gb=o("Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),Oh=c(),_l=a("pre"),Ph=c(),tt=a("p"),Hb=o("Set the "),Po=a("code"),qb=o("number of iterations"),Ub=o(" so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),zo=a("code"),Mb=o("training images \xD7 iterations"),Bb=o(". If there are more regularization images than this, the extras won\u2019t be used."),zh=c(),st=a("p"),Wb=o("Create folders in the training image folder with the format "),No=a("code"),jb=o("<repetition count>_<class>"),Fb=o(" multiple times, and similarly create folders in the regularization image folder with the format "),Co=a("code"),Yb=o("<repetition count>_<class>"),Vb=o("."),Nh=c(),Go=a("p"),Kb=o("If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),Ch=c(),Vs=a("ul"),Ho=a("li"),Xb=o("train_data_dir"),yd=a("ul"),wd=a("li"),Zb=o("10_princeadam"),Qb=c(),qo=a("li"),Jb=o("reg_dir"),Td=a("ul"),Rd=a("li"),$b=o("1_1boy"),Gh=c(),Uo=a("p"),ex=o("For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),Hh=c(),kl=a("p"),El=a("img"),qh=c(),Ks=a("h3"),Xs=a("a"),Sd=a("span"),tx=o("Training Settings"),Uh=c(),Ot=a("p"),sx=o("The training setup we\u2019re going to use is:  "),Mo=a("code"),ax=o("Number of images * repeats * epoch / batch size = total steps"),lx=o(".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Bo=a("code"),rx=o("Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Mh=c(),Pt=a("table"),Wo=a("thead"),re=a("tr"),jo=a("th"),ix=o("Number of Images"),ox=c(),Fo=a("th"),nx=o("Repeats"),cx=c(),Yo=a("th"),ux=o("Epochs"),px=c(),Vo=a("th"),dx=o("Batch Size"),fx=c(),Ko=a("th"),hx=o("Total Steps"),gx=c(),Xo=a("tbody"),ie=a("tr"),Zo=a("td"),mx=o("45"),vx=c(),Qo=a("td"),_x=o("10"),kx=c(),Jo=a("td"),Ex=o("20"),bx=c(),$o=a("td"),xx=o("2"),yx=c(),en=a("td"),wx=o("4500"),Bh=c(),tn=a("p"),Tx=o("Now let\u2019s focus on these training settings:"),Wh=c(),bl=a("pre"),jh=c(),M=a("ul"),sn=a("li"),xl=a("strong"),Rx=o("Learning Rate ("),an=a("code"),Sx=o("learning_rate"),Dx=o(")"),Ax=o(": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Lx=c(),ln=a("li"),yl=a("strong"),Ix=o("Text Encoder Learning Rate ("),rn=a("code"),Ox=o("text_encoder_lr"),Px=o(")"),zx=o(": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Nx=c(),on=a("li"),wl=a("strong"),Cx=o("UNet Learning Rate ("),nn=a("code"),Gx=o("unet_lr"),Hx=o(")"),qx=o(": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Ux=c(),cn=a("li"),Tl=a("strong"),Mx=o("Learning Rate Scheduler ("),un=a("code"),Bx=o("lr_scheduler"),Wx=o(")"),jx=o(": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Fx=c(),pn=a("li"),Rl=a("strong"),Yx=o("Number of Cycles in Learning Rate Scheduler ("),dn=a("code"),Vx=o("lr_scheduler_num_cycles"),Kx=o(")"),Xx=o(": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Zx=c(),fn=a("li"),Sl=a("strong"),Qx=o("Network Dimension ("),hn=a("code"),Jx=o("network_dim"),$x=o(")"),ey=o(": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),ty=c(),gn=a("li"),Dl=a("strong"),sy=o("Network Alpha ("),mn=a("code"),ay=o("network_alpha"),ly=o(")"),ry=o(": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),iy=c(),vn=a("li"),Al=a("strong"),oy=o("Clip Skip ("),_n=a("code"),ny=o("clip_skip"),cy=o(")"),uy=o(": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),py=c(),kn=a("li"),Ll=a("strong"),dy=o("Max Token Length ("),En=a("code"),fy=o("max_token_length"),hy=o(")"),gy=o(": Sets the maximum allowed length for input tokens, enabling training with longer captions."),my=c(),bn=a("li"),Il=a("strong"),vy=o("Noise Offset ("),xn=a("code"),_y=o("noise_offset"),ky=o(")"),Ey=o(": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),by=c(),yn=a("li"),Ol=a("strong"),xy=o("Regularization Data Directory ("),wn=a("code"),yy=o("reg_data_dir"),wy=o(")"),Ty=o(": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Fh=c(),Zs=a("h3"),Qs=a("a"),Dd=a("span"),Ry=o("Fine Tuning"),Yh=c(),Tn=a("p"),Sy=o("Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),Vh=c(),Ra(Pl.$$.fragment),Kh=c(),Js=a("h4"),$s=a("a"),Ad=a("span"),Dy=o("Workflow with Auto1111 WebUI"),Xh=c(),ea=a("p"),Ay=o("We\u2019re going to use "),zl=a("a"),Ly=o("Stable Diffusion web UI"),Iy=o(" to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Zh=c(),ta=a("p"),Oy=o("We\u2019re going to use the "),Rn=a("code"),Py=o("X/Y/Z plot"),zy=o(" script to compare different epochs."),Qh=c(),oe=a("ul"),Sn=a("li"),Ny=o("Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),Jh=a("princeadam0001:0.7"),Cy=c(),Ld=a("li"),Gy=o("In generation parameters and select the X/Y/Z plot script."),Hy=c(),at=a("li"),qy=o("Select "),Dn=a("code"),Uy=o("Prompt SR"),My=o(" for Prompt Replace.  We\u2019re going to replace "),An=a("code"),By=o("<princeadam0001:0.7>"),Wy=o(" with different epoch: "),Ln=a("code"),jy=o("<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),Fy=c(),In=a("li"),Yy=o("Select a fast sampler like "),On=a("code"),Vy=o("DPM2 KARRAS"),Ky=c(),sa=a("li"),Xy=o("CFG Scale set to "),Pn=a("code"),Zy=o("7"),Qy=o(" and Steps to "),zn=a("code"),Jy=o("20"),$h=c(),lt=a("p"),$y=o("After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Nn=a("code"),e3=o("network_dim"),t3=o(" and "),Cn=a("code"),s3=o("network_alpha"),a3=o(`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),eg=c(),be=a("ul"),aa=a("li"),l3=o("Select "),Gn=a("code"),r3=o("Prompt SR"),i3=o(" for Prompt Replace.  We\u2019re going to replace the weights "),Hn=a("code"),o3=o("<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),n3=c(),Nl=a("li"),c3=o("Use Prompt SR to generate a variety of angles: Select "),qn=a("code"),u3=o("Prompt SR"),p3=o(" for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),d3=c(),Id=a("li"),f3=o("If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),h3=c(),Od=a("li"),g3=o("Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),tg=c(),la=a("h4"),ra=a("a"),Pd=a("span"),m3=o("Issues to look for"),sg=c(),xe=a("ul"),Un=a("li"),zd=a("strong"),v3=o("Undercooked:"),_3=o(" Lacks output, adjust unet learning rate or extend training duration."),k3=c(),Mn=a("li"),Nd=a("strong"),E3=o("Overcooked:"),b3=o(" Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),x3=c(),Bn=a("li"),Cd=a("strong"),y3=o("Overfit:"),w3=o(" Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),T3=c(),Wn=a("li"),Gd=a("strong"),R3=o("Mismatched:"),S3=o(" Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),ag=c(),jn=a("p"),D3=o("If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),lg=c(),Cl=a("p"),Gl=a("img"),rg=c(),ia=a("h2"),oa=a("a"),Hd=a("span"),A3=o("Troubleshooting"),ig=c(),Fn=a("p"),L3=o("If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),og=c(),rt=a("ul"),Hl=a("li"),I3=o("Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Yn=a("code"),O3=o("200"),P3=o(" regularization images per training image."),z3=c(),ql=a("li"),N3=o("Repeats of regularization images, but may overfit more.  Increasing the "),Vn=a("code"),C3=o("repetition_count"),G3=o(" will cycle through the images more but the results may have results that overfit the model."),H3=c(),qd=a("li"),q3=o("Create more regularization images without increasing repeats will help with the overfitting."),ng=c(),zt=a("table"),Kn=a("thead"),it=a("tr"),Xn=a("th"),U3=o("Issue"),M3=c(),Zn=a("th"),B3=o("Situation"),W3=c(),Qn=a("th"),j3=o("Recommendation"),F3=c(),ye=a("tbody"),ot=a("tr"),Jn=a("td"),Y3=o("Varying quality"),V3=c(),$n=a("td"),K3=o("Results differ from expectations"),X3=c(),ec=a("td"),Z3=o("Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),Q3=c(),nt=a("tr"),tc=a("td"),J3=o("Inadequate regularization for input data"),$3=c(),sc=a("td"),e4=o("Lower input images, less regularization needed"),t4=c(),ac=a("td"),s4=o("Reduce the number of input images or increasing the quantity of reg images."),a4=c(),ct=a("tr"),lc=a("td"),l4=o("Overfitting due to repetition"),r4=c(),rc=a("td"),i4=o("Repeats of reg images, risk of overfitting"),o4=c(),ic=a("td"),n4=o("Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),c4=c(),ut=a("tr"),oc=a("td"),u4=o("Mitigate overfitting while increasing diversity"),p4=c(),nc=a("td"),d4=o("Create more reg images without repeats"),f4=c(),cc=a("td"),h4=o("Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),cg=c(),na=a("h4"),ca=a("a"),Ud=a("span"),g4=o("More Solutions"),ug=c(),uc=a("p"),m4=o("Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),pg=c(),Nt=a("table"),pc=a("thead"),pt=a("tr"),dc=a("th"),v4=o("Symptom"),_4=c(),fc=a("th"),k4=o("Likely Cause"),E4=c(),hc=a("th"),b4=o("Solution"),x4=c(),W=a("tbody"),dt=a("tr"),gc=a("td"),y4=o("Plastic texture persists"),w4=c(),mc=a("td"),T4=o("Insufficient human reg images"),R4=c(),vc=a("td"),S4=o("Add real photos to reg set"),D4=c(),ft=a("tr"),_c=a("td"),A4=o("Loss plateaus early"),L4=c(),kc=a("td"),I4=o("Learning rate too low"),O4=c(),Ec=a("td"),P4=o("Increase LR by 10x"),z4=c(),ht=a("tr"),bc=a("td"),N4=o("Features blurry"),C4=c(),xc=a("td"),G4=o("Network dimension too small"),H4=c(),yc=a("td"),q4=o("Increase network_dim to 64+"),U4=c(),gt=a("tr"),wc=a("td"),M4=o("Color distortion"),B4=c(),Tc=a("td"),W4=o("Noise offset conflict"),j4=c(),Rc=a("td"),F4=o("Try noise_offset 0.05-0.1"),Y4=c(),mt=a("tr"),Sc=a("td"),V4=o("Overly stylized outputs"),K4=c(),Dc=a("td"),X4=o("Reg image style mismatch"),Z4=c(),Ac=a("td"),Q4=o("Regenerate reg images with base model"),J4=c(),vt=a("tr"),Lc=a("td"),$4=o("Training instability"),e0=c(),Ic=a("td"),t0=o("Batch size too large"),s0=c(),Oc=a("td"),a0=o("Reduce batch_size to 1-2"),l0=c(),_t=a("tr"),Pc=a("td"),r0=o("Slow convergence"),i0=c(),zc=a("td"),o0=o("Network_alpha too high"),n0=c(),Nc=a("td"),c0=o("Set alpha = dim/2 (e.g., 64/2 = 32)"),u0=c(),kt=a("tr"),Cc=a("td"),p0=o("Loss divergence"),d0=c(),Gc=a("td"),f0=o("Text encoder LR too high"),h0=c(),Hc=a("td"),g0=o("Reduce text_encoder_lr by 10x"),m0=c(),Et=a("tr"),qc=a("td"),v0=o("Poor prompt adherence"),_0=c(),Uc=a("td"),k0=o("Clip skip too high"),E0=c(),Mc=a("td"),b0=o("Reduce clip_skip to 1-2"),x0=c(),bt=a("tr"),Bc=a("td"),y0=o("Memory errors"),w0=c(),Wc=a("td"),T0=o("Resolution too high"),R0=c(),jc=a("td"),S0=o("Reduce to 512-768px, enable gradient checkpointing"),dg=c(),ua=a("h2"),pa=a("a"),Md=a("span"),D0=o("Results"),fg=c(),Fc=a("p"),A0=o("The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),hg=c(),Yc=a("p"),L0=o("Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),gg=c(),Ul=a("p"),Ml=a("img"),mg=c(),Vc=a("p"),I0=o("The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),vg=c(),Ct=a("h2"),da=a("a"),Bd=a("span"),O0=o("spacelab"),_g=c(),Te&&Te.c(),kg=Wu(),this.h()},l(s){f=l(s,"P",{});var d=r(f);m=n(d,"I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images."),d.forEach(t),g=u(s),Sa(h.$$.fragment,s),v=u(s),k=l(s,"H2",{id:!0});var P0=r(k);b=l(P0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var r5=r(b);T=l(r5,"SPAN",{class:!0}),r(T).forEach(t),r5.forEach(t),R=n(P0,"What are Regularization Images?"),P0.forEach(t),x=u(s),E=l(s,"P",{});var i5=r(E);y=n(i5,"Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts."),i5.forEach(t),O=u(s),L=l(s,"BLOCKQUOTE",{class:!0});var o5=r(L);P=l(o5,"P",{class:!0});var n5=r(P);G=n(n5,"\u{1F4C4} Regularization tackles two key challenges with model training: overfitting and preserving class distinctions."),n5.forEach(t),o5.forEach(t),S=u(s),Sa(A.$$.fragment,s),D=u(s),z=l(s,"P",{});var c5=r(z);N=n(c5,"By creating regularization images, you\u2019re defining a \u201Cclass\u201D of what you\u2019re trying to invert. For example, if you\u2019re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let\u2019s say \u201Cbike\u201D or \u201Croller skates.\u201D It also helps guard against heading towards a \u201Ctoy skateboard\u201D if you are using real references and not interpretations."),c5.forEach(t),Q=u(s),j=l(s,"P",{});var u5=r(j);F=n(u5,"Regularization ensures that the images you\u2019re trying to invert don\u2019t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue."),u5.forEach(t),B=u(s),C=l(s,"P",{});var p5=r(C);I=n(p5,"In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs."),p5.forEach(t),q=u(s),V=l(s,"TABLE",{class:!0});var bg=r(V);U=l(bg,"THEAD",{class:!0});var d5=r(U);w=l(d5,"TR",{class:!0});var Kc=r(w);H=l(Kc,"TH",{class:!0});var f5=r(H);La=n(f5,"Aspect"),f5.forEach(t),jl=u(Kc),we=l(Kc,"TH",{class:!0});var h5=r(we);Fl=n(h5,"Regularization"),h5.forEach(t),vm=u(Kc),Yl=l(Kc,"TH",{class:!0});var g5=r(Yl);_m=n(g5,"No Regularization"),g5.forEach(t),Kc.forEach(t),d5.forEach(t),km=u(bg),Se=l(bg,"TBODY",{class:!0});var Xc=r(Se);De=l(Xc,"TR",{class:!0});var Zc=r(De);Vl=l(Zc,"TD",{class:!0});var m5=r(Vl);ju=l(m5,"STRONG",{});var v5=r(ju);Em=n(v5,"Class Definition"),v5.forEach(t),m5.forEach(t),bm=u(Zc),Kl=l(Zc,"TD",{class:!0});var _5=r(Kl);xm=n(_5,"Explicit class anchoring"),_5.forEach(t),ym=u(Zc),Xl=l(Zc,"TD",{class:!0});var k5=r(Xl);wm=n(k5,"Implicit class learning"),k5.forEach(t),Zc.forEach(t),Tm=u(Xc),Ae=l(Xc,"TR",{class:!0});var Qc=r(Ae);Zl=l(Qc,"TD",{class:!0});var E5=r(Zl);Fu=l(E5,"STRONG",{});var b5=r(Fu);Rm=n(b5,"Failure Modes"),b5.forEach(t),E5.forEach(t),Sm=u(Qc),Ql=l(Qc,"TD",{class:!0});var x5=r(Ql);Dm=n(x5,"Underfitting if overdone"),x5.forEach(t),Am=u(Qc),Jl=l(Qc,"TD",{class:!0});var y5=r(Jl);Lm=n(y5,"Overfitting/drift"),y5.forEach(t),Qc.forEach(t),Im=u(Xc),Le=l(Xc,"TR",{class:!0});var Jc=r(Le);$l=l(Jc,"TD",{class:!0});var w5=r($l);Yu=l(w5,"STRONG",{});var T5=r(Yu);Om=n(T5,"Data Efficiency"),T5.forEach(t),w5.forEach(t),Pm=u(Jc),er=l(Jc,"TD",{class:!0});var R5=r(er);zm=n(R5,"Better generalization"),R5.forEach(t),Nm=u(Jc),tr=l(Jc,"TD",{class:!0});var S5=r(tr);Cm=n(S5,"Requires more data"),S5.forEach(t),Jc.forEach(t),Xc.forEach(t),bg.forEach(t),Kd=u(s),sr=l(s,"P",{});var D5=r(sr);Gm=n(D5,"Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called \u201Cgeneralization.\u201D If we don\u2019t use regularization, our models can become too complex and \u201Coverfit\u201D to the training data, meaning they won\u2019t work well with new data."),D5.forEach(t),Xd=u(s),ar=l(s,"P",{});var A5=r(ar);Hm=n(A5,"Using too much regularization can be a problem. It can lead to \u201Cunderfitting,\u201D which means our model doesn\u2019t work well with the training data. This happens when we limit our model\u2019s ability too much."),A5.forEach(t),Zd=u(s),Ia=l(s,"BLOCKQUOTE",{class:!0});var L5=r(Ia);lr=l(L5,"P",{class:!0});var I5=r(lr);qm=n(I5,"\u{1F4C4} Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance."),I5.forEach(t),L5.forEach(t),Qd=u(s),Oa=l(s,"P",{});var z0=r(Oa);Vu=l(z0,"STRONG",{});var O5=r(Vu);Um=n(O5,"Scenario 1"),O5.forEach(t),Mm=n(z0,": You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won\u2019t learn enough to accurately recognize your cat."),z0.forEach(t),Jd=u(s),Pa=l(s,"P",{});var N0=r(Pa);Ku=l(N0,"STRONG",{});var P5=r(Ku);Bm=n(P5,"Solution"),P5.forEach(t),Wm=n(N0,": consider using regularization images to help the model learn more about cat features."),N0.forEach(t),$d=u(s),za=l(s,"P",{});var C0=r(za);Xu=l(C0,"STRONG",{});var z5=r(Xu);jm=n(z5,"Scenario 2"),z5.forEach(t),Fm=n(C0,": You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat."),C0.forEach(t),ef=u(s),Na=l(s,"P",{});var G0=r(Na);Zu=l(G0,"STRONG",{});var N5=r(Zu);Ym=n(N5,"Solution"),N5.forEach(t),Vm=n(G0,": using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats."),G0.forEach(t),tf=u(s),qt=l(s,"H2",{id:!0});var H0=r(qt);Ut=l(H0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var C5=r(Ut);Qu=l(C5,"SPAN",{class:!0}),r(Qu).forEach(t),C5.forEach(t),Km=n(H0,"Divergence"),H0.forEach(t),sf=u(s),Ca=l(s,"P",{});var q0=r(Ca);Ju=l(q0,"STRONG",{});var G5=r(Ju);Xm=n(G5,"Divergence"),G5.forEach(t),Zm=n(q0," occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject\u2019s likeness, the model produces unpredictable or incorrect results."),q0.forEach(t),af=u(s),Ie=l(s,"P",{});var $c=r(Ie);Qm=n($c,"Preventing divergence starts with "),$u=l($c,"STRONG",{});var H5=r($u);Jm=n(H5,"careful dataset curation"),H5.forEach(t),$m=n($c,"\u2014selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, "),ep=l($c,"STRONG",{});var q5=r(ep);ev=n(q5,"regularization techniques"),q5.forEach(t),tv=n($c," can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data."),$c.forEach(t),lf=u(s),Oe=l(s,"UL",{});var eu=r(Oe);rr=l(eu,"LI",{});var U0=r(rr);tp=l(U0,"STRONG",{});var U5=r(tp);sv=n(U5,"Chaotic outputs"),U5.forEach(t),av=n(U0," The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images."),U0.forEach(t),lv=u(eu),ir=l(eu,"LI",{});var M0=r(ir);sp=l(M0,"STRONG",{});var M5=r(sp);rv=n(M5,"Exploding gradients"),M5.forEach(t),iv=n(M0," During backpropagation, weight updates grow exponentially, making the model\u2019s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue."),M0.forEach(t),ov=u(eu),Mt=l(eu,"LI",{});var Wd=r(Mt);ap=l(Wd,"STRONG",{});var B5=r(ap);nv=n(B5,"Loss value instability (NaN/infinity values)"),B5.forEach(t),cv=n(Wd," The training loss fluctuates wildly, sometimes becoming "),or=l(Wd,"CODE",{class:!0});var W5=r(or);uv=n(W5,"NaN"),W5.forEach(t),pv=n(Wd," (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization."),Wd.forEach(t),eu.forEach(t),rf=u(s),Ga=l(s,"BLOCKQUOTE",{class:!0});var j5=r(Ga);nr=l(j5,"P",{class:!0});var F5=r(nr);dv=n(F5,"\u{1F4C4} Backpropagation is considered the cornerstone of training deep neural networks, enabling them to learn complex patterns from large datasets."),F5.forEach(t),j5.forEach(t),of=u(s),Bt=l(s,"H2",{id:!0});var B0=r(Bt);Wt=l(B0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Y5=r(Wt);lp=l(Y5,"SPAN",{class:!0}),r(lp).forEach(t),Y5.forEach(t),rp=l(B0,"STRONG",{});var V5=r(rp);fv=n(V5,"Overfitting"),V5.forEach(t),B0.forEach(t),nf=u(s),cr=l(s,"P",{});var K5=r(cr);hv=n(K5,"Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:"),K5.forEach(t),cf=u(s),Pe=l(s,"UL",{});var tu=r(Pe);ur=l(tu,"LI",{});var W0=r(ur);ip=l(W0,"STRONG",{});var X5=r(ip);gv=n(X5,"Perfectly replicates training samples"),X5.forEach(t),mv=n(W0," The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs."),W0.forEach(t),vv=u(tu),pr=l(tu,"LI",{});var j0=r(pr);op=l(j0,"STRONG",{});var Z5=r(op);_v=n(Z5,"Fails to generalize to new inputs"),Z5.forEach(t),kv=n(j0," The model struggles to produce high-quality results for inputs it hasn\u2019t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations."),j0.forEach(t),Ev=u(tu),dr=l(tu,"LI",{});var F0=r(dr);np=l(F0,"STRONG",{});var Q5=r(np);bv=n(Q5,"Shows excellent training loss but poor validation loss"),Q5.forEach(t),xv=n(F0," The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting."),F0.forEach(t),tu.forEach(t),uf=u(s),jt=l(s,"H3",{id:!0});var Y0=r(jt);Ft=l(Y0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var J5=r(Ft);cp=l(J5,"SPAN",{class:!0}),r(cp).forEach(t),J5.forEach(t),up=l(Y0,"STRONG",{});var $5=r(up);yv=n($5,"Key Differences"),$5.forEach(t),Y0.forEach(t),pf=u(s),Dt=l(s,"TABLE",{class:!0});var xg=r(Dt);fr=l(xg,"THEAD",{class:!0});var e6=r(fr);ze=l(e6,"TR",{class:!0});var su=r(ze);hr=l(su,"TH",{class:!0});var t6=r(hr);pp=l(t6,"STRONG",{});var s6=r(pp);wv=n(s6,"Aspect"),s6.forEach(t),t6.forEach(t),Tv=u(su),gr=l(su,"TH",{class:!0});var a6=r(gr);dp=l(a6,"STRONG",{});var l6=r(dp);Rv=n(l6,"Divergence"),l6.forEach(t),a6.forEach(t),Sv=u(su),mr=l(su,"TH",{class:!0});var r6=r(mr);fp=l(r6,"STRONG",{});var i6=r(fp);Dv=n(i6,"Overfitting"),i6.forEach(t),r6.forEach(t),su.forEach(t),e6.forEach(t),Av=u(xg),pe=l(xg,"TBODY",{class:!0});var fa=r(pe);Ne=l(fa,"TR",{class:!0});var au=r(Ne);vr=l(au,"TD",{class:!0});var o6=r(vr);hp=l(o6,"STRONG",{});var n6=r(hp);Lv=n(n6,"Cause"),n6.forEach(t),o6.forEach(t),Iv=u(au),_r=l(au,"TD",{class:!0});var c6=r(_r);Ov=n(c6,"Excessive learning rate"),c6.forEach(t),Pv=u(au),kr=l(au,"TD",{class:!0});var u6=r(kr);zv=n(u6,"Insufficient regularization"),u6.forEach(t),au.forEach(t),Nv=u(fa),Ce=l(fa,"TR",{class:!0});var lu=r(Ce);Er=l(lu,"TD",{class:!0});var p6=r(Er);gp=l(p6,"STRONG",{});var d6=r(gp);Cv=n(d6,"Loss Behavior"),d6.forEach(t),p6.forEach(t),Gv=u(lu),br=l(lu,"TD",{class:!0});var f6=r(br);Hv=n(f6,"Sudden spikes/NaN values"),f6.forEach(t),qv=u(lu),xr=l(lu,"TD",{class:!0});var h6=r(xr);Uv=n(h6,"Steady decrease then rise"),h6.forEach(t),lu.forEach(t),Mv=u(fa),Ge=l(fa,"TR",{class:!0});var ru=r(Ge);yr=l(ru,"TD",{class:!0});var g6=r(yr);mp=l(g6,"STRONG",{});var m6=r(mp);Bv=n(m6,"Output Quality"),m6.forEach(t),g6.forEach(t),Wv=u(ru),wr=l(ru,"TD",{class:!0});var v6=r(wr);jv=n(v6,"Random noise/artifacts"),v6.forEach(t),Fv=u(ru),Tr=l(ru,"TD",{class:!0});var _6=r(Tr);Yv=n(_6,"Overly detailed replicas"),_6.forEach(t),ru.forEach(t),Vv=u(fa),He=l(fa,"TR",{class:!0});var iu=r(He);Rr=l(iu,"TD",{class:!0});var k6=r(Rr);vp=l(k6,"STRONG",{});var E6=r(vp);Kv=n(E6,"Recovery"),E6.forEach(t),k6.forEach(t),Xv=u(iu),Sr=l(iu,"TD",{class:!0});var b6=r(Sr);Zv=n(b6,"Requires restart"),b6.forEach(t),Qv=u(iu),Dr=l(iu,"TD",{class:!0});var x6=r(Dr);Jv=n(x6,"Early stopping works"),x6.forEach(t),iu.forEach(t),fa.forEach(t),xg.forEach(t),df=u(s),Yt=l(s,"H3",{id:!0});var V0=r(Yt);Vt=l(V0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var y6=r(Vt);_p=l(y6,"SPAN",{class:!0}),r(_p).forEach(t),y6.forEach(t),$v=n(V0,"Preventing Divergence"),V0.forEach(t),ff=u(s),At=l(s,"TABLE",{class:!0});var yg=r(At);Ar=l(yg,"THEAD",{class:!0});var w6=r(Ar);Kt=l(w6,"TR",{class:!0});var wg=r(Kt);Lr=l(wg,"TH",{class:!0});var T6=r(Lr);e2=n(T6,"Situation"),T6.forEach(t),t2=u(wg),Ir=l(wg,"TH",{class:!0});var R6=r(Ir);s2=n(R6,"Outcome"),R6.forEach(t),wg.forEach(t),w6.forEach(t),a2=u(yg),de=l(yg,"TBODY",{class:!0});var ha=r(de);Xt=l(ha,"TR",{class:!0});var Tg=r(Xt);Or=l(Tg,"TD",{class:!0});var S6=r(Or);kp=l(S6,"STRONG",{});var D6=r(kp);l2=n(D6,"Excessive or inconsistent data"),D6.forEach(t),S6.forEach(t),r2=u(Tg),Pr=l(Tg,"TD",{class:!0});var A6=r(Pr);i2=n(A6,"Model struggles to learn and produces unreliable predictions."),A6.forEach(t),Tg.forEach(t),o2=u(ha),Zt=l(ha,"TR",{class:!0});var Rg=r(Zt);zr=l(Rg,"TD",{class:!0});var L6=r(zr);Ep=l(L6,"STRONG",{});var I6=r(Ep);n2=n(I6,"Lack of unique and consistent features"),I6.forEach(t),L6.forEach(t),c2=u(Rg),Nr=l(Rg,"TD",{class:!0});var O6=r(Nr);u2=n(O6,"Poor generalization, leading to inaccurate or meaningless outputs."),O6.forEach(t),Rg.forEach(t),p2=u(ha),Qt=l(ha,"TR",{class:!0});var Sg=r(Qt);Cr=l(Sg,"TD",{class:!0});var P6=r(Cr);bp=l(P6,"STRONG",{});var z6=r(bp);d2=n(z6,"Carefully curated datasets"),z6.forEach(t),P6.forEach(t),f2=u(Sg),Gr=l(Sg,"TD",{class:!0});var N6=r(Gr);h2=n(N6,"Improved learning by ensuring the model sees only relevant, high-quality data."),N6.forEach(t),Sg.forEach(t),g2=u(ha),Jt=l(ha,"TR",{class:!0});var Dg=r(Jt);Hr=l(Dg,"TD",{class:!0});var C6=r(Hr);xp=l(C6,"STRONG",{});var G6=r(xp);m2=n(G6,"Effective use of regularization techniques"),G6.forEach(t),C6.forEach(t),v2=u(Dg),qr=l(Dg,"TD",{class:!0});var H6=r(qr);_2=n(H6,"Helps maintain focus on essential features and prevents instability."),H6.forEach(t),Dg.forEach(t),ha.forEach(t),yg.forEach(t),hf=u(s),Ur=l(s,"P",{});var q6=r(Ur);k2=n(q6,"By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence."),q6.forEach(t),gf=u(s),$t=l(s,"H3",{id:!0});var K0=r($t);es=l(K0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var U6=r(es);yp=l(U6,"SPAN",{class:!0}),r(yp).forEach(t),U6.forEach(t),E2=n(K0,"Implementing these Strategies"),K0.forEach(t),mf=u(s),Ha=l(s,"PRE",{class:!0});var yD=r(Ha);yD.forEach(t),vf=u(s),qa=l(s,"PRE",{class:!0});var wD=r(qa);wD.forEach(t),_f=u(s),ts=l(s,"H3",{id:!0});var X0=r(ts);ss=l(X0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var M6=r(ss);wp=l(M6,"SPAN",{class:!0}),r(wp).forEach(t),M6.forEach(t),b2=n(X0,"Data Considerations"),X0.forEach(t),kf=u(s),Lt=l(s,"TABLE",{class:!0});var Ag=r(Lt);Mr=l(Ag,"THEAD",{class:!0});var B6=r(Mr);qe=l(B6,"TR",{class:!0});var ou=r(qe);Br=l(ou,"TH",{class:!0});var W6=r(Br);x2=n(W6,"Situation"),W6.forEach(t),y2=u(ou),Wr=l(ou,"TH",{class:!0});var j6=r(Wr);w2=n(j6,"Actual Risk"),j6.forEach(t),T2=u(ou),jr=l(ou,"TH",{class:!0});var F6=r(jr);R2=n(F6,"Solution"),F6.forEach(t),ou.forEach(t),B6.forEach(t),S2=u(Ag),fe=l(Ag,"TBODY",{class:!0});var ga=r(fe);Ue=l(ga,"TR",{class:!0});var nu=r(Ue);Fr=l(nu,"TD",{class:!0});var Y6=r(Fr);D2=n(Y6,"High LR + small batch size"),Y6.forEach(t),A2=u(nu),Yr=l(nu,"TD",{class:!0});var V6=r(Yr);L2=n(V6,"Divergence"),V6.forEach(t),I2=u(nu),Vr=l(nu,"TD",{class:!0});var K6=r(Vr);O2=n(K6,"Lower LR, increase batch size"),K6.forEach(t),nu.forEach(t),P2=u(ga),Me=l(ga,"TR",{class:!0});var cu=r(Me);Kr=l(cu,"TD",{class:!0});var X6=r(Kr);z2=n(X6,"Inconsistent features"),X6.forEach(t),N2=u(cu),Xr=l(cu,"TD",{class:!0});var Z6=r(Xr);C2=n(Z6,"Overfitting"),Z6.forEach(t),G2=u(cu),Zr=l(cu,"TD",{class:!0});var Q6=r(Zr);H2=n(Q6,"Improve dataset consistency"),Q6.forEach(t),cu.forEach(t),q2=u(ga),Be=l(ga,"TR",{class:!0});var uu=r(Be);Qr=l(uu,"TD",{class:!0});var J6=r(Qr);U2=n(J6,"Insufficient reg images"),J6.forEach(t),M2=u(uu),Jr=l(uu,"TD",{class:!0});var $6=r(Jr);B2=n($6,"Class leakage"),$6.forEach(t),W2=u(uu),$r=l(uu,"TD",{class:!0});var e7=r($r);j2=n(e7,"Add 100-300 class images"),e7.forEach(t),uu.forEach(t),F2=u(ga),We=l(ga,"TR",{class:!0});var pu=r(We);ei=l(pu,"TD",{class:!0});var t7=r(ei);Y2=n(t7,"High variance in training data"),t7.forEach(t),V2=u(pu),ti=l(pu,"TD",{class:!0});var s7=r(ti);K2=n(s7,"Mode collapse"),s7.forEach(t),X2=u(pu),si=l(pu,"TD",{class:!0});var a7=r(si);Z2=n(a7,"Curate focused dataset"),a7.forEach(t),pu.forEach(t),ga.forEach(t),Ag.forEach(t),Ef=u(s),bf=l(s,"HR",{}),xf=u(s),as=l(s,"H2",{id:!0});var Z0=r(as);ls=l(Z0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var l7=r(ls);Tp=l(l7,"SPAN",{class:!0}),r(Tp).forEach(t),l7.forEach(t),Q2=n(Z0,"Monitoring Tips"),Z0.forEach(t),yf=u(s),rs=l(s,"P",{});var Lg=r(rs);J2=n(Lg,"Before we start training the model, let\u2019s go over how we can monitor the process and preview the results as it trains.  For Stable Diffusion model training, I enjoy using "),Ua=l(Lg,"A",{href:!0,rel:!0});var r7=r(Ua);$2=n(r7,"kohya-ss/sd-scripts"),r7.forEach(t),e_=n(Lg,".  These scripts can setup monitoring through TensorBoard as well which we will dive in later."),Lg.forEach(t),wf=u(s),is=l(s,"H3",{id:!0});var Q0=r(is);os=l(Q0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var i7=r(os);Rp=l(i7,"SPAN",{class:!0}),r(Rp).forEach(t),i7.forEach(t),t_=n(Q0,"Track loss curves"),Q0.forEach(t),Tf=u(s),ns=l(s,"P",{});var Ig=r(ns);s_=n(Ig,"Loss curves provide real-time feedback on how well the model is learning. They help identify issues like overfitting, divergence, or stalled training.  Use "),Ma=l(Ig,"A",{href:!0,rel:!0});var o7=r(Ma);a_=n(o7,"TensorBoard"),o7.forEach(t),l_=n(Ig," to create these graphs."),Ig.forEach(t),Rf=u(s),Ba=l(s,"PRE",{class:!0});var TD=r(Ba);TD.forEach(t),Sf=u(s),cs=l(s,"H4",{id:!0});var J0=r(cs);us=l(J0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var n7=r(us);Sp=l(n7,"SPAN",{class:!0}),r(Sp).forEach(t),n7.forEach(t),r_=n(J0,"What to Monitor:"),J0.forEach(t),Df=u(s),je=l(s,"UL",{});var du=r(je);Dp=l(du,"LI",{});var c7=r(Dp);i_=n(c7,"Training Loss: Should decrease steadily but not too quickly."),c7.forEach(t),o_=u(du),Ap=l(du,"LI",{});var u7=r(Ap);n_=n(u7,"Validation Loss: Should follow a similar trend to training loss. A growing gap between the two indicates overfitting."),u7.forEach(t),c_=u(du),Lp=l(du,"LI",{});var p7=r(Lp);u_=n(p7,"Gradient Norm: Should remain between 0.1 and 10.0. Values outside this range suggest instability."),p7.forEach(t),du.forEach(t),Af=u(s),ps=l(s,"H4",{id:!0});var $0=r(ps);ds=l($0,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var d7=r(ds);Ip=l(d7,"SPAN",{class:!0}),r(Ip).forEach(t),d7.forEach(t),p_=n($0,"Warning Signs:"),$0.forEach(t),Lf=u(s),Fe=l(s,"UL",{});var fu=r(Fe);Op=l(fu,"LI",{});var f7=r(Op);d_=n(f7,"Sudden spikes in loss \u2192 Likely divergence."),f7.forEach(t),f_=u(fu),Pp=l(fu,"LI",{});var h7=r(Pp);h_=n(h7,"Loss plateauing too early \u2192 Learning rate may be too low."),h7.forEach(t),g_=u(fu),zp=l(fu,"LI",{});var g7=r(zp);m_=n(g7,"Validation loss increasing while training loss decreases \u2192 Overfitting."),g7.forEach(t),fu.forEach(t),If=u(s),fs=l(s,"H3",{id:!0});var ew=r(fs);hs=l(ew,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var m7=r(hs);Np=l(m7,"SPAN",{class:!0}),r(Np).forEach(t),m7.forEach(t),v_=n(ew,"Generate validation images every 100 steps"),ew.forEach(t),Of=u(s),Wa=l(s,"P",{});var tw=r(Wa);Cp=l(tw,"STRONG",{});var v7=r(Cp);__=n(v7,"Why It Matters"),v7.forEach(t),k_=n(tw," : Validation images provide a visual check of the model\u2019s progress and help catch issues like mode collapse or artifacts early."),tw.forEach(t),Pf=u(s),ja=l(s,"PRE",{class:!0});var RD=r(ja);RD.forEach(t),zf=u(s),gs=l(s,"H4",{id:!0});var sw=r(gs);ms=l(sw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _7=r(ms);Gp=l(_7,"SPAN",{class:!0}),r(Gp).forEach(t),_7.forEach(t),E_=n(sw,"What to Look For:"),sw.forEach(t),Nf=u(s),Ye=l(s,"UL",{});var hu=r(Ye);Hp=l(hu,"LI",{});var k7=r(Hp);b_=n(k7,"Consistency: Outputs should align with the training data style."),k7.forEach(t),x_=u(hu),qp=l(hu,"LI",{});var E7=r(qp);y_=n(E7,"Artifacts: Check for distortions, noise, or unnatural features."),E7.forEach(t),w_=u(hu),Up=l(hu,"LI",{});var b7=r(Up);T_=n(b7,"Diversity: Ensure the model isn\u2019t collapsing to a single output mode."),b7.forEach(t),hu.forEach(t),Cf=u(s),Fa=l(s,"BLOCKQUOTE",{class:!0});var x7=r(Fa);ai=l(x7,"P",{class:!0});var y7=r(ai);R_=n(y7,"\u{1F4C4} Use a fixed set of validation prompts and seeds to compare outputs across training runs."),y7.forEach(t),x7.forEach(t),Gf=u(s),vs=l(s,"H4",{id:!0});var aw=r(vs);_s=l(aw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var w7=r(_s);Mp=l(w7,"SPAN",{class:!0}),r(Mp).forEach(t),w7.forEach(t),S_=n(aw,"Use Gradient Clipping"),aw.forEach(t),Hf=u(s),Ya=l(s,"P",{});var lw=r(Ya);Bp=l(lw,"STRONG",{});var T7=r(Bp);D_=n(T7,"Why It Matters"),T7.forEach(t),A_=n(lw,": Gradient clipping prevents exploding gradients, which can cause training instability and divergence.  1.0-2.0 Norm."),lw.forEach(t),qf=u(s),li=l(s,"P",{});var R7=r(li);L_=n(R7,"Key Insights:"),R7.forEach(t),Uf=u(s),Ve=l(s,"UL",{});var gu=r(Ve);Va=l(gu,"LI",{});var Og=r(Va);I_=n(Og,"Gradient Norm "),ri=l(Og,"CODE",{class:!0});var S7=r(ri);O_=n(S7,"<"),S7.forEach(t),P_=n(Og," than 0.1: Training may stall due to tiny updates."),Og.forEach(t),z_=u(gu),Wp=l(gu,"LI",{});var D7=r(Wp);N_=n(D7,"Gradient Norm > 10.0: Risk of divergence; reduce learning rate or clip gradients."),D7.forEach(t),C_=u(gu),jp=l(gu,"LI",{});var A7=r(jp);G_=n(A7,"Ideal Range: 0.1 to 2.0 for stable training."),A7.forEach(t),gu.forEach(t),Mf=u(s),Ka=l(s,"BLOCKQUOTE",{class:!0});var L7=r(Ka);ii=l(L7,"P",{class:!0});var I7=r(ii);H_=n(I7,"\u{1F4C4} Monitor gradient norms in TensorBoard to fine-tune clipping thresholds."),I7.forEach(t),L7.forEach(t),Bf=u(s),ks=l(s,"H4",{id:!0});var rw=r(ks);Es=l(rw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var O7=r(Es);Fp=l(O7,"SPAN",{class:!0}),r(Fp).forEach(t),O7.forEach(t),q_=n(rw,"Enable Mixed Precision Training"),rw.forEach(t),Wf=u(s),Xa=l(s,"P",{});var iw=r(Xa);Yp=l(iw,"STRONG",{});var P7=r(Yp);U_=n(P7,"Why It Matters"),P7.forEach(t),M_=n(iw,": Mixed precision training speeds up training and reduces VRAM usage without sacrificing model accuracy."),iw.forEach(t),jf=u(s),Za=l(s,"PRE",{class:!0});var SD=r(Za);SD.forEach(t),Ff=u(s),oi=l(s,"P",{});var z7=r(oi);B_=n(z7,"Benefits:"),z7.forEach(t),Yf=u(s),Ke=l(s,"UL",{});var mu=r(Ke);Vp=l(mu,"LI",{});var N7=r(Vp);W_=n(N7,"2-3x Faster Training: Leverages GPU tensor cores."),N7.forEach(t),j_=u(mu),Kp=l(mu,"LI",{});var C7=r(Kp);F_=n(C7,"50% Less VRAM Usage: Allows larger batch sizes or models."),C7.forEach(t),Y_=u(mu),Xp=l(mu,"LI",{});var G7=r(Xp);V_=n(G7,"Minimal Accuracy Impact: Maintains FP32 precision for critical operations."),G7.forEach(t),mu.forEach(t),Vf=u(s),Qa=l(s,"BLOCKQUOTE",{class:!0});var H7=r(Qa);ni=l(H7,"P",{class:!0});var q7=r(ni);K_=n(q7,"\u{1F4C4} Use torch.cuda.amp for automatic mixed precision (AMP) support."),q7.forEach(t),H7.forEach(t),Kf=u(s),bs=l(s,"H4",{id:!0});var ow=r(bs);xs=l(ow,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var U7=r(xs);Zp=l(U7,"SPAN",{class:!0}),r(Zp).forEach(t),U7.forEach(t),X_=n(ow,"Start with Conservative Learning Rates"),ow.forEach(t),Xf=u(s),ys=l(s,"P",{});var Pg=r(ys);Z_=n(Pg,"Start off with 1e-5 to 1e-6.  "),Qp=l(Pg,"STRONG",{});var M7=r(Qp);Q_=n(M7,"Why It Matters"),M7.forEach(t),J_=n(Pg,": A conservative learning rate prevents divergence and ensures stable training, especially during early epochs."),Pg.forEach(t),Zf=u(s),Ja=l(s,"PRE",{class:!0});var DD=r(Ja);DD.forEach(t),Qf=u(s),$a=l(s,"PRE",{class:!0});var AD=r($a);AD.forEach(t),Jf=u(s),el=l(s,"P",{});var nw=r(el);Jp=l(nw,"STRONG",{});var B7=r(Jp);$_=n(B7,"Warning Signs"),B7.forEach(t),e1=n(nw,":"),nw.forEach(t),$f=u(s),Xe=l(s,"UL",{});var vu=r(Xe);$p=l(vu,"LI",{});var W7=r($p);t1=n(W7,"Loss Spikes: Learning rate is too high."),W7.forEach(t),s1=u(vu),ed=l(vu,"LI",{});var j7=r(ed);a1=n(j7,"Slow Convergence: Learning rate is too low."),j7.forEach(t),l1=u(vu),td=l(vu,"LI",{});var F7=r(td);r1=n(F7,"Oscillating Loss: Poor scheduling or unstable gradients."),F7.forEach(t),vu.forEach(t),eh=u(s),It=l(s,"TABLE",{class:!0});var zg=r(It);ci=l(zg,"THEAD",{class:!0});var Y7=r(ci);he=l(Y7,"TR",{class:!0});var ma=r(he);ui=l(ma,"TH",{class:!0});var V7=r(ui);i1=n(V7,"Practice"),V7.forEach(t),o1=u(ma),pi=l(ma,"TH",{class:!0});var K7=r(pi);n1=n(K7,"Key Benefit"),K7.forEach(t),c1=u(ma),di=l(ma,"TH",{class:!0});var X7=r(di);u1=n(X7,"Tool/Setting"),X7.forEach(t),p1=u(ma),fi=l(ma,"TH",{class:!0});var Z7=r(fi);d1=n(Z7,"Warning Signs"),Z7.forEach(t),ma.forEach(t),Y7.forEach(t),f1=u(zg),le=l(zg,"TBODY",{class:!0});var xt=r(le);ge=l(xt,"TR",{class:!0});var va=r(ge);hi=l(va,"TD",{class:!0});var Q7=r(hi);h1=n(Q7,"Track Loss Curves"),Q7.forEach(t),g1=u(va),gi=l(va,"TD",{class:!0});var J7=r(gi);m1=n(J7,"Detect overfitting/divergence early"),J7.forEach(t),v1=u(va),mi=l(va,"TD",{class:!0});var $7=r(mi);_1=n($7,"TensorBoard, Weights & Biases"),$7.forEach(t),k1=u(va),vi=l(va,"TD",{class:!0});var eT=r(vi);E1=n(eT,"Spikes, plateaus, growing gaps"),eT.forEach(t),va.forEach(t),b1=u(xt),me=l(xt,"TR",{class:!0});var _a=r(me);_i=l(_a,"TD",{class:!0});var tT=r(_i);x1=n(tT,"Generate Validation Images"),tT.forEach(t),y1=u(_a),ki=l(_a,"TD",{class:!0});var sT=r(ki);w1=n(sT,"Visualize model progress"),sT.forEach(t),T1=u(_a),Ei=l(_a,"TD",{class:!0});var aT=r(Ei);R1=n(aT,"Fixed prompts/seeds"),aT.forEach(t),S1=u(_a),bi=l(_a,"TD",{class:!0});var lT=r(bi);D1=n(lT,"Artifacts, mode collapse"),lT.forEach(t),_a.forEach(t),A1=u(xt),ve=l(xt,"TR",{class:!0});var ka=r(ve);xi=l(ka,"TD",{class:!0});var rT=r(xi);L1=n(rT,"Gradient Clipping"),rT.forEach(t),I1=u(ka),yi=l(ka,"TD",{class:!0});var iT=r(yi);O1=n(iT,"Prevent exploding gradients"),iT.forEach(t),P1=u(ka),ws=l(ka,"TD",{class:!0});var Ng=r(ws);z1=n(Ng,"clip"),sd=l(Ng,"EM",{});var oT=r(sd);N1=n(oT,"grad_norm"),oT.forEach(t),C1=n(Ng," (1.0-2.0)"),Ng.forEach(t),G1=u(ka),Ze=l(ka,"TD",{class:!0});var _u=r(Ze);H1=n(_u,"Norm "),wi=l(_u,"CODE",{class:!0});var nT=r(wi);q1=n(nT,">"),nT.forEach(t),U1=n(_u," 10.0 or "),Ti=l(_u,"CODE",{class:!0});var cT=r(Ti);M1=n(cT,"<"),cT.forEach(t),B1=n(_u," 0.1"),_u.forEach(t),ka.forEach(t),W1=u(xt),_e=l(xt,"TR",{class:!0});var Ea=r(_e);Ri=l(Ea,"TD",{class:!0});var uT=r(Ri);j1=n(uT,"Mixed Precision Training"),uT.forEach(t),F1=u(Ea),Si=l(Ea,"TD",{class:!0});var pT=r(Si);Y1=n(pT,"Faster training, lower VRAM usage"),pT.forEach(t),V1=u(Ea),Di=l(Ea,"TD",{class:!0});var dT=r(Di);K1=n(dT,"PyTorch AMP (torch.cuda.amp)"),dT.forEach(t),X1=u(Ea),Ai=l(Ea,"TD",{class:!0});var fT=r(Ai);Z1=n(fT,"NaN values (disable if unstable)"),fT.forEach(t),Ea.forEach(t),Q1=u(xt),ke=l(xt,"TR",{class:!0});var ba=r(ke);Li=l(ba,"TD",{class:!0});var hT=r(Li);J1=n(hT,"Conservative Learning Rates"),hT.forEach(t),$1=u(ba),Ii=l(ba,"TD",{class:!0});var gT=r(Ii);ek=n(gT,"Stable training, avoid divergence"),gT.forEach(t),tk=u(ba),Oi=l(ba,"TD",{class:!0});var mT=r(Oi);sk=n(mT,"Start at 1e-5 to 1e-6, use scheduler"),mT.forEach(t),ak=u(ba),Pi=l(ba,"TD",{class:!0});var vT=r(Pi);lk=n(vT,"Spikes, slow convergence"),vT.forEach(t),ba.forEach(t),xt.forEach(t),zg.forEach(t),th=u(s),sh=l(s,"HR",{}),ah=u(s),Ts=l(s,"H2",{id:!0});var cw=r(Ts);Rs=l(cw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _T=r(Rs);ad=l(_T,"SPAN",{class:!0}),r(ad).forEach(t),_T.forEach(t),rk=n(cw,"Generating Regularization images"),cw.forEach(t),lh=u(s),Ss=l(s,"P",{});var Cg=r(Ss);ik=n(Cg,"Regularization images are generated using the model you\u2019re going to train with before training.  These generated images are based on the class name (e.g., "),zi=l(Cg,"CODE",{class:!0});var kT=r(zi);ok=n(kT,"1boy"),kT.forEach(t),nk=n(Cg,")."),Cg.forEach(t),rh=u(s),ue=l(s,"P",{});var Gt=r(ue);ck=n(Gt,"According to the Dreambooth technique, "),Ni=l(Gt,"CODE",{class:!0});var ET=r(Ni);uk=n(ET,"200"),ET.forEach(t),pk=n(Gt," regularization images per training image.  For example, if you have "),Ci=l(Gt,"CODE",{class:!0});var bT=r(Ci);dk=n(bT,"16"),bT.forEach(t),fk=n(Gt," images: "),Gi=l(Gt,"CODE",{class:!0});var xT=r(Gi);hk=n(xT,"200 * 16 = 3200"),xT.forEach(t),gk=n(Gt," total regularization images.  When training, the math involved for calculating total steps is: "),Hi=l(Gt,"CODE",{class:!0});var yT=r(Hi);mk=n(yT,"repeats * training images >= repeats * regularization images"),yT.forEach(t),Gt.forEach(t),ih=u(s),qi=l(s,"P",{});var wT=r(qi);vk=n(wT,"The quality of regularization images impacts the model\u2019s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model\u2019s ability to learn distinctive features."),wT.forEach(t),oh=u(s),Ds=l(s,"H4",{id:!0});var uw=r(Ds);As=l(uw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var TT=r(As);ld=l(TT,"SPAN",{class:!0}),r(ld).forEach(t),TT.forEach(t),_k=n(uw,"Important considerations"),uw.forEach(t),nh=u(s),Qe=l(s,"OL",{});var ku=r(Qe);rd=l(ku,"LI",{});var RT=r(rd);tl=l(RT,"P",{});var Gg=r(tl);id=l(Gg,"STRONG",{});var ST=r(id);kk=n(ST,"Use the same base model for regularization images and training"),ST.forEach(t),Ek=l(Gg,"BR",{}),bk=n(Gg,`
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.`),Gg.forEach(t),RT.forEach(t),xk=u(ku),od=l(ku,"LI",{});var DT=r(od);sl=l(DT,"P",{});var Hg=r(sl);nd=l(Hg,"STRONG",{});var AT=r(nd);yk=n(AT,"Maintain consistent class representation"),AT.forEach(t),wk=l(Hg,"BR",{}),Tk=n(Hg,`
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.`),Hg.forEach(t),DT.forEach(t),Rk=u(ku),cd=l(ku,"LI",{});var LT=r(cd);al=l(LT,"P",{});var qg=r(al);ud=l(qg,"STRONG",{});var IT=r(ud);Sk=n(IT,"Match output resolution to training data"),IT.forEach(t),Dk=l(qg,"BR",{}),Ak=n(qg,`
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.`),qg.forEach(t),LT.forEach(t),ku.forEach(t),ch=u(s),Sa(ll.$$.fragment,s),uh=u(s),Ls=l(s,"H4",{id:!0});var pw=r(Ls);Is=l(pw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var OT=r(Is);pd=l(OT,"SPAN",{class:!0}),r(pd).forEach(t),OT.forEach(t),Lk=n(pw,"Generate using Stable Diffusion web UI"),pw.forEach(t),ph=u(s),Os=l(s,"P",{});var Ug=r(Os);Ik=n(Ug,"We\u2019re going to use "),rl=l(Ug,"A",{href:!0,rel:!0});var PT=r(rl);Ok=n(PT,"Stable Diffusion web UI"),PT.forEach(t),Pk=n(Ug," to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),Ug.forEach(t),dh=u(s),Je=l(s,"P",{});var Eu=r(Je);zk=n(Eu,"We\u2019re going to use the "),Ui=l(Eu,"CODE",{class:!0});var zT=r(Ui);Nk=n(zT,"X/Y/Z plot"),zT.forEach(t),Ck=n(Eu," script to use "),Mi=l(Eu,"CODE",{class:!0});var NT=r(Mi);Gk=n(NT,"Prompt Search & Replace"),NT.forEach(t),Hk=n(Eu," to dynamically build a prompt that will generate hundreds of regularization images."),Eu.forEach(t),fh=u(s),J=l(s,"OL",{});var ne=r(J);dd=l(ne,"LI",{});var CT=r(dd);Bi=l(CT,"P",{});var dw=r(Bi);qk=n(dw,"Select the text 2 image tab.  Enter a generic prompt "),Wi=l(dw,"CODE",{class:!0});var GT=r(Wi);Uk=n(GT,"princeadam, portrait, looking_at_viewer, forest"),GT.forEach(t),dw.forEach(t),CT.forEach(t),Mk=u(ne),fd=l(ne,"LI",{});var HT=r(fd);il=l(HT,"P",{});var Mg=r(il);Bk=n(Mg,"In generation parameters and select the "),ji=l(Mg,"CODE",{class:!0});var qT=r(ji);Wk=n(qT,"X/Y/Z plot"),qT.forEach(t),jk=n(Mg," script."),Mg.forEach(t),HT.forEach(t),Fk=u(ne),hd=l(ne,"LI",{});var UT=r(hd);K=l(UT,"P",{});var te=r(K);Yk=n(te,"Select the "),Fi=l(te,"CODE",{class:!0});var MT=r(Fi);Vk=n(MT,"X"),MT.forEach(t),Kk=n(te," parameter and "),Yi=l(te,"CODE",{class:!0});var BT=r(Yi);Xk=n(BT,"Prompt SR"),BT.forEach(t),Zk=n(te," for Prompt Replace.  We\u2019re going to replace "),Vi=l(te,"CODE",{class:!0});var WT=r(Vi);Qk=n(WT,"portrait"),WT.forEach(t),Jk=n(te," with different camera angle tags: "),Ki=l(te,"CODE",{class:!0});var jT=r(Ki);$k=n(jT,"close-up"),jT.forEach(t),eE=n(te,", "),Xi=l(te,"CODE",{class:!0});var FT=r(Xi);tE=n(FT,"upper_body"),FT.forEach(t),sE=n(te,", "),Zi=l(te,"CODE",{class:!0});var YT=r(Zi);aE=n(YT,"from_below"),YT.forEach(t),lE=n(te,", "),Qi=l(te,"CODE",{class:!0});var VT=r(Qi);rE=n(VT,"from_above"),VT.forEach(t),iE=n(te,", "),Ji=l(te,"CODE",{class:!0});var KT=r(Ji);oE=n(KT,"dutch_angle"),KT.forEach(t),te.forEach(t),UT.forEach(t),nE=u(ne),gd=l(ne,"LI",{});var XT=r(gd);$=l(XT,"P",{});var ae=r($);cE=n(ae,"Select the "),$i=l(ae,"CODE",{class:!0});var ZT=r($i);uE=n(ZT,"Y"),ZT.forEach(t),pE=n(ae," parameter and "),eo=l(ae,"CODE",{class:!0});var QT=r(eo);dE=n(QT,"Prompt SR"),QT.forEach(t),fE=n(ae," for Prompt Replace.  Replace "),to=l(ae,"CODE",{class:!0});var JT=r(to);hE=n(JT,"looking_at_viewer"),JT.forEach(t),gE=n(ae,": "),so=l(ae,"CODE",{class:!0});var $T=r(so);mE=n($T,"looking_away"),$T.forEach(t),vE=n(ae,", "),ao=l(ae,"CODE",{class:!0});var e8=r(ao);_E=n(e8,"looking_to_the_side"),e8.forEach(t),kE=n(ae,", "),lo=l(ae,"CODE",{class:!0});var t8=r(lo);EE=n(t8,"looking_ahead"),t8.forEach(t),bE=n(ae,", "),ro=l(ae,"CODE",{class:!0});var s8=r(ro);xE=n(s8,"looking_down"),s8.forEach(t),ae.forEach(t),XT.forEach(t),yE=u(ne),md=l(ne,"LI",{});var a8=r(md);X=l(a8,"P",{});var se=r(X);wE=n(se,"Select the "),io=l(se,"CODE",{class:!0});var l8=r(io);TE=n(l8,"Z"),l8.forEach(t),RE=n(se," parameter and "),oo=l(se,"CODE",{class:!0});var r8=r(oo);SE=n(r8,"Prompt SR"),r8.forEach(t),DE=n(se," for Prompt Replace. Replace "),no=l(se,"CODE",{class:!0});var i8=r(no);AE=n(i8,"forest"),i8.forEach(t),LE=n(se," with a vareity of locatinos: "),co=l(se,"CODE",{class:!0});var o8=r(co);IE=n(o8,"castle"),o8.forEach(t),OE=n(se,", "),uo=l(se,"CODE",{class:!0});var n8=r(uo);PE=n(n8,"mountain"),n8.forEach(t),zE=n(se,", "),po=l(se,"CODE",{class:!0});var c8=r(po);NE=n(c8,"cave"),c8.forEach(t),CE=n(se,", "),fo=l(se,"CODE",{class:!0});var u8=r(fo);GE=n(u8,"farm"),u8.forEach(t),HE=n(se,", "),ho=l(se,"CODE",{class:!0});var p8=r(ho);qE=n(p8,"ocean"),p8.forEach(t),se.forEach(t),a8.forEach(t),UE=u(ne),vd=l(ne,"LI",{});var d8=r(vd);go=l(d8,"P",{});var fw=r(go);ME=n(fw,"Select a fast sampler like "),mo=l(fw,"CODE",{class:!0});var f8=r(mo);BE=n(f8,"DPM2 KARRAS"),f8.forEach(t),fw.forEach(t),d8.forEach(t),WE=u(ne),_d=l(ne,"LI",{});var h8=r(_d);Ps=l(h8,"P",{});var jd=r(Ps);jE=n(jd,"CFG Scale set to "),vo=l(jd,"CODE",{class:!0});var g8=r(vo);FE=n(g8,"7"),g8.forEach(t),YE=n(jd," and Steps to "),_o=l(jd,"CODE",{class:!0});var m8=r(_o);VE=n(m8,"20"),m8.forEach(t),jd.forEach(t),h8.forEach(t),ne.forEach(t),hh=u(s),$e=l(s,"P",{});var bu=r($e);KE=n(bu,"After the inference finishes, gather the images that were generated and we\u2019ll start captioning.  We may only need "),ko=l(bu,"CODE",{class:!0});var v8=r(ko);XE=n(v8,"150"),v8.forEach(t),ZE=n(bu," - "),Eo=l(bu,"CODE",{class:!0});var _8=r(Eo);QE=n(_8,"200"),_8.forEach(t),JE=n(bu," and keep in mind we can add and remove as we try different training settings with different output."),bu.forEach(t),gh=u(s),Sa(ol.$$.fragment,s),mh=u(s),zs=l(s,"H4",{id:!0});var hw=r(zs);Ns=l(hw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var k8=r(Ns);kd=l(k8,"SPAN",{class:!0}),r(kd).forEach(t),k8.forEach(t),$E=n(hw,"Download images"),hw.forEach(t),vh=u(s),bo=l(s,"P",{});var E8=r(bo);eb=n(E8,"If generating these images isn\u2019t an option, there are many repositories on HuggingFace that host regularization images generated with common models:"),E8.forEach(t),_h=u(s),Ee=l(s,"UL",{});var xa=r(Ee);xo=l(xa,"LI",{});var gw=r(xo);nl=l(gw,"A",{href:!0,rel:!0});var b8=r(nl);tb=n(b8,"3ee Games regularization images"),b8.forEach(t),sb=n(gw,": Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5."),gw.forEach(t),ab=u(xa),yo=l(xa,"LI",{});var mw=r(yo);cl=l(mw,"A",{href:!0,rel:!0});var x8=r(cl);lb=n(x8,"Pre-Rendered Regularization Images"),x8.forEach(t),rb=n(mw,": Includes 1500 regularization images."),mw.forEach(t),ib=u(xa),wo=l(xa,"LI",{});var vw=r(wo);ul=l(vw,"A",{href:!0,rel:!0});var y8=r(ul);ob=n(y8,"Stable Diffusion 1.5 Regularization Images"),y8.forEach(t),nb=n(vw,": includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5."),vw.forEach(t),cb=u(xa),To=l(xa,"LI",{});var _w=r(To);pl=l(_w,"A",{href:!0,rel:!0});var w8=r(pl);ub=n(w8,"Aitrepreneur SDXL image set"),w8.forEach(t),pb=n(_w,": a large image set generated with Stable Diffusion SDXL."),_w.forEach(t),xa.forEach(t),kh=u(s),Cs=l(s,"H4",{id:!0});var kw=r(Cs);Gs=l(kw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var T8=r(Gs);Ed=l(T8,"SPAN",{class:!0}),r(Ed).forEach(t),T8.forEach(t),db=n(kw,"Captioning Regularization images"),kw.forEach(t),Eh=u(s),Hs=l(s,"P",{});var Bg=r(Hs);fb=n(Bg,"While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create "),Ro=l(Bg,"CODE",{class:!0});var R8=r(Ro);hb=n(R8,"txt"),R8.forEach(t),gb=n(Bg," files with a shell script:"),Bg.forEach(t),bh=u(s),dl=l(s,"PRE",{class:!0});var LD=r(dl);LD.forEach(t),xh=u(s),et=l(s,"P",{});var xu=r(et);mb=n(xu,"Save this file as "),So=l(xu,"CODE",{class:!0});var S8=r(So);vb=n(S8,"filename2txt.bat"),S8.forEach(t),_b=n(xu," and place it into the regularization images directory and run: "),Do=l(xu,"CODE",{class:!0});var D8=r(Do);kb=n(D8,".\\filename2txt.bat"),D8.forEach(t),Eb=n(xu,".  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training."),xu.forEach(t),yh=u(s),fl=l(s,"P",{});var Ew=r(fl);bb=n(Ew,"Example filename: "),Ao=l(Ew,"CODE",{class:!0});var A8=r(Ao);xb=n(A8,"18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png"),A8.forEach(t),Ew.forEach(t),wh=u(s),qs=l(s,"P",{});var Wg=r(qs);yb=n(Wg,"Output: "),Lo=l(Wg,"CODE",{class:!0});var L8=r(Lo);wb=n(L8,"aburbres,princeadam,1boy,close-up,purple_vest"),L8.forEach(t),Tb=n(Wg," saved in a text file with the same name as image."),Wg.forEach(t),Th=u(s),Us=l(s,"H2",{id:!0});var bw=r(Us);Ms=l(bw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var I8=r(Ms);bd=l(I8,"SPAN",{class:!0}),r(bd).forEach(t),I8.forEach(t),Rb=n(bw,"Training a LoRA"),bw.forEach(t),Rh=u(s),Bs=l(s,"P",{});var jg=r(Bs);Sb=n(jg,"Now we\u2019re going to setup all the training data to create a LoRA model.  We\u2019re going to go over how to setup your training data to use regularization images with "),hl=l(jg,"A",{href:!0,rel:!0});var O8=r(hl);Db=n(O8,"kohya-ss/sd-scripts"),O8.forEach(t),Ab=n(jg,"."),jg.forEach(t),Sh=u(s),gl=l(s,"BLOCKQUOTE",{class:!0});var P8=r(gl);Ws=l(P8,"P",{class:!0});var Fg=r(Ws);Lb=n(Fg,"\u{1F4C4} Learning how to train a LoRA is a completely different subject all on its own.  See "),ml=l(Fg,"A",{href:!0,rel:!0});var z8=r(ml);Ib=n(z8,"Kohya SD script documentation"),z8.forEach(t),Ob=n(Fg,"."),Fg.forEach(t),P8.forEach(t),Dh=u(s),js=l(s,"H3",{id:!0});var xw=r(js);Fs=l(xw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var N8=r(Fs);xd=l(N8,"SPAN",{class:!0}),r(xd).forEach(t),N8.forEach(t),Pb=n(xw,"Directory setup"),xw.forEach(t),Ah=u(s),Ys=l(s,"P",{});var Yg=r(Ys);zb=n(Yg,"In your configuration json, use "),Io=l(Yg,"CODE",{class:!0});var C8=r(Io);Nb=n(C8,"reg_data_dir"),C8.forEach(t),Cb=n(Yg," to point to the directory with your regularization images:"),Yg.forEach(t),Lh=u(s),vl=l(s,"PRE",{class:!0});var ID=r(vl);ID.forEach(t),Ih=u(s),Oo=l(s,"P",{});var G8=r(Oo);Gb=n(G8,"Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:"),G8.forEach(t),Oh=u(s),_l=l(s,"PRE",{class:!0});var OD=r(_l);OD.forEach(t),Ph=u(s),tt=l(s,"P",{});var yu=r(tt);Hb=n(yu,"Set the "),Po=l(yu,"CODE",{class:!0});var H8=r(Po);qb=n(H8,"number of iterations"),H8.forEach(t),Ub=n(yu," so that training images are used as often as or more often than regularization images. In one epoch, the total data is "),zo=l(yu,"CODE",{class:!0});var q8=r(zo);Mb=n(q8,"training images \xD7 iterations"),q8.forEach(t),Bb=n(yu,". If there are more regularization images than this, the extras won\u2019t be used."),yu.forEach(t),zh=u(s),st=l(s,"P",{});var wu=r(st);Wb=n(wu,"Create folders in the training image folder with the format "),No=l(wu,"CODE",{class:!0});var U8=r(No);jb=n(U8,"<repetition count>_<class>"),U8.forEach(t),Fb=n(wu," multiple times, and similarly create folders in the regularization image folder with the format "),Co=l(wu,"CODE",{class:!0});var M8=r(Co);Yb=n(M8,"<repetition count>_<class>"),M8.forEach(t),Vb=n(wu,"."),wu.forEach(t),Nh=u(s),Go=l(s,"P",{});var B8=r(Go);Kb=n(B8,"If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:"),B8.forEach(t),Ch=u(s),Vs=l(s,"UL",{});var Vg=r(Vs);Ho=l(Vg,"LI",{});var yw=r(Ho);Xb=n(yw,"train_data_dir"),yd=l(yw,"UL",{});var W8=r(yd);wd=l(W8,"LI",{});var j8=r(wd);Zb=n(j8,"10_princeadam"),j8.forEach(t),W8.forEach(t),yw.forEach(t),Qb=u(Vg),qo=l(Vg,"LI",{});var ww=r(qo);Jb=n(ww,"reg_dir"),Td=l(ww,"UL",{});var F8=r(Td);Rd=l(F8,"LI",{});var Y8=r(Rd);$b=n(Y8,"1_1boy"),Y8.forEach(t),F8.forEach(t),ww.forEach(t),Vg.forEach(t),Gh=u(s),Uo=l(s,"P",{});var V8=r(Uo);ex=n(V8,"For example, with the prompt \u201Cfrog\u201D and not repeating the data (only once), it would look like this:"),V8.forEach(t),Hh=u(s),kl=l(s,"P",{class:!0});var K8=r(kl);El=l(K8,"IMG",{src:!0,alt:!0,class:!0}),K8.forEach(t),qh=u(s),Ks=l(s,"H3",{id:!0});var Tw=r(Ks);Xs=l(Tw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var X8=r(Xs);Sd=l(X8,"SPAN",{class:!0}),r(Sd).forEach(t),X8.forEach(t),tx=n(Tw,"Training Settings"),Tw.forEach(t),Uh=u(s),Ot=l(s,"P",{});var Fd=r(Ot);sx=n(Fd,"The training setup we\u2019re going to use is:  "),Mo=l(Fd,"CODE",{class:!0});var Z8=r(Mo);ax=n(Z8,"Number of images * repeats * epoch / batch size = total steps"),Z8.forEach(t),lx=n(Fd,".  Total Steps = (Number of Images \xD7 Repeats \xD7 Epochs) / Batch Size.  "),Bo=l(Fd,"CODE",{class:!0});var Q8=r(Bo);rx=n(Q8,"Example: (45 \xD7 10 \xD7 20) / 2 = 4500 steps"),Q8.forEach(t),Fd.forEach(t),Mh=u(s),Pt=l(s,"TABLE",{class:!0});var Kg=r(Pt);Wo=l(Kg,"THEAD",{class:!0});var J8=r(Wo);re=l(J8,"TR",{class:!0});var yt=r(re);jo=l(yt,"TH",{class:!0});var $8=r(jo);ix=n($8,"Number of Images"),$8.forEach(t),ox=u(yt),Fo=l(yt,"TH",{class:!0});var eR=r(Fo);nx=n(eR,"Repeats"),eR.forEach(t),cx=u(yt),Yo=l(yt,"TH",{class:!0});var tR=r(Yo);ux=n(tR,"Epochs"),tR.forEach(t),px=u(yt),Vo=l(yt,"TH",{class:!0});var sR=r(Vo);dx=n(sR,"Batch Size"),sR.forEach(t),fx=u(yt),Ko=l(yt,"TH",{class:!0});var aR=r(Ko);hx=n(aR,"Total Steps"),aR.forEach(t),yt.forEach(t),J8.forEach(t),gx=u(Kg),Xo=l(Kg,"TBODY",{class:!0});var lR=r(Xo);ie=l(lR,"TR",{class:!0});var wt=r(ie);Zo=l(wt,"TD",{class:!0});var rR=r(Zo);mx=n(rR,"45"),rR.forEach(t),vx=u(wt),Qo=l(wt,"TD",{class:!0});var iR=r(Qo);_x=n(iR,"10"),iR.forEach(t),kx=u(wt),Jo=l(wt,"TD",{class:!0});var oR=r(Jo);Ex=n(oR,"20"),oR.forEach(t),bx=u(wt),$o=l(wt,"TD",{class:!0});var nR=r($o);xx=n(nR,"2"),nR.forEach(t),yx=u(wt),en=l(wt,"TD",{class:!0});var cR=r(en);wx=n(cR,"4500"),cR.forEach(t),wt.forEach(t),lR.forEach(t),Kg.forEach(t),Bh=u(s),tn=l(s,"P",{});var uR=r(tn);Tx=n(uR,"Now let\u2019s focus on these training settings:"),uR.forEach(t),Wh=u(s),bl=l(s,"PRE",{class:!0});var PD=r(bl);PD.forEach(t),jh=u(s),M=l(s,"UL",{});var Y=r(M);sn=l(Y,"LI",{});var Rw=r(sn);xl=l(Rw,"STRONG",{});var Xg=r(xl);Rx=n(Xg,"Learning Rate ("),an=l(Xg,"CODE",{class:!0});var pR=r(an);Sx=n(pR,"learning_rate"),pR.forEach(t),Dx=n(Xg,")"),Xg.forEach(t),Ax=n(Rw,": Determines the step size during optimization, influencing how quickly the model adapts to training data."),Rw.forEach(t),Lx=u(Y),ln=l(Y,"LI",{});var Sw=r(ln);yl=l(Sw,"STRONG",{});var Zg=r(yl);Ix=n(Zg,"Text Encoder Learning Rate ("),rn=l(Zg,"CODE",{class:!0});var dR=r(rn);Ox=n(dR,"text_encoder_lr"),dR.forEach(t),Px=n(Zg,")"),Zg.forEach(t),zx=n(Sw,": Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model."),Sw.forEach(t),Nx=u(Y),on=l(Y,"LI",{});var Dw=r(on);wl=l(Dw,"STRONG",{});var Qg=r(wl);Cx=n(Qg,"UNet Learning Rate ("),nn=l(Qg,"CODE",{class:!0});var fR=r(nn);Gx=n(fR,"unet_lr"),fR.forEach(t),Hx=n(Qg,")"),Qg.forEach(t),qx=n(Dw,": Specifies the learning rate for the UNet component, impacting its performance in the LoRA model."),Dw.forEach(t),Ux=u(Y),cn=l(Y,"LI",{});var Aw=r(cn);Tl=l(Aw,"STRONG",{});var Jg=r(Tl);Mx=n(Jg,"Learning Rate Scheduler ("),un=l(Jg,"CODE",{class:!0});var hR=r(un);Bx=n(hR,"lr_scheduler"),hR.forEach(t),Wx=n(Jg,")"),Jg.forEach(t),jx=n(Aw,": Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training."),Aw.forEach(t),Fx=u(Y),pn=l(Y,"LI",{});var Lw=r(pn);Rl=l(Lw,"STRONG",{});var $g=r(Rl);Yx=n($g,"Number of Cycles in Learning Rate Scheduler ("),dn=l($g,"CODE",{class:!0});var gR=r(dn);Vx=n(gR,"lr_scheduler_num_cycles"),gR.forEach(t),Kx=n($g,")"),$g.forEach(t),Xx=n(Lw,": Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts."),Lw.forEach(t),Zx=u(Y),fn=l(Y,"LI",{});var Iw=r(fn);Sl=l(Iw,"STRONG",{});var em=r(Sl);Qx=n(em,"Network Dimension ("),hn=l(em,"CODE",{class:!0});var mR=r(hn);Jx=n(mR,"network_dim"),mR.forEach(t),$x=n(em,")"),em.forEach(t),ey=n(Iw,": Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand."),Iw.forEach(t),ty=u(Y),gn=l(Y,"LI",{});var Ow=r(gn);Dl=l(Ow,"STRONG",{});var tm=r(Dl);sy=n(tm,"Network Alpha ("),mn=l(tm,"CODE",{class:!0});var vR=r(mn);ay=n(vR,"network_alpha"),vR.forEach(t),ly=n(tm,")"),tm.forEach(t),ry=n(Ow,": Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting."),Ow.forEach(t),iy=u(Y),vn=l(Y,"LI",{});var Pw=r(vn);Al=l(Pw,"STRONG",{});var sm=r(Al);oy=n(sm,"Clip Skip ("),_n=l(sm,"CODE",{class:!0});var _R=r(_n);ny=n(_R,"clip_skip"),_R.forEach(t),cy=n(sm,")"),sm.forEach(t),uy=n(Pw,": Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process."),Pw.forEach(t),py=u(Y),kn=l(Y,"LI",{});var zw=r(kn);Ll=l(zw,"STRONG",{});var am=r(Ll);dy=n(am,"Max Token Length ("),En=l(am,"CODE",{class:!0});var kR=r(En);fy=n(kR,"max_token_length"),kR.forEach(t),hy=n(am,")"),am.forEach(t),gy=n(zw,": Sets the maximum allowed length for input tokens, enabling training with longer captions."),zw.forEach(t),my=u(Y),bn=l(Y,"LI",{});var Nw=r(bn);Il=l(Nw,"STRONG",{});var lm=r(Il);vy=n(lm,"Noise Offset ("),xn=l(lm,"CODE",{class:!0});var ER=r(xn);_y=n(ER,"noise_offset"),ER.forEach(t),ky=n(lm,")"),lm.forEach(t),Ey=n(Nw,": Implements a diffusion process with offset noise, enhancing generation results for dark or bright images."),Nw.forEach(t),by=u(Y),yn=l(Y,"LI",{});var Cw=r(yn);Ol=l(Cw,"STRONG",{});var rm=r(Ol);xy=n(rm,"Regularization Data Directory ("),wn=l(rm,"CODE",{class:!0});var bR=r(wn);yy=n(bR,"reg_data_dir"),bR.forEach(t),wy=n(rm,")"),rm.forEach(t),Ty=n(Cw,": Specifies the directory for regularization data, influencing the quality of regularization images during training."),Cw.forEach(t),Y.forEach(t),Fh=u(s),Zs=l(s,"H3",{id:!0});var Gw=r(Zs);Qs=l(Gw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var xR=r(Qs);Dd=l(xR,"SPAN",{class:!0}),r(Dd).forEach(t),xR.forEach(t),Ry=n(Gw,"Fine Tuning"),Gw.forEach(t),Yh=u(s),Tn=l(s,"P",{});var yR=r(Tn);Sy=n(yR,"Once training has completed, it\u2019s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session."),yR.forEach(t),Vh=u(s),Sa(Pl.$$.fragment,s),Kh=u(s),Js=l(s,"H4",{id:!0});var Hw=r(Js);$s=l(Hw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var wR=r($s);Ad=l(wR,"SPAN",{class:!0}),r(Ad).forEach(t),wR.forEach(t),Dy=n(Hw,"Workflow with Auto1111 WebUI"),Hw.forEach(t),Xh=u(s),ea=l(s,"P",{});var im=r(ea);Ay=n(im,"We\u2019re going to use "),zl=l(im,"A",{href:!0,rel:!0});var TR=r(zl);Ly=n(TR,"Stable Diffusion web UI"),TR.forEach(t),Iy=n(im," to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips."),im.forEach(t),Zh=u(s),ta=l(s,"P",{});var om=r(ta);Oy=n(om,"We\u2019re going to use the "),Rn=l(om,"CODE",{class:!0});var RR=r(Rn);Py=n(RR,"X/Y/Z plot"),RR.forEach(t),zy=n(om," script to compare different epochs."),om.forEach(t),Qh=u(s),oe=l(s,"UL",{});var Tt=r(oe);Sn=l(Tt,"LI",{});var qw=r(Sn);Ny=n(qw,"Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, "),Jh=l(qw,"PRINCEADAM0001:0.7",{}),r(Jh).forEach(t),qw.forEach(t),Cy=u(Tt),Ld=l(Tt,"LI",{});var SR=r(Ld);Gy=n(SR,"In generation parameters and select the X/Y/Z plot script."),SR.forEach(t),Hy=u(Tt),at=l(Tt,"LI",{});var Bl=r(at);qy=n(Bl,"Select "),Dn=l(Bl,"CODE",{class:!0});var DR=r(Dn);Uy=n(DR,"Prompt SR"),DR.forEach(t),My=n(Bl," for Prompt Replace.  We\u2019re going to replace "),An=l(Bl,"CODE",{class:!0});var AR=r(An);By=n(AR,"<princeadam0001:0.7>"),AR.forEach(t),Wy=n(Bl," with different epoch: "),Ln=l(Bl,"CODE",{class:!0});var LR=r(Ln);jy=n(LR,"<princeadam0001:0.7>, <princeadam0003:0.7>, <princeadam0023:0.7>"),LR.forEach(t),Bl.forEach(t),Fy=u(Tt),In=l(Tt,"LI",{});var Uw=r(In);Yy=n(Uw,"Select a fast sampler like "),On=l(Uw,"CODE",{class:!0});var IR=r(On);Vy=n(IR,"DPM2 KARRAS"),IR.forEach(t),Uw.forEach(t),Ky=u(Tt),sa=l(Tt,"LI",{});var Yd=r(sa);Xy=n(Yd,"CFG Scale set to "),Pn=l(Yd,"CODE",{class:!0});var OR=r(Pn);Zy=n(OR,"7"),OR.forEach(t),Qy=n(Yd," and Steps to "),zn=l(Yd,"CODE",{class:!0});var PR=r(zn);Jy=n(PR,"20"),PR.forEach(t),Yd.forEach(t),Tt.forEach(t),$h=u(s),lt=l(s,"P",{});var Tu=r(lt);$y=n(Tu,"After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA\u2019s strength.  Recall setting "),Nn=l(Tu,"CODE",{class:!0});var zR=r(Nn);e3=n(zR,"network_dim"),zR.forEach(t),t3=n(Tu," and "),Cn=l(Tu,"CODE",{class:!0});var NR=r(Cn);s3=n(NR,"network_alpha"),NR.forEach(t),a3=n(Tu,`?  Those are the settings that directly control the output strength mentioned earlier.
Use another`),Tu.forEach(t),eg=u(s),be=l(s,"UL",{});var ya=r(be);aa=l(ya,"LI",{});var Vd=r(aa);l3=n(Vd,"Select "),Gn=l(Vd,"CODE",{class:!0});var CR=r(Gn);r3=n(CR,"Prompt SR"),CR.forEach(t),i3=n(Vd," for Prompt Replace.  We\u2019re going to replace the weights "),Hn=l(Vd,"CODE",{class:!0});var GR=r(Hn);o3=n(GR,"<princeadam12:0.4>, <princeadam12:0.5>, <princeadam12:0.6>, <princeadam12:0.7>, <princeadam12:0.8>, <princeadam12:0.9>, <princeadam12:1.0>"),GR.forEach(t),Vd.forEach(t),n3=u(ya),Nl=l(ya,"LI",{});var nm=r(Nl);c3=n(nm,"Use Prompt SR to generate a variety of angles: Select "),qn=l(nm,"CODE",{class:!0});var HR=r(qn);u3=n(HR,"Prompt SR"),HR.forEach(t),p3=n(nm," for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up."),nm.forEach(t),d3=u(ya),Id=l(ya,"LI",{});var qR=r(Id);f3=n(qR,"If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data."),qR.forEach(t),h3=u(ya),Od=l(ya,"LI",{});var UR=r(Od);g3=n(UR,"Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model."),UR.forEach(t),ya.forEach(t),tg=u(s),la=l(s,"H4",{id:!0});var Mw=r(la);ra=l(Mw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var MR=r(ra);Pd=l(MR,"SPAN",{class:!0}),r(Pd).forEach(t),MR.forEach(t),m3=n(Mw,"Issues to look for"),Mw.forEach(t),sg=u(s),xe=l(s,"UL",{});var wa=r(xe);Un=l(wa,"LI",{});var Bw=r(Un);zd=l(Bw,"STRONG",{});var BR=r(zd);v3=n(BR,"Undercooked:"),BR.forEach(t),_3=n(Bw," Lacks output, adjust unet learning rate or extend training duration."),Bw.forEach(t),k3=u(wa),Mn=l(wa,"LI",{});var Ww=r(Mn);Nd=l(Ww,"STRONG",{});var WR=r(Nd);E3=n(WR,"Overcooked:"),WR.forEach(t),b3=n(Ww," Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats."),Ww.forEach(t),x3=u(wa),Bn=l(wa,"LI",{});var jw=r(Bn);Cd=l(jw,"STRONG",{});var jR=r(Cd);y3=n(jR,"Overfit:"),jR.forEach(t),w3=n(jw," Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues."),jw.forEach(t),T3=u(wa),Wn=l(wa,"LI",{});var Fw=r(Wn);Gd=l(Fw,"STRONG",{});var FR=r(Gd);R3=n(FR,"Mismatched:"),FR.forEach(t),S3=n(Fw," Doesn\u2019t match expectations, it might be undercooked or have a low-quality dataset."),Fw.forEach(t),wa.forEach(t),ag=u(s),jn=l(s,"P",{});var YR=r(jn);D3=n(YR,"If you\u2019re experiencing these issues, it\u2019s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning."),YR.forEach(t),lg=u(s),Cl=l(s,"P",{class:!0});var VR=r(Cl);Gl=l(VR,"IMG",{src:!0,alt:!0,class:!0}),VR.forEach(t),rg=u(s),ia=l(s,"H2",{id:!0});var Yw=r(ia);oa=l(Yw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var KR=r(oa);Hd=l(KR,"SPAN",{class:!0}),r(Hd).forEach(t),KR.forEach(t),A3=n(Yw,"Troubleshooting"),Yw.forEach(t),ig=u(s),Fn=l(s,"P",{});var XR=r(Fn);L3=n(XR,"If you find your results aren\u2019t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:"),XR.forEach(t),og=u(s),rt=l(s,"UL",{});var Ru=r(rt);Hl=l(Ru,"LI",{});var cm=r(Hl);I3=n(cm,"Lower input images, less regularization images needed.  Remember Dreambooth calls for about "),Yn=l(cm,"CODE",{class:!0});var ZR=r(Yn);O3=n(ZR,"200"),ZR.forEach(t),P3=n(cm," regularization images per training image."),cm.forEach(t),z3=u(Ru),ql=l(Ru,"LI",{});var um=r(ql);N3=n(um,"Repeats of regularization images, but may overfit more.  Increasing the "),Vn=l(um,"CODE",{class:!0});var QR=r(Vn);C3=n(QR,"repetition_count"),QR.forEach(t),G3=n(um," will cycle through the images more but the results may have results that overfit the model."),um.forEach(t),H3=u(Ru),qd=l(Ru,"LI",{});var JR=r(qd);q3=n(JR,"Create more regularization images without increasing repeats will help with the overfitting."),JR.forEach(t),Ru.forEach(t),ng=u(s),zt=l(s,"TABLE",{class:!0});var pm=r(zt);Kn=l(pm,"THEAD",{class:!0});var $R=r(Kn);it=l($R,"TR",{class:!0});var Su=r(it);Xn=l(Su,"TH",{class:!0});var eS=r(Xn);U3=n(eS,"Issue"),eS.forEach(t),M3=u(Su),Zn=l(Su,"TH",{class:!0});var tS=r(Zn);B3=n(tS,"Situation"),tS.forEach(t),W3=u(Su),Qn=l(Su,"TH",{class:!0});var sS=r(Qn);j3=n(sS,"Recommendation"),sS.forEach(t),Su.forEach(t),$R.forEach(t),F3=u(pm),ye=l(pm,"TBODY",{class:!0});var Ta=r(ye);ot=l(Ta,"TR",{class:!0});var Du=r(ot);Jn=l(Du,"TD",{class:!0});var aS=r(Jn);Y3=n(aS,"Varying quality"),aS.forEach(t),V3=u(Du),$n=l(Du,"TD",{class:!0});var lS=r($n);K3=n(lS,"Results differ from expectations"),lS.forEach(t),X3=u(Du),ec=l(Du,"TD",{class:!0});var rS=r(ec);Z3=n(rS,"Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results."),rS.forEach(t),Du.forEach(t),Q3=u(Ta),nt=l(Ta,"TR",{class:!0});var Au=r(nt);tc=l(Au,"TD",{class:!0});var iS=r(tc);J3=n(iS,"Inadequate regularization for input data"),iS.forEach(t),$3=u(Au),sc=l(Au,"TD",{class:!0});var oS=r(sc);e4=n(oS,"Lower input images, less regularization needed"),oS.forEach(t),t4=u(Au),ac=l(Au,"TD",{class:!0});var nS=r(ac);s4=n(nS,"Reduce the number of input images or increasing the quantity of reg images."),nS.forEach(t),Au.forEach(t),a4=u(Ta),ct=l(Ta,"TR",{class:!0});var Lu=r(ct);lc=l(Lu,"TD",{class:!0});var cS=r(lc);l4=n(cS,"Overfitting due to repetition"),cS.forEach(t),r4=u(Lu),rc=l(Lu,"TD",{class:!0});var uS=r(rc);i4=n(uS,"Repeats of reg images, risk of overfitting"),uS.forEach(t),o4=u(Lu),ic=l(Lu,"TD",{class:!0});var pS=r(ic);n4=n(pS,"Adjust repetition_count to balance cycling through images without overfitting. Monitor results."),pS.forEach(t),Lu.forEach(t),c4=u(Ta),ut=l(Ta,"TR",{class:!0});var Iu=r(ut);oc=l(Iu,"TD",{class:!0});var dS=r(oc);u4=n(dS,"Mitigate overfitting while increasing diversity"),dS.forEach(t),p4=u(Iu),nc=l(Iu,"TD",{class:!0});var fS=r(nc);d4=n(fS,"Create more reg images without repeats"),fS.forEach(t),f4=u(Iu),cc=l(Iu,"TD",{class:!0});var hS=r(cc);h4=n(hS,"Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting."),hS.forEach(t),Iu.forEach(t),Ta.forEach(t),pm.forEach(t),cg=u(s),na=l(s,"H4",{id:!0});var Vw=r(na);ca=l(Vw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var gS=r(ca);Ud=l(gS,"SPAN",{class:!0}),r(Ud).forEach(t),gS.forEach(t),g4=n(Vw,"More Solutions"),Vw.forEach(t),ug=u(s),uc=l(s,"P",{});var mS=r(uc);m4=n(mS,"Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training."),mS.forEach(t),pg=u(s),Nt=l(s,"TABLE",{class:!0});var dm=r(Nt);pc=l(dm,"THEAD",{class:!0});var vS=r(pc);pt=l(vS,"TR",{class:!0});var Ou=r(pt);dc=l(Ou,"TH",{class:!0});var _S=r(dc);v4=n(_S,"Symptom"),_S.forEach(t),_4=u(Ou),fc=l(Ou,"TH",{class:!0});var kS=r(fc);k4=n(kS,"Likely Cause"),kS.forEach(t),E4=u(Ou),hc=l(Ou,"TH",{class:!0});var ES=r(hc);b4=n(ES,"Solution"),ES.forEach(t),Ou.forEach(t),vS.forEach(t),x4=u(dm),W=l(dm,"TBODY",{class:!0});var Z=r(W);dt=l(Z,"TR",{class:!0});var Pu=r(dt);gc=l(Pu,"TD",{class:!0});var bS=r(gc);y4=n(bS,"Plastic texture persists"),bS.forEach(t),w4=u(Pu),mc=l(Pu,"TD",{class:!0});var xS=r(mc);T4=n(xS,"Insufficient human reg images"),xS.forEach(t),R4=u(Pu),vc=l(Pu,"TD",{class:!0});var yS=r(vc);S4=n(yS,"Add real photos to reg set"),yS.forEach(t),Pu.forEach(t),D4=u(Z),ft=l(Z,"TR",{class:!0});var zu=r(ft);_c=l(zu,"TD",{class:!0});var wS=r(_c);A4=n(wS,"Loss plateaus early"),wS.forEach(t),L4=u(zu),kc=l(zu,"TD",{class:!0});var TS=r(kc);I4=n(TS,"Learning rate too low"),TS.forEach(t),O4=u(zu),Ec=l(zu,"TD",{class:!0});var RS=r(Ec);P4=n(RS,"Increase LR by 10x"),RS.forEach(t),zu.forEach(t),z4=u(Z),ht=l(Z,"TR",{class:!0});var Nu=r(ht);bc=l(Nu,"TD",{class:!0});var SS=r(bc);N4=n(SS,"Features blurry"),SS.forEach(t),C4=u(Nu),xc=l(Nu,"TD",{class:!0});var DS=r(xc);G4=n(DS,"Network dimension too small"),DS.forEach(t),H4=u(Nu),yc=l(Nu,"TD",{class:!0});var AS=r(yc);q4=n(AS,"Increase network_dim to 64+"),AS.forEach(t),Nu.forEach(t),U4=u(Z),gt=l(Z,"TR",{class:!0});var Cu=r(gt);wc=l(Cu,"TD",{class:!0});var LS=r(wc);M4=n(LS,"Color distortion"),LS.forEach(t),B4=u(Cu),Tc=l(Cu,"TD",{class:!0});var IS=r(Tc);W4=n(IS,"Noise offset conflict"),IS.forEach(t),j4=u(Cu),Rc=l(Cu,"TD",{class:!0});var OS=r(Rc);F4=n(OS,"Try noise_offset 0.05-0.1"),OS.forEach(t),Cu.forEach(t),Y4=u(Z),mt=l(Z,"TR",{class:!0});var Gu=r(mt);Sc=l(Gu,"TD",{class:!0});var PS=r(Sc);V4=n(PS,"Overly stylized outputs"),PS.forEach(t),K4=u(Gu),Dc=l(Gu,"TD",{class:!0});var zS=r(Dc);X4=n(zS,"Reg image style mismatch"),zS.forEach(t),Z4=u(Gu),Ac=l(Gu,"TD",{class:!0});var NS=r(Ac);Q4=n(NS,"Regenerate reg images with base model"),NS.forEach(t),Gu.forEach(t),J4=u(Z),vt=l(Z,"TR",{class:!0});var Hu=r(vt);Lc=l(Hu,"TD",{class:!0});var CS=r(Lc);$4=n(CS,"Training instability"),CS.forEach(t),e0=u(Hu),Ic=l(Hu,"TD",{class:!0});var GS=r(Ic);t0=n(GS,"Batch size too large"),GS.forEach(t),s0=u(Hu),Oc=l(Hu,"TD",{class:!0});var HS=r(Oc);a0=n(HS,"Reduce batch_size to 1-2"),HS.forEach(t),Hu.forEach(t),l0=u(Z),_t=l(Z,"TR",{class:!0});var qu=r(_t);Pc=l(qu,"TD",{class:!0});var qS=r(Pc);r0=n(qS,"Slow convergence"),qS.forEach(t),i0=u(qu),zc=l(qu,"TD",{class:!0});var US=r(zc);o0=n(US,"Network_alpha too high"),US.forEach(t),n0=u(qu),Nc=l(qu,"TD",{class:!0});var MS=r(Nc);c0=n(MS,"Set alpha = dim/2 (e.g., 64/2 = 32)"),MS.forEach(t),qu.forEach(t),u0=u(Z),kt=l(Z,"TR",{class:!0});var Uu=r(kt);Cc=l(Uu,"TD",{class:!0});var BS=r(Cc);p0=n(BS,"Loss divergence"),BS.forEach(t),d0=u(Uu),Gc=l(Uu,"TD",{class:!0});var WS=r(Gc);f0=n(WS,"Text encoder LR too high"),WS.forEach(t),h0=u(Uu),Hc=l(Uu,"TD",{class:!0});var jS=r(Hc);g0=n(jS,"Reduce text_encoder_lr by 10x"),jS.forEach(t),Uu.forEach(t),m0=u(Z),Et=l(Z,"TR",{class:!0});var Mu=r(Et);qc=l(Mu,"TD",{class:!0});var FS=r(qc);v0=n(FS,"Poor prompt adherence"),FS.forEach(t),_0=u(Mu),Uc=l(Mu,"TD",{class:!0});var YS=r(Uc);k0=n(YS,"Clip skip too high"),YS.forEach(t),E0=u(Mu),Mc=l(Mu,"TD",{class:!0});var VS=r(Mc);b0=n(VS,"Reduce clip_skip to 1-2"),VS.forEach(t),Mu.forEach(t),x0=u(Z),bt=l(Z,"TR",{class:!0});var Bu=r(bt);Bc=l(Bu,"TD",{class:!0});var KS=r(Bc);y0=n(KS,"Memory errors"),KS.forEach(t),w0=u(Bu),Wc=l(Bu,"TD",{class:!0});var XS=r(Wc);T0=n(XS,"Resolution too high"),XS.forEach(t),R0=u(Bu),jc=l(Bu,"TD",{class:!0});var ZS=r(jc);S0=n(ZS,"Reduce to 512-768px, enable gradient checkpointing"),ZS.forEach(t),Bu.forEach(t),Z.forEach(t),dm.forEach(t),dg=u(s),ua=l(s,"H2",{id:!0});var Kw=r(ua);pa=l(Kw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var QS=r(pa);Md=l(QS,"SPAN",{class:!0}),r(Md).forEach(t),QS.forEach(t),D0=n(Kw,"Results"),Kw.forEach(t),fg=u(s),Fc=l(s,"P",{});var JS=r(Fc);A0=n(JS,"The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images."),JS.forEach(t),hg=u(s),Yc=l(s,"P",{});var $S=r(Yc);L0=n($S,"Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model\u2019s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance."),$S.forEach(t),gg=u(s),Ul=l(s,"P",{class:!0});var eD=r(Ul);Ml=l(eD,"IMG",{src:!0,alt:!0,class:!0}),eD.forEach(t),mg=u(s),Vc=l(s,"P",{});var tD=r(Vc);I0=n(tD,"The journey doesn\u2019t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art."),tD.forEach(t),vg=u(s),Ct=l(s,"H2",{id:!0,class:!0});var Xw=r(Ct);da=l(Xw,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var sD=r(da);Bd=l(sD,"SPAN",{class:!0}),r(Bd).forEach(t),sD.forEach(t),O0=n(Xw,"spacelab"),Xw.forEach(t),_g=u(s),Te&&Te.l(s),kg=Wu(),this.h()},h(){i(T,"class","icon icon-link"),i(b,"aria-hidden","true"),i(b,"tabindex","-1"),i(b,"href","#what-are-regularization-images"),i(k,"id","what-are-regularization-images"),i(P,"class","svelte-x2kgxs"),i(L,"class","svelte-x2kgxs"),i(H,"class","svelte-x2kgxs"),i(we,"class","svelte-x2kgxs"),i(Yl,"class","svelte-x2kgxs"),i(w,"class","svelte-x2kgxs"),i(U,"class","svelte-x2kgxs"),i(Vl,"class","svelte-x2kgxs"),i(Kl,"class","svelte-x2kgxs"),i(Xl,"class","svelte-x2kgxs"),i(De,"class","svelte-x2kgxs"),i(Zl,"class","svelte-x2kgxs"),i(Ql,"class","svelte-x2kgxs"),i(Jl,"class","svelte-x2kgxs"),i(Ae,"class","svelte-x2kgxs"),i($l,"class","svelte-x2kgxs"),i(er,"class","svelte-x2kgxs"),i(tr,"class","svelte-x2kgxs"),i(Le,"class","svelte-x2kgxs"),i(Se,"class","svelte-x2kgxs"),i(V,"class","svelte-x2kgxs"),i(lr,"class","svelte-x2kgxs"),i(Ia,"class","svelte-x2kgxs"),i(Qu,"class","icon icon-link"),i(Ut,"aria-hidden","true"),i(Ut,"tabindex","-1"),i(Ut,"href","#divergence"),i(qt,"id","divergence"),i(or,"class","svelte-x2kgxs"),i(nr,"class","svelte-x2kgxs"),i(Ga,"class","svelte-x2kgxs"),i(lp,"class","icon icon-link"),i(Wt,"aria-hidden","true"),i(Wt,"tabindex","-1"),i(Wt,"href","#overfitting"),i(Bt,"id","overfitting"),i(cp,"class","icon icon-link"),i(Ft,"aria-hidden","true"),i(Ft,"tabindex","-1"),i(Ft,"href","#key-differences"),i(jt,"id","key-differences"),i(hr,"class","svelte-x2kgxs"),i(gr,"class","svelte-x2kgxs"),i(mr,"class","svelte-x2kgxs"),i(ze,"class","svelte-x2kgxs"),i(fr,"class","svelte-x2kgxs"),i(vr,"class","svelte-x2kgxs"),i(_r,"class","svelte-x2kgxs"),i(kr,"class","svelte-x2kgxs"),i(Ne,"class","svelte-x2kgxs"),i(Er,"class","svelte-x2kgxs"),i(br,"class","svelte-x2kgxs"),i(xr,"class","svelte-x2kgxs"),i(Ce,"class","svelte-x2kgxs"),i(yr,"class","svelte-x2kgxs"),i(wr,"class","svelte-x2kgxs"),i(Tr,"class","svelte-x2kgxs"),i(Ge,"class","svelte-x2kgxs"),i(Rr,"class","svelte-x2kgxs"),i(Sr,"class","svelte-x2kgxs"),i(Dr,"class","svelte-x2kgxs"),i(He,"class","svelte-x2kgxs"),i(pe,"class","svelte-x2kgxs"),i(Dt,"class","svelte-x2kgxs"),i(_p,"class","icon icon-link"),i(Vt,"aria-hidden","true"),i(Vt,"tabindex","-1"),i(Vt,"href","#preventing-divergence"),i(Yt,"id","preventing-divergence"),i(Lr,"class","svelte-x2kgxs"),i(Ir,"class","svelte-x2kgxs"),i(Kt,"class","svelte-x2kgxs"),i(Ar,"class","svelte-x2kgxs"),i(Or,"class","svelte-x2kgxs"),i(Pr,"class","svelte-x2kgxs"),i(Xt,"class","svelte-x2kgxs"),i(zr,"class","svelte-x2kgxs"),i(Nr,"class","svelte-x2kgxs"),i(Zt,"class","svelte-x2kgxs"),i(Cr,"class","svelte-x2kgxs"),i(Gr,"class","svelte-x2kgxs"),i(Qt,"class","svelte-x2kgxs"),i(Hr,"class","svelte-x2kgxs"),i(qr,"class","svelte-x2kgxs"),i(Jt,"class","svelte-x2kgxs"),i(de,"class","svelte-x2kgxs"),i(At,"class","svelte-x2kgxs"),i(yp,"class","icon icon-link"),i(es,"aria-hidden","true"),i(es,"tabindex","-1"),i(es,"href","#implementing-these-strategies"),i($t,"id","implementing-these-strategies"),i(Ha,"class","language-python"),i(qa,"class","language-python"),i(wp,"class","icon icon-link"),i(ss,"aria-hidden","true"),i(ss,"tabindex","-1"),i(ss,"href","#data-considerations"),i(ts,"id","data-considerations"),i(Br,"class","svelte-x2kgxs"),i(Wr,"class","svelte-x2kgxs"),i(jr,"class","svelte-x2kgxs"),i(qe,"class","svelte-x2kgxs"),i(Mr,"class","svelte-x2kgxs"),i(Fr,"class","svelte-x2kgxs"),i(Yr,"class","svelte-x2kgxs"),i(Vr,"class","svelte-x2kgxs"),i(Ue,"class","svelte-x2kgxs"),i(Kr,"class","svelte-x2kgxs"),i(Xr,"class","svelte-x2kgxs"),i(Zr,"class","svelte-x2kgxs"),i(Me,"class","svelte-x2kgxs"),i(Qr,"class","svelte-x2kgxs"),i(Jr,"class","svelte-x2kgxs"),i($r,"class","svelte-x2kgxs"),i(Be,"class","svelte-x2kgxs"),i(ei,"class","svelte-x2kgxs"),i(ti,"class","svelte-x2kgxs"),i(si,"class","svelte-x2kgxs"),i(We,"class","svelte-x2kgxs"),i(fe,"class","svelte-x2kgxs"),i(Lt,"class","svelte-x2kgxs"),i(Tp,"class","icon icon-link"),i(ls,"aria-hidden","true"),i(ls,"tabindex","-1"),i(ls,"href","#monitoring-tips"),i(as,"id","monitoring-tips"),i(Ua,"href","https://github.com/kohya-ss/sd-scripts"),i(Ua,"rel","nofollow"),i(Rp,"class","icon icon-link"),i(os,"aria-hidden","true"),i(os,"tabindex","-1"),i(os,"href","#track-loss-curves"),i(is,"id","track-loss-curves"),i(Ma,"href","https://www.tensorflow.org/tensorboard"),i(Ma,"rel","nofollow"),i(Ba,"class","language-bash"),i(Sp,"class","icon icon-link"),i(us,"aria-hidden","true"),i(us,"tabindex","-1"),i(us,"href","#what-to-monitor"),i(cs,"id","what-to-monitor"),i(Ip,"class","icon icon-link"),i(ds,"aria-hidden","true"),i(ds,"tabindex","-1"),i(ds,"href","#warning-signs"),i(ps,"id","warning-signs"),i(Np,"class","icon icon-link"),i(hs,"aria-hidden","true"),i(hs,"tabindex","-1"),i(hs,"href","#generate-validation-images-every-100-steps"),i(fs,"id","generate-validation-images-every-100-steps"),i(ja,"class","language-json"),i(Gp,"class","icon icon-link"),i(ms,"aria-hidden","true"),i(ms,"tabindex","-1"),i(ms,"href","#what-to-look-for"),i(gs,"id","what-to-look-for"),i(ai,"class","svelte-x2kgxs"),i(Fa,"class","svelte-x2kgxs"),i(Mp,"class","icon icon-link"),i(_s,"aria-hidden","true"),i(_s,"tabindex","-1"),i(_s,"href","#use-gradient-clipping"),i(vs,"id","use-gradient-clipping"),i(ri,"class","svelte-x2kgxs"),i(ii,"class","svelte-x2kgxs"),i(Ka,"class","svelte-x2kgxs"),i(Fp,"class","icon icon-link"),i(Es,"aria-hidden","true"),i(Es,"tabindex","-1"),i(Es,"href","#enable-mixed-precision-training"),i(ks,"id","enable-mixed-precision-training"),i(Za,"class","language-python"),i(ni,"class","svelte-x2kgxs"),i(Qa,"class","svelte-x2kgxs"),i(Zp,"class","icon icon-link"),i(xs,"aria-hidden","true"),i(xs,"tabindex","-1"),i(xs,"href","#start-with-conservative-learning-rates"),i(bs,"id","start-with-conservative-learning-rates"),i(Ja,"class","language-yml"),i($a,"class","language-python"),i(ui,"class","svelte-x2kgxs"),i(pi,"class","svelte-x2kgxs"),i(di,"class","svelte-x2kgxs"),i(fi,"class","svelte-x2kgxs"),i(he,"class","svelte-x2kgxs"),i(ci,"class","svelte-x2kgxs"),i(hi,"class","svelte-x2kgxs"),i(gi,"class","svelte-x2kgxs"),i(mi,"class","svelte-x2kgxs"),i(vi,"class","svelte-x2kgxs"),i(ge,"class","svelte-x2kgxs"),i(_i,"class","svelte-x2kgxs"),i(ki,"class","svelte-x2kgxs"),i(Ei,"class","svelte-x2kgxs"),i(bi,"class","svelte-x2kgxs"),i(me,"class","svelte-x2kgxs"),i(xi,"class","svelte-x2kgxs"),i(yi,"class","svelte-x2kgxs"),i(ws,"class","svelte-x2kgxs"),i(wi,"class","svelte-x2kgxs"),i(Ti,"class","svelte-x2kgxs"),i(Ze,"class","svelte-x2kgxs"),i(ve,"class","svelte-x2kgxs"),i(Ri,"class","svelte-x2kgxs"),i(Si,"class","svelte-x2kgxs"),i(Di,"class","svelte-x2kgxs"),i(Ai,"class","svelte-x2kgxs"),i(_e,"class","svelte-x2kgxs"),i(Li,"class","svelte-x2kgxs"),i(Ii,"class","svelte-x2kgxs"),i(Oi,"class","svelte-x2kgxs"),i(Pi,"class","svelte-x2kgxs"),i(ke,"class","svelte-x2kgxs"),i(le,"class","svelte-x2kgxs"),i(It,"class","svelte-x2kgxs"),i(ad,"class","icon icon-link"),i(Rs,"aria-hidden","true"),i(Rs,"tabindex","-1"),i(Rs,"href","#generating-regularization-images"),i(Ts,"id","generating-regularization-images"),i(zi,"class","svelte-x2kgxs"),i(Ni,"class","svelte-x2kgxs"),i(Ci,"class","svelte-x2kgxs"),i(Gi,"class","svelte-x2kgxs"),i(Hi,"class","svelte-x2kgxs"),i(ld,"class","icon icon-link"),i(As,"aria-hidden","true"),i(As,"tabindex","-1"),i(As,"href","#important-considerations"),i(Ds,"id","important-considerations"),i(pd,"class","icon icon-link"),i(Is,"aria-hidden","true"),i(Is,"tabindex","-1"),i(Is,"href","#generate-using-stable-diffusion-web-ui"),i(Ls,"id","generate-using-stable-diffusion-web-ui"),i(rl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(rl,"rel","nofollow"),i(Ui,"class","svelte-x2kgxs"),i(Mi,"class","svelte-x2kgxs"),i(Wi,"class","svelte-x2kgxs"),i(ji,"class","svelte-x2kgxs"),i(Fi,"class","svelte-x2kgxs"),i(Yi,"class","svelte-x2kgxs"),i(Vi,"class","svelte-x2kgxs"),i(Ki,"class","svelte-x2kgxs"),i(Xi,"class","svelte-x2kgxs"),i(Zi,"class","svelte-x2kgxs"),i(Qi,"class","svelte-x2kgxs"),i(Ji,"class","svelte-x2kgxs"),i($i,"class","svelte-x2kgxs"),i(eo,"class","svelte-x2kgxs"),i(to,"class","svelte-x2kgxs"),i(so,"class","svelte-x2kgxs"),i(ao,"class","svelte-x2kgxs"),i(lo,"class","svelte-x2kgxs"),i(ro,"class","svelte-x2kgxs"),i(io,"class","svelte-x2kgxs"),i(oo,"class","svelte-x2kgxs"),i(no,"class","svelte-x2kgxs"),i(co,"class","svelte-x2kgxs"),i(uo,"class","svelte-x2kgxs"),i(po,"class","svelte-x2kgxs"),i(fo,"class","svelte-x2kgxs"),i(ho,"class","svelte-x2kgxs"),i(mo,"class","svelte-x2kgxs"),i(vo,"class","svelte-x2kgxs"),i(_o,"class","svelte-x2kgxs"),i(ko,"class","svelte-x2kgxs"),i(Eo,"class","svelte-x2kgxs"),i(kd,"class","icon icon-link"),i(Ns,"aria-hidden","true"),i(Ns,"tabindex","-1"),i(Ns,"href","#download-images"),i(zs,"id","download-images"),i(nl,"href","https://huggingface.co/3ee"),i(nl,"rel","nofollow"),i(cl,"href","https://github.com/Luehrsen/sd_regularization_images"),i(cl,"rel","nofollow"),i(ul,"href","https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images"),i(ul,"rel","nofollow"),i(pl,"href","https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main"),i(pl,"rel","nofollow"),i(Ed,"class","icon icon-link"),i(Gs,"aria-hidden","true"),i(Gs,"tabindex","-1"),i(Gs,"href","#captioning-regularization-images"),i(Cs,"id","captioning-regularization-images"),i(Ro,"class","svelte-x2kgxs"),i(dl,"class","language-shell"),i(So,"class","svelte-x2kgxs"),i(Do,"class","svelte-x2kgxs"),i(Ao,"class","svelte-x2kgxs"),i(Lo,"class","svelte-x2kgxs"),i(bd,"class","icon icon-link"),i(Ms,"aria-hidden","true"),i(Ms,"tabindex","-1"),i(Ms,"href","#training-a-lora"),i(Us,"id","training-a-lora"),i(hl,"href","https://github.com/kohya-ss/sd-scripts"),i(hl,"rel","nofollow"),i(ml,"href","https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md"),i(ml,"rel","nofollow"),i(Ws,"class","svelte-x2kgxs"),i(gl,"class","svelte-x2kgxs"),i(xd,"class","icon icon-link"),i(Fs,"aria-hidden","true"),i(Fs,"tabindex","-1"),i(Fs,"href","#directory-setup"),i(js,"id","directory-setup"),i(Io,"class","svelte-x2kgxs"),i(vl,"class","language-json"),i(_l,"class","language-xml"),i(Po,"class","svelte-x2kgxs"),i(zo,"class","svelte-x2kgxs"),i(No,"class","svelte-x2kgxs"),i(Co,"class","svelte-x2kgxs"),Wl(El.src,s5="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png")||i(El,"src",s5),i(El,"alt","image"),i(El,"class","svelte-x2kgxs"),i(kl,"class","svelte-x2kgxs"),i(Sd,"class","icon icon-link"),i(Xs,"aria-hidden","true"),i(Xs,"tabindex","-1"),i(Xs,"href","#training-settings"),i(Ks,"id","training-settings"),i(Mo,"class","svelte-x2kgxs"),i(Bo,"class","svelte-x2kgxs"),i(jo,"class","svelte-x2kgxs"),i(Fo,"class","svelte-x2kgxs"),i(Yo,"class","svelte-x2kgxs"),i(Vo,"class","svelte-x2kgxs"),i(Ko,"class","svelte-x2kgxs"),i(re,"class","svelte-x2kgxs"),i(Wo,"class","svelte-x2kgxs"),i(Zo,"class","svelte-x2kgxs"),i(Qo,"class","svelte-x2kgxs"),i(Jo,"class","svelte-x2kgxs"),i($o,"class","svelte-x2kgxs"),i(en,"class","svelte-x2kgxs"),i(ie,"class","svelte-x2kgxs"),i(Xo,"class","svelte-x2kgxs"),i(Pt,"class","svelte-x2kgxs"),i(bl,"class","language-json"),i(an,"class","svelte-x2kgxs"),i(rn,"class","svelte-x2kgxs"),i(nn,"class","svelte-x2kgxs"),i(un,"class","svelte-x2kgxs"),i(dn,"class","svelte-x2kgxs"),i(hn,"class","svelte-x2kgxs"),i(mn,"class","svelte-x2kgxs"),i(_n,"class","svelte-x2kgxs"),i(En,"class","svelte-x2kgxs"),i(xn,"class","svelte-x2kgxs"),i(wn,"class","svelte-x2kgxs"),i(Dd,"class","icon icon-link"),i(Qs,"aria-hidden","true"),i(Qs,"tabindex","-1"),i(Qs,"href","#fine-tuning"),i(Zs,"id","fine-tuning"),i(Ad,"class","icon icon-link"),i($s,"aria-hidden","true"),i($s,"tabindex","-1"),i($s,"href","#workflow-with-auto1111-webui"),i(Js,"id","workflow-with-auto1111-webui"),i(zl,"href","https://github.com/AUTOMATIC1111/stable-diffusion-webui"),i(zl,"rel","nofollow"),i(Rn,"class","svelte-x2kgxs"),i(Dn,"class","svelte-x2kgxs"),i(An,"class","svelte-x2kgxs"),i(Ln,"class","svelte-x2kgxs"),i(On,"class","svelte-x2kgxs"),i(Pn,"class","svelte-x2kgxs"),i(zn,"class","svelte-x2kgxs"),i(Nn,"class","svelte-x2kgxs"),i(Cn,"class","svelte-x2kgxs"),i(Gn,"class","svelte-x2kgxs"),i(Hn,"class","svelte-x2kgxs"),i(qn,"class","svelte-x2kgxs"),i(Pd,"class","icon icon-link"),i(ra,"aria-hidden","true"),i(ra,"tabindex","-1"),i(ra,"href","#issues-to-look-for"),i(la,"id","issues-to-look-for"),Wl(Gl.src,a5="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png")||i(Gl,"src",a5),i(Gl,"alt","image"),i(Gl,"class","svelte-x2kgxs"),i(Cl,"class","svelte-x2kgxs"),i(Hd,"class","icon icon-link"),i(oa,"aria-hidden","true"),i(oa,"tabindex","-1"),i(oa,"href","#troubleshooting"),i(ia,"id","troubleshooting"),i(Yn,"class","svelte-x2kgxs"),i(Vn,"class","svelte-x2kgxs"),i(Xn,"class","svelte-x2kgxs"),i(Zn,"class","svelte-x2kgxs"),i(Qn,"class","svelte-x2kgxs"),i(it,"class","svelte-x2kgxs"),i(Kn,"class","svelte-x2kgxs"),i(Jn,"class","svelte-x2kgxs"),i($n,"class","svelte-x2kgxs"),i(ec,"class","svelte-x2kgxs"),i(ot,"class","svelte-x2kgxs"),i(tc,"class","svelte-x2kgxs"),i(sc,"class","svelte-x2kgxs"),i(ac,"class","svelte-x2kgxs"),i(nt,"class","svelte-x2kgxs"),i(lc,"class","svelte-x2kgxs"),i(rc,"class","svelte-x2kgxs"),i(ic,"class","svelte-x2kgxs"),i(ct,"class","svelte-x2kgxs"),i(oc,"class","svelte-x2kgxs"),i(nc,"class","svelte-x2kgxs"),i(cc,"class","svelte-x2kgxs"),i(ut,"class","svelte-x2kgxs"),i(ye,"class","svelte-x2kgxs"),i(zt,"class","svelte-x2kgxs"),i(Ud,"class","icon icon-link"),i(ca,"aria-hidden","true"),i(ca,"tabindex","-1"),i(ca,"href","#more-solutions"),i(na,"id","more-solutions"),i(dc,"class","svelte-x2kgxs"),i(fc,"class","svelte-x2kgxs"),i(hc,"class","svelte-x2kgxs"),i(pt,"class","svelte-x2kgxs"),i(pc,"class","svelte-x2kgxs"),i(gc,"class","svelte-x2kgxs"),i(mc,"class","svelte-x2kgxs"),i(vc,"class","svelte-x2kgxs"),i(dt,"class","svelte-x2kgxs"),i(_c,"class","svelte-x2kgxs"),i(kc,"class","svelte-x2kgxs"),i(Ec,"class","svelte-x2kgxs"),i(ft,"class","svelte-x2kgxs"),i(bc,"class","svelte-x2kgxs"),i(xc,"class","svelte-x2kgxs"),i(yc,"class","svelte-x2kgxs"),i(ht,"class","svelte-x2kgxs"),i(wc,"class","svelte-x2kgxs"),i(Tc,"class","svelte-x2kgxs"),i(Rc,"class","svelte-x2kgxs"),i(gt,"class","svelte-x2kgxs"),i(Sc,"class","svelte-x2kgxs"),i(Dc,"class","svelte-x2kgxs"),i(Ac,"class","svelte-x2kgxs"),i(mt,"class","svelte-x2kgxs"),i(Lc,"class","svelte-x2kgxs"),i(Ic,"class","svelte-x2kgxs"),i(Oc,"class","svelte-x2kgxs"),i(vt,"class","svelte-x2kgxs"),i(Pc,"class","svelte-x2kgxs"),i(zc,"class","svelte-x2kgxs"),i(Nc,"class","svelte-x2kgxs"),i(_t,"class","svelte-x2kgxs"),i(Cc,"class","svelte-x2kgxs"),i(Gc,"class","svelte-x2kgxs"),i(Hc,"class","svelte-x2kgxs"),i(kt,"class","svelte-x2kgxs"),i(qc,"class","svelte-x2kgxs"),i(Uc,"class","svelte-x2kgxs"),i(Mc,"class","svelte-x2kgxs"),i(Et,"class","svelte-x2kgxs"),i(Bc,"class","svelte-x2kgxs"),i(Wc,"class","svelte-x2kgxs"),i(jc,"class","svelte-x2kgxs"),i(bt,"class","svelte-x2kgxs"),i(W,"class","svelte-x2kgxs"),i(Nt,"class","svelte-x2kgxs"),i(Md,"class","icon icon-link"),i(pa,"aria-hidden","true"),i(pa,"tabindex","-1"),i(pa,"href","#results"),i(ua,"id","results"),Wl(Ml.src,l5="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png")||i(Ml,"src",l5),i(Ml,"alt","image"),i(Ml,"class","svelte-x2kgxs"),i(Ul,"class","svelte-x2kgxs"),i(Bd,"class","icon icon-link"),i(da,"aria-hidden","true"),i(da,"tabindex","-1"),i(da,"href","#spacelab"),i(Ct,"id","spacelab"),i(Ct,"class","svelte-x2kgxs")},m(s,d){p(s,f,d),e(f,m),p(s,g,d),Da(h,s,d),p(s,v,d),p(s,k,d),e(k,b),e(b,T),e(k,R),p(s,x,d),p(s,E,d),e(E,y),p(s,O,d),p(s,L,d),e(L,P),e(P,G),p(s,S,d),Da(A,s,d),p(s,D,d),p(s,z,d),e(z,N),p(s,Q,d),p(s,j,d),e(j,F),p(s,B,d),p(s,C,d),e(C,I),p(s,q,d),p(s,V,d),e(V,U),e(U,w),e(w,H),e(H,La),e(w,jl),e(w,we),e(we,Fl),e(w,vm),e(w,Yl),e(Yl,_m),e(V,km),e(V,Se),e(Se,De),e(De,Vl),e(Vl,ju),e(ju,Em),e(De,bm),e(De,Kl),e(Kl,xm),e(De,ym),e(De,Xl),e(Xl,wm),e(Se,Tm),e(Se,Ae),e(Ae,Zl),e(Zl,Fu),e(Fu,Rm),e(Ae,Sm),e(Ae,Ql),e(Ql,Dm),e(Ae,Am),e(Ae,Jl),e(Jl,Lm),e(Se,Im),e(Se,Le),e(Le,$l),e($l,Yu),e(Yu,Om),e(Le,Pm),e(Le,er),e(er,zm),e(Le,Nm),e(Le,tr),e(tr,Cm),p(s,Kd,d),p(s,sr,d),e(sr,Gm),p(s,Xd,d),p(s,ar,d),e(ar,Hm),p(s,Zd,d),p(s,Ia,d),e(Ia,lr),e(lr,qm),p(s,Qd,d),p(s,Oa,d),e(Oa,Vu),e(Vu,Um),e(Oa,Mm),p(s,Jd,d),p(s,Pa,d),e(Pa,Ku),e(Ku,Bm),e(Pa,Wm),p(s,$d,d),p(s,za,d),e(za,Xu),e(Xu,jm),e(za,Fm),p(s,ef,d),p(s,Na,d),e(Na,Zu),e(Zu,Ym),e(Na,Vm),p(s,tf,d),p(s,qt,d),e(qt,Ut),e(Ut,Qu),e(qt,Km),p(s,sf,d),p(s,Ca,d),e(Ca,Ju),e(Ju,Xm),e(Ca,Zm),p(s,af,d),p(s,Ie,d),e(Ie,Qm),e(Ie,$u),e($u,Jm),e(Ie,$m),e(Ie,ep),e(ep,ev),e(Ie,tv),p(s,lf,d),p(s,Oe,d),e(Oe,rr),e(rr,tp),e(tp,sv),e(rr,av),e(Oe,lv),e(Oe,ir),e(ir,sp),e(sp,rv),e(ir,iv),e(Oe,ov),e(Oe,Mt),e(Mt,ap),e(ap,nv),e(Mt,cv),e(Mt,or),e(or,uv),e(Mt,pv),p(s,rf,d),p(s,Ga,d),e(Ga,nr),e(nr,dv),p(s,of,d),p(s,Bt,d),e(Bt,Wt),e(Wt,lp),e(Bt,rp),e(rp,fv),p(s,nf,d),p(s,cr,d),e(cr,hv),p(s,cf,d),p(s,Pe,d),e(Pe,ur),e(ur,ip),e(ip,gv),e(ur,mv),e(Pe,vv),e(Pe,pr),e(pr,op),e(op,_v),e(pr,kv),e(Pe,Ev),e(Pe,dr),e(dr,np),e(np,bv),e(dr,xv),p(s,uf,d),p(s,jt,d),e(jt,Ft),e(Ft,cp),e(jt,up),e(up,yv),p(s,pf,d),p(s,Dt,d),e(Dt,fr),e(fr,ze),e(ze,hr),e(hr,pp),e(pp,wv),e(ze,Tv),e(ze,gr),e(gr,dp),e(dp,Rv),e(ze,Sv),e(ze,mr),e(mr,fp),e(fp,Dv),e(Dt,Av),e(Dt,pe),e(pe,Ne),e(Ne,vr),e(vr,hp),e(hp,Lv),e(Ne,Iv),e(Ne,_r),e(_r,Ov),e(Ne,Pv),e(Ne,kr),e(kr,zv),e(pe,Nv),e(pe,Ce),e(Ce,Er),e(Er,gp),e(gp,Cv),e(Ce,Gv),e(Ce,br),e(br,Hv),e(Ce,qv),e(Ce,xr),e(xr,Uv),e(pe,Mv),e(pe,Ge),e(Ge,yr),e(yr,mp),e(mp,Bv),e(Ge,Wv),e(Ge,wr),e(wr,jv),e(Ge,Fv),e(Ge,Tr),e(Tr,Yv),e(pe,Vv),e(pe,He),e(He,Rr),e(Rr,vp),e(vp,Kv),e(He,Xv),e(He,Sr),e(Sr,Zv),e(He,Qv),e(He,Dr),e(Dr,Jv),p(s,df,d),p(s,Yt,d),e(Yt,Vt),e(Vt,_p),e(Yt,$v),p(s,ff,d),p(s,At,d),e(At,Ar),e(Ar,Kt),e(Kt,Lr),e(Lr,e2),e(Kt,t2),e(Kt,Ir),e(Ir,s2),e(At,a2),e(At,de),e(de,Xt),e(Xt,Or),e(Or,kp),e(kp,l2),e(Xt,r2),e(Xt,Pr),e(Pr,i2),e(de,o2),e(de,Zt),e(Zt,zr),e(zr,Ep),e(Ep,n2),e(Zt,c2),e(Zt,Nr),e(Nr,u2),e(de,p2),e(de,Qt),e(Qt,Cr),e(Cr,bp),e(bp,d2),e(Qt,f2),e(Qt,Gr),e(Gr,h2),e(de,g2),e(de,Jt),e(Jt,Hr),e(Hr,xp),e(xp,m2),e(Jt,v2),e(Jt,qr),e(qr,_2),p(s,hf,d),p(s,Ur,d),e(Ur,k2),p(s,gf,d),p(s,$t,d),e($t,es),e(es,yp),e($t,E2),p(s,mf,d),p(s,Ha,d),Ha.innerHTML=dD,p(s,vf,d),p(s,qa,d),qa.innerHTML=fD,p(s,_f,d),p(s,ts,d),e(ts,ss),e(ss,wp),e(ts,b2),p(s,kf,d),p(s,Lt,d),e(Lt,Mr),e(Mr,qe),e(qe,Br),e(Br,x2),e(qe,y2),e(qe,Wr),e(Wr,w2),e(qe,T2),e(qe,jr),e(jr,R2),e(Lt,S2),e(Lt,fe),e(fe,Ue),e(Ue,Fr),e(Fr,D2),e(Ue,A2),e(Ue,Yr),e(Yr,L2),e(Ue,I2),e(Ue,Vr),e(Vr,O2),e(fe,P2),e(fe,Me),e(Me,Kr),e(Kr,z2),e(Me,N2),e(Me,Xr),e(Xr,C2),e(Me,G2),e(Me,Zr),e(Zr,H2),e(fe,q2),e(fe,Be),e(Be,Qr),e(Qr,U2),e(Be,M2),e(Be,Jr),e(Jr,B2),e(Be,W2),e(Be,$r),e($r,j2),e(fe,F2),e(fe,We),e(We,ei),e(ei,Y2),e(We,V2),e(We,ti),e(ti,K2),e(We,X2),e(We,si),e(si,Z2),p(s,Ef,d),p(s,bf,d),p(s,xf,d),p(s,as,d),e(as,ls),e(ls,Tp),e(as,Q2),p(s,yf,d),p(s,rs,d),e(rs,J2),e(rs,Ua),e(Ua,$2),e(rs,e_),p(s,wf,d),p(s,is,d),e(is,os),e(os,Rp),e(is,t_),p(s,Tf,d),p(s,ns,d),e(ns,s_),e(ns,Ma),e(Ma,a_),e(ns,l_),p(s,Rf,d),p(s,Ba,d),Ba.innerHTML=hD,p(s,Sf,d),p(s,cs,d),e(cs,us),e(us,Sp),e(cs,r_),p(s,Df,d),p(s,je,d),e(je,Dp),e(Dp,i_),e(je,o_),e(je,Ap),e(Ap,n_),e(je,c_),e(je,Lp),e(Lp,u_),p(s,Af,d),p(s,ps,d),e(ps,ds),e(ds,Ip),e(ps,p_),p(s,Lf,d),p(s,Fe,d),e(Fe,Op),e(Op,d_),e(Fe,f_),e(Fe,Pp),e(Pp,h_),e(Fe,g_),e(Fe,zp),e(zp,m_),p(s,If,d),p(s,fs,d),e(fs,hs),e(hs,Np),e(fs,v_),p(s,Of,d),p(s,Wa,d),e(Wa,Cp),e(Cp,__),e(Wa,k_),p(s,Pf,d),p(s,ja,d),ja.innerHTML=gD,p(s,zf,d),p(s,gs,d),e(gs,ms),e(ms,Gp),e(gs,E_),p(s,Nf,d),p(s,Ye,d),e(Ye,Hp),e(Hp,b_),e(Ye,x_),e(Ye,qp),e(qp,y_),e(Ye,w_),e(Ye,Up),e(Up,T_),p(s,Cf,d),p(s,Fa,d),e(Fa,ai),e(ai,R_),p(s,Gf,d),p(s,vs,d),e(vs,_s),e(_s,Mp),e(vs,S_),p(s,Hf,d),p(s,Ya,d),e(Ya,Bp),e(Bp,D_),e(Ya,A_),p(s,qf,d),p(s,li,d),e(li,L_),p(s,Uf,d),p(s,Ve,d),e(Ve,Va),e(Va,I_),e(Va,ri),e(ri,O_),e(Va,P_),e(Ve,z_),e(Ve,Wp),e(Wp,N_),e(Ve,C_),e(Ve,jp),e(jp,G_),p(s,Mf,d),p(s,Ka,d),e(Ka,ii),e(ii,H_),p(s,Bf,d),p(s,ks,d),e(ks,Es),e(Es,Fp),e(ks,q_),p(s,Wf,d),p(s,Xa,d),e(Xa,Yp),e(Yp,U_),e(Xa,M_),p(s,jf,d),p(s,Za,d),Za.innerHTML=mD,p(s,Ff,d),p(s,oi,d),e(oi,B_),p(s,Yf,d),p(s,Ke,d),e(Ke,Vp),e(Vp,W_),e(Ke,j_),e(Ke,Kp),e(Kp,F_),e(Ke,Y_),e(Ke,Xp),e(Xp,V_),p(s,Vf,d),p(s,Qa,d),e(Qa,ni),e(ni,K_),p(s,Kf,d),p(s,bs,d),e(bs,xs),e(xs,Zp),e(bs,X_),p(s,Xf,d),p(s,ys,d),e(ys,Z_),e(ys,Qp),e(Qp,Q_),e(ys,J_),p(s,Zf,d),p(s,Ja,d),Ja.innerHTML=vD,p(s,Qf,d),p(s,$a,d),$a.innerHTML=_D,p(s,Jf,d),p(s,el,d),e(el,Jp),e(Jp,$_),e(el,e1),p(s,$f,d),p(s,Xe,d),e(Xe,$p),e($p,t1),e(Xe,s1),e(Xe,ed),e(ed,a1),e(Xe,l1),e(Xe,td),e(td,r1),p(s,eh,d),p(s,It,d),e(It,ci),e(ci,he),e(he,ui),e(ui,i1),e(he,o1),e(he,pi),e(pi,n1),e(he,c1),e(he,di),e(di,u1),e(he,p1),e(he,fi),e(fi,d1),e(It,f1),e(It,le),e(le,ge),e(ge,hi),e(hi,h1),e(ge,g1),e(ge,gi),e(gi,m1),e(ge,v1),e(ge,mi),e(mi,_1),e(ge,k1),e(ge,vi),e(vi,E1),e(le,b1),e(le,me),e(me,_i),e(_i,x1),e(me,y1),e(me,ki),e(ki,w1),e(me,T1),e(me,Ei),e(Ei,R1),e(me,S1),e(me,bi),e(bi,D1),e(le,A1),e(le,ve),e(ve,xi),e(xi,L1),e(ve,I1),e(ve,yi),e(yi,O1),e(ve,P1),e(ve,ws),e(ws,z1),e(ws,sd),e(sd,N1),e(ws,C1),e(ve,G1),e(ve,Ze),e(Ze,H1),e(Ze,wi),e(wi,q1),e(Ze,U1),e(Ze,Ti),e(Ti,M1),e(Ze,B1),e(le,W1),e(le,_e),e(_e,Ri),e(Ri,j1),e(_e,F1),e(_e,Si),e(Si,Y1),e(_e,V1),e(_e,Di),e(Di,K1),e(_e,X1),e(_e,Ai),e(Ai,Z1),e(le,Q1),e(le,ke),e(ke,Li),e(Li,J1),e(ke,$1),e(ke,Ii),e(Ii,ek),e(ke,tk),e(ke,Oi),e(Oi,sk),e(ke,ak),e(ke,Pi),e(Pi,lk),p(s,th,d),p(s,sh,d),p(s,ah,d),p(s,Ts,d),e(Ts,Rs),e(Rs,ad),e(Ts,rk),p(s,lh,d),p(s,Ss,d),e(Ss,ik),e(Ss,zi),e(zi,ok),e(Ss,nk),p(s,rh,d),p(s,ue,d),e(ue,ck),e(ue,Ni),e(Ni,uk),e(ue,pk),e(ue,Ci),e(Ci,dk),e(ue,fk),e(ue,Gi),e(Gi,hk),e(ue,gk),e(ue,Hi),e(Hi,mk),p(s,ih,d),p(s,qi,d),e(qi,vk),p(s,oh,d),p(s,Ds,d),e(Ds,As),e(As,ld),e(Ds,_k),p(s,nh,d),p(s,Qe,d),e(Qe,rd),e(rd,tl),e(tl,id),e(id,kk),e(tl,Ek),e(tl,bk),e(Qe,xk),e(Qe,od),e(od,sl),e(sl,nd),e(nd,yk),e(sl,wk),e(sl,Tk),e(Qe,Rk),e(Qe,cd),e(cd,al),e(al,ud),e(ud,Sk),e(al,Dk),e(al,Ak),p(s,ch,d),Da(ll,s,d),p(s,uh,d),p(s,Ls,d),e(Ls,Is),e(Is,pd),e(Ls,Lk),p(s,ph,d),p(s,Os,d),e(Os,Ik),e(Os,rl),e(rl,Ok),e(Os,Pk),p(s,dh,d),p(s,Je,d),e(Je,zk),e(Je,Ui),e(Ui,Nk),e(Je,Ck),e(Je,Mi),e(Mi,Gk),e(Je,Hk),p(s,fh,d),p(s,J,d),e(J,dd),e(dd,Bi),e(Bi,qk),e(Bi,Wi),e(Wi,Uk),e(J,Mk),e(J,fd),e(fd,il),e(il,Bk),e(il,ji),e(ji,Wk),e(il,jk),e(J,Fk),e(J,hd),e(hd,K),e(K,Yk),e(K,Fi),e(Fi,Vk),e(K,Kk),e(K,Yi),e(Yi,Xk),e(K,Zk),e(K,Vi),e(Vi,Qk),e(K,Jk),e(K,Ki),e(Ki,$k),e(K,eE),e(K,Xi),e(Xi,tE),e(K,sE),e(K,Zi),e(Zi,aE),e(K,lE),e(K,Qi),e(Qi,rE),e(K,iE),e(K,Ji),e(Ji,oE),e(J,nE),e(J,gd),e(gd,$),e($,cE),e($,$i),e($i,uE),e($,pE),e($,eo),e(eo,dE),e($,fE),e($,to),e(to,hE),e($,gE),e($,so),e(so,mE),e($,vE),e($,ao),e(ao,_E),e($,kE),e($,lo),e(lo,EE),e($,bE),e($,ro),e(ro,xE),e(J,yE),e(J,md),e(md,X),e(X,wE),e(X,io),e(io,TE),e(X,RE),e(X,oo),e(oo,SE),e(X,DE),e(X,no),e(no,AE),e(X,LE),e(X,co),e(co,IE),e(X,OE),e(X,uo),e(uo,PE),e(X,zE),e(X,po),e(po,NE),e(X,CE),e(X,fo),e(fo,GE),e(X,HE),e(X,ho),e(ho,qE),e(J,UE),e(J,vd),e(vd,go),e(go,ME),e(go,mo),e(mo,BE),e(J,WE),e(J,_d),e(_d,Ps),e(Ps,jE),e(Ps,vo),e(vo,FE),e(Ps,YE),e(Ps,_o),e(_o,VE),p(s,hh,d),p(s,$e,d),e($e,KE),e($e,ko),e(ko,XE),e($e,ZE),e($e,Eo),e(Eo,QE),e($e,JE),p(s,gh,d),Da(ol,s,d),p(s,mh,d),p(s,zs,d),e(zs,Ns),e(Ns,kd),e(zs,$E),p(s,vh,d),p(s,bo,d),e(bo,eb),p(s,_h,d),p(s,Ee,d),e(Ee,xo),e(xo,nl),e(nl,tb),e(xo,sb),e(Ee,ab),e(Ee,yo),e(yo,cl),e(cl,lb),e(yo,rb),e(Ee,ib),e(Ee,wo),e(wo,ul),e(ul,ob),e(wo,nb),e(Ee,cb),e(Ee,To),e(To,pl),e(pl,ub),e(To,pb),p(s,kh,d),p(s,Cs,d),e(Cs,Gs),e(Gs,Ed),e(Cs,db),p(s,Eh,d),p(s,Hs,d),e(Hs,fb),e(Hs,Ro),e(Ro,hb),e(Hs,gb),p(s,bh,d),p(s,dl,d),dl.innerHTML=kD,p(s,xh,d),p(s,et,d),e(et,mb),e(et,So),e(So,vb),e(et,_b),e(et,Do),e(Do,kb),e(et,Eb),p(s,yh,d),p(s,fl,d),e(fl,bb),e(fl,Ao),e(Ao,xb),p(s,wh,d),p(s,qs,d),e(qs,yb),e(qs,Lo),e(Lo,wb),e(qs,Tb),p(s,Th,d),p(s,Us,d),e(Us,Ms),e(Ms,bd),e(Us,Rb),p(s,Rh,d),p(s,Bs,d),e(Bs,Sb),e(Bs,hl),e(hl,Db),e(Bs,Ab),p(s,Sh,d),p(s,gl,d),e(gl,Ws),e(Ws,Lb),e(Ws,ml),e(ml,Ib),e(Ws,Ob),p(s,Dh,d),p(s,js,d),e(js,Fs),e(Fs,xd),e(js,Pb),p(s,Ah,d),p(s,Ys,d),e(Ys,zb),e(Ys,Io),e(Io,Nb),e(Ys,Cb),p(s,Lh,d),p(s,vl,d),vl.innerHTML=ED,p(s,Ih,d),p(s,Oo,d),e(Oo,Gb),p(s,Oh,d),p(s,_l,d),_l.innerHTML=bD,p(s,Ph,d),p(s,tt,d),e(tt,Hb),e(tt,Po),e(Po,qb),e(tt,Ub),e(tt,zo),e(zo,Mb),e(tt,Bb),p(s,zh,d),p(s,st,d),e(st,Wb),e(st,No),e(No,jb),e(st,Fb),e(st,Co),e(Co,Yb),e(st,Vb),p(s,Nh,d),p(s,Go,d),e(Go,Kb),p(s,Ch,d),p(s,Vs,d),e(Vs,Ho),e(Ho,Xb),e(Ho,yd),e(yd,wd),e(wd,Zb),e(Vs,Qb),e(Vs,qo),e(qo,Jb),e(qo,Td),e(Td,Rd),e(Rd,$b),p(s,Gh,d),p(s,Uo,d),e(Uo,ex),p(s,Hh,d),p(s,kl,d),e(kl,El),p(s,qh,d),p(s,Ks,d),e(Ks,Xs),e(Xs,Sd),e(Ks,tx),p(s,Uh,d),p(s,Ot,d),e(Ot,sx),e(Ot,Mo),e(Mo,ax),e(Ot,lx),e(Ot,Bo),e(Bo,rx),p(s,Mh,d),p(s,Pt,d),e(Pt,Wo),e(Wo,re),e(re,jo),e(jo,ix),e(re,ox),e(re,Fo),e(Fo,nx),e(re,cx),e(re,Yo),e(Yo,ux),e(re,px),e(re,Vo),e(Vo,dx),e(re,fx),e(re,Ko),e(Ko,hx),e(Pt,gx),e(Pt,Xo),e(Xo,ie),e(ie,Zo),e(Zo,mx),e(ie,vx),e(ie,Qo),e(Qo,_x),e(ie,kx),e(ie,Jo),e(Jo,Ex),e(ie,bx),e(ie,$o),e($o,xx),e(ie,yx),e(ie,en),e(en,wx),p(s,Bh,d),p(s,tn,d),e(tn,Tx),p(s,Wh,d),p(s,bl,d),bl.innerHTML=xD,p(s,jh,d),p(s,M,d),e(M,sn),e(sn,xl),e(xl,Rx),e(xl,an),e(an,Sx),e(xl,Dx),e(sn,Ax),e(M,Lx),e(M,ln),e(ln,yl),e(yl,Ix),e(yl,rn),e(rn,Ox),e(yl,Px),e(ln,zx),e(M,Nx),e(M,on),e(on,wl),e(wl,Cx),e(wl,nn),e(nn,Gx),e(wl,Hx),e(on,qx),e(M,Ux),e(M,cn),e(cn,Tl),e(Tl,Mx),e(Tl,un),e(un,Bx),e(Tl,Wx),e(cn,jx),e(M,Fx),e(M,pn),e(pn,Rl),e(Rl,Yx),e(Rl,dn),e(dn,Vx),e(Rl,Kx),e(pn,Xx),e(M,Zx),e(M,fn),e(fn,Sl),e(Sl,Qx),e(Sl,hn),e(hn,Jx),e(Sl,$x),e(fn,ey),e(M,ty),e(M,gn),e(gn,Dl),e(Dl,sy),e(Dl,mn),e(mn,ay),e(Dl,ly),e(gn,ry),e(M,iy),e(M,vn),e(vn,Al),e(Al,oy),e(Al,_n),e(_n,ny),e(Al,cy),e(vn,uy),e(M,py),e(M,kn),e(kn,Ll),e(Ll,dy),e(Ll,En),e(En,fy),e(Ll,hy),e(kn,gy),e(M,my),e(M,bn),e(bn,Il),e(Il,vy),e(Il,xn),e(xn,_y),e(Il,ky),e(bn,Ey),e(M,by),e(M,yn),e(yn,Ol),e(Ol,xy),e(Ol,wn),e(wn,yy),e(Ol,wy),e(yn,Ty),p(s,Fh,d),p(s,Zs,d),e(Zs,Qs),e(Qs,Dd),e(Zs,Ry),p(s,Yh,d),p(s,Tn,d),e(Tn,Sy),p(s,Vh,d),Da(Pl,s,d),p(s,Kh,d),p(s,Js,d),e(Js,$s),e($s,Ad),e(Js,Dy),p(s,Xh,d),p(s,ea,d),e(ea,Ay),e(ea,zl),e(zl,Ly),e(ea,Iy),p(s,Zh,d),p(s,ta,d),e(ta,Oy),e(ta,Rn),e(Rn,Py),e(ta,zy),p(s,Qh,d),p(s,oe,d),e(oe,Sn),e(Sn,Ny),e(Sn,Jh),e(oe,Cy),e(oe,Ld),e(Ld,Gy),e(oe,Hy),e(oe,at),e(at,qy),e(at,Dn),e(Dn,Uy),e(at,My),e(at,An),e(An,By),e(at,Wy),e(at,Ln),e(Ln,jy),e(oe,Fy),e(oe,In),e(In,Yy),e(In,On),e(On,Vy),e(oe,Ky),e(oe,sa),e(sa,Xy),e(sa,Pn),e(Pn,Zy),e(sa,Qy),e(sa,zn),e(zn,Jy),p(s,$h,d),p(s,lt,d),e(lt,$y),e(lt,Nn),e(Nn,e3),e(lt,t3),e(lt,Cn),e(Cn,s3),e(lt,a3),p(s,eg,d),p(s,be,d),e(be,aa),e(aa,l3),e(aa,Gn),e(Gn,r3),e(aa,i3),e(aa,Hn),e(Hn,o3),e(be,n3),e(be,Nl),e(Nl,c3),e(Nl,qn),e(qn,u3),e(Nl,p3),e(be,d3),e(be,Id),e(Id,f3),e(be,h3),e(be,Od),e(Od,g3),p(s,tg,d),p(s,la,d),e(la,ra),e(ra,Pd),e(la,m3),p(s,sg,d),p(s,xe,d),e(xe,Un),e(Un,zd),e(zd,v3),e(Un,_3),e(xe,k3),e(xe,Mn),e(Mn,Nd),e(Nd,E3),e(Mn,b3),e(xe,x3),e(xe,Bn),e(Bn,Cd),e(Cd,y3),e(Bn,w3),e(xe,T3),e(xe,Wn),e(Wn,Gd),e(Gd,R3),e(Wn,S3),p(s,ag,d),p(s,jn,d),e(jn,D3),p(s,lg,d),p(s,Cl,d),e(Cl,Gl),p(s,rg,d),p(s,ia,d),e(ia,oa),e(oa,Hd),e(ia,A3),p(s,ig,d),p(s,Fn,d),e(Fn,L3),p(s,og,d),p(s,rt,d),e(rt,Hl),e(Hl,I3),e(Hl,Yn),e(Yn,O3),e(Hl,P3),e(rt,z3),e(rt,ql),e(ql,N3),e(ql,Vn),e(Vn,C3),e(ql,G3),e(rt,H3),e(rt,qd),e(qd,q3),p(s,ng,d),p(s,zt,d),e(zt,Kn),e(Kn,it),e(it,Xn),e(Xn,U3),e(it,M3),e(it,Zn),e(Zn,B3),e(it,W3),e(it,Qn),e(Qn,j3),e(zt,F3),e(zt,ye),e(ye,ot),e(ot,Jn),e(Jn,Y3),e(ot,V3),e(ot,$n),e($n,K3),e(ot,X3),e(ot,ec),e(ec,Z3),e(ye,Q3),e(ye,nt),e(nt,tc),e(tc,J3),e(nt,$3),e(nt,sc),e(sc,e4),e(nt,t4),e(nt,ac),e(ac,s4),e(ye,a4),e(ye,ct),e(ct,lc),e(lc,l4),e(ct,r4),e(ct,rc),e(rc,i4),e(ct,o4),e(ct,ic),e(ic,n4),e(ye,c4),e(ye,ut),e(ut,oc),e(oc,u4),e(ut,p4),e(ut,nc),e(nc,d4),e(ut,f4),e(ut,cc),e(cc,h4),p(s,cg,d),p(s,na,d),e(na,ca),e(ca,Ud),e(na,g4),p(s,ug,d),p(s,uc,d),e(uc,m4),p(s,pg,d),p(s,Nt,d),e(Nt,pc),e(pc,pt),e(pt,dc),e(dc,v4),e(pt,_4),e(pt,fc),e(fc,k4),e(pt,E4),e(pt,hc),e(hc,b4),e(Nt,x4),e(Nt,W),e(W,dt),e(dt,gc),e(gc,y4),e(dt,w4),e(dt,mc),e(mc,T4),e(dt,R4),e(dt,vc),e(vc,S4),e(W,D4),e(W,ft),e(ft,_c),e(_c,A4),e(ft,L4),e(ft,kc),e(kc,I4),e(ft,O4),e(ft,Ec),e(Ec,P4),e(W,z4),e(W,ht),e(ht,bc),e(bc,N4),e(ht,C4),e(ht,xc),e(xc,G4),e(ht,H4),e(ht,yc),e(yc,q4),e(W,U4),e(W,gt),e(gt,wc),e(wc,M4),e(gt,B4),e(gt,Tc),e(Tc,W4),e(gt,j4),e(gt,Rc),e(Rc,F4),e(W,Y4),e(W,mt),e(mt,Sc),e(Sc,V4),e(mt,K4),e(mt,Dc),e(Dc,X4),e(mt,Z4),e(mt,Ac),e(Ac,Q4),e(W,J4),e(W,vt),e(vt,Lc),e(Lc,$4),e(vt,e0),e(vt,Ic),e(Ic,t0),e(vt,s0),e(vt,Oc),e(Oc,a0),e(W,l0),e(W,_t),e(_t,Pc),e(Pc,r0),e(_t,i0),e(_t,zc),e(zc,o0),e(_t,n0),e(_t,Nc),e(Nc,c0),e(W,u0),e(W,kt),e(kt,Cc),e(Cc,p0),e(kt,d0),e(kt,Gc),e(Gc,f0),e(kt,h0),e(kt,Hc),e(Hc,g0),e(W,m0),e(W,Et),e(Et,qc),e(qc,v0),e(Et,_0),e(Et,Uc),e(Uc,k0),e(Et,E0),e(Et,Mc),e(Mc,b0),e(W,x0),e(W,bt),e(bt,Bc),e(Bc,y0),e(bt,w0),e(bt,Wc),e(Wc,T0),e(bt,R0),e(bt,jc),e(jc,S0),p(s,dg,d),p(s,ua,d),e(ua,pa),e(pa,Md),e(ua,D0),p(s,fg,d),p(s,Fc,d),e(Fc,A0),p(s,hg,d),p(s,Yc,d),e(Yc,L0),p(s,gg,d),p(s,Ul,d),e(Ul,Ml),p(s,mg,d),p(s,Vc,d),e(Vc,I0),p(s,vg,d),p(s,Ct,d),e(Ct,da),e(da,Bd),e(Ct,O0),p(s,_g,d),Te&&Te.m(s,d),p(s,kg,d),Eg=!0},p(s,d){pD&&Te.p(s,d)},i(s){Eg||(Rt(h.$$.fragment,s),Rt(A.$$.fragment,s),Rt(ll.$$.fragment,s),Rt(ol.$$.fragment,s),Rt(Pl.$$.fragment,s),Rt(Te),Eg=!0)},o(s){St(h.$$.fragment,s),St(A.$$.fragment,s),St(ll.$$.fragment,s),St(ol.$$.fragment,s),St(Pl.$$.fragment,s),St(Te),Eg=!1},d(s){s&&t(f),s&&t(g),Aa(h,s),s&&t(v),s&&t(k),s&&t(x),s&&t(E),s&&t(O),s&&t(L),s&&t(S),Aa(A,s),s&&t(D),s&&t(z),s&&t(Q),s&&t(j),s&&t(B),s&&t(C),s&&t(q),s&&t(V),s&&t(Kd),s&&t(sr),s&&t(Xd),s&&t(ar),s&&t(Zd),s&&t(Ia),s&&t(Qd),s&&t(Oa),s&&t(Jd),s&&t(Pa),s&&t($d),s&&t(za),s&&t(ef),s&&t(Na),s&&t(tf),s&&t(qt),s&&t(sf),s&&t(Ca),s&&t(af),s&&t(Ie),s&&t(lf),s&&t(Oe),s&&t(rf),s&&t(Ga),s&&t(of),s&&t(Bt),s&&t(nf),s&&t(cr),s&&t(cf),s&&t(Pe),s&&t(uf),s&&t(jt),s&&t(pf),s&&t(Dt),s&&t(df),s&&t(Yt),s&&t(ff),s&&t(At),s&&t(hf),s&&t(Ur),s&&t(gf),s&&t($t),s&&t(mf),s&&t(Ha),s&&t(vf),s&&t(qa),s&&t(_f),s&&t(ts),s&&t(kf),s&&t(Lt),s&&t(Ef),s&&t(bf),s&&t(xf),s&&t(as),s&&t(yf),s&&t(rs),s&&t(wf),s&&t(is),s&&t(Tf),s&&t(ns),s&&t(Rf),s&&t(Ba),s&&t(Sf),s&&t(cs),s&&t(Df),s&&t(je),s&&t(Af),s&&t(ps),s&&t(Lf),s&&t(Fe),s&&t(If),s&&t(fs),s&&t(Of),s&&t(Wa),s&&t(Pf),s&&t(ja),s&&t(zf),s&&t(gs),s&&t(Nf),s&&t(Ye),s&&t(Cf),s&&t(Fa),s&&t(Gf),s&&t(vs),s&&t(Hf),s&&t(Ya),s&&t(qf),s&&t(li),s&&t(Uf),s&&t(Ve),s&&t(Mf),s&&t(Ka),s&&t(Bf),s&&t(ks),s&&t(Wf),s&&t(Xa),s&&t(jf),s&&t(Za),s&&t(Ff),s&&t(oi),s&&t(Yf),s&&t(Ke),s&&t(Vf),s&&t(Qa),s&&t(Kf),s&&t(bs),s&&t(Xf),s&&t(ys),s&&t(Zf),s&&t(Ja),s&&t(Qf),s&&t($a),s&&t(Jf),s&&t(el),s&&t($f),s&&t(Xe),s&&t(eh),s&&t(It),s&&t(th),s&&t(sh),s&&t(ah),s&&t(Ts),s&&t(lh),s&&t(Ss),s&&t(rh),s&&t(ue),s&&t(ih),s&&t(qi),s&&t(oh),s&&t(Ds),s&&t(nh),s&&t(Qe),s&&t(ch),Aa(ll,s),s&&t(uh),s&&t(Ls),s&&t(ph),s&&t(Os),s&&t(dh),s&&t(Je),s&&t(fh),s&&t(J),s&&t(hh),s&&t($e),s&&t(gh),Aa(ol,s),s&&t(mh),s&&t(zs),s&&t(vh),s&&t(bo),s&&t(_h),s&&t(Ee),s&&t(kh),s&&t(Cs),s&&t(Eh),s&&t(Hs),s&&t(bh),s&&t(dl),s&&t(xh),s&&t(et),s&&t(yh),s&&t(fl),s&&t(wh),s&&t(qs),s&&t(Th),s&&t(Us),s&&t(Rh),s&&t(Bs),s&&t(Sh),s&&t(gl),s&&t(Dh),s&&t(js),s&&t(Ah),s&&t(Ys),s&&t(Lh),s&&t(vl),s&&t(Ih),s&&t(Oo),s&&t(Oh),s&&t(_l),s&&t(Ph),s&&t(tt),s&&t(zh),s&&t(st),s&&t(Nh),s&&t(Go),s&&t(Ch),s&&t(Vs),s&&t(Gh),s&&t(Uo),s&&t(Hh),s&&t(kl),s&&t(qh),s&&t(Ks),s&&t(Uh),s&&t(Ot),s&&t(Mh),s&&t(Pt),s&&t(Bh),s&&t(tn),s&&t(Wh),s&&t(bl),s&&t(jh),s&&t(M),s&&t(Fh),s&&t(Zs),s&&t(Yh),s&&t(Tn),s&&t(Vh),Aa(Pl,s),s&&t(Kh),s&&t(Js),s&&t(Xh),s&&t(ea),s&&t(Zh),s&&t(ta),s&&t(Qh),s&&t(oe),s&&t($h),s&&t(lt),s&&t(eg),s&&t(be),s&&t(tg),s&&t(la),s&&t(sg),s&&t(xe),s&&t(ag),s&&t(jn),s&&t(lg),s&&t(Cl),s&&t(rg),s&&t(ia),s&&t(ig),s&&t(Fn),s&&t(og),s&&t(rt),s&&t(ng),s&&t(zt),s&&t(cg),s&&t(na),s&&t(ug),s&&t(uc),s&&t(pg),s&&t(Nt),s&&t(dg),s&&t(ua),s&&t(fg),s&&t(Fc),s&&t(hg),s&&t(Yc),s&&t(gg),s&&t(Ul),s&&t(mg),s&&t(Vc),s&&t(vg),s&&t(Ct),s&&t(_g),Te&&Te.d(s),s&&t(kg)}}}function m9(_){let f,m;const g=[_[0],t5];let h={$$slots:{default:[g9]},$$scope:{ctx:_}};for(let v=0;v<g.length;v+=1)h=e5(h,g[v]);return f=new MD({props:h}),{c(){Ra(f.$$.fragment)},l(v){Sa(f.$$.fragment,v)},m(v,k){Da(f,v,k),m=!0},p(v,[k]){const b=k&1?UD(g,[k&1&&lD(v[0]),k&0&&lD(t5)]):{};k&2&&(b.$$scope={dirty:k,ctx:v}),f.$set(b)},i(v){m||(Rt(f.$$.fragment,v),m=!0)},o(v){St(f.$$.fragment,v),m=!1},d(v){Aa(f,v)}}}const t5={title:"Action Figure Art",date:"2025-01-28 11:00:20",modifiedDate:"2025-01-29 15:00:00",categories:["stable diffusion","ai training"],svg:"ActionFigure",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Artwork created with action figure training sets.",author:"Ryan Sadwick",spacelab:!0,id:1,spacelabDefaultTitle:"Training Dataset",spacelabDefaultContent:"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.",menu:[{name:"Regularization?",icon:"\u2696\uFE0F",url:"/blog/action-figure-art/#what-are-regularization-images"},{name:"Divergence",icon:"\u{1F4A5}",url:"/blog/action-figure-art/#divergence"},{name:"Overfitting",icon:"\u{1F3AD}",url:"/blog/action-figure-art/#overfitting"},{name:"Generating",icon:"\u2728",url:"/blog/action-figure-art/#generating-regularization-images"},{name:"Train LoRA",icon:"\u{1F373}",url:"/blog/action-figure-art/#training-a-lora"},{name:"Troubleshooting",icon:"\u{1F6E0}\uFE0F",url:"/blog/action-figure-art/#troubleshooting"},{name:"Results",icon:"\u{1F4CA}",url:"/blog/action-figure-art/#results"},{name:"Spacelab Content",icon:"\u{1F512}",url:"/blog/action-figure-art/#spacelab"}],keywords:["stable diffusion","generative ai","lora","machine learning","action figures","python"]},{title:A9,date:L9,modifiedDate:I9,categories:O9,svg:P9,seoImage:z9,shortDescription:N9,author:C9,spacelab:pD,id:v9,spacelabDefaultTitle:_9,spacelabDefaultContent:k9,menu:G9,keywords:H9}=t5;function E9(_,f,m){return _.$$set=g=>{m(0,f=e5(e5({},f),rD(g)))},f=rD(f),[f]}class q9 extends hm{constructor(f){super(),gm(this,f,E9,m9,mm,{})}}export{q9 as default,t5 as metadata};
