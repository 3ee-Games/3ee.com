import{S as Ya,i as Qa,s as Ja,l as Ra,g as r,E as Xe,d as t,v as al,e as o,t as h,c as n,a as p,h as m,b as w,I as i,j as ne,k as b,m as _,H as oe,J as Xa,C as Ri,w as Za,x as el,y as tl,z as ll,A as Ma,q as Fi,o as Wi,B as il,Y as Fa,R as sl}from"../../chunks/index-8ca01e64.js";import{P as rl}from"../../chunks/_post-7867e3e5.js";import{a as ol}from"../../chunks/accountStore-c3ff6133.js";import"../../chunks/index-12b3acf3.js";function nl(g){let a,c,l,f,s,y,S,L,I,H,O,x,A,$,N,C,j,U,M,W;function V(v,k){return typeof v[0].title!="undefined"?ul:pl}let T=V(g),D=T(g);function B(v,k){return typeof v[0].description!="undefined"?cl:dl}let G=B(g),P=G(g),E=typeof g[0].list_description!="undefined"&&Wa(g),d=typeof g[0].footer_description!="undefined"&&Ba(g);return{c(){a=o("hr"),c=b(),l=o("div"),D.c(),f=b(),s=o("p"),y=o("ion-icon"),S=h("SpaceLab Content"),L=b(),P.c(),I=b(),E&&E.c(),H=b(),d&&d.c(),O=b(),x=o("button"),A=o("ion-icon"),$=b(),N=o("span"),C=h("SpaceLab"),j=b(),U=o("hr"),this.h()},l(v){a=n(v,"HR",{}),c=_(v),l=n(v,"DIV",{class:!0});var k=p(l);D.l(k),f=_(k),s=n(k,"P",{class:!0});var q=p(s);y=n(q,"ION-ICON",{class:!0,name:!0}),p(y).forEach(t),S=m(q,"SpaceLab Content"),q.forEach(t),L=_(k),P.l(k),I=_(k),E&&E.l(k),H=_(k),d&&d.l(k),O=_(k),x=n(k,"BUTTON",{class:!0});var R=p(x);A=n(R,"ION-ICON",{class:!0,name:!0}),p(A).forEach(t),$=_(R),N=n(R,"SPAN",{});var Y=p(N);C=m(Y,"SpaceLab"),Y.forEach(t),R.forEach(t),k.forEach(t),j=_(v),U=n(v,"HR",{}),this.h()},h(){oe(y,"class","icon svelte-vjvavh"),oe(y,"name","lock-closed"),w(s,"class","highlight large svelte-vjvavh"),oe(A,"class","icon svelte-vjvavh"),oe(A,"name","planet"),w(x,"class","button subscribe svelte-vjvavh"),w(l,"class","subscribe svelte-vjvavh")},m(v,k){r(v,a,k),r(v,c,k),r(v,l,k),D.m(l,null),i(l,f),i(l,s),i(s,y),i(s,S),i(l,L),P.m(l,null),i(l,I),E&&E.m(l,null),i(l,H),d&&d.m(l,null),i(l,O),i(l,x),i(x,A),i(x,$),i(x,N),i(N,C),r(v,j,k),r(v,U,k),M||(W=Xa(x,"click",g[3]),M=!0)},p(v,k){T===(T=V(v))&&D?D.p(v,k):(D.d(1),D=T(v),D&&(D.c(),D.m(l,f))),G===(G=B(v))&&P?P.p(v,k):(P.d(1),P=G(v),P&&(P.c(),P.m(l,I))),typeof v[0].list_description!="undefined"?E?E.p(v,k):(E=Wa(v),E.c(),E.m(l,H)):E&&(E.d(1),E=null),typeof v[0].footer_description!="undefined"?d?d.p(v,k):(d=Ba(v),d.c(),d.m(l,O)):d&&(d.d(1),d=null)},d(v){v&&t(a),v&&t(c),v&&t(l),D.d(),P.d(),E&&E.d(),d&&d.d(),v&&t(j),v&&t(U),M=!1,W()}}}function fl(g){let a,c,l,f=g[0].title+"",s,y,S,L,I,H,O,x=g[0].description+"",A,$,N,C,j,U,M,W,V,T,D,B,G,P=typeof g[0].list_description!="undefined"&&Va(g),E=typeof g[0].footer_description!="undefined"&&Ga(g);return{c(){a=o("hr"),c=b(),l=o("h2"),s=h(f),y=b(),S=o("p"),L=o("ion-icon"),I=h("SpaceLab Content"),H=b(),O=o("p"),A=h(x),$=b(),P&&P.c(),N=b(),E&&E.c(),C=b(),j=o("button"),U=o("ion-icon"),M=b(),W=o("span"),V=h("Download"),T=b(),D=o("hr"),this.h()},l(d){a=n(d,"HR",{}),c=_(d),l=n(d,"H2",{class:!0});var v=p(l);s=m(v,f),v.forEach(t),y=_(d),S=n(d,"P",{class:!0});var k=p(S);L=n(k,"ION-ICON",{class:!0,name:!0}),p(L).forEach(t),I=m(k,"SpaceLab Content"),k.forEach(t),H=_(d),O=n(d,"P",{class:!0});var q=p(O);A=m(q,x),q.forEach(t),$=_(d),P&&P.l(d),N=_(d),E&&E.l(d),C=_(d),j=n(d,"BUTTON",{class:!0});var R=p(j);U=n(R,"ION-ICON",{class:!0,name:!0}),p(U).forEach(t),M=_(R),W=n(R,"SPAN",{});var Y=p(W);V=m(Y,"Download"),Y.forEach(t),R.forEach(t),T=_(d),D=n(d,"HR",{}),this.h()},h(){w(l,"class","svelte-vjvavh"),oe(L,"class","icon svelte-vjvavh"),oe(L,"name","planet-sharp"),w(S,"class","highlight large svelte-vjvavh"),w(O,"class","svelte-vjvavh"),oe(U,"class","icon svelte-vjvavh"),oe(U,"name","cloud-download"),w(j,"class","button svelte-vjvavh")},m(d,v){r(d,a,v),r(d,c,v),r(d,l,v),i(l,s),r(d,y,v),r(d,S,v),i(S,L),i(S,I),r(d,H,v),r(d,O,v),i(O,A),r(d,$,v),P&&P.m(d,v),r(d,N,v),E&&E.m(d,v),r(d,C,v),r(d,j,v),i(j,U),i(j,M),i(j,W),i(W,V),r(d,T,v),r(d,D,v),B||(G=Xa(j,"click",g[2]),B=!0)},p(d,v){v&1&&f!==(f=d[0].title+"")&&ne(s,f),v&1&&x!==(x=d[0].description+"")&&ne(A,x),typeof d[0].list_description!="undefined"?P?P.p(d,v):(P=Va(d),P.c(),P.m(N.parentNode,N)):P&&(P.d(1),P=null),typeof d[0].footer_description!="undefined"?E?E.p(d,v):(E=Ga(d),E.c(),E.m(C.parentNode,C)):E&&(E.d(1),E=null)},d(d){d&&t(a),d&&t(c),d&&t(l),d&&t(y),d&&t(S),d&&t(H),d&&t(O),d&&t($),P&&P.d(d),d&&t(N),E&&E.d(d),d&&t(C),d&&t(j),d&&t(T),d&&t(D),B=!1,G()}}}function pl(g){let a,c;return{c(){a=o("h2"),c=h("SpaceLab Content"),this.h()},l(l){a=n(l,"H2",{class:!0});var f=p(a);c=m(f,"SpaceLab Content"),f.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(l,f){r(l,a,f),i(a,c)},p:Xe,d(l){l&&t(a)}}}function ul(g){let a,c=g[0].title+"",l;return{c(){a=o("h2"),l=h(c),this.h()},l(f){a=n(f,"H2",{class:!0});var s=p(a);l=m(s,c),s.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(f,s){r(f,a,s),i(a,l)},p(f,s){s&1&&c!==(c=f[0].title+"")&&ne(l,c)},d(f){f&&t(a)}}}function dl(g){let a,c;return{c(){a=o("p"),c=h("To access this content, you need a SpaceLab subscription."),this.h()},l(l){a=n(l,"P",{class:!0});var f=p(a);c=m(f,"To access this content, you need a SpaceLab subscription."),f.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(l,f){r(l,a,f),i(a,c)},p:Xe,d(l){l&&t(a)}}}function cl(g){let a,c=g[0].description+"",l;return{c(){a=o("p"),l=h(c),this.h()},l(f){a=n(f,"P",{class:!0});var s=p(a);l=m(s,c),s.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(f,s){r(f,a,s),i(a,l)},p(f,s){s&1&&c!==(c=f[0].description+"")&&ne(l,c)},d(f){f&&t(a)}}}function Wa(g){let a,c,l=g[0].list_description+"",f;return{c(){a=o("div"),c=o("p"),f=h(l),this.h()},l(s){a=n(s,"DIV",{class:!0});var y=p(a);c=n(y,"P",{class:!0});var S=p(c);f=m(S,l),S.forEach(t),y.forEach(t),this.h()},h(){w(c,"class","svelte-vjvavh"),w(a,"class","list-description svelte-vjvavh")},m(s,y){r(s,a,y),i(a,c),i(c,f)},p(s,y){y&1&&l!==(l=s[0].list_description+"")&&ne(f,l)},d(s){s&&t(a)}}}function Ba(g){let a,c=g[0].footer_description+"",l;return{c(){a=o("p"),l=h(c),this.h()},l(f){a=n(f,"P",{class:!0});var s=p(a);l=m(s,c),s.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(f,s){r(f,a,s),i(a,l)},p(f,s){s&1&&c!==(c=f[0].footer_description+"")&&ne(l,c)},d(f){f&&t(a)}}}function Va(g){let a,c,l=g[0].list_description+"",f;return{c(){a=o("div"),c=o("p"),f=h(l),this.h()},l(s){a=n(s,"DIV",{class:!0});var y=p(a);c=n(y,"P",{class:!0});var S=p(c);f=m(S,l),S.forEach(t),y.forEach(t),this.h()},h(){w(c,"class","svelte-vjvavh"),w(a,"class","list-description svelte-vjvavh")},m(s,y){r(s,a,y),i(a,c),i(c,f)},p(s,y){y&1&&l!==(l=s[0].list_description+"")&&ne(f,l)},d(s){s&&t(a)}}}function Ga(g){let a,c=g[0].footer_description+"",l;return{c(){a=o("p"),l=h(c),this.h()},l(f){a=n(f,"P",{class:!0});var s=p(a);l=m(s,c),s.forEach(t),this.h()},h(){w(a,"class","svelte-vjvavh")},m(f,s){r(f,a,s),i(a,l)},p(f,s){s&1&&c!==(c=f[0].footer_description+"")&&ne(l,c)},d(f){f&&t(a)}}}function hl(g){let a;function c(s,y){return typeof s[0]!="undefined"&&typeof s[0].pk!="undefined"?fl:nl}let l=c(g),f=l(g);return{c(){f.c(),a=Ra()},l(s){f.l(s),a=Ra()},m(s,y){f.m(s,y),r(s,a,y)},p(s,[y]){l===(l=c(s))&&f?f.p(s,y):(f.d(1),f=l(s),f&&(f.c(),f.m(a.parentNode,a)))},i:Xe,o:Xe,d(s){f.d(s),s&&t(a)}}}function ml(g,a,c){let{id:l}=a,f={},s;ol.subscribe(L=>{s=L}),al(async()=>{if(typeof(s==null?void 0:s.token)!="undefined"){let I=await(await fetch(`https://3ee.dev/education/spacelab/${l}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+s.token},mode:"cors"})).json();c(0,f=I)}else c(0,f.success=!1,f)});const y=()=>window.open(f.url,"_blank"),S=()=>window.open("/spacelab/","_blank");return g.$$set=L=>{"id"in L&&c(1,l=L.id)},[f,l,y,S]}class vl extends Ya{constructor(a){super(),Qa(this,a,ml,hl,Ja,{id:1})}}function bl(g){let a,c;return a=new vl({props:{id:gl}}),{c(){Za(a.$$.fragment)},l(l){el(a.$$.fragment,l)},m(l,f){tl(a,l,f),c=!0},p:Xe,i(l){c||(Fi(a.$$.fragment,l),c=!0)},o(l){Wi(a.$$.fragment,l),c=!1},d(l){il(a,l)}}}function _l(g){let a,c,l,f,s,y,S,L,I,H,O,x,A,$,N,C,j,U,M,W,V,T,D,B,G,P,E,d,v,k,q,R,Y,Ht,Ce,$t,Ze,ue,qt,et,de,Rt,tt,ce,Mt,it,Q,Te,Ft,Wt,ze,Bt,at,he,Vt,lt,me,Gt,st,ve,Kt,rt,J,X,Oe,Yt,ot,be,Qt,nt,Z,Jt,Ne,Xt,Zt,ft,ee,ei,Ue,ti,ii,pt,te,ie,He,ai,ut,_e,li,dt,we,$e,si,ct,ge,ri,ht,ye,qe,oi,mt,Ee,Re,ni,vt,ke,fe,fi,pe,pi,ui,bt,_t,ae,le,Me,di,wt,Pe,ci,gt,Se,hi,yt,Le,mi,Et,xe,vi,kt,se,re,Fe,bi,Pt,De,_i,St,Ie,We,wi,Lt,je,gi,xt,z,Be,yi,Ei,Ve,ki,Pi,Ge,Si,Li,Ke,xi,Di,Ye,Ii,ji,Qe,Ai,Ci,Je,Ti,Dt,Ae,zi,It,jt,At,K=Ka&&bl();return{c(){a=o("p"),c=h("A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),l=b(),f=o("p"),s=o("img"),S=b(),L=o("h2"),I=o("a"),H=o("span"),O=h("What is Textual Inversion?"),x=b(),A=o("blockquote"),$=o("p"),N=h("\u{1F4C4} See the paper: "),C=o("a"),j=h("https://arxiv.org/abs/2208.01618"),U=b(),M=o("p"),W=h("Stable Diffusion is a denoising tool which is fine-tuned to predict what is noise in an image to remove it. Running that process 20 to 40 times in a row on pure noise can repair it into a brand new image."),V=b(),T=o("p"),D=h("Stable Diffusion uses a diffusion model called a "),B=o("strong"),G=h("latent diffusion model"),P=h(" (LDM).  The CLIP encoder describes images with 768 latents (in SD 1.x models - SD 2.x uses 1024), where each latent is a spectrum of some type of feature."),E=b(),d=o("p"),v=h("Examples:"),k=b(),q=o("ul"),R=o("li"),Y=h("At one end might be round objects and at the other end might be square objects, but it\u2019s much more complex than that."),Ht=b(),Ce=o("li"),$t=h("At one end might be chairs, and at another end might be giraffes."),Ze=b(),ue=o("p"),qt=h("These feature spectrums are probably beyond human understanding."),et=b(),de=o("p"),Rt=h("The latents were built with captions where words can also be encoded to these same latents (e.g. \u2018cat\u2019, \u2018planet\u2019, \u2018spaceship\u2019, etc, each concept can be described in 768 values of various spectrums)."),tt=b(),ce=o("p"),Mt=h("Stable Diffusion is guided by those latents:"),it=b(),Q=o("ul"),Te=o("li"),Ft=h("Learns to understand what each one means when you inference using prompts."),Wt=b(),ze=o("li"),Bt=h("Gives each a weighting to different areas of an image."),at=b(),he=o("p"),Vt=h("While training, it\u2019s possible to introduce latents never trained on using textual inversion or manually combining existing word latents.  Stable Diffusion will draw those concepts because it learned to understand those spectrums of ideas - not copy existing content."),lt=b(),me=o("p"),Gt=h("For example, you can combine 50% of cat and 50% of a kangaroo and it can draw a cat-kangaroo hybrid creature which it never trained on."),st=b(),ve=o("p"),Kt=h("You can find the latents which describe your own face, or a new artstyle - despite it never training on it."),rt=b(),J=o("h2"),X=o("a"),Oe=o("span"),Yt=h("Embedding Usage"),ot=b(),be=o("p"),Qt=h("Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),nt=b(),Z=o("p"),Jt=h("\u2728 V2: Use the token "),Ne=o("code"),Xt=h("aubreyplazav2-300"),Zt=h(" in your prompts to activate the embedding."),ft=b(),ee=o("p"),ei=h("\u2728 V1: Use the token "),Ue=o("code"),ti=h("aubreyplazav1-7375"),ii=h(" in your prompts to activate the embedding."),pt=b(),te=o("h2"),ie=o("a"),He=o("span"),ai=h("Prompt Example"),ut=b(),_e=o("p"),li=h("\u{1F9FE} Prompt:"),dt=b(),we=o("p"),$e=o("code"),si=h("Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),ct=b(),ge=o("p"),ri=h("\u2796 Negative:"),ht=b(),ye=o("p"),qe=o("code"),oi=h("(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),mt=b(),Ee=o("p"),Re=o("em"),ni=h("Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),vt=b(),ke=o("blockquote"),fe=o("p"),fi=h("\u{1F305} For more information on how to use this embedding, see "),pe=o("a"),pi=h("https://huggingface.co/datasets/zuleo/aubrey-plaza"),ui=h("."),bt=b(),K&&K.c(),_t=b(),ae=o("h2"),le=o("a"),Me=o("span"),di=h("Understanding Learning Rates"),wt=b(),Pe=o("p"),ci=h("\u{1F4C8} Learning rates: How fast the embedding evolves per training step. The higher the value, the faster Stable Diffusion will learn."),gt=b(),Se=o("p"),hi=h("Using a high value for a learning rate for a long running duration will cause the embedding to become inflexible or cause deformities and visual artifacts to start appearing in your images."),yt=b(),Le=o("p"),mi=h("Example: a large learning rate is like using a sledgehammer to create a stone statue from a large boulder.  It\u2019s great to make rapid progress at the start by knocking off large pieces of stone. but eventually you need to use something smaller like a hammer to get more precision. Finally, end up at a chisel to get the fine details you want."),Et=b(),xe=o("p"),vi=h("Values around the default of 0.005 work well for most subject based training. But we aren\u2019t limited to a static learning rate, we can have it change at set step intervals with using a progressive learning rate."),kt=b(),se=o("h3"),re=o("a"),Fe=o("span"),bi=h("Progressive Learning Rates"),Pt=b(),De=o("p"),_i=h("Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),St=b(),Ie=o("p"),We=o("code"),wi=h("0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Lt=b(),je=o("p"),gi=h("This is a list of learning rates and step intervals.  When training a model, the learning rate will change at the specified step intervals.  Here is what happens step by step during each interval when training your own embedding:"),xt=b(),z=o("ul"),Be=o("li"),yi=h("Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Ei=b(),Ve=o("li"),ki=h("Steps 10 - 20: lowered to 0.02"),Pi=b(),Ge=o("li"),Si=h("20 - 60: lowered to 0.01"),Li=b(),Ke=o("li"),xi=h("60 - 200: lowered to 0.005"),Di=b(),Ye=o("li"),Ii=h("200 - 500: lowered to 0.002"),ji=b(),Qe=o("li"),Ai=h("500 - 3000: lowered to 0.001"),Ci=b(),Je=o("li"),Ti=h("3000+ is lowered to 0.0005 (slow learning rate)"),Dt=b(),Ae=o("p"),zi=h("When the learning rate is lowered, the more fine tuning happens and increase how precise the embedding will become. This should produce subject likeness results in the 200-500 step range.  Results may get better or worse towards 1000-1500 steps depending on the subject."),It=b(),jt=o("hr"),this.h()},l(e){a=n(e,"P",{});var u=p(a);c=m(u,"A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),u.forEach(t),l=_(e),f=n(e,"P",{});var Bi=p(f);s=n(Bi,"IMG",{src:!0,alt:!0,title:!0,class:!0}),Bi.forEach(t),S=_(e),L=n(e,"H2",{id:!0});var Oi=p(L);I=n(Oi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Vi=p(I);H=n(Vi,"SPAN",{class:!0}),p(H).forEach(t),Vi.forEach(t),O=m(Oi,"What is Textual Inversion?"),Oi.forEach(t),x=_(e),A=n(e,"BLOCKQUOTE",{});var Gi=p(A);$=n(Gi,"P",{});var Ni=p($);N=m(Ni,"\u{1F4C4} See the paper: "),C=n(Ni,"A",{href:!0,rel:!0});var Ki=p(C);j=m(Ki,"https://arxiv.org/abs/2208.01618"),Ki.forEach(t),Ni.forEach(t),Gi.forEach(t),U=_(e),M=n(e,"P",{});var Yi=p(M);W=m(Yi,"Stable Diffusion is a denoising tool which is fine-tuned to predict what is noise in an image to remove it. Running that process 20 to 40 times in a row on pure noise can repair it into a brand new image."),Yi.forEach(t),V=_(e),T=n(e,"P",{});var Ct=p(T);D=m(Ct,"Stable Diffusion uses a diffusion model called a "),B=n(Ct,"STRONG",{});var Qi=p(B);G=m(Qi,"latent diffusion model"),Qi.forEach(t),P=m(Ct," (LDM).  The CLIP encoder describes images with 768 latents (in SD 1.x models - SD 2.x uses 1024), where each latent is a spectrum of some type of feature."),Ct.forEach(t),E=_(e),d=n(e,"P",{});var Ji=p(d);v=m(Ji,"Examples:"),Ji.forEach(t),k=_(e),q=n(e,"UL",{});var Tt=p(q);R=n(Tt,"LI",{});var Xi=p(R);Y=m(Xi,"At one end might be round objects and at the other end might be square objects, but it\u2019s much more complex than that."),Xi.forEach(t),Ht=_(Tt),Ce=n(Tt,"LI",{});var Zi=p(Ce);$t=m(Zi,"At one end might be chairs, and at another end might be giraffes."),Zi.forEach(t),Tt.forEach(t),Ze=_(e),ue=n(e,"P",{});var ea=p(ue);qt=m(ea,"These feature spectrums are probably beyond human understanding."),ea.forEach(t),et=_(e),de=n(e,"P",{});var ta=p(de);Rt=m(ta,"The latents were built with captions where words can also be encoded to these same latents (e.g. \u2018cat\u2019, \u2018planet\u2019, \u2018spaceship\u2019, etc, each concept can be described in 768 values of various spectrums)."),ta.forEach(t),tt=_(e),ce=n(e,"P",{});var ia=p(ce);Mt=m(ia,"Stable Diffusion is guided by those latents:"),ia.forEach(t),it=_(e),Q=n(e,"UL",{});var zt=p(Q);Te=n(zt,"LI",{});var aa=p(Te);Ft=m(aa,"Learns to understand what each one means when you inference using prompts."),aa.forEach(t),Wt=_(zt),ze=n(zt,"LI",{});var la=p(ze);Bt=m(la,"Gives each a weighting to different areas of an image."),la.forEach(t),zt.forEach(t),at=_(e),he=n(e,"P",{});var sa=p(he);Vt=m(sa,"While training, it\u2019s possible to introduce latents never trained on using textual inversion or manually combining existing word latents.  Stable Diffusion will draw those concepts because it learned to understand those spectrums of ideas - not copy existing content."),sa.forEach(t),lt=_(e),me=n(e,"P",{});var ra=p(me);Gt=m(ra,"For example, you can combine 50% of cat and 50% of a kangaroo and it can draw a cat-kangaroo hybrid creature which it never trained on."),ra.forEach(t),st=_(e),ve=n(e,"P",{});var oa=p(ve);Kt=m(oa,"You can find the latents which describe your own face, or a new artstyle - despite it never training on it."),oa.forEach(t),rt=_(e),J=n(e,"H2",{id:!0});var Ui=p(J);X=n(Ui,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var na=p(X);Oe=n(na,"SPAN",{class:!0}),p(Oe).forEach(t),na.forEach(t),Yt=m(Ui,"Embedding Usage"),Ui.forEach(t),ot=_(e),be=n(e,"P",{});var fa=p(be);Qt=m(fa,"Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),fa.forEach(t),nt=_(e),Z=n(e,"P",{});var Ot=p(Z);Jt=m(Ot,"\u2728 V2: Use the token "),Ne=n(Ot,"CODE",{});var pa=p(Ne);Xt=m(pa,"aubreyplazav2-300"),pa.forEach(t),Zt=m(Ot," in your prompts to activate the embedding."),Ot.forEach(t),ft=_(e),ee=n(e,"P",{});var Nt=p(ee);ei=m(Nt,"\u2728 V1: Use the token "),Ue=n(Nt,"CODE",{});var ua=p(Ue);ti=m(ua,"aubreyplazav1-7375"),ua.forEach(t),ii=m(Nt," in your prompts to activate the embedding."),Nt.forEach(t),pt=_(e),te=n(e,"H2",{id:!0});var Hi=p(te);ie=n(Hi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var da=p(ie);He=n(da,"SPAN",{class:!0}),p(He).forEach(t),da.forEach(t),ai=m(Hi,"Prompt Example"),Hi.forEach(t),ut=_(e),_e=n(e,"P",{});var ca=p(_e);li=m(ca,"\u{1F9FE} Prompt:"),ca.forEach(t),dt=_(e),we=n(e,"P",{});var ha=p(we);$e=n(ha,"CODE",{});var ma=p($e);si=m(ma,"Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),ma.forEach(t),ha.forEach(t),ct=_(e),ge=n(e,"P",{});var va=p(ge);ri=m(va,"\u2796 Negative:"),va.forEach(t),ht=_(e),ye=n(e,"P",{});var ba=p(ye);qe=n(ba,"CODE",{});var _a=p(qe);oi=m(_a,"(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),_a.forEach(t),ba.forEach(t),mt=_(e),Ee=n(e,"P",{});var wa=p(Ee);Re=n(wa,"EM",{});var ga=p(Re);ni=m(ga,"Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),ga.forEach(t),wa.forEach(t),vt=_(e),ke=n(e,"BLOCKQUOTE",{});var ya=p(ke);fe=n(ya,"P",{});var Ut=p(fe);fi=m(Ut,"\u{1F305} For more information on how to use this embedding, see "),pe=n(Ut,"A",{href:!0,rel:!0});var Ea=p(pe);pi=m(Ea,"https://huggingface.co/datasets/zuleo/aubrey-plaza"),Ea.forEach(t),ui=m(Ut,"."),Ut.forEach(t),ya.forEach(t),bt=_(e),K&&K.l(e),_t=_(e),ae=n(e,"H2",{id:!0});var $i=p(ae);le=n($i,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ka=p(le);Me=n(ka,"SPAN",{class:!0}),p(Me).forEach(t),ka.forEach(t),di=m($i,"Understanding Learning Rates"),$i.forEach(t),wt=_(e),Pe=n(e,"P",{});var Pa=p(Pe);ci=m(Pa,"\u{1F4C8} Learning rates: How fast the embedding evolves per training step. The higher the value, the faster Stable Diffusion will learn."),Pa.forEach(t),gt=_(e),Se=n(e,"P",{});var Sa=p(Se);hi=m(Sa,"Using a high value for a learning rate for a long running duration will cause the embedding to become inflexible or cause deformities and visual artifacts to start appearing in your images."),Sa.forEach(t),yt=_(e),Le=n(e,"P",{});var La=p(Le);mi=m(La,"Example: a large learning rate is like using a sledgehammer to create a stone statue from a large boulder.  It\u2019s great to make rapid progress at the start by knocking off large pieces of stone. but eventually you need to use something smaller like a hammer to get more precision. Finally, end up at a chisel to get the fine details you want."),La.forEach(t),Et=_(e),xe=n(e,"P",{});var xa=p(xe);vi=m(xa,"Values around the default of 0.005 work well for most subject based training. But we aren\u2019t limited to a static learning rate, we can have it change at set step intervals with using a progressive learning rate."),xa.forEach(t),kt=_(e),se=n(e,"H3",{id:!0});var qi=p(se);re=n(qi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Da=p(re);Fe=n(Da,"SPAN",{class:!0}),p(Fe).forEach(t),Da.forEach(t),bi=m(qi,"Progressive Learning Rates"),qi.forEach(t),Pt=_(e),De=n(e,"P",{});var Ia=p(De);_i=m(Ia,"Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),Ia.forEach(t),St=_(e),Ie=n(e,"P",{});var ja=p(Ie);We=n(ja,"CODE",{});var Aa=p(We);wi=m(Aa,"0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Aa.forEach(t),ja.forEach(t),Lt=_(e),je=n(e,"P",{});var Ca=p(je);gi=m(Ca,"This is a list of learning rates and step intervals.  When training a model, the learning rate will change at the specified step intervals.  Here is what happens step by step during each interval when training your own embedding:"),Ca.forEach(t),xt=_(e),z=n(e,"UL",{});var F=p(z);Be=n(F,"LI",{});var Ta=p(Be);yi=m(Ta,"Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Ta.forEach(t),Ei=_(F),Ve=n(F,"LI",{});var za=p(Ve);ki=m(za,"Steps 10 - 20: lowered to 0.02"),za.forEach(t),Pi=_(F),Ge=n(F,"LI",{});var Oa=p(Ge);Si=m(Oa,"20 - 60: lowered to 0.01"),Oa.forEach(t),Li=_(F),Ke=n(F,"LI",{});var Na=p(Ke);xi=m(Na,"60 - 200: lowered to 0.005"),Na.forEach(t),Di=_(F),Ye=n(F,"LI",{});var Ua=p(Ye);Ii=m(Ua,"200 - 500: lowered to 0.002"),Ua.forEach(t),ji=_(F),Qe=n(F,"LI",{});var Ha=p(Qe);Ai=m(Ha,"500 - 3000: lowered to 0.001"),Ha.forEach(t),Ci=_(F),Je=n(F,"LI",{});var $a=p(Je);Ti=m($a,"3000+ is lowered to 0.0005 (slow learning rate)"),$a.forEach(t),F.forEach(t),Dt=_(e),Ae=n(e,"P",{});var qa=p(Ae);zi=m(qa,"When the learning rate is lowered, the more fine tuning happens and increase how precise the embedding will become. This should produce subject likeness results in the 200-500 step range.  Results may get better or worse towards 1000-1500 steps depending on the subject."),qa.forEach(t),It=_(e),jt=n(e,"HR",{}),this.h()},h(){sl(s.src,y="https://huggingface.co/datasets/zuleo/aubrey-plaza/resolve/main/images/grid_v2.png")||w(s,"src",y),w(s,"alt","Detailed Samples"),w(s,"title","A photo booth of the model's output: images of santa claus"),w(s,"class","svelte-3z7sly"),w(H,"class","icon icon-link"),w(I,"aria-hidden","true"),w(I,"tabindex","-1"),w(I,"href","#what-is-textual-inversion"),w(L,"id","what-is-textual-inversion"),w(C,"href","https://arxiv.org/abs/2208.01618"),w(C,"rel","nofollow"),w(Oe,"class","icon icon-link"),w(X,"aria-hidden","true"),w(X,"tabindex","-1"),w(X,"href","#embedding-usage"),w(J,"id","embedding-usage"),w(He,"class","icon icon-link"),w(ie,"aria-hidden","true"),w(ie,"tabindex","-1"),w(ie,"href","#prompt-example"),w(te,"id","prompt-example"),w(pe,"href","https://huggingface.co/datasets/zuleo/aubrey-plaza"),w(pe,"rel","nofollow"),w(Me,"class","icon icon-link"),w(le,"aria-hidden","true"),w(le,"tabindex","-1"),w(le,"href","#understanding-learning-rates"),w(ae,"id","understanding-learning-rates"),w(Fe,"class","icon icon-link"),w(re,"aria-hidden","true"),w(re,"tabindex","-1"),w(re,"href","#progressive-learning-rates"),w(se,"id","progressive-learning-rates")},m(e,u){r(e,a,u),i(a,c),r(e,l,u),r(e,f,u),i(f,s),r(e,S,u),r(e,L,u),i(L,I),i(I,H),i(L,O),r(e,x,u),r(e,A,u),i(A,$),i($,N),i($,C),i(C,j),r(e,U,u),r(e,M,u),i(M,W),r(e,V,u),r(e,T,u),i(T,D),i(T,B),i(B,G),i(T,P),r(e,E,u),r(e,d,u),i(d,v),r(e,k,u),r(e,q,u),i(q,R),i(R,Y),i(q,Ht),i(q,Ce),i(Ce,$t),r(e,Ze,u),r(e,ue,u),i(ue,qt),r(e,et,u),r(e,de,u),i(de,Rt),r(e,tt,u),r(e,ce,u),i(ce,Mt),r(e,it,u),r(e,Q,u),i(Q,Te),i(Te,Ft),i(Q,Wt),i(Q,ze),i(ze,Bt),r(e,at,u),r(e,he,u),i(he,Vt),r(e,lt,u),r(e,me,u),i(me,Gt),r(e,st,u),r(e,ve,u),i(ve,Kt),r(e,rt,u),r(e,J,u),i(J,X),i(X,Oe),i(J,Yt),r(e,ot,u),r(e,be,u),i(be,Qt),r(e,nt,u),r(e,Z,u),i(Z,Jt),i(Z,Ne),i(Ne,Xt),i(Z,Zt),r(e,ft,u),r(e,ee,u),i(ee,ei),i(ee,Ue),i(Ue,ti),i(ee,ii),r(e,pt,u),r(e,te,u),i(te,ie),i(ie,He),i(te,ai),r(e,ut,u),r(e,_e,u),i(_e,li),r(e,dt,u),r(e,we,u),i(we,$e),i($e,si),r(e,ct,u),r(e,ge,u),i(ge,ri),r(e,ht,u),r(e,ye,u),i(ye,qe),i(qe,oi),r(e,mt,u),r(e,Ee,u),i(Ee,Re),i(Re,ni),r(e,vt,u),r(e,ke,u),i(ke,fe),i(fe,fi),i(fe,pe),i(pe,pi),i(fe,ui),r(e,bt,u),K&&K.m(e,u),r(e,_t,u),r(e,ae,u),i(ae,le),i(le,Me),i(ae,di),r(e,wt,u),r(e,Pe,u),i(Pe,ci),r(e,gt,u),r(e,Se,u),i(Se,hi),r(e,yt,u),r(e,Le,u),i(Le,mi),r(e,Et,u),r(e,xe,u),i(xe,vi),r(e,kt,u),r(e,se,u),i(se,re),i(re,Fe),i(se,bi),r(e,Pt,u),r(e,De,u),i(De,_i),r(e,St,u),r(e,Ie,u),i(Ie,We),i(We,wi),r(e,Lt,u),r(e,je,u),i(je,gi),r(e,xt,u),r(e,z,u),i(z,Be),i(Be,yi),i(z,Ei),i(z,Ve),i(Ve,ki),i(z,Pi),i(z,Ge),i(Ge,Si),i(z,Li),i(z,Ke),i(Ke,xi),i(z,Di),i(z,Ye),i(Ye,Ii),i(z,ji),i(z,Qe),i(Qe,Ai),i(z,Ci),i(z,Je),i(Je,Ti),r(e,Dt,u),r(e,Ae,u),i(Ae,zi),r(e,It,u),r(e,jt,u),At=!0},p(e,u){Ka&&K.p(e,u)},i(e){At||(Fi(K),At=!0)},o(e){Wi(K),At=!1},d(e){e&&t(a),e&&t(l),e&&t(f),e&&t(S),e&&t(L),e&&t(x),e&&t(A),e&&t(U),e&&t(M),e&&t(V),e&&t(T),e&&t(E),e&&t(d),e&&t(k),e&&t(q),e&&t(Ze),e&&t(ue),e&&t(et),e&&t(de),e&&t(tt),e&&t(ce),e&&t(it),e&&t(Q),e&&t(at),e&&t(he),e&&t(lt),e&&t(me),e&&t(st),e&&t(ve),e&&t(rt),e&&t(J),e&&t(ot),e&&t(be),e&&t(nt),e&&t(Z),e&&t(ft),e&&t(ee),e&&t(pt),e&&t(te),e&&t(ut),e&&t(_e),e&&t(dt),e&&t(we),e&&t(ct),e&&t(ge),e&&t(ht),e&&t(ye),e&&t(mt),e&&t(Ee),e&&t(vt),e&&t(ke),e&&t(bt),K&&K.d(e),e&&t(_t),e&&t(ae),e&&t(wt),e&&t(Pe),e&&t(gt),e&&t(Se),e&&t(yt),e&&t(Le),e&&t(Et),e&&t(xe),e&&t(kt),e&&t(se),e&&t(Pt),e&&t(De),e&&t(St),e&&t(Ie),e&&t(Lt),e&&t(je),e&&t(xt),e&&t(z),e&&t(Dt),e&&t(Ae),e&&t(It),e&&t(jt)}}}function wl(g){let a,c;const l=[g[0],Mi];let f={$$slots:{default:[_l]},$$scope:{ctx:g}};for(let s=0;s<l.length;s+=1)f=Ri(f,l[s]);return a=new rl({props:f}),{c(){Za(a.$$.fragment)},l(s){el(a.$$.fragment,s)},m(s,y){tl(a,s,y),c=!0},p(s,[y]){const S=y&1?ll(l,[y&1&&Ma(s[0]),y&0&&Ma(Mi)]):{};y&2&&(S.$$scope={dirty:y,ctx:s}),a.$set(S)},i(s){c||(Fi(a.$$.fragment,s),c=!0)},o(s){Wi(a.$$.fragment,s),c=!1},d(s){il(a,s)}}}const Mi={title:"textual inversion with Aubrey Plaza",date:"2023-01-27",modifiedDate:"2023-01-27",categories:["stable diffusion","ai training"],svg:"Santa",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Check out Ornamental Santa Diffusion, a model that uses stable diffusion to generate Santa Claus.",author:"Ryan Sadwick",spacelab:!0,id:1},{title:Ll,date:xl,modifiedDate:Dl,categories:Il,svg:jl,seoImage:Al,shortDescription:Cl,author:Tl,spacelab:Ka,id:gl}=Mi;function yl(g,a,c){return g.$$set=l=>{c(0,a=Ri(Ri({},a),Fa(l)))},a=Fa(a),[a]}class zl extends Ya{constructor(a){super(),Qa(this,a,yl,wl,Ja,{})}}export{zl as default,Mi as metadata};
