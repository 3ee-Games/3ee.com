import{S as ns,i as fs,s as ps,l as $t,g as p,E as at,d as t,v as us,e as l,t as d,c as o,a as f,h as u,b as y,I as i,j as ce,k as b,m as g,H as ue,J as ds,C as ea,w as ia,x as aa,y as sa,z as cs,A as ts,q as Ht,o as Rt,B as ra,Z as is}from"../../chunks/index-e1315fa8.js";import{P as hs}from"../../chunks/_post-b40ff661.js";import{R as ms}from"../../chunks/ResponsivePicture-a22ececa.js";import{a as Xi}from"../../chunks/accountStore-0546593d.js";/* empty css                                                                   */import"../../chunks/menuContextStore-8d5e7108.js";import"../../chunks/index-1440c114.js";function vs(w){let a,h,s,n,r,_,S,D,U,q,C,x,z,N,A,$,j,H,F,L;function K(v,k){return typeof v[0].title!="undefined"?_s:gs}let R=K(w),O=R(w);function J(v,k){return typeof v[0].description!="undefined"?ws:ys}let B=J(w),P=B(w),E=typeof w[0].list_description!="undefined"&&as(w),c=typeof w[0].footer_description!="undefined"&&ss(w);return{c(){a=l("hr"),h=b(),s=l("div"),O.c(),n=b(),r=l("p"),_=l("ion-icon"),S=d("SpaceLab Content"),D=b(),P.c(),U=b(),E&&E.c(),q=b(),c&&c.c(),C=b(),x=l("button"),z=l("ion-icon"),N=b(),A=l("span"),$=d("SpaceLab"),j=b(),H=l("hr"),this.h()},l(v){a=o(v,"HR",{}),h=g(v),s=o(v,"DIV",{class:!0});var k=f(s);O.l(k),n=g(k),r=o(k,"P",{class:!0});var W=f(r);_=o(W,"ION-ICON",{class:!0,name:!0}),f(_).forEach(t),S=u(W,"SpaceLab Content"),W.forEach(t),D=g(k),P.l(k),U=g(k),E&&E.l(k),q=g(k),c&&c.l(k),C=g(k),x=o(k,"BUTTON",{class:!0});var I=f(x);z=o(I,"ION-ICON",{class:!0,name:!0}),f(z).forEach(t),N=g(I),A=o(I,"SPAN",{});var Y=f(A);$=u(Y,"SpaceLab"),Y.forEach(t),I.forEach(t),k.forEach(t),j=g(v),H=o(v,"HR",{}),this.h()},h(){ue(_,"class","icon svelte-vjvavh"),ue(_,"name","lock-closed"),y(r,"class","highlight large svelte-vjvavh"),ue(z,"class","icon svelte-vjvavh"),ue(z,"name","planet"),y(x,"class","button subscribe svelte-vjvavh"),y(s,"class","subscribe svelte-vjvavh")},m(v,k){p(v,a,k),p(v,h,k),p(v,s,k),O.m(s,null),i(s,n),i(s,r),i(r,_),i(r,S),i(s,D),P.m(s,null),i(s,U),E&&E.m(s,null),i(s,q),c&&c.m(s,null),i(s,C),i(s,x),i(x,z),i(x,N),i(x,A),i(A,$),p(v,j,k),p(v,H,k),F||(L=ds(x,"click",w[3]),F=!0)},p(v,k){R===(R=K(v))&&O?O.p(v,k):(O.d(1),O=R(v),O&&(O.c(),O.m(s,n))),B===(B=J(v))&&P?P.p(v,k):(P.d(1),P=B(v),P&&(P.c(),P.m(s,U))),typeof v[0].list_description!="undefined"?E?E.p(v,k):(E=as(v),E.c(),E.m(s,q)):E&&(E.d(1),E=null),typeof v[0].footer_description!="undefined"?c?c.p(v,k):(c=ss(v),c.c(),c.m(s,C)):c&&(c.d(1),c=null)},d(v){v&&t(a),v&&t(h),v&&t(s),O.d(),P.d(),E&&E.d(),c&&c.d(),v&&t(j),v&&t(H),F=!1,L()}}}function bs(w){let a,h,s,n=w[0].title+"",r,_,S,D,U,q,C,x=w[0].description+"",z,N,A,$,j,H,F,L,K,R,O,J,B,P=typeof w[0].list_description!="undefined"&&rs(w),E=typeof w[0].footer_description!="undefined"&&ls(w);return{c(){a=l("hr"),h=b(),s=l("h2"),r=d(n),_=b(),S=l("p"),D=l("ion-icon"),U=d("SpaceLab Content"),q=b(),C=l("p"),z=d(x),N=b(),P&&P.c(),A=b(),E&&E.c(),$=b(),j=l("button"),H=l("ion-icon"),F=b(),L=l("span"),K=d("Download"),R=b(),O=l("hr"),this.h()},l(c){a=o(c,"HR",{}),h=g(c),s=o(c,"H2",{class:!0});var v=f(s);r=u(v,n),v.forEach(t),_=g(c),S=o(c,"P",{class:!0});var k=f(S);D=o(k,"ION-ICON",{class:!0,name:!0}),f(D).forEach(t),U=u(k,"SpaceLab Content"),k.forEach(t),q=g(c),C=o(c,"P",{class:!0});var W=f(C);z=u(W,x),W.forEach(t),N=g(c),P&&P.l(c),A=g(c),E&&E.l(c),$=g(c),j=o(c,"BUTTON",{class:!0});var I=f(j);H=o(I,"ION-ICON",{class:!0,name:!0}),f(H).forEach(t),F=g(I),L=o(I,"SPAN",{});var Y=f(L);K=u(Y,"Download"),Y.forEach(t),I.forEach(t),R=g(c),O=o(c,"HR",{}),this.h()},h(){y(s,"class","svelte-vjvavh"),ue(D,"class","icon svelte-vjvavh"),ue(D,"name","planet-sharp"),y(S,"class","highlight large svelte-vjvavh"),y(C,"class","svelte-vjvavh"),ue(H,"class","icon svelte-vjvavh"),ue(H,"name","cloud-download"),y(j,"class","button svelte-vjvavh")},m(c,v){p(c,a,v),p(c,h,v),p(c,s,v),i(s,r),p(c,_,v),p(c,S,v),i(S,D),i(S,U),p(c,q,v),p(c,C,v),i(C,z),p(c,N,v),P&&P.m(c,v),p(c,A,v),E&&E.m(c,v),p(c,$,v),p(c,j,v),i(j,H),i(j,F),i(j,L),i(L,K),p(c,R,v),p(c,O,v),J||(B=ds(j,"click",w[2]),J=!0)},p(c,v){v&1&&n!==(n=c[0].title+"")&&ce(r,n),v&1&&x!==(x=c[0].description+"")&&ce(z,x),typeof c[0].list_description!="undefined"?P?P.p(c,v):(P=rs(c),P.c(),P.m(A.parentNode,A)):P&&(P.d(1),P=null),typeof c[0].footer_description!="undefined"?E?E.p(c,v):(E=ls(c),E.c(),E.m($.parentNode,$)):E&&(E.d(1),E=null)},d(c){c&&t(a),c&&t(h),c&&t(s),c&&t(_),c&&t(S),c&&t(q),c&&t(C),c&&t(N),P&&P.d(c),c&&t(A),E&&E.d(c),c&&t($),c&&t(j),c&&t(R),c&&t(O),J=!1,B()}}}function gs(w){let a,h;return{c(){a=l("h2"),h=d("SpaceLab Content"),this.h()},l(s){a=o(s,"H2",{class:!0});var n=f(a);h=u(n,"SpaceLab Content"),n.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(s,n){p(s,a,n),i(a,h)},p:at,d(s){s&&t(a)}}}function _s(w){let a,h=w[0].title+"",s;return{c(){a=l("h2"),s=d(h),this.h()},l(n){a=o(n,"H2",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].title+"")&&ce(s,h)},d(n){n&&t(a)}}}function ys(w){let a,h;return{c(){a=l("p"),h=d("To access this content, you need a SpaceLab subscription."),this.h()},l(s){a=o(s,"P",{class:!0});var n=f(a);h=u(n,"To access this content, you need a SpaceLab subscription."),n.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(s,n){p(s,a,n),i(a,h)},p:at,d(s){s&&t(a)}}}function ws(w){let a,h=w[0].description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].description+"")&&ce(s,h)},d(n){n&&t(a)}}}function as(w){let a,h,s=w[0].list_description+"",n;return{c(){a=l("div"),h=l("p"),n=d(s),this.h()},l(r){a=o(r,"DIV",{class:!0});var _=f(a);h=o(_,"P",{class:!0});var S=f(h);n=u(S,s),S.forEach(t),_.forEach(t),this.h()},h(){y(h,"class","svelte-vjvavh"),y(a,"class","list-description svelte-vjvavh")},m(r,_){p(r,a,_),i(a,h),i(h,n)},p(r,_){_&1&&s!==(s=r[0].list_description+"")&&ce(n,s)},d(r){r&&t(a)}}}function ss(w){let a,h=w[0].footer_description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].footer_description+"")&&ce(s,h)},d(n){n&&t(a)}}}function rs(w){let a,h,s=w[0].list_description+"",n;return{c(){a=l("div"),h=l("p"),n=d(s),this.h()},l(r){a=o(r,"DIV",{class:!0});var _=f(a);h=o(_,"P",{class:!0});var S=f(h);n=u(S,s),S.forEach(t),_.forEach(t),this.h()},h(){y(h,"class","svelte-vjvavh"),y(a,"class","list-description svelte-vjvavh")},m(r,_){p(r,a,_),i(a,h),i(h,n)},p(r,_){_&1&&s!==(s=r[0].list_description+"")&&ce(n,s)},d(r){r&&t(a)}}}function ls(w){let a,h=w[0].footer_description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].footer_description+"")&&ce(s,h)},d(n){n&&t(a)}}}function Es(w){let a;function h(r,_){return typeof r[0]!="undefined"&&typeof r[0].pk!="undefined"?bs:vs}let s=h(w),n=s(w);return{c(){n.c(),a=$t()},l(r){n.l(r),a=$t()},m(r,_){n.m(r,_),p(r,a,_)},p(r,[_]){s===(s=h(r))&&n?n.p(r,_):(n.d(1),n=s(r),n&&(n.c(),n.m(a.parentNode,a)))},i:at,o:at,d(r){n.d(r),r&&t(a)}}}function ks(w,a,h){let{id:s}=a,n={},r;Xi.subscribe(D=>{r=D}),us(async()=>{if(typeof(r==null?void 0:r.token)!="undefined"){const D=await fetch(`https://3ee.dev/education/spacelab/${s}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+r.token},mode:"cors"});if(D.status===401){Xi.set({}),Xi.deleteLocalStorage();return}let U=await D.json();h(0,n=U)}else h(0,n.success=!1,n)});const _=()=>window.open(n.url,"_blank"),S=()=>window.open("/spacelab/","_blank");return w.$$set=D=>{"id"in D&&h(1,s=D.id)},[n,s,_,S]}class Ss extends ns{constructor(a){super(),fs(this,a,ks,Es,ps,{id:1})}}function Ps(w){let a,h;return a=new Ss({props:{id:xs}}),{c(){ia(a.$$.fragment)},l(s){aa(a.$$.fragment,s)},m(s,n){sa(a,s,n),h=!0},p:at,i(s){h||(Ht(a.$$.fragment,s),h=!0)},o(s){Rt(a.$$.fragment,s),h=!1},d(s){ra(a,s)}}}function Ds(w){let a,h,s,n,r,_,S,D,U,q,C,x,z,N,A,$,j,H,F,L,K,R,O,J,B,P,E,c,v,k,W,I,Y,Oe,Ut,qt,Ce,Gt,Bt,Te,Ft,Mt,Ne,Wt,Vt,st,ve,Kt,rt,be,Jt,lt,ge,Qt,ot,Z,X,Ae,Yt,nt,_e,Zt,ft,ee,Xt,ze,ei,ti,pt,te,ii,$e,ai,si,dt,ie,ae,He,ri,ut,ye,li,ct,we,Re,oi,ht,Ee,ni,mt,ke,Ue,fi,vt,Se,qe,pi,bt,Pe,he,di,me,ui,ci,gt,se,re,Ge,hi,_t,De,mi,yt,M,vi,Be,bi,gi,Fe,_i,yi,Me,wi,Ei,wt,le,ki,We,Si,Pi,Et,oe,Di,Ve,Ii,xi,kt,ne,fe,Ke,ji,St,Ie,Li,Pt,xe,Je,Oi,Dt,je,Ci,It,T,Qe,Ti,Ni,Ye,Ai,zi,Ze,$i,Hi,Xe,Ri,Ui,et,qi,Gi,tt,Bi,Fi,it,Mi,xt,Le,Wi,jt,Lt,Ot;n=new ms({props:{smallImage:"https://3ee.s3.amazonaws.com/img/aub_small.webp",largeImage:"https://3ee.s3.amazonaws.com/img/aub_large.webp",alt:"Six images of Aubrey Plaza",largeWidth:"786",largeHeight:"786",smallWidth:"461",smallHeight:"461"}});let V=os&&Ps();return{c(){a=l("p"),h=d("A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),s=b(),ia(n.$$.fragment),r=b(),_=l("h2"),S=l("a"),D=l("span"),U=d("What is Textual Inversion?"),q=b(),C=l("blockquote"),x=l("p"),z=d("\u{1F4C4} See the paper: "),N=l("a"),A=d("https://arxiv.org/abs/2208.01618"),$=b(),j=l("p"),H=d("Stable Diffusion is designed to predict and eliminate noise from images. By applying this process 20 to 40 times successively on pure noise, you can remarkably transform it into an entirely new image."),F=b(),L=l("p"),K=d("At its core, Stable Diffusion employs a distinctive diffusion model called the "),R=l("strong"),O=d("latent diffusion model (LDM)"),J=d(", fine-tuned to accurately depict images. The CLIP encoder portrays images with "),B=l("strong"),P=d("768"),E=d(" latents in SD 1.x models, while SD 2.x models utilize "),c=l("strong"),v=d("1024"),k=d(" latents. Each latent represents a specific feature type within a highly intricate spectrum that surpasses human comprehension."),W=b(),I=l("p"),Y=d("For example, one end of the spectrum might represent round objects, while the opposite end showcases square objects. It\u2019s crucial to understand that these representations are far more refined and complex than a straightforward binary illustration. Likewise, the spectrum might span from chairs at one end to giraffes at the other. Feature spectra are encoded with captions, enabling words like \u201D"),Oe=l("code"),Ut=d("cat"),qt=d(",\u201D \u201D"),Ce=l("code"),Gt=d("planet"),Bt=d(",\u201D or \u201D"),Te=l("code"),Ft=d("spaceship"),Mt=d("\u201D to be described by "),Ne=l("strong"),Wt=d("768"),Vt=d(" values across various spectra."),st=b(),ve=l("p"),Kt=d("Guided by these latents, Stable Diffusion learns to discern the meaning of each latent through inference using prompts. It allocates weights to different image regions, pinpointing areas that require correction. During training, you can introduce latents never trained on before through textual inversion or by manually merging existing word latents."),rt=b(),be=l("p"),Jt=d("Stable Diffusion generates new concepts by grasping the idea spectra associated with latents, instead of duplicating existing content. For instance, it can blend 50% cat with 50% kangaroo to create a cat-kangaroo hybrid creature it has never encountered during training."),lt=b(),ge=l("p"),Qt=d("You can discover latents that characterize your own face or a novel art style, even if Stable Diffusion has never trained on them before, unlocking boundless creative potential."),ot=b(),Z=l("h2"),X=l("a"),Ae=l("span"),Yt=d("Embedding Usage"),nt=b(),_e=l("p"),Zt=d("Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),ft=b(),ee=l("p"),Xt=d("\u2728 V2: Use the token "),ze=l("code"),ei=d("aubreyplazav2-300"),ti=d(" in your prompts to activate the embedding."),pt=b(),te=l("p"),ii=d("\u2728 V1: Use the token "),$e=l("code"),ai=d("aubreyplazav1-7375"),si=d(" in your prompts to activate the embedding."),dt=b(),ie=l("h2"),ae=l("a"),He=l("span"),ri=d("Prompt Example"),ut=b(),ye=l("p"),li=d("\u{1F9FE} Prompt:"),ct=b(),we=l("p"),Re=l("code"),oi=d("Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),ht=b(),Ee=l("p"),ni=d("\u2796 Negative:"),mt=b(),ke=l("p"),Ue=l("code"),fi=d("(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),vt=b(),Se=l("p"),qe=l("em"),pi=d("Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),bt=b(),Pe=l("blockquote"),he=l("p"),di=d("\u{1F305} For more information on how to use this embedding, see "),me=l("a"),ui=d("https://huggingface.co/datasets/zuleo/aubrey-plaza"),ci=d("."),gt=b(),se=l("h2"),re=l("a"),Ge=l("span"),hi=d("Understanding Learning Rates"),_t=b(),De=l("p"),mi=d("\u{1F4C8} Learning rates play a pivotal role in training machine learning models. Just as an artist sculpts a masterpiece from a boulder, the learning rate influences how quickly and precisely the model evolves with each training iteration. In the context of Stable Diffusion, a high learning rate enables rapid learning, but it also heightens the risk of producing distorted images with visual artifacts."),yt=b(),M=l("p"),vi=d("Imagine you\u2019re sculpting a statue from a colossal boulder. In the beginning, using a "),Be=l("strong"),bi=d("sledgehammer"),gi=d(" (akin to a high learning rate) helps you remove large chunks of stone quickly, making significant progress. However, as the sculpture takes shape, you need to transition to "),Fe=l("strong"),_i=d("smaller tools"),yi=d(" like a hammer for improved precision. Ultimately, you\u2019ll use a "),Me=l("strong"),wi=d("chisel"),Ei=d(" to carve the intricate details that bring your masterpiece to life."),wt=b(),le=l("p"),ki=d("Persisting with a high learning rate throughout the entire process can render the embedding rigid and impede Stable Diffusion\u2019s ability to learn new information. Instead, it\u2019s advisable to stick to a value around the default of "),We=l("strong"),Si=d("0.005"),Pi=d(", which generally performs well for most subject-based training."),Et=b(),oe=l("p"),Di=d("That being said, you don\u2019t have to confine yourself to a static learning rate. Employing a "),Ve=l("strong"),Ii=d("progressive learning rate"),xi=d(" that adjusts at specified intervals can yield even better results. By starting with a higher learning rate and gradually reducing it as the training advances, Stable Diffusion can achieve more stable and accurate outcomes, akin to a sculptor\u2019s masterpiece."),kt=b(),ne=l("h3"),fe=l("a"),Ke=l("span"),ji=d("Progressive Learning Rates"),St=b(),Ie=l("p"),Li=d("Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),Pt=b(),xe=l("p"),Je=l("code"),Oi=d("0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Dt=b(),je=l("p"),Ci=d("This is a list of learning rates and step intervals. When training a model, the learning rate will change at the specified step intervals. Here\u2019s what happens step-by-step during each interval when training your own embedding:"),It=b(),T=l("ul"),Qe=l("li"),Ti=d("Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Ni=b(),Ye=l("li"),Ai=d("Steps 10 - 20: lowered to 0.02"),zi=b(),Ze=l("li"),$i=d("20 - 60: lowered to 0.01"),Hi=b(),Xe=l("li"),Ri=d("60 - 200: lowered to 0.005"),Ui=b(),et=l("li"),qi=d("200 - 500: lowered to 0.002"),Gi=b(),tt=l("li"),Bi=d("500 - 3000: lowered to 0.001"),Fi=b(),it=l("li"),Mi=d("3000+ is lowered to 0.0005 (slow learning rate)"),xt=b(),Le=l("p"),Wi=d("As the learning rate is lowered, more fine tuning happens, increasing the precision of the embedding. This should produce subject likeness results in the 200 - 500 step range. Results may get better or worse towards 1000 - 1500 steps, depending on the subject."),jt=b(),V&&V.c(),Lt=$t(),this.h()},l(e){a=o(e,"P",{});var m=f(a);h=u(m,"A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),m.forEach(t),s=g(e),aa(n.$$.fragment,e),r=g(e),_=o(e,"H2",{id:!0});var Vi=f(_);S=o(Vi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var la=f(S);D=o(la,"SPAN",{class:!0}),f(D).forEach(t),la.forEach(t),U=u(Vi,"What is Textual Inversion?"),Vi.forEach(t),q=g(e),C=o(e,"BLOCKQUOTE",{});var oa=f(C);x=o(oa,"P",{});var Ki=f(x);z=u(Ki,"\u{1F4C4} See the paper: "),N=o(Ki,"A",{href:!0,rel:!0});var na=f(N);A=u(na,"https://arxiv.org/abs/2208.01618"),na.forEach(t),Ki.forEach(t),oa.forEach(t),$=g(e),j=o(e,"P",{});var fa=f(j);H=u(fa,"Stable Diffusion is designed to predict and eliminate noise from images. By applying this process 20 to 40 times successively on pure noise, you can remarkably transform it into an entirely new image."),fa.forEach(t),F=g(e),L=o(e,"P",{});var pe=f(L);K=u(pe,"At its core, Stable Diffusion employs a distinctive diffusion model called the "),R=o(pe,"STRONG",{});var pa=f(R);O=u(pa,"latent diffusion model (LDM)"),pa.forEach(t),J=u(pe,", fine-tuned to accurately depict images. The CLIP encoder portrays images with "),B=o(pe,"STRONG",{});var da=f(B);P=u(da,"768"),da.forEach(t),E=u(pe," latents in SD 1.x models, while SD 2.x models utilize "),c=o(pe,"STRONG",{});var ua=f(c);v=u(ua,"1024"),ua.forEach(t),k=u(pe," latents. Each latent represents a specific feature type within a highly intricate spectrum that surpasses human comprehension."),pe.forEach(t),W=g(e),I=o(e,"P",{});var Q=f(I);Y=u(Q,"For example, one end of the spectrum might represent round objects, while the opposite end showcases square objects. It\u2019s crucial to understand that these representations are far more refined and complex than a straightforward binary illustration. Likewise, the spectrum might span from chairs at one end to giraffes at the other. Feature spectra are encoded with captions, enabling words like \u201D"),Oe=o(Q,"CODE",{});var ca=f(Oe);Ut=u(ca,"cat"),ca.forEach(t),qt=u(Q,",\u201D \u201D"),Ce=o(Q,"CODE",{});var ha=f(Ce);Gt=u(ha,"planet"),ha.forEach(t),Bt=u(Q,",\u201D or \u201D"),Te=o(Q,"CODE",{});var ma=f(Te);Ft=u(ma,"spaceship"),ma.forEach(t),Mt=u(Q,"\u201D to be described by "),Ne=o(Q,"STRONG",{});var va=f(Ne);Wt=u(va,"768"),va.forEach(t),Vt=u(Q," values across various spectra."),Q.forEach(t),st=g(e),ve=o(e,"P",{});var ba=f(ve);Kt=u(ba,"Guided by these latents, Stable Diffusion learns to discern the meaning of each latent through inference using prompts. It allocates weights to different image regions, pinpointing areas that require correction. During training, you can introduce latents never trained on before through textual inversion or by manually merging existing word latents."),ba.forEach(t),rt=g(e),be=o(e,"P",{});var ga=f(be);Jt=u(ga,"Stable Diffusion generates new concepts by grasping the idea spectra associated with latents, instead of duplicating existing content. For instance, it can blend 50% cat with 50% kangaroo to create a cat-kangaroo hybrid creature it has never encountered during training."),ga.forEach(t),lt=g(e),ge=o(e,"P",{});var _a=f(ge);Qt=u(_a,"You can discover latents that characterize your own face or a novel art style, even if Stable Diffusion has never trained on them before, unlocking boundless creative potential."),_a.forEach(t),ot=g(e),Z=o(e,"H2",{id:!0});var Ji=f(Z);X=o(Ji,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ya=f(X);Ae=o(ya,"SPAN",{class:!0}),f(Ae).forEach(t),ya.forEach(t),Yt=u(Ji,"Embedding Usage"),Ji.forEach(t),nt=g(e),_e=o(e,"P",{});var wa=f(_e);Zt=u(wa,"Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),wa.forEach(t),ft=g(e),ee=o(e,"P",{});var Ct=f(ee);Xt=u(Ct,"\u2728 V2: Use the token "),ze=o(Ct,"CODE",{});var Ea=f(ze);ei=u(Ea,"aubreyplazav2-300"),Ea.forEach(t),ti=u(Ct," in your prompts to activate the embedding."),Ct.forEach(t),pt=g(e),te=o(e,"P",{});var Tt=f(te);ii=u(Tt,"\u2728 V1: Use the token "),$e=o(Tt,"CODE",{});var ka=f($e);ai=u(ka,"aubreyplazav1-7375"),ka.forEach(t),si=u(Tt," in your prompts to activate the embedding."),Tt.forEach(t),dt=g(e),ie=o(e,"H2",{id:!0});var Qi=f(ie);ae=o(Qi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Sa=f(ae);He=o(Sa,"SPAN",{class:!0}),f(He).forEach(t),Sa.forEach(t),ri=u(Qi,"Prompt Example"),Qi.forEach(t),ut=g(e),ye=o(e,"P",{});var Pa=f(ye);li=u(Pa,"\u{1F9FE} Prompt:"),Pa.forEach(t),ct=g(e),we=o(e,"P",{});var Da=f(we);Re=o(Da,"CODE",{});var Ia=f(Re);oi=u(Ia,"Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),Ia.forEach(t),Da.forEach(t),ht=g(e),Ee=o(e,"P",{});var xa=f(Ee);ni=u(xa,"\u2796 Negative:"),xa.forEach(t),mt=g(e),ke=o(e,"P",{});var ja=f(ke);Ue=o(ja,"CODE",{});var La=f(Ue);fi=u(La,"(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),La.forEach(t),ja.forEach(t),vt=g(e),Se=o(e,"P",{});var Oa=f(Se);qe=o(Oa,"EM",{});var Ca=f(qe);pi=u(Ca,"Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),Ca.forEach(t),Oa.forEach(t),bt=g(e),Pe=o(e,"BLOCKQUOTE",{});var Ta=f(Pe);he=o(Ta,"P",{});var Nt=f(he);di=u(Nt,"\u{1F305} For more information on how to use this embedding, see "),me=o(Nt,"A",{href:!0,rel:!0});var Na=f(me);ui=u(Na,"https://huggingface.co/datasets/zuleo/aubrey-plaza"),Na.forEach(t),ci=u(Nt,"."),Nt.forEach(t),Ta.forEach(t),gt=g(e),se=o(e,"H2",{id:!0});var Yi=f(se);re=o(Yi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Aa=f(re);Ge=o(Aa,"SPAN",{class:!0}),f(Ge).forEach(t),Aa.forEach(t),hi=u(Yi,"Understanding Learning Rates"),Yi.forEach(t),_t=g(e),De=o(e,"P",{});var za=f(De);mi=u(za,"\u{1F4C8} Learning rates play a pivotal role in training machine learning models. Just as an artist sculpts a masterpiece from a boulder, the learning rate influences how quickly and precisely the model evolves with each training iteration. In the context of Stable Diffusion, a high learning rate enables rapid learning, but it also heightens the risk of producing distorted images with visual artifacts."),za.forEach(t),yt=g(e),M=o(e,"P",{});var de=f(M);vi=u(de,"Imagine you\u2019re sculpting a statue from a colossal boulder. In the beginning, using a "),Be=o(de,"STRONG",{});var $a=f(Be);bi=u($a,"sledgehammer"),$a.forEach(t),gi=u(de," (akin to a high learning rate) helps you remove large chunks of stone quickly, making significant progress. However, as the sculpture takes shape, you need to transition to "),Fe=o(de,"STRONG",{});var Ha=f(Fe);_i=u(Ha,"smaller tools"),Ha.forEach(t),yi=u(de," like a hammer for improved precision. Ultimately, you\u2019ll use a "),Me=o(de,"STRONG",{});var Ra=f(Me);wi=u(Ra,"chisel"),Ra.forEach(t),Ei=u(de," to carve the intricate details that bring your masterpiece to life."),de.forEach(t),wt=g(e),le=o(e,"P",{});var At=f(le);ki=u(At,"Persisting with a high learning rate throughout the entire process can render the embedding rigid and impede Stable Diffusion\u2019s ability to learn new information. Instead, it\u2019s advisable to stick to a value around the default of "),We=o(At,"STRONG",{});var Ua=f(We);Si=u(Ua,"0.005"),Ua.forEach(t),Pi=u(At,", which generally performs well for most subject-based training."),At.forEach(t),Et=g(e),oe=o(e,"P",{});var zt=f(oe);Di=u(zt,"That being said, you don\u2019t have to confine yourself to a static learning rate. Employing a "),Ve=o(zt,"STRONG",{});var qa=f(Ve);Ii=u(qa,"progressive learning rate"),qa.forEach(t),xi=u(zt," that adjusts at specified intervals can yield even better results. By starting with a higher learning rate and gradually reducing it as the training advances, Stable Diffusion can achieve more stable and accurate outcomes, akin to a sculptor\u2019s masterpiece."),zt.forEach(t),kt=g(e),ne=o(e,"H3",{id:!0});var Zi=f(ne);fe=o(Zi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Ga=f(fe);Ke=o(Ga,"SPAN",{class:!0}),f(Ke).forEach(t),Ga.forEach(t),ji=u(Zi,"Progressive Learning Rates"),Zi.forEach(t),St=g(e),Ie=o(e,"P",{});var Ba=f(Ie);Li=u(Ba,"Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),Ba.forEach(t),Pt=g(e),xe=o(e,"P",{});var Fa=f(xe);Je=o(Fa,"CODE",{});var Ma=f(Je);Oi=u(Ma,"0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Ma.forEach(t),Fa.forEach(t),Dt=g(e),je=o(e,"P",{});var Wa=f(je);Ci=u(Wa,"This is a list of learning rates and step intervals. When training a model, the learning rate will change at the specified step intervals. Here\u2019s what happens step-by-step during each interval when training your own embedding:"),Wa.forEach(t),It=g(e),T=o(e,"UL",{});var G=f(T);Qe=o(G,"LI",{});var Va=f(Qe);Ti=u(Va,"Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Va.forEach(t),Ni=g(G),Ye=o(G,"LI",{});var Ka=f(Ye);Ai=u(Ka,"Steps 10 - 20: lowered to 0.02"),Ka.forEach(t),zi=g(G),Ze=o(G,"LI",{});var Ja=f(Ze);$i=u(Ja,"20 - 60: lowered to 0.01"),Ja.forEach(t),Hi=g(G),Xe=o(G,"LI",{});var Qa=f(Xe);Ri=u(Qa,"60 - 200: lowered to 0.005"),Qa.forEach(t),Ui=g(G),et=o(G,"LI",{});var Ya=f(et);qi=u(Ya,"200 - 500: lowered to 0.002"),Ya.forEach(t),Gi=g(G),tt=o(G,"LI",{});var Za=f(tt);Bi=u(Za,"500 - 3000: lowered to 0.001"),Za.forEach(t),Fi=g(G),it=o(G,"LI",{});var Xa=f(it);Mi=u(Xa,"3000+ is lowered to 0.0005 (slow learning rate)"),Xa.forEach(t),G.forEach(t),xt=g(e),Le=o(e,"P",{});var es=f(Le);Wi=u(es,"As the learning rate is lowered, more fine tuning happens, increasing the precision of the embedding. This should produce subject likeness results in the 200 - 500 step range. Results may get better or worse towards 1000 - 1500 steps, depending on the subject."),es.forEach(t),jt=g(e),V&&V.l(e),Lt=$t(),this.h()},h(){y(D,"class","icon icon-link"),y(S,"aria-hidden","true"),y(S,"tabindex","-1"),y(S,"href","#what-is-textual-inversion"),y(_,"id","what-is-textual-inversion"),y(N,"href","https://arxiv.org/abs/2208.01618"),y(N,"rel","nofollow"),y(Ae,"class","icon icon-link"),y(X,"aria-hidden","true"),y(X,"tabindex","-1"),y(X,"href","#embedding-usage"),y(Z,"id","embedding-usage"),y(He,"class","icon icon-link"),y(ae,"aria-hidden","true"),y(ae,"tabindex","-1"),y(ae,"href","#prompt-example"),y(ie,"id","prompt-example"),y(me,"href","https://huggingface.co/datasets/zuleo/aubrey-plaza"),y(me,"rel","nofollow"),y(Ge,"class","icon icon-link"),y(re,"aria-hidden","true"),y(re,"tabindex","-1"),y(re,"href","#understanding-learning-rates"),y(se,"id","understanding-learning-rates"),y(Ke,"class","icon icon-link"),y(fe,"aria-hidden","true"),y(fe,"tabindex","-1"),y(fe,"href","#progressive-learning-rates"),y(ne,"id","progressive-learning-rates")},m(e,m){p(e,a,m),i(a,h),p(e,s,m),sa(n,e,m),p(e,r,m),p(e,_,m),i(_,S),i(S,D),i(_,U),p(e,q,m),p(e,C,m),i(C,x),i(x,z),i(x,N),i(N,A),p(e,$,m),p(e,j,m),i(j,H),p(e,F,m),p(e,L,m),i(L,K),i(L,R),i(R,O),i(L,J),i(L,B),i(B,P),i(L,E),i(L,c),i(c,v),i(L,k),p(e,W,m),p(e,I,m),i(I,Y),i(I,Oe),i(Oe,Ut),i(I,qt),i(I,Ce),i(Ce,Gt),i(I,Bt),i(I,Te),i(Te,Ft),i(I,Mt),i(I,Ne),i(Ne,Wt),i(I,Vt),p(e,st,m),p(e,ve,m),i(ve,Kt),p(e,rt,m),p(e,be,m),i(be,Jt),p(e,lt,m),p(e,ge,m),i(ge,Qt),p(e,ot,m),p(e,Z,m),i(Z,X),i(X,Ae),i(Z,Yt),p(e,nt,m),p(e,_e,m),i(_e,Zt),p(e,ft,m),p(e,ee,m),i(ee,Xt),i(ee,ze),i(ze,ei),i(ee,ti),p(e,pt,m),p(e,te,m),i(te,ii),i(te,$e),i($e,ai),i(te,si),p(e,dt,m),p(e,ie,m),i(ie,ae),i(ae,He),i(ie,ri),p(e,ut,m),p(e,ye,m),i(ye,li),p(e,ct,m),p(e,we,m),i(we,Re),i(Re,oi),p(e,ht,m),p(e,Ee,m),i(Ee,ni),p(e,mt,m),p(e,ke,m),i(ke,Ue),i(Ue,fi),p(e,vt,m),p(e,Se,m),i(Se,qe),i(qe,pi),p(e,bt,m),p(e,Pe,m),i(Pe,he),i(he,di),i(he,me),i(me,ui),i(he,ci),p(e,gt,m),p(e,se,m),i(se,re),i(re,Ge),i(se,hi),p(e,_t,m),p(e,De,m),i(De,mi),p(e,yt,m),p(e,M,m),i(M,vi),i(M,Be),i(Be,bi),i(M,gi),i(M,Fe),i(Fe,_i),i(M,yi),i(M,Me),i(Me,wi),i(M,Ei),p(e,wt,m),p(e,le,m),i(le,ki),i(le,We),i(We,Si),i(le,Pi),p(e,Et,m),p(e,oe,m),i(oe,Di),i(oe,Ve),i(Ve,Ii),i(oe,xi),p(e,kt,m),p(e,ne,m),i(ne,fe),i(fe,Ke),i(ne,ji),p(e,St,m),p(e,Ie,m),i(Ie,Li),p(e,Pt,m),p(e,xe,m),i(xe,Je),i(Je,Oi),p(e,Dt,m),p(e,je,m),i(je,Ci),p(e,It,m),p(e,T,m),i(T,Qe),i(Qe,Ti),i(T,Ni),i(T,Ye),i(Ye,Ai),i(T,zi),i(T,Ze),i(Ze,$i),i(T,Hi),i(T,Xe),i(Xe,Ri),i(T,Ui),i(T,et),i(et,qi),i(T,Gi),i(T,tt),i(tt,Bi),i(T,Fi),i(T,it),i(it,Mi),p(e,xt,m),p(e,Le,m),i(Le,Wi),p(e,jt,m),V&&V.m(e,m),p(e,Lt,m),Ot=!0},p(e,m){os&&V.p(e,m)},i(e){Ot||(Ht(n.$$.fragment,e),Ht(V),Ot=!0)},o(e){Rt(n.$$.fragment,e),Rt(V),Ot=!1},d(e){e&&t(a),e&&t(s),ra(n,e),e&&t(r),e&&t(_),e&&t(q),e&&t(C),e&&t($),e&&t(j),e&&t(F),e&&t(L),e&&t(W),e&&t(I),e&&t(st),e&&t(ve),e&&t(rt),e&&t(be),e&&t(lt),e&&t(ge),e&&t(ot),e&&t(Z),e&&t(nt),e&&t(_e),e&&t(ft),e&&t(ee),e&&t(pt),e&&t(te),e&&t(dt),e&&t(ie),e&&t(ut),e&&t(ye),e&&t(ct),e&&t(we),e&&t(ht),e&&t(Ee),e&&t(mt),e&&t(ke),e&&t(vt),e&&t(Se),e&&t(bt),e&&t(Pe),e&&t(gt),e&&t(se),e&&t(_t),e&&t(De),e&&t(yt),e&&t(M),e&&t(wt),e&&t(le),e&&t(Et),e&&t(oe),e&&t(kt),e&&t(ne),e&&t(St),e&&t(Ie),e&&t(Pt),e&&t(xe),e&&t(Dt),e&&t(je),e&&t(It),e&&t(T),e&&t(xt),e&&t(Le),e&&t(jt),V&&V.d(e),e&&t(Lt)}}}function Is(w){let a,h;const s=[w[0],ta];let n={$$slots:{default:[Ds]},$$scope:{ctx:w}};for(let r=0;r<s.length;r+=1)n=ea(n,s[r]);return a=new hs({props:n}),{c(){ia(a.$$.fragment)},l(r){aa(a.$$.fragment,r)},m(r,_){sa(a,r,_),h=!0},p(r,[_]){const S=_&1?cs(s,[_&1&&ts(r[0]),_&0&&ts(ta)]):{};_&2&&(S.$$scope={dirty:_,ctx:r}),a.$set(S)},i(r){h||(Ht(a.$$.fragment,r),h=!0)},o(r){Rt(a.$$.fragment,r),h=!1},d(r){ra(a,r)}}}const ta={title:"textual inversions",date:"2023-01-27",modifiedDate:"2023-01-27",categories:["stable diffusion","ai training"],svg:"Beakers",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Learn how to train textual inversions to use with Stable Diffusion.",author:"Ryan Sadwick",spacelab:!0,id:1},{title:$s,date:Hs,modifiedDate:Rs,categories:Us,svg:qs,seoImage:Gs,shortDescription:Bs,author:Fs,spacelab:os,id:xs}=ta;function js(w,a,h){return w.$$set=s=>{h(0,a=ea(ea({},a),is(s)))},a=is(a),[a]}class Ms extends ns{constructor(a){super(),fs(this,a,js,Is,ps,{})}}export{Ms as default,ta as metadata};
