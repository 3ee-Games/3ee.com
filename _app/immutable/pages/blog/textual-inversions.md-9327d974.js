import{S as os,i as ns,s as fs,l as $t,g as p,E as at,d as t,v as ds,e as l,t as d,c as o,a as f,h as u,b as y,I as i,j as ce,k as b,m as g,H as ue,J as ps,C as Xi,w as ta,x as ia,y as aa,z as us,A as es,q as Ht,o as Rt,B as sa,Z as ts}from"../../chunks/index-8ed999ca.js";import{P as cs}from"../../chunks/_post-60c1c672.js";import{R as hs}from"../../chunks/ResponsivePicture-c98b3942.js";import{a as ms}from"../../chunks/accountStore-859cf7a0.js";/* empty css                                                                   */import"../../chunks/menuContextStore-382f91e1.js";import"../../chunks/index-71ac3aa5.js";function vs(w){let a,h,s,n,r,_,S,I,U,q,C,x,z,N,A,$,j,H,F,L;function K(v,k){return typeof v[0].title!="undefined"?_s:gs}let R=K(w),O=R(w);function J(v,k){return typeof v[0].description!="undefined"?ws:ys}let B=J(w),P=B(w),E=typeof w[0].list_description!="undefined"&&is(w),c=typeof w[0].footer_description!="undefined"&&as(w);return{c(){a=l("hr"),h=b(),s=l("div"),O.c(),n=b(),r=l("p"),_=l("ion-icon"),S=d("SpaceLab Content"),I=b(),P.c(),U=b(),E&&E.c(),q=b(),c&&c.c(),C=b(),x=l("button"),z=l("ion-icon"),N=b(),A=l("span"),$=d("SpaceLab"),j=b(),H=l("hr"),this.h()},l(v){a=o(v,"HR",{}),h=g(v),s=o(v,"DIV",{class:!0});var k=f(s);O.l(k),n=g(k),r=o(k,"P",{class:!0});var W=f(r);_=o(W,"ION-ICON",{class:!0,name:!0}),f(_).forEach(t),S=u(W,"SpaceLab Content"),W.forEach(t),I=g(k),P.l(k),U=g(k),E&&E.l(k),q=g(k),c&&c.l(k),C=g(k),x=o(k,"BUTTON",{class:!0});var D=f(x);z=o(D,"ION-ICON",{class:!0,name:!0}),f(z).forEach(t),N=g(D),A=o(D,"SPAN",{});var Y=f(A);$=u(Y,"SpaceLab"),Y.forEach(t),D.forEach(t),k.forEach(t),j=g(v),H=o(v,"HR",{}),this.h()},h(){ue(_,"class","icon svelte-vjvavh"),ue(_,"name","lock-closed"),y(r,"class","highlight large svelte-vjvavh"),ue(z,"class","icon svelte-vjvavh"),ue(z,"name","planet"),y(x,"class","button subscribe svelte-vjvavh"),y(s,"class","subscribe svelte-vjvavh")},m(v,k){p(v,a,k),p(v,h,k),p(v,s,k),O.m(s,null),i(s,n),i(s,r),i(r,_),i(r,S),i(s,I),P.m(s,null),i(s,U),E&&E.m(s,null),i(s,q),c&&c.m(s,null),i(s,C),i(s,x),i(x,z),i(x,N),i(x,A),i(A,$),p(v,j,k),p(v,H,k),F||(L=ps(x,"click",w[3]),F=!0)},p(v,k){R===(R=K(v))&&O?O.p(v,k):(O.d(1),O=R(v),O&&(O.c(),O.m(s,n))),B===(B=J(v))&&P?P.p(v,k):(P.d(1),P=B(v),P&&(P.c(),P.m(s,U))),typeof v[0].list_description!="undefined"?E?E.p(v,k):(E=is(v),E.c(),E.m(s,q)):E&&(E.d(1),E=null),typeof v[0].footer_description!="undefined"?c?c.p(v,k):(c=as(v),c.c(),c.m(s,C)):c&&(c.d(1),c=null)},d(v){v&&t(a),v&&t(h),v&&t(s),O.d(),P.d(),E&&E.d(),c&&c.d(),v&&t(j),v&&t(H),F=!1,L()}}}function bs(w){let a,h,s,n=w[0].title+"",r,_,S,I,U,q,C,x=w[0].description+"",z,N,A,$,j,H,F,L,K,R,O,J,B,P=typeof w[0].list_description!="undefined"&&ss(w),E=typeof w[0].footer_description!="undefined"&&rs(w);return{c(){a=l("hr"),h=b(),s=l("h2"),r=d(n),_=b(),S=l("p"),I=l("ion-icon"),U=d("SpaceLab Content"),q=b(),C=l("p"),z=d(x),N=b(),P&&P.c(),A=b(),E&&E.c(),$=b(),j=l("button"),H=l("ion-icon"),F=b(),L=l("span"),K=d("Download"),R=b(),O=l("hr"),this.h()},l(c){a=o(c,"HR",{}),h=g(c),s=o(c,"H2",{class:!0});var v=f(s);r=u(v,n),v.forEach(t),_=g(c),S=o(c,"P",{class:!0});var k=f(S);I=o(k,"ION-ICON",{class:!0,name:!0}),f(I).forEach(t),U=u(k,"SpaceLab Content"),k.forEach(t),q=g(c),C=o(c,"P",{class:!0});var W=f(C);z=u(W,x),W.forEach(t),N=g(c),P&&P.l(c),A=g(c),E&&E.l(c),$=g(c),j=o(c,"BUTTON",{class:!0});var D=f(j);H=o(D,"ION-ICON",{class:!0,name:!0}),f(H).forEach(t),F=g(D),L=o(D,"SPAN",{});var Y=f(L);K=u(Y,"Download"),Y.forEach(t),D.forEach(t),R=g(c),O=o(c,"HR",{}),this.h()},h(){y(s,"class","svelte-vjvavh"),ue(I,"class","icon svelte-vjvavh"),ue(I,"name","planet-sharp"),y(S,"class","highlight large svelte-vjvavh"),y(C,"class","svelte-vjvavh"),ue(H,"class","icon svelte-vjvavh"),ue(H,"name","cloud-download"),y(j,"class","button svelte-vjvavh")},m(c,v){p(c,a,v),p(c,h,v),p(c,s,v),i(s,r),p(c,_,v),p(c,S,v),i(S,I),i(S,U),p(c,q,v),p(c,C,v),i(C,z),p(c,N,v),P&&P.m(c,v),p(c,A,v),E&&E.m(c,v),p(c,$,v),p(c,j,v),i(j,H),i(j,F),i(j,L),i(L,K),p(c,R,v),p(c,O,v),J||(B=ps(j,"click",w[2]),J=!0)},p(c,v){v&1&&n!==(n=c[0].title+"")&&ce(r,n),v&1&&x!==(x=c[0].description+"")&&ce(z,x),typeof c[0].list_description!="undefined"?P?P.p(c,v):(P=ss(c),P.c(),P.m(A.parentNode,A)):P&&(P.d(1),P=null),typeof c[0].footer_description!="undefined"?E?E.p(c,v):(E=rs(c),E.c(),E.m($.parentNode,$)):E&&(E.d(1),E=null)},d(c){c&&t(a),c&&t(h),c&&t(s),c&&t(_),c&&t(S),c&&t(q),c&&t(C),c&&t(N),P&&P.d(c),c&&t(A),E&&E.d(c),c&&t($),c&&t(j),c&&t(R),c&&t(O),J=!1,B()}}}function gs(w){let a,h;return{c(){a=l("h2"),h=d("SpaceLab Content"),this.h()},l(s){a=o(s,"H2",{class:!0});var n=f(a);h=u(n,"SpaceLab Content"),n.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(s,n){p(s,a,n),i(a,h)},p:at,d(s){s&&t(a)}}}function _s(w){let a,h=w[0].title+"",s;return{c(){a=l("h2"),s=d(h),this.h()},l(n){a=o(n,"H2",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].title+"")&&ce(s,h)},d(n){n&&t(a)}}}function ys(w){let a,h;return{c(){a=l("p"),h=d("To access this content, you need a SpaceLab subscription."),this.h()},l(s){a=o(s,"P",{class:!0});var n=f(a);h=u(n,"To access this content, you need a SpaceLab subscription."),n.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(s,n){p(s,a,n),i(a,h)},p:at,d(s){s&&t(a)}}}function ws(w){let a,h=w[0].description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].description+"")&&ce(s,h)},d(n){n&&t(a)}}}function is(w){let a,h,s=w[0].list_description+"",n;return{c(){a=l("div"),h=l("p"),n=d(s),this.h()},l(r){a=o(r,"DIV",{class:!0});var _=f(a);h=o(_,"P",{class:!0});var S=f(h);n=u(S,s),S.forEach(t),_.forEach(t),this.h()},h(){y(h,"class","svelte-vjvavh"),y(a,"class","list-description svelte-vjvavh")},m(r,_){p(r,a,_),i(a,h),i(h,n)},p(r,_){_&1&&s!==(s=r[0].list_description+"")&&ce(n,s)},d(r){r&&t(a)}}}function as(w){let a,h=w[0].footer_description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].footer_description+"")&&ce(s,h)},d(n){n&&t(a)}}}function ss(w){let a,h,s=w[0].list_description+"",n;return{c(){a=l("div"),h=l("p"),n=d(s),this.h()},l(r){a=o(r,"DIV",{class:!0});var _=f(a);h=o(_,"P",{class:!0});var S=f(h);n=u(S,s),S.forEach(t),_.forEach(t),this.h()},h(){y(h,"class","svelte-vjvavh"),y(a,"class","list-description svelte-vjvavh")},m(r,_){p(r,a,_),i(a,h),i(h,n)},p(r,_){_&1&&s!==(s=r[0].list_description+"")&&ce(n,s)},d(r){r&&t(a)}}}function rs(w){let a,h=w[0].footer_description+"",s;return{c(){a=l("p"),s=d(h),this.h()},l(n){a=o(n,"P",{class:!0});var r=f(a);s=u(r,h),r.forEach(t),this.h()},h(){y(a,"class","svelte-vjvavh")},m(n,r){p(n,a,r),i(a,s)},p(n,r){r&1&&h!==(h=n[0].footer_description+"")&&ce(s,h)},d(n){n&&t(a)}}}function Es(w){let a;function h(r,_){return typeof r[0]!="undefined"&&typeof r[0].pk!="undefined"?bs:vs}let s=h(w),n=s(w);return{c(){n.c(),a=$t()},l(r){n.l(r),a=$t()},m(r,_){n.m(r,_),p(r,a,_)},p(r,[_]){s===(s=h(r))&&n?n.p(r,_):(n.d(1),n=s(r),n&&(n.c(),n.m(a.parentNode,a)))},i:at,o:at,d(r){n.d(r),r&&t(a)}}}function ks(w,a,h){let{id:s}=a,n={},r;ms.subscribe(I=>{r=I}),ds(async()=>{if(typeof(r==null?void 0:r.token)!="undefined"){let U=await(await fetch(`https://3ee.dev/education/spacelab/${s}/`,{headers:{Accept:"application/json","Content-Type":"application/json","Access-Control-Allow-Origin":"https://3ee.com",Authorization:"Token "+r.token},mode:"cors"})).json();h(0,n=U)}else h(0,n.success=!1,n)});const _=()=>window.open(n.url,"_blank"),S=()=>window.open("/spacelab/","_blank");return w.$$set=I=>{"id"in I&&h(1,s=I.id)},[n,s,_,S]}class Ss extends os{constructor(a){super(),ns(this,a,ks,Es,fs,{id:1})}}function Ps(w){let a,h;return a=new Ss({props:{id:xs}}),{c(){ta(a.$$.fragment)},l(s){ia(a.$$.fragment,s)},m(s,n){aa(a,s,n),h=!0},p:at,i(s){h||(Ht(a.$$.fragment,s),h=!0)},o(s){Rt(a.$$.fragment,s),h=!1},d(s){sa(a,s)}}}function Ds(w){let a,h,s,n,r,_,S,I,U,q,C,x,z,N,A,$,j,H,F,L,K,R,O,J,B,P,E,c,v,k,W,D,Y,Oe,Ut,qt,Ce,Gt,Bt,Te,Ft,Mt,Ne,Wt,Vt,st,ve,Kt,rt,be,Jt,lt,ge,Qt,ot,Z,X,Ae,Yt,nt,_e,Zt,ft,ee,Xt,ze,ei,ti,pt,te,ii,$e,ai,si,dt,ie,ae,He,ri,ut,ye,li,ct,we,Re,oi,ht,Ee,ni,mt,ke,Ue,fi,vt,Se,qe,pi,bt,Pe,he,di,me,ui,ci,gt,se,re,Ge,hi,_t,De,mi,yt,M,vi,Be,bi,gi,Fe,_i,yi,Me,wi,Ei,wt,le,ki,We,Si,Pi,Et,oe,Di,Ve,Ii,xi,kt,ne,fe,Ke,ji,St,Ie,Li,Pt,xe,Je,Oi,Dt,je,Ci,It,T,Qe,Ti,Ni,Ye,Ai,zi,Ze,$i,Hi,Xe,Ri,Ui,et,qi,Gi,tt,Bi,Fi,it,Mi,xt,Le,Wi,jt,Lt,Ot;n=new hs({props:{smallImage:"https://3ee.s3.amazonaws.com/img/aub_small.webp",largeImage:"https://3ee.s3.amazonaws.com/img/aub_large.webp",alt:"Six images of Aubrey Plaza",largeWidth:"786",largeHeight:"786",smallWidth:"461",smallHeight:"461"}});let V=ls&&Ps();return{c(){a=l("p"),h=d("A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),s=b(),ta(n.$$.fragment),r=b(),_=l("h2"),S=l("a"),I=l("span"),U=d("What is Textual Inversion?"),q=b(),C=l("blockquote"),x=l("p"),z=d("\u{1F4C4} See the paper: "),N=l("a"),A=d("https://arxiv.org/abs/2208.01618"),$=b(),j=l("p"),H=d("Stable Diffusion is designed to predict and eliminate noise from images. By applying this process 20 to 40 times successively on pure noise, you can remarkably transform it into an entirely new image."),F=b(),L=l("p"),K=d("At its core, Stable Diffusion employs a distinctive diffusion model called the "),R=l("strong"),O=d("latent diffusion model (LDM)"),J=d(", fine-tuned to accurately depict images. The CLIP encoder portrays images with "),B=l("strong"),P=d("768"),E=d(" latents in SD 1.x models, while SD 2.x models utilize "),c=l("strong"),v=d("1024"),k=d(" latents. Each latent represents a specific feature type within a highly intricate spectrum that surpasses human comprehension."),W=b(),D=l("p"),Y=d("For example, one end of the spectrum might represent round objects, while the opposite end showcases square objects. It\u2019s crucial to understand that these representations are far more refined and complex than a straightforward binary illustration. Likewise, the spectrum might span from chairs at one end to giraffes at the other. Feature spectra are encoded with captions, enabling words like \u201D"),Oe=l("code"),Ut=d("cat"),qt=d(",\u201D \u201D"),Ce=l("code"),Gt=d("planet"),Bt=d(",\u201D or \u201D"),Te=l("code"),Ft=d("spaceship"),Mt=d("\u201D to be described by "),Ne=l("strong"),Wt=d("768"),Vt=d(" values across various spectra."),st=b(),ve=l("p"),Kt=d("Guided by these latents, Stable Diffusion learns to discern the meaning of each latent through inference using prompts. It allocates weights to different image regions, pinpointing areas that require correction. During training, you can introduce latents never trained on before through textual inversion or by manually merging existing word latents."),rt=b(),be=l("p"),Jt=d("Stable Diffusion generates new concepts by grasping the idea spectra associated with latents, instead of duplicating existing content. For instance, it can blend 50% cat with 50% kangaroo to create a cat-kangaroo hybrid creature it has never encountered during training."),lt=b(),ge=l("p"),Qt=d("You can discover latents that characterize your own face or a novel art style, even if Stable Diffusion has never trained on them before, unlocking boundless creative potential."),ot=b(),Z=l("h2"),X=l("a"),Ae=l("span"),Yt=d("Embedding Usage"),nt=b(),_e=l("p"),Zt=d("Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),ft=b(),ee=l("p"),Xt=d("\u2728 V2: Use the token "),ze=l("code"),ei=d("aubreyplazav2-300"),ti=d(" in your prompts to activate the embedding."),pt=b(),te=l("p"),ii=d("\u2728 V1: Use the token "),$e=l("code"),ai=d("aubreyplazav1-7375"),si=d(" in your prompts to activate the embedding."),dt=b(),ie=l("h2"),ae=l("a"),He=l("span"),ri=d("Prompt Example"),ut=b(),ye=l("p"),li=d("\u{1F9FE} Prompt:"),ct=b(),we=l("p"),Re=l("code"),oi=d("Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),ht=b(),Ee=l("p"),ni=d("\u2796 Negative:"),mt=b(),ke=l("p"),Ue=l("code"),fi=d("(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),vt=b(),Se=l("p"),qe=l("em"),pi=d("Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),bt=b(),Pe=l("blockquote"),he=l("p"),di=d("\u{1F305} For more information on how to use this embedding, see "),me=l("a"),ui=d("https://huggingface.co/datasets/zuleo/aubrey-plaza"),ci=d("."),gt=b(),se=l("h2"),re=l("a"),Ge=l("span"),hi=d("Understanding Learning Rates"),_t=b(),De=l("p"),mi=d("\u{1F4C8} Learning rates play a pivotal role in training machine learning models. Just as an artist sculpts a masterpiece from a boulder, the learning rate influences how quickly and precisely the model evolves with each training iteration. In the context of Stable Diffusion, a high learning rate enables rapid learning, but it also heightens the risk of producing distorted images with visual artifacts."),yt=b(),M=l("p"),vi=d("Imagine you\u2019re sculpting a statue from a colossal boulder. In the beginning, using a "),Be=l("strong"),bi=d("sledgehammer"),gi=d(" (akin to a high learning rate) helps you remove large chunks of stone quickly, making significant progress. However, as the sculpture takes shape, you need to transition to "),Fe=l("strong"),_i=d("smaller tools"),yi=d(" like a hammer for improved precision. Ultimately, you\u2019ll use a "),Me=l("strong"),wi=d("chisel"),Ei=d(" to carve the intricate details that bring your masterpiece to life."),wt=b(),le=l("p"),ki=d("Persisting with a high learning rate throughout the entire process can render the embedding rigid and impede Stable Diffusion\u2019s ability to learn new information. Instead, it\u2019s advisable to stick to a value around the default of "),We=l("strong"),Si=d("0.005"),Pi=d(", which generally performs well for most subject-based training."),Et=b(),oe=l("p"),Di=d("That being said, you don\u2019t have to confine yourself to a static learning rate. Employing a "),Ve=l("strong"),Ii=d("progressive learning rate"),xi=d(" that adjusts at specified intervals can yield even better results. By starting with a higher learning rate and gradually reducing it as the training advances, Stable Diffusion can achieve more stable and accurate outcomes, akin to a sculptor\u2019s masterpiece."),kt=b(),ne=l("h3"),fe=l("a"),Ke=l("span"),ji=d("Progressive Learning Rates"),St=b(),Ie=l("p"),Li=d("Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),Pt=b(),xe=l("p"),Je=l("code"),Oi=d("0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Dt=b(),je=l("p"),Ci=d("This is a list of learning rates and step intervals. When training a model, the learning rate will change at the specified step intervals. Here\u2019s what happens step-by-step during each interval when training your own embedding:"),It=b(),T=l("ul"),Qe=l("li"),Ti=d("Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Ni=b(),Ye=l("li"),Ai=d("Steps 10 - 20: lowered to 0.02"),zi=b(),Ze=l("li"),$i=d("20 - 60: lowered to 0.01"),Hi=b(),Xe=l("li"),Ri=d("60 - 200: lowered to 0.005"),Ui=b(),et=l("li"),qi=d("200 - 500: lowered to 0.002"),Gi=b(),tt=l("li"),Bi=d("500 - 3000: lowered to 0.001"),Fi=b(),it=l("li"),Mi=d("3000+ is lowered to 0.0005 (slow learning rate)"),xt=b(),Le=l("p"),Wi=d("As the learning rate is lowered, more fine tuning happens, increasing the precision of the embedding. This should produce subject likeness results in the 200 - 500 step range. Results may get better or worse towards 1000 - 1500 steps, depending on the subject."),jt=b(),V&&V.c(),Lt=$t(),this.h()},l(e){a=o(e,"P",{});var m=f(a);h=u(m,"A great way to dive into the methods of training an embedding using textual inversion is to use a celebrity.  This model was trained on a wide variety of different images of Aubrey Plaza, we encourage you to try different variations of vivid prompts.  Below are my findings with this experiment and deep dive into the model."),m.forEach(t),s=g(e),ia(n.$$.fragment,e),r=g(e),_=o(e,"H2",{id:!0});var Vi=f(_);S=o(Vi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ra=f(S);I=o(ra,"SPAN",{class:!0}),f(I).forEach(t),ra.forEach(t),U=u(Vi,"What is Textual Inversion?"),Vi.forEach(t),q=g(e),C=o(e,"BLOCKQUOTE",{});var la=f(C);x=o(la,"P",{});var Ki=f(x);z=u(Ki,"\u{1F4C4} See the paper: "),N=o(Ki,"A",{href:!0,rel:!0});var oa=f(N);A=u(oa,"https://arxiv.org/abs/2208.01618"),oa.forEach(t),Ki.forEach(t),la.forEach(t),$=g(e),j=o(e,"P",{});var na=f(j);H=u(na,"Stable Diffusion is designed to predict and eliminate noise from images. By applying this process 20 to 40 times successively on pure noise, you can remarkably transform it into an entirely new image."),na.forEach(t),F=g(e),L=o(e,"P",{});var pe=f(L);K=u(pe,"At its core, Stable Diffusion employs a distinctive diffusion model called the "),R=o(pe,"STRONG",{});var fa=f(R);O=u(fa,"latent diffusion model (LDM)"),fa.forEach(t),J=u(pe,", fine-tuned to accurately depict images. The CLIP encoder portrays images with "),B=o(pe,"STRONG",{});var pa=f(B);P=u(pa,"768"),pa.forEach(t),E=u(pe," latents in SD 1.x models, while SD 2.x models utilize "),c=o(pe,"STRONG",{});var da=f(c);v=u(da,"1024"),da.forEach(t),k=u(pe," latents. Each latent represents a specific feature type within a highly intricate spectrum that surpasses human comprehension."),pe.forEach(t),W=g(e),D=o(e,"P",{});var Q=f(D);Y=u(Q,"For example, one end of the spectrum might represent round objects, while the opposite end showcases square objects. It\u2019s crucial to understand that these representations are far more refined and complex than a straightforward binary illustration. Likewise, the spectrum might span from chairs at one end to giraffes at the other. Feature spectra are encoded with captions, enabling words like \u201D"),Oe=o(Q,"CODE",{});var ua=f(Oe);Ut=u(ua,"cat"),ua.forEach(t),qt=u(Q,",\u201D \u201D"),Ce=o(Q,"CODE",{});var ca=f(Ce);Gt=u(ca,"planet"),ca.forEach(t),Bt=u(Q,",\u201D or \u201D"),Te=o(Q,"CODE",{});var ha=f(Te);Ft=u(ha,"spaceship"),ha.forEach(t),Mt=u(Q,"\u201D to be described by "),Ne=o(Q,"STRONG",{});var ma=f(Ne);Wt=u(ma,"768"),ma.forEach(t),Vt=u(Q," values across various spectra."),Q.forEach(t),st=g(e),ve=o(e,"P",{});var va=f(ve);Kt=u(va,"Guided by these latents, Stable Diffusion learns to discern the meaning of each latent through inference using prompts. It allocates weights to different image regions, pinpointing areas that require correction. During training, you can introduce latents never trained on before through textual inversion or by manually merging existing word latents."),va.forEach(t),rt=g(e),be=o(e,"P",{});var ba=f(be);Jt=u(ba,"Stable Diffusion generates new concepts by grasping the idea spectra associated with latents, instead of duplicating existing content. For instance, it can blend 50% cat with 50% kangaroo to create a cat-kangaroo hybrid creature it has never encountered during training."),ba.forEach(t),lt=g(e),ge=o(e,"P",{});var ga=f(ge);Qt=u(ga,"You can discover latents that characterize your own face or a novel art style, even if Stable Diffusion has never trained on them before, unlocking boundless creative potential."),ga.forEach(t),ot=g(e),Z=o(e,"H2",{id:!0});var Ji=f(Z);X=o(Ji,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var _a=f(X);Ae=o(_a,"SPAN",{class:!0}),f(Ae).forEach(t),_a.forEach(t),Yt=u(Ji,"Embedding Usage"),Ji.forEach(t),nt=g(e),_e=o(e,"P",{});var ya=f(_e);Zt=u(ya,"Using embeddings within different Stable Diffusion UIs is usually the same process: add the embedding token to your prompt and modify the weight of that specific token in your prompts."),ya.forEach(t),ft=g(e),ee=o(e,"P",{});var Ct=f(ee);Xt=u(Ct,"\u2728 V2: Use the token "),ze=o(Ct,"CODE",{});var wa=f(ze);ei=u(wa,"aubreyplazav2-300"),wa.forEach(t),ti=u(Ct," in your prompts to activate the embedding."),Ct.forEach(t),pt=g(e),te=o(e,"P",{});var Tt=f(te);ii=u(Tt,"\u2728 V1: Use the token "),$e=o(Tt,"CODE",{});var Ea=f($e);ai=u(Ea,"aubreyplazav1-7375"),Ea.forEach(t),si=u(Tt," in your prompts to activate the embedding."),Tt.forEach(t),dt=g(e),ie=o(e,"H2",{id:!0});var Qi=f(ie);ae=o(Qi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var ka=f(ae);He=o(ka,"SPAN",{class:!0}),f(He).forEach(t),ka.forEach(t),ri=u(Qi,"Prompt Example"),Qi.forEach(t),ut=g(e),ye=o(e,"P",{});var Sa=f(ye);li=u(Sa,"\u{1F9FE} Prompt:"),Sa.forEach(t),ct=g(e),we=o(e,"P",{});var Pa=f(we);Re=o(Pa,"CODE",{});var Da=f(Re);oi=u(Da,"Perfectly-centered close up portrait-photograph of a real life warrior aubreyplazav2-300, hair flowing in the wind with beautiful bright blue eyes, (wearing gold and white armor and big hoop gold earrings and a tiara:1.22223), (battle axe and broad sword hanging from her belt:1.112), standing near a rain forest with a waterfall, lifelike, super highly detailed, professional digital painting, artstation, concept art, Photorealism, HD quality, 8k resolution, beautiful, cinematic, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP"),Da.forEach(t),Pa.forEach(t),ht=g(e),Ee=o(e,"P",{});var Ia=f(Ee);ni=u(Ia,"\u2796 Negative:"),Ia.forEach(t),mt=g(e),ke=o(e,"P",{});var xa=f(ke);Ue=o(xa,"CODE",{});var ja=f(Ue);fi=u(ja,"(bad_prompt_version2:0.8), ((((ugly)))), (((duplicate))), ((morbid)), ((mutilated)), [out of frame], extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, (((disfigured))), out of frame, ugly, extra limbs, (bad anatomy), gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), watermark, signature, words, (text:1.4), cross eyed"),ja.forEach(t),xa.forEach(t),vt=g(e),Se=o(e,"P",{});var La=f(Se);qe=o(La,"EM",{});var Oa=f(qe);pi=u(Oa,"Steps: 20, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 3960559569, Size: 512x512, Model hash: 67abd65708"),Oa.forEach(t),La.forEach(t),bt=g(e),Pe=o(e,"BLOCKQUOTE",{});var Ca=f(Pe);he=o(Ca,"P",{});var Nt=f(he);di=u(Nt,"\u{1F305} For more information on how to use this embedding, see "),me=o(Nt,"A",{href:!0,rel:!0});var Ta=f(me);ui=u(Ta,"https://huggingface.co/datasets/zuleo/aubrey-plaza"),Ta.forEach(t),ci=u(Nt,"."),Nt.forEach(t),Ca.forEach(t),gt=g(e),se=o(e,"H2",{id:!0});var Yi=f(se);re=o(Yi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var Na=f(re);Ge=o(Na,"SPAN",{class:!0}),f(Ge).forEach(t),Na.forEach(t),hi=u(Yi,"Understanding Learning Rates"),Yi.forEach(t),_t=g(e),De=o(e,"P",{});var Aa=f(De);mi=u(Aa,"\u{1F4C8} Learning rates play a pivotal role in training machine learning models. Just as an artist sculpts a masterpiece from a boulder, the learning rate influences how quickly and precisely the model evolves with each training iteration. In the context of Stable Diffusion, a high learning rate enables rapid learning, but it also heightens the risk of producing distorted images with visual artifacts."),Aa.forEach(t),yt=g(e),M=o(e,"P",{});var de=f(M);vi=u(de,"Imagine you\u2019re sculpting a statue from a colossal boulder. In the beginning, using a "),Be=o(de,"STRONG",{});var za=f(Be);bi=u(za,"sledgehammer"),za.forEach(t),gi=u(de," (akin to a high learning rate) helps you remove large chunks of stone quickly, making significant progress. However, as the sculpture takes shape, you need to transition to "),Fe=o(de,"STRONG",{});var $a=f(Fe);_i=u($a,"smaller tools"),$a.forEach(t),yi=u(de," like a hammer for improved precision. Ultimately, you\u2019ll use a "),Me=o(de,"STRONG",{});var Ha=f(Me);wi=u(Ha,"chisel"),Ha.forEach(t),Ei=u(de," to carve the intricate details that bring your masterpiece to life."),de.forEach(t),wt=g(e),le=o(e,"P",{});var At=f(le);ki=u(At,"Persisting with a high learning rate throughout the entire process can render the embedding rigid and impede Stable Diffusion\u2019s ability to learn new information. Instead, it\u2019s advisable to stick to a value around the default of "),We=o(At,"STRONG",{});var Ra=f(We);Si=u(Ra,"0.005"),Ra.forEach(t),Pi=u(At,", which generally performs well for most subject-based training."),At.forEach(t),Et=g(e),oe=o(e,"P",{});var zt=f(oe);Di=u(zt,"That being said, you don\u2019t have to confine yourself to a static learning rate. Employing a "),Ve=o(zt,"STRONG",{});var Ua=f(Ve);Ii=u(Ua,"progressive learning rate"),Ua.forEach(t),xi=u(zt," that adjusts at specified intervals can yield even better results. By starting with a higher learning rate and gradually reducing it as the training advances, Stable Diffusion can achieve more stable and accurate outcomes, akin to a sculptor\u2019s masterpiece."),zt.forEach(t),kt=g(e),ne=o(e,"H3",{id:!0});var Zi=f(ne);fe=o(Zi,"A",{"aria-hidden":!0,tabindex:!0,href:!0});var qa=f(fe);Ke=o(qa,"SPAN",{class:!0}),f(Ke).forEach(t),qa.forEach(t),ji=u(Zi,"Progressive Learning Rates"),Zi.forEach(t),St=g(e),Ie=o(e,"P",{});var Ga=f(Ie);Li=u(Ga,"Progressive learning rates are able to change during specified steps and can be appended to a list.  Most training CLIs and/or UIs accept a list of learning rates and step intervals.  For example:"),Ga.forEach(t),Pt=g(e),xe=o(e,"P",{});var Ba=f(xe);Je=o(Ba,"CODE",{});var Fa=f(Je);Oi=u(Fa,"0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005"),Fa.forEach(t),Ba.forEach(t),Dt=g(e),je=o(e,"P",{});var Ma=f(je);Ci=u(Ma,"This is a list of learning rates and step intervals. When training a model, the learning rate will change at the specified step intervals. Here\u2019s what happens step-by-step during each interval when training your own embedding:"),Ma.forEach(t),It=g(e),T=o(e,"UL",{});var G=f(T);Qe=o(G,"LI",{});var Wa=f(Qe);Ti=u(Wa,"Step 1 - 10 uses a learning rate of 0.05. (high learning rate)"),Wa.forEach(t),Ni=g(G),Ye=o(G,"LI",{});var Va=f(Ye);Ai=u(Va,"Steps 10 - 20: lowered to 0.02"),Va.forEach(t),zi=g(G),Ze=o(G,"LI",{});var Ka=f(Ze);$i=u(Ka,"20 - 60: lowered to 0.01"),Ka.forEach(t),Hi=g(G),Xe=o(G,"LI",{});var Ja=f(Xe);Ri=u(Ja,"60 - 200: lowered to 0.005"),Ja.forEach(t),Ui=g(G),et=o(G,"LI",{});var Qa=f(et);qi=u(Qa,"200 - 500: lowered to 0.002"),Qa.forEach(t),Gi=g(G),tt=o(G,"LI",{});var Ya=f(tt);Bi=u(Ya,"500 - 3000: lowered to 0.001"),Ya.forEach(t),Fi=g(G),it=o(G,"LI",{});var Za=f(it);Mi=u(Za,"3000+ is lowered to 0.0005 (slow learning rate)"),Za.forEach(t),G.forEach(t),xt=g(e),Le=o(e,"P",{});var Xa=f(Le);Wi=u(Xa,"As the learning rate is lowered, more fine tuning happens, increasing the precision of the embedding. This should produce subject likeness results in the 200 - 500 step range. Results may get better or worse towards 1000 - 1500 steps, depending on the subject."),Xa.forEach(t),jt=g(e),V&&V.l(e),Lt=$t(),this.h()},h(){y(I,"class","icon icon-link"),y(S,"aria-hidden","true"),y(S,"tabindex","-1"),y(S,"href","#what-is-textual-inversion"),y(_,"id","what-is-textual-inversion"),y(N,"href","https://arxiv.org/abs/2208.01618"),y(N,"rel","nofollow"),y(Ae,"class","icon icon-link"),y(X,"aria-hidden","true"),y(X,"tabindex","-1"),y(X,"href","#embedding-usage"),y(Z,"id","embedding-usage"),y(He,"class","icon icon-link"),y(ae,"aria-hidden","true"),y(ae,"tabindex","-1"),y(ae,"href","#prompt-example"),y(ie,"id","prompt-example"),y(me,"href","https://huggingface.co/datasets/zuleo/aubrey-plaza"),y(me,"rel","nofollow"),y(Ge,"class","icon icon-link"),y(re,"aria-hidden","true"),y(re,"tabindex","-1"),y(re,"href","#understanding-learning-rates"),y(se,"id","understanding-learning-rates"),y(Ke,"class","icon icon-link"),y(fe,"aria-hidden","true"),y(fe,"tabindex","-1"),y(fe,"href","#progressive-learning-rates"),y(ne,"id","progressive-learning-rates")},m(e,m){p(e,a,m),i(a,h),p(e,s,m),aa(n,e,m),p(e,r,m),p(e,_,m),i(_,S),i(S,I),i(_,U),p(e,q,m),p(e,C,m),i(C,x),i(x,z),i(x,N),i(N,A),p(e,$,m),p(e,j,m),i(j,H),p(e,F,m),p(e,L,m),i(L,K),i(L,R),i(R,O),i(L,J),i(L,B),i(B,P),i(L,E),i(L,c),i(c,v),i(L,k),p(e,W,m),p(e,D,m),i(D,Y),i(D,Oe),i(Oe,Ut),i(D,qt),i(D,Ce),i(Ce,Gt),i(D,Bt),i(D,Te),i(Te,Ft),i(D,Mt),i(D,Ne),i(Ne,Wt),i(D,Vt),p(e,st,m),p(e,ve,m),i(ve,Kt),p(e,rt,m),p(e,be,m),i(be,Jt),p(e,lt,m),p(e,ge,m),i(ge,Qt),p(e,ot,m),p(e,Z,m),i(Z,X),i(X,Ae),i(Z,Yt),p(e,nt,m),p(e,_e,m),i(_e,Zt),p(e,ft,m),p(e,ee,m),i(ee,Xt),i(ee,ze),i(ze,ei),i(ee,ti),p(e,pt,m),p(e,te,m),i(te,ii),i(te,$e),i($e,ai),i(te,si),p(e,dt,m),p(e,ie,m),i(ie,ae),i(ae,He),i(ie,ri),p(e,ut,m),p(e,ye,m),i(ye,li),p(e,ct,m),p(e,we,m),i(we,Re),i(Re,oi),p(e,ht,m),p(e,Ee,m),i(Ee,ni),p(e,mt,m),p(e,ke,m),i(ke,Ue),i(Ue,fi),p(e,vt,m),p(e,Se,m),i(Se,qe),i(qe,pi),p(e,bt,m),p(e,Pe,m),i(Pe,he),i(he,di),i(he,me),i(me,ui),i(he,ci),p(e,gt,m),p(e,se,m),i(se,re),i(re,Ge),i(se,hi),p(e,_t,m),p(e,De,m),i(De,mi),p(e,yt,m),p(e,M,m),i(M,vi),i(M,Be),i(Be,bi),i(M,gi),i(M,Fe),i(Fe,_i),i(M,yi),i(M,Me),i(Me,wi),i(M,Ei),p(e,wt,m),p(e,le,m),i(le,ki),i(le,We),i(We,Si),i(le,Pi),p(e,Et,m),p(e,oe,m),i(oe,Di),i(oe,Ve),i(Ve,Ii),i(oe,xi),p(e,kt,m),p(e,ne,m),i(ne,fe),i(fe,Ke),i(ne,ji),p(e,St,m),p(e,Ie,m),i(Ie,Li),p(e,Pt,m),p(e,xe,m),i(xe,Je),i(Je,Oi),p(e,Dt,m),p(e,je,m),i(je,Ci),p(e,It,m),p(e,T,m),i(T,Qe),i(Qe,Ti),i(T,Ni),i(T,Ye),i(Ye,Ai),i(T,zi),i(T,Ze),i(Ze,$i),i(T,Hi),i(T,Xe),i(Xe,Ri),i(T,Ui),i(T,et),i(et,qi),i(T,Gi),i(T,tt),i(tt,Bi),i(T,Fi),i(T,it),i(it,Mi),p(e,xt,m),p(e,Le,m),i(Le,Wi),p(e,jt,m),V&&V.m(e,m),p(e,Lt,m),Ot=!0},p(e,m){ls&&V.p(e,m)},i(e){Ot||(Ht(n.$$.fragment,e),Ht(V),Ot=!0)},o(e){Rt(n.$$.fragment,e),Rt(V),Ot=!1},d(e){e&&t(a),e&&t(s),sa(n,e),e&&t(r),e&&t(_),e&&t(q),e&&t(C),e&&t($),e&&t(j),e&&t(F),e&&t(L),e&&t(W),e&&t(D),e&&t(st),e&&t(ve),e&&t(rt),e&&t(be),e&&t(lt),e&&t(ge),e&&t(ot),e&&t(Z),e&&t(nt),e&&t(_e),e&&t(ft),e&&t(ee),e&&t(pt),e&&t(te),e&&t(dt),e&&t(ie),e&&t(ut),e&&t(ye),e&&t(ct),e&&t(we),e&&t(ht),e&&t(Ee),e&&t(mt),e&&t(ke),e&&t(vt),e&&t(Se),e&&t(bt),e&&t(Pe),e&&t(gt),e&&t(se),e&&t(_t),e&&t(De),e&&t(yt),e&&t(M),e&&t(wt),e&&t(le),e&&t(Et),e&&t(oe),e&&t(kt),e&&t(ne),e&&t(St),e&&t(Ie),e&&t(Pt),e&&t(xe),e&&t(Dt),e&&t(je),e&&t(It),e&&t(T),e&&t(xt),e&&t(Le),e&&t(jt),V&&V.d(e),e&&t(Lt)}}}function Is(w){let a,h;const s=[w[0],ea];let n={$$slots:{default:[Ds]},$$scope:{ctx:w}};for(let r=0;r<s.length;r+=1)n=Xi(n,s[r]);return a=new cs({props:n}),{c(){ta(a.$$.fragment)},l(r){ia(a.$$.fragment,r)},m(r,_){aa(a,r,_),h=!0},p(r,[_]){const S=_&1?us(s,[_&1&&es(r[0]),_&0&&es(ea)]):{};_&2&&(S.$$scope={dirty:_,ctx:r}),a.$set(S)},i(r){h||(Ht(a.$$.fragment,r),h=!0)},o(r){Rt(a.$$.fragment,r),h=!1},d(r){sa(a,r)}}}const ea={title:"textual inversions",date:"2023-01-27",modifiedDate:"2023-01-27",categories:["stable diffusion","ai training"],svg:"Beakers",seoImage:"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg",shortDescription:"Learn how to train textual inversions to use with Stable Diffusion.",author:"Ryan Sadwick",spacelab:!0,id:1},{title:$s,date:Hs,modifiedDate:Rs,categories:Us,svg:qs,seoImage:Gs,shortDescription:Bs,author:Fs,spacelab:ls,id:xs}=ea;function js(w,a,h){return w.$$set=s=>{h(0,a=Xi(Xi({},a),ts(s)))},a=ts(a),[a]}class Ms extends os{constructor(a){super(),ns(this,a,js,Is,fs,{})}}export{Ms as default,ea as metadata};
