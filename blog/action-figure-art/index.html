<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="description" content="3ee Games website" />

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="icon" href="/favicon.png" />
	<link rel="manifest" href="/site.webmanifest">

	<link href="https://fonts.googleapis.com/css?family=Merriweather|Muli:300" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<meta http-equiv="content-security-policy" content=""><title>3ee Games Blog - Action Figure Art</title><meta property="og:title" content="Action Figure Art" data-svelte="svelte-6qx33q"><!-- HTML_TAG_START -->
		<script type="application/ld+json" ✂prettier:content✂="CgkJICAke0pTT04uc3RyaW5naWZ5KHNjaGVtYSl9CgkJ">{}</script>
		<!-- HTML_TAG_END -->
	<link rel="stylesheet" href="/_app/immutable/assets/pages/__layout.svelte-0ce23f93.css">
	<link rel="stylesheet" href="/_app/immutable/assets/pages/blog/action-figure-art.md-1ae8c5d6.css">
	<link rel="stylesheet" href="/_app/immutable/assets/_post-26be357b.css">
	<link rel="stylesheet" href="/_app/immutable/assets/Player-713e4035.css">
	<link rel="stylesheet" href="/_app/immutable/assets/ResponsivePicture-a0dba1c8.css">
	<link rel="modulepreload" href="/_app/immutable/start-03a37488.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/index-2a82a4a8.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/index-16dda89e.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/paths-396f020f.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/singletons-d1fb5791.js">
	<link rel="modulepreload" href="/_app/immutable/pages/__layout.svelte-da96b465.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/config-201c2df4.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/accountStore-3492c591.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/navigation-0e6511d1.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/menuContextStore-c2e700c4.js">
	<link rel="modulepreload" href="/_app/immutable/pages/blog/action-figure-art.md-6772cc57.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/_post-913f18eb.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/Player-9202028c.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/ResponsivePicture-526d3695.js">
</head>

<body>
	<div id="svelte">


<header class="svelte-f7ujdu"><nav class="svelte-f7ujdu"><a href="/" class="svelte-f7ujdu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30.162 5.292" class="svelte-1fksyth"><defs><clipPath id="three-games-logo-svg-header"><ellipse cx="106.822" cy="119.364" fill="none" stroke="#c43b37" stroke-width=".825" rx="49.117" ry="39.162"></ellipse></clipPath></defs><g transform="matrix(.04573 0 0 .04594 2.319 2.243)"><ellipse class="logo-eye-color svelte-1fksyth" cx="16.269" cy="9.431" fill="#3899ed" stroke="#000" stroke-width="2.628" rx="59.737" ry="49.977"></ellipse><g clip-path="url(#three-games-logo-svg-header)" transform="translate(-119.654 -141.447) scale(1.26422)"><ellipse cx="107.576" cy="119.667" rx="26.46" ry="25.524"></ellipse><path d="M77.486 89.412 65.352 77.278l14.94-.163c42.264-.462 61.806-.685 65.178-.743l3.732-.065-12.144 12.145-12.143 12.144-.543-.409c-5.324-4.013-12.023-6.001-18.474-5.483-3.756.302-6.754 1.11-9.997 2.696-2.075 1.014-3.781 2.098-5.245 3.33-.532.449-.983.816-1.002.816-.02 0-5.495-5.46-12.168-12.134zm-.1 60.876L65.352 162.52l14.94.042c42.267.118 61.81.182 65.182.213l3.732.034-12.242-12.045-12.242-12.045-.538.413c-5.292 4.056-11.975 6.099-18.43 5.633-3.758-.272-6.762-1.055-10.019-2.614-2.082-.997-3.797-2.067-5.27-3.288-.536-.444-.99-.808-1.01-.808-.019 0-5.45 5.505-12.069 12.233z"></path></g><ellipse cx="29.051" cy="-1.073" fill="#fff" rx="6.69" ry="6.212"></ellipse></g><g class="logo-font svelte-1fksyth" fill="#3899ed" stroke-width=".265" aria-label="3EE GAMES" font-family="Alata" font-size="4.586" style="line-height:1.25"><path d="M7.955 4.392q-.294 0-.592-.083-.293-.087-.426-.22l.215-.436q.138.11.349.193.21.078.43.078.785 0 .785-.638 0-.27-.215-.435-.211-.166-.574-.166-.252 0-.426.028l.844-1.312H7.079v-.45h2.178l-.954 1.363q.29.01.51.138.224.128.343.339.12.206.12.459 0 .33-.156.591-.156.257-.454.404-.298.147-.711.147ZM9.958.952h1.476v.45h-.967v.93h.78v.459h-.78v1.078h1.119v.454H9.958ZM12.098.952h1.477v.45h-.968v.93h.78v.459h-.78v1.078h1.12v.454h-1.629zM16.936 4.369q-.5 0-.894-.23-.394-.229-.619-.628-.22-.404-.22-.903 0-.487.225-.876.224-.39.623-.61.4-.22.9-.22.27 0 .485.05.22.046.358.11.138.06.188.105l-.202.432q-.284-.23-.839-.23-.367 0-.637.16-.271.161-.413.436-.142.276-.142.615 0 .385.151.688.156.303.426.472.276.165.62.165.215 0 .412-.05.198-.055.335-.17v-.651h-.692v-.472h1.201v1.32q-.165.207-.5.349-.33.138-.766.138zM20.01.947l1.623 3.376h-.591l-.29-.66h-1.545l-.289.66h-.573L19.959.947Zm-.23 1.436-.366.816h1.137l-.362-.812-.198-.463h-.009zM22.787 2.75l-.211-.477-.096.477-.312 1.573h-.51l.698-3.371h.055l.926 1.82.275.61.276-.61.908-1.82h.05l.725 3.37h-.505l-.34-1.572-.1-.477-.184.477-.816 1.573H23.6zM26.018.952h1.477v.45h-.968v.93h.78v.459h-.78v1.078h1.119v.454h-1.628zM28.938 4.369q-.275 0-.545-.097-.271-.096-.39-.215l.243-.436q.096.087.298.183.206.092.394.092.243 0 .395-.114.156-.115.156-.317 0-.156-.083-.27-.082-.115-.202-.188-.119-.078-.339-.189-.261-.128-.358-.192-.445-.298-.445-.826 0-.435.29-.665.288-.234.729-.234.472 0 .802.271l-.243.417q-.087-.091-.248-.156-.156-.068-.334-.068-.23 0-.363.105-.128.101-.128.303 0 .142.082.257.083.11.207.192.128.083.344.202.206.115.316.184.11.064.207.155.133.12.215.285.083.165.083.362 0 .307-.142.523-.138.215-.386.326-.243.11-.555.11z"></path></g></svg>
			<svg xmlns="http://www.w3.org/2000/svg" class="s-fjJKdSXdEtef svelte-16qfog0" viewBox="0 0 6 5"><defs class="s-fjJKdSXdEtef"><clipPath id="three-games-logo-svg-header" class="s-fjJKdSXdEtef"><ellipse cx="106.822" cy="119.364" fill="none" stroke="#c43b37" stroke-width=".825" rx="49.117" ry="39.162" class="s-fjJKdSXdEtef"></ellipse></clipPath></defs><g transform="matrix(.04573 0 0 .04594 2.319 2.243)" class="s-fjJKdSXdEtef"><ellipse class="logo-eye-color s-fjJKdSXdEtef svelte-16qfog0" cx="16.269" cy="9.431" fill="#3899ed" stroke="#000" stroke-width="2.628" rx="59.737" ry="49.977"></ellipse><g clip-path="url(#three-games-logo-svg-header)" transform="translate(-119.654 -141.447) scale(1.26422)" class="s-fjJKdSXdEtef"><ellipse cx="107.576" cy="119.667" rx="26.46" ry="25.524" class="s-fjJKdSXdEtef"></ellipse><path d="M77.486 89.412 65.352 77.278l14.94-.163c42.264-.462 61.806-.685 65.178-.743l3.732-.065-12.144 12.145-12.143 12.144-.543-.409c-5.324-4.013-12.023-6.001-18.474-5.483-3.756.302-6.754 1.11-9.997 2.696-2.075 1.014-3.781 2.098-5.245 3.33-.532.449-.983.816-1.002.816-.02 0-5.495-5.46-12.168-12.134zm-.1 60.876L65.352 162.52l14.94.042c42.267.118 61.81.182 65.182.213l3.732.034-12.242-12.045-12.242-12.045-.538.413c-5.292 4.056-11.975 6.099-18.43 5.633-3.758-.272-6.762-1.055-10.019-2.614-2.082-.997-3.797-2.067-5.27-3.288-.536-.444-.99-.808-1.01-.808-.019 0-5.45 5.505-12.069 12.233z" class="s-fjJKdSXdEtef"></path></g><ellipse cx="29.051" cy="-1.073" fill="#fff" rx="6.69" ry="6.212" class="s-fjJKdSXdEtef"></ellipse></g></svg></a></nav>

	<div class="search-container svelte-39tot0"><input type="text" placeholder="Search 3ee Games" class="svelte-39tot0" value="">
</div>

	

	<nav class="svelte-1qhiw35"><button class="svelte-1qhiw35"><ion-icon class="icon svelte-1qhiw35" name="reorder-three-outline"></ion-icon></button>
</nav>
		<nav class="svelte-1wxzkl">
</nav></header>

<div class="search-results svelte-1sv4ykx">
	

	

	
	
</div>

<main class="svelte-1l4pbsd">

<section class="background svelte-1pdjjzv"><article class="blog content svelte-1pdjjzv"><h1 id="action-figure-art" class="svelte-1pdjjzv">Action Figure Art</h1>
		<aside class="date-aside svelte-1pdjjzv"><ul class="svelte-1pdjjzv"><li class="published-date svelte-1pdjjzv"><address class="author svelte-1pdjjzv">By <a rel="author" href="/about" class="svelte-1pdjjzv">Ryan Sadwick</a></address></li>
				<li class="published-date svelte-1pdjjzv"><strong>Published:</strong> January 27, 2025</li>

				</ul></aside>

		<aside class="categories svelte-1pdjjzv"><ul class="svelte-1pdjjzv"><li class="svelte-1pdjjzv"><a href="/blog/categories/stable diffusion" class="svelte-1pdjjzv">Stable diffusion</a>
						</li><li class="svelte-1pdjjzv"><a href="/blog/categories/ai training" class="svelte-1pdjjzv">Ai training</a>
						</li></ul></aside>

		

		<div class="article"><p>I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images.</p>
<picture class="svelte-e5c5nc"><source media="(min-width: 100px) and (max-width: 896.98px)" srcset="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png" width="484" height="256">

	<img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png" alt="Action Figure with reg images" width="968" height="512" class="svelte-e5c5nc">
</picture>
<h2 id="what-are-regularization-images"><a aria-hidden="true" tabindex="-1" href="#what-are-regularization-images"><span class="icon icon-link"></span></a>What are Regularization Images?</h2>
<p>Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model.  To further illustrate: regularization images are extra pictures that are used to help Stable Diffusion learn better. </p>
<blockquote class="svelte-1lvyfvh"><p class="svelte-1lvyfvh">Regularization tackles two key challenges with model training: overfitting and preserving class distinctions.</p></blockquote>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<p>By creating regularization images, you’re defining a “class” of what you’re trying to invert. For example, if you’re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let’s say “bike” or “roller skates.” It also helps guard against heading towards a “toy skateboard” if you are using real references and not interpretations.</p>
<p>Regularization ensures that the images you’re trying to invert don’t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue.</p>
<p>In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs.</p>
<table class="svelte-1lvyfvh"><thead><tr><th>Aspect</th>
<th>Regularization</th>
<th>No Regularization</th></tr></thead>
<tbody><tr><td class="svelte-1lvyfvh"><strong>Definition</strong></td>
<td class="svelte-1lvyfvh">Defines skateboard class</td>
<td class="svelte-1lvyfvh">No specific class</td></tr>
<tr><td class="svelte-1lvyfvh"><strong>Example</strong></td>
<td class="svelte-1lvyfvh">Uses skateboard images</td>
<td class="svelte-1lvyfvh">No specific images</td></tr>
<tr><td class="svelte-1lvyfvh"><strong>Purpose</strong></td>
<td class="svelte-1lvyfvh">Prevents drift, focuses on skateboard class</td>
<td class="svelte-1lvyfvh">May drift to unrelated classes</td></tr>
<tr><td class="svelte-1lvyfvh"><strong>Overfitting</strong></td>
<td class="svelte-1lvyfvh">Guards against overfitting</td>
<td class="svelte-1lvyfvh">Higher risk of overfitting</td></tr></tbody></table>
<p>Regularization helps us make sure our models can correctly classify new data points they were not trained on. We call this ability to work well with new data “generalization.” If we don’t use regularization, our models can become too complex and “overfit” to the training data, meaning they won’t work well with new data.</p>
<p>Using too much regularization can be a problem. It can lead to “underfitting,” which means our model doesn’t work well even with the training data. This happens when we limit our model’s ability too much.</p>
<blockquote class="svelte-1lvyfvh"><p class="svelte-1lvyfvh">Imagine a graph of points. We want to find a function that fits those points well. We could choose a simple function, which might not fit the points very well. Or we could choose a very complex function that fits the points perfectly, but it might not work well with new points we haven’t seen before. The key is to find the right balance between simplicity and complexity to achieve the best performance.</p></blockquote>
<p><strong>Scenario 1</strong>: You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won’t learn enough to accurately recognize your cat.</p>
<p><strong>Solution</strong>: consider using regularization images to help the model learn more about cat features.</p>
<p><strong>Scenario 2</strong>: You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat.</p>
<p><strong>Solution</strong>: using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats.</p>
<h2 id="divergence"><a aria-hidden="true" tabindex="-1" href="#divergence"><span class="icon icon-link"></span></a>Divergence</h2>
<p>Providing too much data leads to <strong>divergence</strong>. Divergence happens when the model produces random outputs that do not accurately represent the subject’s likeness. This can occur because the model is trying to learn from too many images with inconsistent features, causing it to become confused and produce poor results.</p>
<p>To avoid divergence, we need to ensure the model is focusing on the features that are unique and consistent with your subject.  This starts from carefully curating the dataset by selecting high-quality images that accurately represent the object.</p>
<p>Training a model to recognize specific objects requires careful consideration of the dataset and the use of regularization techniques to ensure the model is focused on the right features and is not prone to divergence.</p>
<table class="svelte-1lvyfvh"><thead><tr><th>Situation</th>
<th>Outcome</th></tr></thead>
<tbody><tr><td class="svelte-1lvyfvh">Too many regularization images or inconsistent features</td>
<td class="svelte-1lvyfvh">Model performance suffers, leading to inaccurate predictions.</td></tr>
<tr><td class="svelte-1lvyfvh">Lack of focus on unique and consistent features</td>
<td class="svelte-1lvyfvh">Difficulty learning meaningful patterns, impacting prediction accuracy.</td></tr>
<tr><td class="svelte-1lvyfvh">Need for careful dataset curation</td>
<td class="svelte-1lvyfvh">High-quality image selection to avoid confusion and divergence.</td></tr>
<tr><td class="svelte-1lvyfvh">Importance of regularization techniques</td>
<td class="svelte-1lvyfvh">Proper use ensures model focuses on relevant features for accurate predictions.</td></tr></tbody></table>
<h2 id="generating-regularization-images"><a aria-hidden="true" tabindex="-1" href="#generating-regularization-images"><span class="icon icon-link"></span></a>Generating Regularization images</h2>
<p>Regularization images are generated using model you’re going to train with before training.  These generated images are based on the class name (e.g., <code>1boy</code>).</p>
<p>According to the Dreambooth technique, <code>200</code> regularization images per training image.  For example, if you have <code>16</code> images: <code>200 * 16 = 3200</code> total regularization images.  When training, the math involved for calculating total steps is:</p>
<blockquote class="svelte-1lvyfvh"><p class="svelte-1lvyfvh"><code>repeats * training images &gt;= repeats * regularization images</code></p></blockquote>
<p>The quality of regularization images impacts the model’s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model’s ability to learn distinctive features.</p>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="generate-using-stable-diffusion-web-ui"><a aria-hidden="true" tabindex="-1" href="#generate-using-stable-diffusion-web-ui"><span class="icon icon-link"></span></a>Generate using Stable Diffusion web UI</h4>
<p>We’re going to use <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="nofollow">Stable Diffusion web UI</a> to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips.</p>
<p>We’re going to use the <code>X/Y/Z plot</code> script to use <code>Prompt Search &amp; Replace</code> to dynamically build a prompt that will generate hundreds of regularization images.</p>
<ol><li><p>Select the text 2 image tab.  Enter a generic prompt <code>princeadam, portrait, looking_at_viewer, forest</code></p></li>
<li><p>In generation parameters and select the <code>X/Y/Z plot</code> script.</p></li>
<li><p>Select the <code>X</code> parameter and <code>Prompt SR</code> for Prompt Replace.  We’re going to replace <code>portrait</code> with different camera angle tags: <code>close-up</code>, <code>upper_body</code>, <code>from_below</code>, <code>from_above</code>, <code>dutch_angle</code></p></li>
<li><p>Select the <code>Y</code> parameter and <code>Prompt SR</code> for Prompt Replace.  Replace <code>looking_at_viewer</code>: <code>looking_away</code>, <code>looking_to_the_side</code>, <code>looking_ahead</code>, <code>looking_down</code></p></li>
<li><p>Select the <code>Z</code> parameter and <code>Prompt SR</code> for Prompt Replace. Replace <code>forest</code> with a vareity of locatinos: <code>castle</code>, <code>mountain</code>, <code>cave</code>, <code>farm</code>, <code>ocean</code></p></li>
<li><p>Select a fast sampler like <code>DPM2 KARRAS</code></p></li>
<li><p>CFG Scale set to <code>7</code> and Steps to <code>20</code></p></li></ol>
<p>After the inference finishes, gather the images that were generated and we’ll start captioning.  We may only need <code>150</code> - <code>200</code> and keep in mind we can add and remove as we try different training settings with different output.</p>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="download-images"><a aria-hidden="true" tabindex="-1" href="#download-images"><span class="icon icon-link"></span></a>Download images</h4>
<p>If generating these images isn’t an option, there are many repositories on HuggingFace that host regularization images generated with common models:</p>
<ul><li><a href="https://huggingface.co/3ee" rel="nofollow">3ee Games regularization images</a>: Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5.</li>
<li><a href="https://github.com/Luehrsen/sd_regularization_images" rel="nofollow">Pre-Rendered Regularization Images</a>: Includes 1500 regularization images.</li>
<li><a href="https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images" rel="nofollow">Stable Diffusion 1.5 Regularization Images</a>: includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5.  </li>
<li><a href="https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main" rel="nofollow">Aitrepreneur SDXL image set</a>: a large image set generated with Stable Diffusion SDXL.</li></ul>
<h4 id="captioning-regularization-images"><a aria-hidden="true" tabindex="-1" href="#captioning-regularization-images"><span class="icon icon-link"></span></a>Captioning Regularization images</h4>
<p>While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create <code>txt</code> files with a shell script:</p>
<pre class="language-shell"><!-- HTML_TAG_START --><code class="language-shell">@echo off
setlocal EnableDelayedExpansion

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"filename=%%i"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption_filename=%%~ni.txt"</span>
    <span class="token builtin class-name">set</span> <span class="token string">"caption=%%~ni"</span>

    rem Extracting the part from the first character to the first comma <span class="token keyword">in</span> the filename
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1,* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!caption!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>

    <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span> <span class="token operator">></span> <span class="token string">"!caption_filename!"</span>
<span class="token punctuation">)</span></code><!-- HTML_TAG_END --></pre>
<p>Save this file as <code>filename2txt.bat</code> and place it into the regularization images directory and run: <code>.\filename2txt.bat</code>.  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training.</p>
<p>Example filename: <code>18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png</code></p>
<p>Output: <code>aburbres,princeadam,1boy,close-up,purple_vest</code> saved in a text file with the same name as image.</p>
<h2 id="training-a-lora"><a aria-hidden="true" tabindex="-1" href="#training-a-lora"><span class="icon icon-link"></span></a>Training a LoRA</h2>
<p>Now we’re going to setup all the training data to create a LoRA model.  We’re going to go over how to setup your training data to use regularization images.</p>
<blockquote class="svelte-1lvyfvh"><p class="svelte-1lvyfvh">Learning how to train a LoRA is a completely different subject all on its own.  Learn more about LoRA training: LINK HERE.  </p></blockquote>
<h3 id="directory-setup"><a aria-hidden="true" tabindex="-1" href="#directory-setup"><span class="icon icon-link"></span></a>Directory setup</h3>
<p>In your configuration json, use <code>reg_data_dir</code> to point to the directory with your regularization images:</p>
<pre class="language-json"><!-- HTML_TAG_START --><code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<p>Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:</p>
<pre class="language-xml"><!-- HTML_TAG_START --><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code><!-- HTML_TAG_END --></pre>
<p>Specify the <code>number of iterations</code> so that the number of iterations of training images <code>x</code> =  the number of training images <code>≥</code> the number of iterations of regularization images <code>x</code> the number of regularization images .
(The number of data in one epoch is “number of repetitions of training images <code>x</code> number of training images”. If the number of regularization images is more than that, the remaining regularization images will not be used.)</p>
<p>Create folders in the training image folder with the format <code>&lt;repetition count&gt;_&lt;class&gt;</code> multiple times, and similarly create folders in the regularization image folder with the format <code>&lt;repetition count&gt;_&lt;class&gt;</code>.</p>
<p>If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:</p>
<ul><li>train_data_dir<ul><li>10_princeadam</li></ul></li>
<li>reg_dir<ul><li>1_1boy</li></ul></li></ul>
<p>For example, with the prompt “frog” and not repeating the data (only once), it would look like this:</p>
<p class="svelte-1lvyfvh"><img src="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png" alt="image" class="svelte-1lvyfvh"></p>
<h3 id="training-settings"><a aria-hidden="true" tabindex="-1" href="#training-settings"><span class="icon icon-link"></span></a>Training Settings</h3>
<p>The training setup we’re going to use is:  <code>Number of images * repeats * epoch / batch size = total steps</code>.  Based on our training data, we have 45 images and going for 4500 steps:</p>
<table class="svelte-1lvyfvh"><thead><tr><th>Number of Images</th>
<th>Repeats</th>
<th>Epochs</th>
<th>Batch Size</th>
<th>Total Steps</th></tr></thead>
<tbody><tr><td class="svelte-1lvyfvh">45</td>
<td class="svelte-1lvyfvh">10</td>
<td class="svelte-1lvyfvh">20</td>
<td class="svelte-1lvyfvh">2</td>
<td class="svelte-1lvyfvh">4500</td></tr></tbody></table>
<p>Now let’s focus on these training settings:</p>
<pre class="language-json"><!-- HTML_TAG_START --><code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"5e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"5e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<ul><li><strong>Learning Rate (<code>learning_rate</code>)</strong>: Determines the step size during optimization, influencing how quickly the model adapts to training data.</li>
<li><strong>Text Encoder Learning Rate (<code>text_encoder_lr</code>)</strong>: Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model.</li>
<li><strong>UNet Learning Rate (<code>unet_lr</code>)</strong>: Specifies the learning rate for the UNet component, impacting its performance in the LoRA model.</li>
<li><strong>Learning Rate Scheduler (<code>lr_scheduler</code>)</strong>: Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training.</li>
<li><strong>Number of Cycles in Learning Rate Scheduler (<code>lr_scheduler_num_cycles</code>)</strong>: Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts.</li>
<li><strong>Network Dimension (<code>network_dim</code>)</strong>: Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand.</li>
<li><strong>Network Alpha (<code>network_alpha</code>)</strong>: Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting.</li>
<li><strong>Clip Skip (<code>clip_skip</code>)</strong>: Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process.</li>
<li><strong>Max Token Length (<code>max_token_length</code>)</strong>: Sets the maximum allowed length for input tokens, enabling training with longer captions.</li>
<li><strong>Noise Offset (<code>noise_offset</code>)</strong>: Implements a diffusion process with offset noise, enhancing generation results for dark or bright images.</li>
<li><strong>Regularization Data Directory (<code>reg_data_dir</code>)</strong>: Specifies the directory for regularization data, influencing the quality of regularization images during training.</li></ul>
<h3 id="fine-tuning"><a aria-hidden="true" tabindex="-1" href="#fine-tuning"><span class="icon icon-link"></span></a>Fine Tuning</h3>
<p>Once training has completed, it’s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session.</p>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="workflow-with-auto1111-webui"><a aria-hidden="true" tabindex="-1" href="#workflow-with-auto1111-webui"><span class="icon icon-link"></span></a>Workflow with Auto1111 WebUI</h4>
<p>We’re going to use <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="nofollow">Stable Diffusion web UI</a> to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips.</p>
<p>We’re going to use the <code>X/Y/Z plot</code> script to compare different epochs.</p>
<ul><li>Select the text 2 image tab.  Enter a generic prompt <code>princeadam, portrait, &lt;princeadam0001:0.7&gt;</code></li>
<li>In generation parameters and select the <code>X/Y/Z plot</code> script.</li>
<li>Select <code>Prompt SR</code> for Prompt Replace.  We’re going to replace <code>&lt;princeadam0001:0.7&gt;</code> with different epoch: <code>&lt;princeadam0001:0.7&gt;</code>, <code>&lt;princeadam0003:0.7&gt;</code>, <code>&lt;princeadam0023:0.7&gt;</code></li>
<li>Select a fast sampler like <code>DPM2 KARRAS</code></li>
<li>CFG Scale set to <code>7</code> and Steps to <code>20</code></li></ul>
<p>After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA’s strength.  Recall setting <code>network_dim</code> and <code>network_alpha</code>?  Those are the settings that directly control the output strength mentioned earlier.</p>
<ul><li>Select <code>Prompt SR</code> for Prompt Replace.  We’re going to replace the weights <code>&lt;princeadam12:0.4&gt;</code>,<code>&lt;princeadam12:0.5&gt;</code>, <code>&lt;princeadam12:0.6&gt;</code>, <code>&lt;princeadam12:0.7&gt;</code>, <code>&lt;princeadam12:0.8&gt;</code>, <code>&lt;princeadam12:0.9&gt;</code>, <code>&lt;princeadam12:1.0&gt;</code></li>
<li>Use another <code>Prompt SR</code> to generate a variety of different angles: Select <code>Prompt SR</code> for Prompt Replace.  Replace <code>upper_body</code> with different camera angles: <code>from_below</code>, <code>from_above</code>, <code>close_up</code></li>
<li>If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data.</li>
<li>Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model.</li></ul>
<h4 id="issues-to-look-for"><a aria-hidden="true" tabindex="-1" href="#issues-to-look-for"><span class="icon icon-link"></span></a>Issues to look for</h4>
<ul><li><strong>Undercooked:</strong> Lacks output, adjust unet learning rate or extend training duration.</li>
<li><strong>Overcooked:</strong> Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats.</li>
<li><strong>Overfit:</strong> Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues.</li>
<li><strong>Mismatched:</strong> Doesn’t match expectations, it might be undercooked or have a low-quality dataset.</li></ul>
<p>If you’re experiencing these issues, it’s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning.</p>
<p class="svelte-1lvyfvh"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png" alt="image" class="svelte-1lvyfvh"></p>
<h4 id="troubleshooting"><a aria-hidden="true" tabindex="-1" href="#troubleshooting"><span class="icon icon-link"></span></a>Troubleshooting</h4>
<p>If you find your results aren’t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:</p>
<ul><li>Lower input images, less regularization images needed.  Remember Dreambooth calls for about <code>200</code> regularization images per training image.</li>
<li>Repeats of regularization images, but may overfit more.  Increasing the <code>repetition_count</code> will cycle through the images more but the results may have results that overfit the model.</li>
<li>Create more regularization images without increasing repeats will help with the overfitting.</li></ul>
<table class="svelte-1lvyfvh"><thead><tr><th>Issue</th>
<th>Situation</th>
<th>Recommendation</th></tr></thead>
<tbody><tr><td class="svelte-1lvyfvh">Varying quality</td>
<td class="svelte-1lvyfvh">Results differ from expectations</td>
<td class="svelte-1lvyfvh">Evaluate the quality and quantity of regularization images. Adjust the number and selection and check for better results.</td></tr>
<tr><td class="svelte-1lvyfvh">Inadequate regularization for input data</td>
<td class="svelte-1lvyfvh">Lower input images, less regularization needed</td>
<td class="svelte-1lvyfvh">Consider reducing the number of input images or increasing the quantity and diversity of regularization images.</td></tr>
<tr><td class="svelte-1lvyfvh">Overfitting due to repetition</td>
<td class="svelte-1lvyfvh">Repeats of regularization images, risk of overfitting</td>
<td class="svelte-1lvyfvh">Adjust the <code>repetition_count</code> to balance cycling through images without overfitting. Monitor results for improvements.</td></tr>
<tr><td class="svelte-1lvyfvh">Mitigate overfitting while increasing diversity</td>
<td class="svelte-1lvyfvh">Create more regularization images without repeats</td>
<td class="svelte-1lvyfvh">Generate additional regularization images without increasing repetitions. Enhance model adaptability without overfitting.</td></tr></tbody></table>
<h3 id="results"><a aria-hidden="true" tabindex="-1" href="#results"><span class="icon icon-link"></span></a>Results</h3>
<p>The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images.</p>
<p>Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model’s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance.</p>
<p class="svelte-1lvyfvh"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png" alt="image" class="svelte-1lvyfvh"></p>
<p>The journey doesn’t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art.</p>
<hr>
	<div class="subscribe svelte-s12rf8"><h2 class="svelte-s12rf8">Training Dataset</h2>

		<p class="highlight large svelte-s12rf8"><ion-icon class="icon svelte-s12rf8" name="lock-closed"></ion-icon>SpaceLab Content</p>

		<p class="svelte-s12rf8">You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.</p>

		

		

		<button class="button subscribe svelte-s12rf8"><ion-icon class="icon svelte-s12rf8" name="planet"></ion-icon>
			<span>SpaceLab</span></button></div></div></article>
</section></main>

<footer class="svelte-1pv61cd"><div class="footer-container svelte-1pv61cd"><div class="footer-main svelte-1pv61cd"><div class="brand svelte-1pv61cd"><div class="footer-logo footer-logo-animation svelte-1pv61cd"><svg viewBox="0 0 30 17" class="svelte-1pv61cd"><g><g aria-label="3EE" font-size="16.383" stroke-width=".41"><path class="three-ee-text-logo svelte-1pv61cd" d="M7.077 3.584H3.649v1.132H.91V3.258q0-.583.063-1.08.078-.498.313-.84.235-.343.688-.532Q2.444.6 3.242.6h.063L7.42.566h.063q.36 0 .72.051.36.035.751.309.423.309.61.703.189.377.235.875.047.497.047.96 0 .223-.015.446v.411q-.016.223-.016.446v.463q0 .463-.11.789-.093.326-.36.617.267.274.36.617.11.326.11.79v2.417q0 .446-.156.823-.141.36-.407.652-.25.274-.61.428-.345.155-.736.155H2.788q-.391 0-.735-.155-.345-.154-.595-.428-.25-.292-.407-.652-.14-.377-.14-.823V8.402h2.738v1.132h3.428v-1.68H2.961V4.853h4.116zM19.205 9.568v3.001h-8.39V.566h8.39V3.55h-5.65v1.526h4.633v2.983h-4.633v1.51zM28.499 9.568v3.001h-8.39V.566h8.39V3.55h-5.65v1.526h4.632v2.983h-4.633v1.51z"></path></g><g aria-label="Third Eye Entertainment" font-size="2.117" stroke-width=".265"><path class="three-ee-unwrapped-text svelte-1pv61cd" d="M2.237 13.958v.368H1.82v1.113h-.37v-1.113h-.417v-.368zM3.555 13.954v1.481h-.368v-.556H2.72v.556h-.368v-1.481h.368v.556h.466v-.556zM4.068 13.958v1.481h-.37v-1.481zM5.35 14.356v.05l.002.05v.042l.002.038-.002.093-.006.093q-.009.061-.036.106-.025.042-.076.078-.034.023-.066.032-.03.006-.063.008l.273.49h-.422l-.27-.488h-.144v.487h-.37v-1.481h.91q.056 0 .105.02.049.02.085.058.036.036.057.087.021.048.021.105zm-.375.224v-.256h-.433v.256zM6.479 13.964q.07.021.108.053.038.03.055.068.017.038.021.082.004.045.004.093v.026q.002.01.002.023.003.03.003.07v.692q0 .06-.003.112-.002.053-.02.098-.02.044-.062.08-.04.036-.117.061-.019.005-.074.009l-.116.004h-.812v-1.481h.535q.046-.003.095-.003h.068q.055 0 .116.003.064 0 .119.004.057.002.076.006zM6.3 15.067v-.743h-.463v.743zM8.756 15.069v.37H7.62v-1.481h1.135v.368H7.99v.188h.627v.369h-.627v.186zM10.222 13.956l-.531.842v.64h-.369v-.64l-.533-.842h.436l.281.442.28-.442zM11.401 15.069v.37h-1.134v-1.481H11.4v.368h-.764v.188h.627v.369h-.627v.186zM13.477 15.069v.37h-1.135v-1.481h1.135v.368h-.764v.188h.626v.369h-.626v.186zM14.814 13.96v1.482h-.347l-.487-.762v.762h-.368V13.96h.347l.487.76v-.76zM16.136 13.958v.368h-.417v1.113h-.37v-1.113h-.417v-.368zM17.367 15.069v.37h-1.135v-1.481h1.135v.368h-.764v.188h.626v.369h-.626v.186zM18.67 14.356v.05l.002.05v.042l.002.038-.002.093-.006.093q-.008.061-.036.106-.025.042-.076.078-.034.023-.066.032-.03.006-.063.008l.273.49h-.421l-.271-.488h-.144v.487h-.37v-1.481h.91q.057 0 .105.02.049.02.085.058.036.036.057.087.021.048.021.105zm-.374.224v-.256h-.434v.256zM19.964 13.958v.368h-.417v1.113h-.37v-1.113h-.417v-.368zM20.903 13.954l.538 1.481h-.396l-.1-.277h-.45l-.1.277h-.394l.538-1.481zm-.093.834q-.013-.034-.021-.06l-.02-.053q-.008-.027-.02-.057l-.028-.076-.091.246zM21.87 13.958v1.481h-.37v-1.481zM23.186 13.96v1.482h-.348l-.486-.762v.762h-.369V13.96h.347l.487.76v-.76zM24.755 13.956v1.481h-.37v-.74l-.104.165-.097.158h-.271l-.201-.326v.743h-.37v-1.481h.35l.356.578.358-.578zM26.04 15.069v.37h-1.134v-1.481h1.134v.368h-.764v.188h.627v.369h-.627v.186zM27.377 13.96v1.482h-.347l-.486-.762v.762h-.369V13.96h.347l.487.76v-.76zM28.7 13.958v.368h-.417v1.113h-.37v-1.113h-.418v-.368z"></path></g></g></svg></div>
				<p class="legal svelte-1pv61cd">© Copyright 2025 3ee Games LLC. All rights reserved.</p>
				<p class="legal svelte-1pv61cd">Made with a giant barrel of <ion-icon class="heart-icon svelte-1pv61cd" name="heart-sharp"></ion-icon> by 3ee Games.
				</p>
				<p class="legal svelte-1pv61cd">In memory of Teela 🐱</p></div>
			<div class="footer-routes svelte-1pv61cd"><div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="planet-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">discover</h6></div>
					<a href="/about" aria-current="page" class="svelte-1pv61cd">about</a>
					<a href="/games" aria-current="page" class="svelte-1pv61cd">games</a>
					<a href="/blog" aria-current="page" class="svelte-1pv61cd">blog</a>
					<a href="https://discord.gg/3ee" target="_blank" class="svelte-1pv61cd">discord</a>
					<a href="/contact" aria-current="page" class="svelte-1pv61cd">contact</a></div>
				<div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="person-circle-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">account</h6></div>
					<a href="/account/login" aria-current="page" class="svelte-1pv61cd">login</a>
						<a href="/account/create" aria-current="page" class="svelte-1pv61cd">create an account</a>
						<a href="/account/accessibility" aria-current="page" class="svelte-1pv61cd">accessibility</a>
						<a href="/account/conduct" aria-current="page" class="svelte-1pv61cd">code of conduct</a>
						<a href="/account/privacy" aria-current="page" class="svelte-1pv61cd">privacy policy</a>
						<a href="/account/terms" aria-current="page" class="svelte-1pv61cd">terms of service</a></div>
				<div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="chatbubbles-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">social</h6></div>

					<a href="https://github.com/3ee-Games" target="_blank" class="svelte-1pv61cd">github</a>
					<a href="https://huggingface.co/3ee" target="_blank" class="svelte-1pv61cd">huggingface</a>
					<a href="https://www.youtube.com/@3eegames" target="_blank" class="svelte-1pv61cd">youtube</a>
					<a href="https://x.com/3ee_Games" target="_blank" class="svelte-1pv61cd">X</a>
					<a href="https://www.linkedin.com/company/3ee-games" target="_blank" class="svelte-1pv61cd">linkedin</a>
					<a href="https://www.facebook.com/3eecom" target="_blank" class="svelte-1pv61cd">facebook</a></div></div></div></div></footer>





	<script defer src="https://cloud.umami.is/script.js" data-website-id="ce2999d5-1ac8-4c93-b775-e76c96c916d1"></script>


		<script type="module" data-sveltekit-hydrate="cg3xeu">
		import { start } from "/_app/immutable/start-03a37488.js";
		start({
			target: document.querySelector('[data-sveltekit-hydrate="cg3xeu"]').parentNode,
			paths: {"base":"","assets":""},
			session: {},
			route: true,
			spa: false,
			trailing_slash: "always",
			hydrate: {
				status: 200,
				error: null,
				nodes: [0, 19],
				params: {},
				routeId: "blog/action-figure-art"
			}
		});
	</script><script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/posts.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Action Figure Art\",\"date\":\"2025-01-28\",\"modifiedDate\":\"2025-01-28\",\"categories\":[\"stable diffusion\",\"ai training\"],\"svg\":\"ActionFigure\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"Artwork created with action figure training sets.\",\"author\":\"Ryan Sadwick\",\"spacelab\":true,\"id\":1,\"spacelabDefaultTitle\":\"Training Dataset\",\"spacelabDefaultContent\":\"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.\"},\"path\":\"/blog/action-figure-art\"},{\"meta\":{\"title\":\"First-Party Experience\",\"date\":\"2025-01-08 11:00:20\",\"modifiedDate\":\"2025-01-15 11:00:20\",\"categories\":[\"cookies\",\"analytics\",\"containers\",\"docker\"],\"svg\":\"Cookie\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1736376433/blog/o5nsfwkgjhamizuegzzp.png\",\"shortDescription\":\"Discuss the insights of moving towards a first party experience.\",\"author\":\"Ryan Sadwick\",\"menu\":[{\"name\":\"First Party\",\"icon\":\"🥇\",\"url\":\"/blog/first-party-experience/#first-party-centric-built-in-privacy\"},{\"name\":\"cookies\",\"icon\":\"🍪\",\"url\":\"/blog/first-party-experience/#identify-all-cookies\"},{\"name\":\"google analytics\",\"icon\":\"⛅\",\"url\":\"/blog/first-party-experience/#example-replace-google-analytics\"},{\"name\":\"localstorage\",\"icon\":\"🛡️\",\"url\":\"/blog/first-party-experience/#from-cookies-to-localstorage\"},{\"name\":\"privacy policies\",\"icon\":\"🔒\",\"url\":\"/blog/first-party-experience/#updating-privacy-policies\"},{\"name\":\"Containerization\",\"icon\":\"📦\",\"url\":\"/blog/first-party-experience/#streamlining-with-containers\"}],\"keywords\":[\"analytics\",\"docker\",\"containers\",\"google\",\"youtube\",\"web development\"]},\"path\":\"/blog/first-party-experience\"},{\"meta\":{\"title\":\"Github Actions 101\",\"date\":\"2025-01-06 12:34:20\",\"modifiedDate\":\"2025-01-18 13:00:00\",\"categories\":[\"github\",\"automation\",\"web development\"],\"svg\":\"Api\",\"youtubeId\":\"wx6eOvvGEc8\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1736376656/blog/ydtnowkeirmxxcyjoyr5.png\",\"shortDescription\":\"Learn how 3ee Games uses Github Actions and GraphQL to automate issue tracking, enhancing transparency in game development.\",\"keywords\":[\"github\",\"issue tracker\",\"transparency\",\"web development\",\"actions\",\"automation\"],\"author\":\"Ryan Sadwick\"},\"path\":\"/blog/github-actions-101\"},{\"meta\":{\"title\":\"Ornamental Santa Diffusion\",\"date\":\"2022-12-08 19:30:10\",\"modifiedDate\":\"2023-01-08 19:30:10\",\"categories\":[\"stable diffusion\",\"ai training\"],\"svg\":\"Santa\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"Check out Ornamental Santa Diffusion, a model that uses stable diffusion to generate Santa Claus.\",\"keywords\":[\"stable diffusion\",\"generative art\",\"ai art\",\"santa claus\",\"ai training\"],\"author\":\"3ee Games\"},\"path\":\"/blog/ornamental-santa-diffusion\"},{\"meta\":{\"title\":\"Using Tiled as a level editor with Phaser\",\"date\":\"2021-02-07 20:55:50\",\"modifiedDate\":\"2023-04-25 20:55:50\",\"categories\":[\"tiled\",\"game development\",\"phaser\"],\"svg\":\"Scene\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703434770/img/tiled-poster.webp\",\"shortDescription\":\"When developing a game, look for ways to use tools that are proven to work and have solid integration with your game engine. This will allow you to focus on your game and not be distracted by creating custom tools to build your game's content.\",\"keywords\":[\"tiled\",\"game development\",\"phaser\",\"level design\",\"level editor\"],\"author\":\"Ryan Sadwick\",\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703434770/img/tiled-poster.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703434669/img/tiled-video.mp4\",\"type\":\"video/mp4\"}],\"tracks\":[{\"src\":\"/captions/tiled_phaser.vtt\",\"kind\":\"captions\",\"default\":true}]}]},\"path\":\"/blog/tiled-level-editor-phaser\"},{\"meta\":{\"title\":\"Flappy Jacob Prototype\",\"date\":\"2020-08-18\",\"modifiedDate\":\"2023-03-30 15:50:00\",\"categories\":[\"game development\",\"phaser\"],\"svg\":\"Balance\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703435222/img/flapper-poster.webp\",\"shortDescription\":\"Jamming on a flappy bird type game with my son called Flappy Jacob. We've implemented a heart point system, powerups based on a random number generator, bosses that have set patterns and attacks, and a scoring system.\",\"keywords\":[\"game jams\",\"game development\"],\"author\":\"Ryan Sadwick\",\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703435222/img/flapper-poster.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703435082/img/flapper-video.mp4\",\"type\":\"video/mp4\"}]}]},\"path\":\"/blog/flappy-jacob-prototype\"},{\"meta\":{\"title\":\"Phaser game with a React UI\",\"date\":\"2020-06-11 13:27:42\",\"modifiedDate\":\"2023-04-30 13:27:42\",\"youtubeId\":\"EDbW7lbtHOA\",\"categories\":[\"phaser\",\"react\",\"game development\"],\"svg\":\"Controller\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703433443/img/phaser-blog.webp\",\"shortDescription\":\"In this video, we show developing a game with Phaser and using React for the user interface. Using React to alleviate the burden of handling the UI in Canvas. RequestAnimationFrame can be expensive and should be used for the game only.\",\"keywords\":[\"phaser\",\"react\",\"game development\",\"javascript\",\"canvas\"],\"author\":\"Ryan Sadwick\",\"codePen\":{\"user\":\"halvves\",\"hash\":\"qQxPNo\"},\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703433443/img/phaser-blog.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703434143/img/phaser-video.mp4\",\"type\":\"video/mp4\"}]}]},\"path\":\"/blog/phaser-game-react-ui\"},{\"meta\":{\"title\":\"3ee Games YouTube Channel\",\"date\":\"2019-08-22 11:20:00\",\"modifiedDate\":\"2022-05-30 11:20:00\",\"categories\":[\"videos\",\"phaser\",\"game development\"],\"svg\":\"Youtube\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"We've created a mixture of game dev, playing games, and comedy Youtube channel for 3ee Games.  Our goal is to bring humorous and informative content to game developers, gamers, and folks that simply enjoy hearing a good story.\",\"keywords\":[\"youtube\",\"social media\",\"videos\",\"game development\"],\"author\":\"3ee Games\"},\"path\":\"/blog/3ee-games-youtube-channel\"},{\"meta\":{\"title\":\"Pong Kombat 2\",\"date\":\"2019-01-06 14:00:00\",\"modifiedDate\":\"2024-01-09 14:00:00 \",\"categories\":[\"pong kombat\",\"game development\"],\"svg\":\"Pong\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703431871/img/pong-kombat-17.jpg\",\"shortDescription\":\"In the summer of 1996, Ryan Sadwick decided to make a sequel to Pong Kombat. While that was over 25 years ago, the experience provided an immense amount of insight into game design and development.\",\"keywords\":[\"ryan sadwick\",\"pong kombat\",\"game development\",\"klik and play\",\"clickteam\"],\"author\":\"Ryan Sadwick\"},\"path\":\"/blog/pong-kombat-2\"},{\"meta\":{\"title\":\"Shenanijam 2018\",\"date\":\"2018-06-01 16:45:00\",\"modifiedDate\":\"2022-05-30 16:45:00\",\"categories\":[\"game jams\"],\"svg\":\"Idea\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/shenanijam2.png\",\"shortDescription\":\"We are participating in The Shenanijam 2018.\",\"keywords\":[\"game jam\",\"game development\",\"shenanijam\"],\"author\":\"3ee Games\"},\"path\":\"/blog/shenanijam2018\"},{\"meta\":{\"title\":\"No Ads In Our Games\",\"date\":\"2018-05-26 15:00:20\",\"modifiedDate\":\"2023-04-20 15:00:20\",\"categories\":[\"games\",\"advertisements\"],\"svg\":\"Choice\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/ads_suck.jpg\",\"shortDescription\":\"Read about why we do not have advertisements in our games.\",\"author\":\"3ee Games\"},\"path\":\"/blog/no-ads-in-our-games\"}]"}</script>
	<script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/games.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Divine Sun\",\"date\":\"2024-06-25\",\"categories\":[\"2d\",\"adventure\"],\"keywords\":[\"adventure\",\"games\",\"side scroll\",\"wizard\"],\"image\":\"ds_game.png\",\"description\":\"Step into the world of Kizomerre, a planet that once thrived under the harmonious yet discordant gaze of the Sun.\",\"content\":[{\"name\":\"Spells\",\"icon\":\"flask-sharp\",\"description\":\"Discover new spells to create all types of builds to devastate, support, and manipulate.\"},{\"name\":\"Questing\",\"icon\":\"receipt\",\"description\":\"Adventure through hundreds of different quests and explore the vast world.\"},{\"name\":\"Explore\",\"icon\":\"water\",\"description\":\"Explore the vast underwater caverns for difficult adventures with rare armor.\"}]},\"path\":\"/games/divine-sun\"},{\"meta\":{\"title\":\"Gorgons Legend\",\"date\":\"2022-06-25\",\"categories\":[\"2d\",\"arcade\",\"platformer\"],\"keywords\":[\"arcade\",\"platform\",\"2d game\",\"adventure\",\"games\"],\"image\":\"gorgons.png\",\"description\":\"The consequences of your choices shape the world around you. A journey that explores the dualities of good and evil, intricately woven into the tapestry of Greek Mythology.\",\"content\":[{\"name\":\"Adventures\",\"icon\":\"planet-sharp\",\"description\":\"As the game unfolders, you can play up to a total of 3 different characters, each with their own unique abilities and story.\"},{\"name\":\"Fast Paced\",\"icon\":\"trending-up-sharp\",\"description\":\"a mix of platformer with fast paced arcade action\"},{\"name\":\"Custom Builds\",\"icon\":\"git-branch-sharp\",\"description\":\"Customize and build each character with different attributes and abilities\"}]},\"path\":\"/games/cupids-balance\"},{\"meta\":{\"title\":\"Isle of Zultiki\",\"date\":\"2021-12-14\",\"categories\":[\"2d\",\"rpg\",\"action\"],\"keywords\":[\"role playing\",\"healing\",\"spells\",\"adventure\",\"games\"],\"image\":\"zultiki.png\",\"description\":\"Witness an enigmatic island, summoning souls from distant lands. These adventurers united by the island's allure, unfurl an epic saga of exploration and mystique.\",\"content\":[{\"name\":\"Professions\",\"icon\":\"bonfire-sharp\",\"description\":\"Enjoy up to 12 different professions to choose from that feature different spells and builds to customize.\"},{\"name\":\"Spells\",\"icon\":\"flask-sharp\",\"description\":\"Uncover new spells and abilities as you level up.  Use them strategically to your advantage.\"},{\"name\":\"Customize\",\"icon\":\"library-sharp\",\"description\":\"Build on your character's attributes and abilities to make them your own.\"}]},\"path\":\"/games/zultiki\"}]"}</script>
	<script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/account.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Accessibility\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-05-02\",\"shortDescription\":\"all of our games offer high levels of accessibility\",\"categories\":[\"accessibility\",\"control\",\"animation\",\"sound\",\"input\"],\"keywords\":[\"accessibility\",\"control\",\"animation\",\"sound\",\"input\"]},\"path\":\"/account/accessibility\"},{\"meta\":{\"title\":\"Code of Conduct\",\"shortDescription\":\"Code of conduct for playing games on 3ee platforms.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-14\",\"categories\":[\"behavior\",\"report\",\"ban\",\"cheat\",\"harass\"],\"keywords\":[\"behavior\",\"report\",\"ban\",\"cheat\",\"harass\"],\"svg\":\"Ocean\"},\"path\":\"/account/conduct\"},{\"meta\":{\"title\":\"Privacy Policy\",\"shortDescription\":\"Interactive privacy policy that contains data, protection, and privacy.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-30\",\"categories\":[\"privacy\",\"data\",\"protection\",\"collection\"],\"keywords\":[\"privacy\",\"data\",\"protection\",\"collection\"],\"menu\":[{\"name\":\"warm welcome\",\"icon\":\"☕\",\"url\":\"/account/privacy/#a-warm-welcome-from-3ee-games\"},{\"name\":\"info collected\",\"icon\":\"ℹ️\",\"url\":\"/account/privacy/#information-collection\"},{\"name\":\"shared info\",\"icon\":\"🫱🏾‍🫲🏼\",\"url\":\"/account/privacy/#using-your-information\"},{\"name\":\"Data & Protection\",\"icon\":\"🛡️\",\"url\":\"/account/privacy/#data-retention--protection\"},{\"name\":\"your privacy\",\"icon\":\"🔏\",\"url\":\"/account/privacy/#controlling-your-privacy\"},{\"name\":\"California Users\",\"icon\":\"🌅\",\"url\":\"/account/privacy/#california-user-information\"},{\"name\":\"Changes\",\"icon\":\"🧾\",\"url\":\"/account/privacy/#privacy-policy-updates\"}]},\"path\":\"/account/privacy\"},{\"meta\":{\"title\":\"Terms of Service\",\"shortDescription\":\"Check the terms of our service and what to expect when gaming on 3ee's platform.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-30\",\"categories\":[\"terms\",\"account\",\"copyright\",\"indemnity\"],\"keywords\":[\"terms\",\"account\",\"copyright\",\"indemnity\"],\"menu\":[{\"name\":\"who we are\",\"icon\":\"🌠\",\"url\":\"/account/terms/#who-we-are\"},{\"name\":\"age requirements\",\"icon\":\"ℹ️\",\"url\":\"/account/terms/#age-requirements\"},{\"name\":\"What you can expect\",\"icon\":\"🫱🏾‍🫲🏼\",\"url\":\"/account/terms/#what-you-can-expect\"},{\"name\":\"your account\",\"icon\":\"📒\",\"url\":\"/account/terms/#your-account\"},{\"name\":\"content\",\"icon\":\"✨\",\"url\":\"/account/terms/#content\"},{\"name\":\"software in services\",\"icon\":\"🔏\",\"url\":\"/account/terms/#software-in-3ee-games-services\"},{\"name\":\"copyright\",\"icon\":\"©️\",\"url\":\"/account/terms/#copyright\"},{\"name\":\"paid services\",\"icon\":\"🌅\",\"url\":\"/account/terms/#paid-services\"},{\"name\":\"Restrictions\",\"icon\":\"🚫\",\"url\":\"/account/terms/#usage-restrictions\"},{\"name\":\"termination\",\"icon\":\"💀\",\"url\":\"/account/terms/#termination\"},{\"name\":\"indemnity\",\"icon\":\"⚖️\",\"url\":\"/account/terms/#indemnity\"},{\"name\":\"as is\",\"icon\":\"🌅\",\"url\":\"/account/terms/#services-as-is\"},{\"name\":\"liability\",\"icon\":\"🧾\",\"url\":\"/account/terms/#limitation-of-liability\"},{\"name\":\"bonus level\",\"icon\":\"🏝️\",\"url\":\"/account/terms/#additional-important-information\"},{\"name\":\"contact us\",\"icon\":\"🛟\",\"url\":\"/account/terms/#contact-information\"}]},\"path\":\"/account/terms\"}]"}</script></div>
</body>

<script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
<script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</html>