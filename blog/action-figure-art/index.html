<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="description" content="3ee Games website" />

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="icon" href="/favicon.png" />
	<link rel="manifest" href="/site.webmanifest">

	<link href="https://fonts.googleapis.com/css?family=Merriweather|Muli:300" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<meta http-equiv="content-security-policy" content=""><title>3ee Games Blog - Action Figure Art</title><meta property="og:title" content="Action Figure Art" data-svelte="svelte-6qx33q"><!-- HTML_TAG_START -->
		<script type="application/ld+json" ✂prettier:content✂="CgkJICAke0pTT04uc3RyaW5naWZ5KHNjaGVtYSl9CgkJ">{}</script>
		<!-- HTML_TAG_END -->
	<link rel="stylesheet" href="/_app/immutable/assets/pages/__layout.svelte-010d24fc.css">
	<link rel="stylesheet" href="/_app/immutable/assets/pages/blog/action-figure-art.md-0ea1ead6.css">
	<link rel="stylesheet" href="/_app/immutable/assets/_post-26be357b.css">
	<link rel="stylesheet" href="/_app/immutable/assets/Player-713e4035.css">
	<link rel="stylesheet" href="/_app/immutable/assets/ResponsivePicture-a0dba1c8.css">
	<link rel="modulepreload" href="/_app/immutable/start-6d8ebd8f.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/index-2a82a4a8.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/index-16dda89e.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/paths-396f020f.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/singletons-d1fb5791.js">
	<link rel="modulepreload" href="/_app/immutable/pages/__layout.svelte-da96b465.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/config-201c2df4.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/accountStore-3492c591.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/navigation-0e6511d1.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/menuContextStore-c2e700c4.js">
	<link rel="modulepreload" href="/_app/immutable/pages/blog/action-figure-art.md-cb0f6723.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/_post-913f18eb.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/Player-9202028c.js">
	<link rel="modulepreload" href="/_app/immutable/chunks/ResponsivePicture-526d3695.js">
</head>

<body>
	<div id="svelte">


<header class="svelte-f7ujdu"><nav class="svelte-f7ujdu"><a href="/" class="svelte-f7ujdu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30.162 5.292" class="svelte-1fksyth"><defs><clipPath id="three-games-logo-svg-header"><ellipse cx="106.822" cy="119.364" fill="none" stroke="#c43b37" stroke-width=".825" rx="49.117" ry="39.162"></ellipse></clipPath></defs><g transform="matrix(.04573 0 0 .04594 2.319 2.243)"><ellipse class="logo-eye-color svelte-1fksyth" cx="16.269" cy="9.431" fill="#3899ed" stroke="#000" stroke-width="2.628" rx="59.737" ry="49.977"></ellipse><g clip-path="url(#three-games-logo-svg-header)" transform="translate(-119.654 -141.447) scale(1.26422)"><ellipse cx="107.576" cy="119.667" rx="26.46" ry="25.524"></ellipse><path d="M77.486 89.412 65.352 77.278l14.94-.163c42.264-.462 61.806-.685 65.178-.743l3.732-.065-12.144 12.145-12.143 12.144-.543-.409c-5.324-4.013-12.023-6.001-18.474-5.483-3.756.302-6.754 1.11-9.997 2.696-2.075 1.014-3.781 2.098-5.245 3.33-.532.449-.983.816-1.002.816-.02 0-5.495-5.46-12.168-12.134zm-.1 60.876L65.352 162.52l14.94.042c42.267.118 61.81.182 65.182.213l3.732.034-12.242-12.045-12.242-12.045-.538.413c-5.292 4.056-11.975 6.099-18.43 5.633-3.758-.272-6.762-1.055-10.019-2.614-2.082-.997-3.797-2.067-5.27-3.288-.536-.444-.99-.808-1.01-.808-.019 0-5.45 5.505-12.069 12.233z"></path></g><ellipse cx="29.051" cy="-1.073" fill="#fff" rx="6.69" ry="6.212"></ellipse></g><g class="logo-font svelte-1fksyth" fill="#3899ed" stroke-width=".265" aria-label="3EE GAMES" font-family="Alata" font-size="4.586" style="line-height:1.25"><path d="M7.955 4.392q-.294 0-.592-.083-.293-.087-.426-.22l.215-.436q.138.11.349.193.21.078.43.078.785 0 .785-.638 0-.27-.215-.435-.211-.166-.574-.166-.252 0-.426.028l.844-1.312H7.079v-.45h2.178l-.954 1.363q.29.01.51.138.224.128.343.339.12.206.12.459 0 .33-.156.591-.156.257-.454.404-.298.147-.711.147ZM9.958.952h1.476v.45h-.967v.93h.78v.459h-.78v1.078h1.119v.454H9.958ZM12.098.952h1.477v.45h-.968v.93h.78v.459h-.78v1.078h1.12v.454h-1.629zM16.936 4.369q-.5 0-.894-.23-.394-.229-.619-.628-.22-.404-.22-.903 0-.487.225-.876.224-.39.623-.61.4-.22.9-.22.27 0 .485.05.22.046.358.11.138.06.188.105l-.202.432q-.284-.23-.839-.23-.367 0-.637.16-.271.161-.413.436-.142.276-.142.615 0 .385.151.688.156.303.426.472.276.165.62.165.215 0 .412-.05.198-.055.335-.17v-.651h-.692v-.472h1.201v1.32q-.165.207-.5.349-.33.138-.766.138zM20.01.947l1.623 3.376h-.591l-.29-.66h-1.545l-.289.66h-.573L19.959.947Zm-.23 1.436-.366.816h1.137l-.362-.812-.198-.463h-.009zM22.787 2.75l-.211-.477-.096.477-.312 1.573h-.51l.698-3.371h.055l.926 1.82.275.61.276-.61.908-1.82h.05l.725 3.37h-.505l-.34-1.572-.1-.477-.184.477-.816 1.573H23.6zM26.018.952h1.477v.45h-.968v.93h.78v.459h-.78v1.078h1.119v.454h-1.628zM28.938 4.369q-.275 0-.545-.097-.271-.096-.39-.215l.243-.436q.096.087.298.183.206.092.394.092.243 0 .395-.114.156-.115.156-.317 0-.156-.083-.27-.082-.115-.202-.188-.119-.078-.339-.189-.261-.128-.358-.192-.445-.298-.445-.826 0-.435.29-.665.288-.234.729-.234.472 0 .802.271l-.243.417q-.087-.091-.248-.156-.156-.068-.334-.068-.23 0-.363.105-.128.101-.128.303 0 .142.082.257.083.11.207.192.128.083.344.202.206.115.316.184.11.064.207.155.133.12.215.285.083.165.083.362 0 .307-.142.523-.138.215-.386.326-.243.11-.555.11z"></path></g></svg>
			<svg xmlns="http://www.w3.org/2000/svg" class="s-fjJKdSXdEtef svelte-16qfog0" viewBox="0 0 6 5"><defs class="s-fjJKdSXdEtef"><clipPath id="three-games-logo-svg-header" class="s-fjJKdSXdEtef"><ellipse cx="106.822" cy="119.364" fill="none" stroke="#c43b37" stroke-width=".825" rx="49.117" ry="39.162" class="s-fjJKdSXdEtef"></ellipse></clipPath></defs><g transform="matrix(.04573 0 0 .04594 2.319 2.243)" class="s-fjJKdSXdEtef"><ellipse class="logo-eye-color s-fjJKdSXdEtef svelte-16qfog0" cx="16.269" cy="9.431" fill="#3899ed" stroke="#000" stroke-width="2.628" rx="59.737" ry="49.977"></ellipse><g clip-path="url(#three-games-logo-svg-header)" transform="translate(-119.654 -141.447) scale(1.26422)" class="s-fjJKdSXdEtef"><ellipse cx="107.576" cy="119.667" rx="26.46" ry="25.524" class="s-fjJKdSXdEtef"></ellipse><path d="M77.486 89.412 65.352 77.278l14.94-.163c42.264-.462 61.806-.685 65.178-.743l3.732-.065-12.144 12.145-12.143 12.144-.543-.409c-5.324-4.013-12.023-6.001-18.474-5.483-3.756.302-6.754 1.11-9.997 2.696-2.075 1.014-3.781 2.098-5.245 3.33-.532.449-.983.816-1.002.816-.02 0-5.495-5.46-12.168-12.134zm-.1 60.876L65.352 162.52l14.94.042c42.267.118 61.81.182 65.182.213l3.732.034-12.242-12.045-12.242-12.045-.538.413c-5.292 4.056-11.975 6.099-18.43 5.633-3.758-.272-6.762-1.055-10.019-2.614-2.082-.997-3.797-2.067-5.27-3.288-.536-.444-.99-.808-1.01-.808-.019 0-5.45 5.505-12.069 12.233z" class="s-fjJKdSXdEtef"></path></g><ellipse cx="29.051" cy="-1.073" fill="#fff" rx="6.69" ry="6.212" class="s-fjJKdSXdEtef"></ellipse></g></svg></a></nav>

	<div class="search-container svelte-39tot0"><input type="text" placeholder="Search 3ee Games" class="svelte-39tot0" value="">
</div>

	

	<nav class="svelte-1qhiw35"><button class="svelte-1qhiw35"><ion-icon class="icon svelte-1qhiw35" name="reorder-three-outline"></ion-icon></button>
</nav>
		<nav class="svelte-1wxzkl">
</nav></header>

<div class="search-results svelte-1sv4ykx">
	

	

	
	
</div>

<main class="svelte-1l4pbsd">

<section class="background svelte-1pdjjzv"><article class="blog content svelte-1pdjjzv"><h1 id="action-figure-art" class="svelte-1pdjjzv">Action Figure Art</h1>
		<aside class="date-aside svelte-1pdjjzv"><ul class="svelte-1pdjjzv"><li class="published-date svelte-1pdjjzv"><address class="author svelte-1pdjjzv">By <a rel="author" href="/about" class="svelte-1pdjjzv">Ryan Sadwick</a></address></li>
				<li class="published-date svelte-1pdjjzv"><strong>Published:</strong> January 28, 2025</li>

				<li class="published-date svelte-1pdjjzv"><strong>Modified:</strong> January 29, 2025</li></ul></aside>

		<aside class="categories svelte-1pdjjzv"><ul class="svelte-1pdjjzv"><li class="svelte-1pdjjzv"><a href="/blog/categories/stable diffusion" class="svelte-1pdjjzv">Stable diffusion</a>
						</li><li class="svelte-1pdjjzv"><a href="/blog/categories/ai training" class="svelte-1pdjjzv">Ai training</a>
						</li></ul></aside>

		

		<div class="article"><p>I recently conducted an experiment using action figures to create a LoRA model. During the training process, I noticed that the model was learning to draw the action figures with all the paint flaws and inaccurices in the plastic. While there is nothing inherently wrong with those flaws, I wanted to adjust the model to prevent it from resembling a plastic toy. To achieve this, I decided to experiment with regularization images.</p>
<picture class="svelte-e5c5nc"><source media="(min-width: 100px) and (max-width: 896.98px)" srcset="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851601/blog/ovnfxvhmbsh3ctbj0pzn.png" width="484" height="256">

	<img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737851602/blog/nu7xnpfs7m0m4mforrpf.png" alt="Action Figure with reg images" width="968" height="512" class="svelte-e5c5nc">
</picture>
<h2 id="what-are-regularization-images"><a aria-hidden="true" tabindex="-1" href="#what-are-regularization-images"><span class="icon icon-link"></span></a>What are Regularization Images?</h2>
<p>Regularization images are used for prior-preservation loss to prevent overfitting in a machine learning model. They help maintain class consistency while allowing model adaptation to new concepts.</p>
<blockquote class="svelte-1ti8m27"><p class="svelte-1ti8m27">📄 Regularization tackles two key challenges with model training: overfitting and preserving class distinctions.</p></blockquote>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/rhor7neqffebs3mkb4jl.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854420/blog/paxaerqrspuqlkckjf0d.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<p>By creating regularization images, you’re defining a “class” of what you’re trying to invert. For example, if you’re trying to invert a skateboard, you might want to create a collection of skateboard images for regularization. This is to prevent your training from drifting into another class, let’s say “bike” or “roller skates.” It also helps guard against heading towards a “toy skateboard” if you are using real references and not interpretations.</p>
<p>Regularization ensures that the images you’re trying to invert don’t overfit. Overfitting occurs if the likeness to the images you generate becomes too similar to the training set. One challenge with textual inversions is the potential loss of editability during inversion, especially with prolonged training. The inclusion of regularization images and adjustments to learning rates helps mitigate this issue.</p>
<p>In essence, regularization ensures your model stays on course, navigating the delicate balance between fidelity to the training set and adaptability to novel inputs.</p>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Aspect</th>
<th class="svelte-1ti8m27">Regularization</th>
<th class="svelte-1ti8m27">No Regularization</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Class Definition</strong></td>
<td class="svelte-1ti8m27">Explicit class anchoring</td>
<td class="svelte-1ti8m27">Implicit class learning</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Failure Modes</strong></td>
<td class="svelte-1ti8m27">Underfitting if overdone</td>
<td class="svelte-1ti8m27">Overfitting/drift</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Data Efficiency</strong></td>
<td class="svelte-1ti8m27">Better generalization</td>
<td class="svelte-1ti8m27">Requires more data</td></tr></tbody></table>
<p>Regularization helps us make sure our models can correctly classify new data points they were not trained on. The ability to work well with new data is called “generalization.” If we don’t use regularization, our models can become too complex and “overfit” to the training data, meaning they won’t work well with new data.</p>
<p>Using too much regularization can be a problem. It can lead to “underfitting,” which means our model doesn’t work well with the training data. This happens when we limit our model’s ability too much.</p>
<blockquote class="svelte-1ti8m27"><p class="svelte-1ti8m27">📄 Imagine a graph of points. We need a function that fits them well: a simple one might miss the mark, while an overly complex one could fit perfectly but fail with new data. The goal is to balance simplicity and complexity for optimal performance.</p></blockquote>
<p><strong>Scenario 1</strong>: You have only a few pictures of your cat and no pictures of other cats.  If you train the model on just these few pictures - won’t learn enough to accurately recognize your cat.</p>
<p><strong>Solution</strong>: consider using regularization images to help the model learn more about cat features.</p>
<p><strong>Scenario 2</strong>: You have a lot of pictures of other cats, but only a few pictures of your cat.  If you train the model on all of these pictures, it might get confused and not learn how to accurately recognize your cat.</p>
<p><strong>Solution</strong>: using regularization images to help the model focus more on cat features in general, rather than getting distracted by other cats.</p>
<h2 id="divergence"><a aria-hidden="true" tabindex="-1" href="#divergence"><span class="icon icon-link"></span></a>Divergence</h2>
<p><strong>Divergence</strong> occurs when a model becomes unstable and fails to learn meaningful patterns, leading to erratic, low-quality outputs. This instability often arises from overly large or inconsistent datasets that lack clear, generalizable features. Instead of accurately capturing the subject’s likeness, the model produces unpredictable or incorrect results.  </p>
<p>Preventing divergence starts with <strong>careful dataset curation</strong>—selecting high-quality images with consistent and representative features helps the model focus on relevant patterns. Additionally, <strong>regularization techniques</strong> can reinforce learning stability, reducing the risk of both divergence and overfitting to noisy or inconsistent data.</p>
<ul><li><strong>Chaotic outputs</strong> The model generates erratic images that lack structure, coherence, or resemblance to the intended subject. This often results from an excessive learning rate, poor dataset quality, or an imbalance between training and regularization images.  </li>
<li><strong>Exploding gradients</strong> During backpropagation, weight updates grow exponentially, making the model’s parameters uncontrollably large. This leads to unpredictable updates and renders training ineffective. Techniques like gradient clipping can help mitigate this issue.  </li>
<li><strong>Loss value instability (NaN/infinity values)</strong> The training loss fluctuates wildly, sometimes becoming <code class="svelte-1ti8m27">NaN</code> (not a number) or reaching infinity. This typically indicates a numerical instability caused by extreme learning rates, batch size mismatches, or insufficient regularization.  </li></ul>
<h2 id="overfitting"><a aria-hidden="true" tabindex="-1" href="#overfitting"><span class="icon icon-link"></span></a><strong>Overfitting</strong></h2>
<p>Overfitting happens when a model memorizes the training data instead of learning generalizable patterns, leading to poor performance on new inputs. Signs of overfitting include:  </p>
<ul><li><strong>Perfectly replicates training samples</strong> The model reproduces training images with extreme accuracy, capturing even minor details and noise, rather than generalizing the features needed to create new, diverse outputs.  </li>
<li><strong>Fails to generalize to new inputs</strong> The model struggles to produce high-quality results for inputs it hasn’t seen before. This happens when it over-relies on specific patterns from the training set instead of learning broader representations.  </li>
<li><strong>Shows excellent training loss but poor validation loss</strong> The model achieves low loss during training but performs poorly on validation data, indicating that it has memorized the dataset rather than learning meaningful, generalizable features. Using techniques like dropout, data augmentation, and proper regularization can help reduce overfitting.  </li></ul>
<h3 id="key-differences"><a aria-hidden="true" tabindex="-1" href="#key-differences"><span class="icon icon-link"></span></a><strong>Key Differences</strong></h3>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27"><strong>Aspect</strong></th>
<th class="svelte-1ti8m27"><strong>Divergence</strong></th>
<th class="svelte-1ti8m27"><strong>Overfitting</strong></th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Cause</strong></td>
<td class="svelte-1ti8m27">Excessive learning rate</td>
<td class="svelte-1ti8m27">Insufficient regularization</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Loss Behavior</strong></td>
<td class="svelte-1ti8m27">Sudden spikes/NaN values</td>
<td class="svelte-1ti8m27">Steady decrease then rise</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Output Quality</strong></td>
<td class="svelte-1ti8m27">Random noise/artifacts</td>
<td class="svelte-1ti8m27">Overly detailed replicas</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Recovery</strong></td>
<td class="svelte-1ti8m27">Requires restart</td>
<td class="svelte-1ti8m27">Early stopping works</td></tr></tbody></table>
<h3 id="preventing-divergence"><a aria-hidden="true" tabindex="-1" href="#preventing-divergence"><span class="icon icon-link"></span></a>Preventing Divergence</h3>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Situation</th>
<th class="svelte-1ti8m27">Outcome</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Excessive or inconsistent data</strong></td>
<td class="svelte-1ti8m27">Model struggles to learn and produces unreliable predictions.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Lack of unique and consistent features</strong></td>
<td class="svelte-1ti8m27">Poor generalization, leading to inaccurate or meaningless outputs.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Carefully curated datasets</strong></td>
<td class="svelte-1ti8m27">Improved learning by ensuring the model sees only relevant, high-quality data.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27"><strong>Effective use of regularization techniques</strong></td>
<td class="svelte-1ti8m27">Helps maintain focus on essential features and prevents instability.</td></tr></tbody></table>
<p>By balancing dataset size, consistency, and regularization, we can train more stable and accurate models while avoiding divergence.</p>
<h3 id="implementing-these-strategies"><a aria-hidden="true" tabindex="-1" href="#implementing-these-strategies"><span class="icon icon-link"></span></a>Implementing these Strategies</h3>
<pre class="language-python"><!-- HTML_TAG_START --><code class="language-python"><span class="token comment"># Training parameters to prevent divergence</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"max_grad_norm"</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>    <span class="token comment"># Gradient clipping</span>
  <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span> <span class="token comment"># Conservative starting LR</span>
  <span class="token string">"lr_scheduler"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span> <span class="token comment"># Stable scheduling</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<pre class="language-python"><!-- HTML_TAG_START --><code class="language-python"><span class="token comment"># Regularization techniques</span>
<span class="token punctuation">&#123;</span>
  <span class="token string">"reg_data_dir"</span><span class="token punctuation">:</span> <span class="token string">"/reg_images"</span><span class="token punctuation">,</span>
  <span class="token string">"dropout_prob"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"train_batch_size"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"max_train_steps"</span><span class="token punctuation">:</span> <span class="token number">1500</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<h3 id="data-considerations"><a aria-hidden="true" tabindex="-1" href="#data-considerations"><span class="icon icon-link"></span></a>Data Considerations</h3>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Situation</th>
<th class="svelte-1ti8m27">Actual Risk</th>
<th class="svelte-1ti8m27">Solution</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">High LR + small batch size</td>
<td class="svelte-1ti8m27">Divergence</td>
<td class="svelte-1ti8m27">Lower LR, increase batch size</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Inconsistent features</td>
<td class="svelte-1ti8m27">Overfitting</td>
<td class="svelte-1ti8m27">Improve dataset consistency</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Insufficient reg images</td>
<td class="svelte-1ti8m27">Class leakage</td>
<td class="svelte-1ti8m27">Add 100-300 class images</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">High variance in training data</td>
<td class="svelte-1ti8m27">Mode collapse</td>
<td class="svelte-1ti8m27">Curate focused dataset</td></tr></tbody></table>
<h3 id="monitoring-tips"><a aria-hidden="true" tabindex="-1" href="#monitoring-tips"><span class="icon icon-link"></span></a>Monitoring Tips</h3>
<ul><li>Track loss curves with tools like <a href="https://www.tensorflow.org/tensorboard" rel="nofollow">TensorBoard</a></li>
<li>Generate validation images every 100 steps  </li>
<li>Use gradient clipping (1.0-2.0 norm)  </li>
<li>Enable mixed precision training  </li>
<li>Start with conservative learning rates (1e-5 to 1e-6)  </li></ul>
<h2 id="generating-regularization-images"><a aria-hidden="true" tabindex="-1" href="#generating-regularization-images"><span class="icon icon-link"></span></a>Generating Regularization images</h2>
<p>Regularization images are generated using the model you’re going to train with before training.  These generated images are based on the class name (e.g., <code class="svelte-1ti8m27">1boy</code>).</p>
<p>According to the Dreambooth technique, <code class="svelte-1ti8m27">200</code> regularization images per training image.  For example, if you have <code class="svelte-1ti8m27">16</code> images: <code class="svelte-1ti8m27">200 * 16 = 3200</code> total regularization images.  When training, the math involved for calculating total steps is:</p>
<blockquote class="svelte-1ti8m27"><p class="svelte-1ti8m27"><code class="svelte-1ti8m27">repeats * training images &gt;= repeats * regularization images</code></p></blockquote>
<p>The quality of regularization images impacts the model’s performance, as they are learned during training. Ideally, a few hundred high-quality regularized images should be prepared. Inadequate quantities may hinder generalization of class images, affecting the model’s ability to learn distinctive features.</p>
<h4 id="important-considerations"><a aria-hidden="true" tabindex="-1" href="#important-considerations"><span class="icon icon-link"></span></a>Important considerations</h4>
<ol><li><p><strong>Use the same base model for regularization images and training</strong><br>
Ensure that both the regularization images and training data originate from the same base model. This maintains consistency in feature representation and prevents the model from learning conflicting styles or patterns.  </p></li>
<li><p><strong>Maintain consistent class representation</strong><br>
The dataset should have a balanced distribution of each class to avoid bias. If certain classes dominate the dataset, the model may overfit to them while underperforming on underrepresented categories.</p></li>
<li><p><strong>Match output resolution to training data</strong><br>
The resolution of the generated outputs should align with the resolution of the training images. Mismatched resolutions can lead to artifacts, loss of detail, or unexpected distortions.  </p></li></ol>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/fbytgzx431mlr1cirrwa.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/syplrg2ay7kbonyjpxxu.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="generate-using-stable-diffusion-web-ui"><a aria-hidden="true" tabindex="-1" href="#generate-using-stable-diffusion-web-ui"><span class="icon icon-link"></span></a>Generate using Stable Diffusion web UI</h4>
<p>We’re going to use <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="nofollow">Stable Diffusion web UI</a> to generate all the regularization images.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips.</p>
<p>We’re going to use the <code class="svelte-1ti8m27">X/Y/Z plot</code> script to use <code class="svelte-1ti8m27">Prompt Search &amp; Replace</code> to dynamically build a prompt that will generate hundreds of regularization images.</p>
<ol><li><p>Select the text 2 image tab.  Enter a generic prompt <code class="svelte-1ti8m27">princeadam, portrait, looking_at_viewer, forest</code></p></li>
<li><p>In generation parameters and select the <code class="svelte-1ti8m27">X/Y/Z plot</code> script.</p></li>
<li><p>Select the <code class="svelte-1ti8m27">X</code> parameter and <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace.  We’re going to replace <code class="svelte-1ti8m27">portrait</code> with different camera angle tags: <code class="svelte-1ti8m27">close-up</code>, <code class="svelte-1ti8m27">upper_body</code>, <code class="svelte-1ti8m27">from_below</code>, <code class="svelte-1ti8m27">from_above</code>, <code class="svelte-1ti8m27">dutch_angle</code></p></li>
<li><p>Select the <code class="svelte-1ti8m27">Y</code> parameter and <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace.  Replace <code class="svelte-1ti8m27">looking_at_viewer</code>: <code class="svelte-1ti8m27">looking_away</code>, <code class="svelte-1ti8m27">looking_to_the_side</code>, <code class="svelte-1ti8m27">looking_ahead</code>, <code class="svelte-1ti8m27">looking_down</code></p></li>
<li><p>Select the <code class="svelte-1ti8m27">Z</code> parameter and <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace. Replace <code class="svelte-1ti8m27">forest</code> with a vareity of locatinos: <code class="svelte-1ti8m27">castle</code>, <code class="svelte-1ti8m27">mountain</code>, <code class="svelte-1ti8m27">cave</code>, <code class="svelte-1ti8m27">farm</code>, <code class="svelte-1ti8m27">ocean</code></p></li>
<li><p>Select a fast sampler like <code class="svelte-1ti8m27">DPM2 KARRAS</code></p></li>
<li><p>CFG Scale set to <code class="svelte-1ti8m27">7</code> and Steps to <code class="svelte-1ti8m27">20</code></p></li></ol>
<p>After the inference finishes, gather the images that were generated and we’ll start captioning.  We may only need <code class="svelte-1ti8m27">150</code> - <code class="svelte-1ti8m27">200</code> and keep in mind we can add and remove as we try different training settings with different output.</p>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854869/blog/alkw0c8naloochwgb2fp.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737854419/blog/nmlxqfiefc7bzll12ewv.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="download-images"><a aria-hidden="true" tabindex="-1" href="#download-images"><span class="icon icon-link"></span></a>Download images</h4>
<p>If generating these images isn’t an option, there are many repositories on HuggingFace that host regularization images generated with common models:</p>
<ul><li><a href="https://huggingface.co/3ee" rel="nofollow">3ee Games regularization images</a>: Our own regularization repository that has a large variety including architecture, horses, man, woman, forest, etc. All generated with Stable Diffusion 1.5.</li>
<li><a href="https://github.com/Luehrsen/sd_regularization_images" rel="nofollow">Pre-Rendered Regularization Images</a>: Includes 1500 regularization images.</li>
<li><a href="https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images" rel="nofollow">Stable Diffusion 1.5 Regularization Images</a>: includes art styles, illustration, landscapes, and many other types and themes of images generated with Stable Diffusion 1.5.  </li>
<li><a href="https://huggingface.co/Aitrepreneur/SDXL_REGULARIZATION_IMAGES/tree/main" rel="nofollow">Aitrepreneur SDXL image set</a>: a large image set generated with Stable Diffusion SDXL.</li></ul>
<h4 id="captioning-regularization-images"><a aria-hidden="true" tabindex="-1" href="#captioning-regularization-images"><span class="icon icon-link"></span></a>Captioning Regularization images</h4>
<p>While not required, you can caption regularization images just like how you can with training images.  Since Stable Diffusion Web UI named all of the images with the prompt within the filename, we can easily exact and create <code class="svelte-1ti8m27">txt</code> files with a shell script:</p>
<pre class="language-shell"><!-- HTML_TAG_START --><code class="language-shell">@echo off
setlocal EnableDelayedExpansion EnableExtensions

:: Batch Caption Extractor
:: Creates .txt files from filenames containing prompts
:: Usage: Drag folder onto script or run <span class="token keyword">in</span> images directory

<span class="token builtin class-name">echo</span> Starting caption extraction<span class="token punctuation">..</span>.
echo.

<span class="token builtin class-name">set</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">error_count</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> %%i <span class="token keyword">in</span> <span class="token punctuation">(</span>*.png *.jpg *.webp<span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
    <span class="token builtin class-name">set</span> <span class="token string">"original=%%~ni"</span>
    
    :: Replace commas with a safer delimiter <span class="token keyword">for</span> processing
    <span class="token builtin class-name">set</span> <span class="token string">"safe_name=!original:,=|!"</span>
    
    :: Extract caption <span class="token punctuation">(</span>everything after the first comma<span class="token punctuation">)</span>
    <span class="token keyword">for</span> /f <span class="token string">"tokens=1* delims=,"</span> %%a <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">"!safe_name!"</span><span class="token punctuation">)</span> <span class="token keyword">do</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=%%b"</span>
    <span class="token punctuation">)</span>
    
    :: Restore commas <span class="token keyword">if</span> a caption was extracted
    <span class="token keyword">if</span> defined caption <span class="token punctuation">(</span>
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!caption:|=,!"</span>
    <span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Warning: No comma found <span class="token keyword">in</span> <span class="token string">"%%i"</span> - using full filename
        <span class="token builtin class-name">set</span> <span class="token string">"caption=!original!"</span>
    <span class="token punctuation">)</span>

    :: Write to .txt <span class="token function">file</span>
    <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> <span class="token operator">!</span>caption<span class="token operator">!</span>
    <span class="token punctuation">)</span> <span class="token operator">></span> <span class="token string">"%%~ni.txt"</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Created: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>
        <span class="token builtin class-name">echo</span> Error creating: %%~ni.txt
        <span class="token builtin class-name">set</span> /a <span class="token assign-left variable">error_count</span><span class="token operator">+=</span><span class="token number">1</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

echo.
<span class="token builtin class-name">echo</span> Process complete: <span class="token operator">!</span>count<span class="token operator">!</span> files created, <span class="token operator">!</span>error_count<span class="token operator">!</span> errors.
pause
</code><!-- HTML_TAG_END --></pre>
<p>Save this file as <code class="svelte-1ti8m27">filename2txt.bat</code> and place it into the regularization images directory and run: <code class="svelte-1ti8m27">.\filename2txt.bat</code>.  The script extracts the prompt from the filename and outputs a text file with the prompt.  The text file is named the same filename as the image and will be picked up by the text encoder during training.</p>
<p>Example filename: <code class="svelte-1ti8m27">18967-19144263-izaniak, aburbres, princeadam, 1boy, close-up, purple_vest.png</code></p>
<p>Output: <code class="svelte-1ti8m27">aburbres,princeadam,1boy,close-up,purple_vest</code> saved in a text file with the same name as image.</p>
<h2 id="training-a-lora"><a aria-hidden="true" tabindex="-1" href="#training-a-lora"><span class="icon icon-link"></span></a>Training a LoRA</h2>
<p>Now we’re going to setup all the training data to create a LoRA model.  We’re going to go over how to setup your training data to use regularization images with <a href="https://github.com/kohya-ss/sd-scripts" rel="nofollow">kohya-ss/sd-scripts</a>.</p>
<blockquote class="svelte-1ti8m27"><p class="svelte-1ti8m27">📄 Learning how to train a LoRA is a completely different subject all on its own.  See <a href="https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_README-en.md" rel="nofollow">Kohya SD script documentation</a>.  </p></blockquote>
<h3 id="directory-setup"><a aria-hidden="true" tabindex="-1" href="#directory-setup"><span class="icon icon-link"></span></a>Directory setup</h3>
<p>In your configuration json, use <code class="svelte-1ti8m27">reg_data_dir</code> to point to the directory with your regularization images:</p>
<pre class="language-json"><!-- HTML_TAG_START --><code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"c:/prince_adam_loras/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<p>Within that folder, the setup is similar to setting up your train data directory, create directories with the following a repetition count and name:</p>
<pre class="language-xml"><!-- HTML_TAG_START --><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repetition</span> <span class="token attr-name">count</span><span class="token punctuation">></span></span>_<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>identifier</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span></code><!-- HTML_TAG_END --></pre>
<p>Set the <code class="svelte-1ti8m27">number of iterations</code> so that training images are used as often as or more often than regularization images. In one epoch, the total data is <code class="svelte-1ti8m27">training images × iterations</code>. If there are more regularization images than this, the extras won’t be used.</p>
<p>Create folders in the training image folder with the format <code class="svelte-1ti8m27">&lt;repetition count&gt;_&lt;class&gt;</code> multiple times, and similarly create folders in the regularization image folder with the format <code class="svelte-1ti8m27">&lt;repetition count&gt;_&lt;class&gt;</code>.</p>
<p>If there is only one class with multiple targets, you only need one regularization image folder.  For example, if there is character A and character B in 1girl, it would look like this:</p>
<ul><li>train_data_dir<ul><li>10_princeadam</li></ul></li>
<li>reg_dir<ul><li>1_1boy</li></ul></li></ul>
<p>For example, with the prompt “frog” and not repeating the data (only once), it would look like this:</p>
<p class="svelte-1ti8m27"><img src="https://user-images.githubusercontent.com/52813779/210770897-329758e5-3675-49f1-b345-c135f1725832.png" alt="image" class="svelte-1ti8m27"></p>
<h3 id="training-settings"><a aria-hidden="true" tabindex="-1" href="#training-settings"><span class="icon icon-link"></span></a>Training Settings</h3>
<p>The training setup we’re going to use is:  <code class="svelte-1ti8m27">Number of images * repeats * epoch / batch size = total steps</code>.  Total Steps = (Number of Images × Repeats × Epochs) / Batch Size.  <code class="svelte-1ti8m27">Example: (45 × 10 × 20) / 2 = 4500 steps</code></p>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Number of Images</th>
<th class="svelte-1ti8m27">Repeats</th>
<th class="svelte-1ti8m27">Epochs</th>
<th class="svelte-1ti8m27">Batch Size</th>
<th class="svelte-1ti8m27">Total Steps</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">45</td>
<td class="svelte-1ti8m27">10</td>
<td class="svelte-1ti8m27">20</td>
<td class="svelte-1ti8m27">2</td>
<td class="svelte-1ti8m27">4500</td></tr></tbody></table>
<p>Now let’s focus on these training settings:</p>
<pre class="language-json"><!-- HTML_TAG_START --><code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token string">"1e-4"</span><span class="token punctuation">,</span>
  <span class="token property">"text_encoder_lr"</span><span class="token operator">:</span> <span class="token string">"1e-6"</span><span class="token punctuation">,</span>
  <span class="token property">"unet_lr"</span><span class="token operator">:</span> <span class="token string">"1e-5"</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">64</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">32</span>
  <span class="token property">"lr_scheduler"</span><span class="token operator">:</span> <span class="token string">"cosine_with_restarts"</span><span class="token punctuation">,</span>
  <span class="token property">"lr_scheduler_num_cycles"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"network_dim"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
  <span class="token property">"network_alpha"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
  <span class="token property">"clip_skip"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">"max_token_length"</span><span class="token operator">:</span> <span class="token string">"225"</span><span class="token punctuation">,</span>
  <span class="token property">"noise_offset"</span><span class="token operator">:</span> <span class="token string">"0.1"</span><span class="token punctuation">,</span>
  <span class="token property">"reg_data_dir"</span><span class="token operator">:</span> <span class="token string">"/prince_adam_loras/action/reg_dir"</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span></code><!-- HTML_TAG_END --></pre>
<ul><li><strong>Learning Rate (<code class="svelte-1ti8m27">learning_rate</code>)</strong>: Determines the step size during optimization, influencing how quickly the model adapts to training data.</li>
<li><strong>Text Encoder Learning Rate (<code class="svelte-1ti8m27">text_encoder_lr</code>)</strong>: Sets the learning rate specifically for the Text Encoder, optimizing its contribution to the model.</li>
<li><strong>UNet Learning Rate (<code class="svelte-1ti8m27">unet_lr</code>)</strong>: Specifies the learning rate for the UNet component, impacting its performance in the LoRA model.</li>
<li><strong>Learning Rate Scheduler (<code class="svelte-1ti8m27">lr_scheduler</code>)</strong>: Utilizes a cosine annealing schedule with restarts for dynamic learning rate adjustment during training.</li>
<li><strong>Number of Cycles in Learning Rate Scheduler (<code class="svelte-1ti8m27">lr_scheduler_num_cycles</code>)</strong>: Sets the number of cycles for the cosine annealing schedule, influencing the frequency of learning rate restarts.</li>
<li><strong>Network Dimension (<code class="svelte-1ti8m27">network_dim</code>)</strong>: Defines the dimensionality of the latent space in the LoRA model, capturing more complex patterns but increasing computational demand.</li>
<li><strong>Network Alpha (<code class="svelte-1ti8m27">network_alpha</code>)</strong>: Regulates the strength of regularization in ordinal regression loss, balancing fitting training data closely and preventing overfitting.</li>
<li><strong>Clip Skip (<code class="svelte-1ti8m27">clip_skip</code>)</strong>: Acts as a safety net during training, skipping updates if the loss remains unchanged for two consecutive iterations, stabilizing the learning process.</li>
<li><strong>Max Token Length (<code class="svelte-1ti8m27">max_token_length</code>)</strong>: Sets the maximum allowed length for input tokens, enabling training with longer captions.</li>
<li><strong>Noise Offset (<code class="svelte-1ti8m27">noise_offset</code>)</strong>: Implements a diffusion process with offset noise, enhancing generation results for dark or bright images.</li>
<li><strong>Regularization Data Directory (<code class="svelte-1ti8m27">reg_data_dir</code>)</strong>: Specifies the directory for regularization data, influencing the quality of regularization images during training.</li></ul>
<h3 id="fine-tuning"><a aria-hidden="true" tabindex="-1" href="#fine-tuning"><span class="icon icon-link"></span></a>Fine Tuning</h3>
<p>Once training has completed, it’s time to fine tune the model through visual inference with each step saved.  We have 45 LoRAs but we only need to go through the higher steps that were output.  Each represents a different LoRA saved at different epochs of the training session.</p>
<div class="image-compare-container svelte-s79nww"><div style="display: contents; --handle-size:2.5rem; --handle-background-color:rgba(0, 0, 0, 0.6); --handle-background-image:url(&#39;data:image/svg+xml;utf8,&lt;svg viewBox=&quot;0 0 24 24&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;path d=&quot;M3 12H21M3 12L7 8M3 12L7 16M21 12L17 16M21 12L17 8&quot; stroke=&quot;white&quot; stroke-width=&quot;2&quot; stroke-linecap=&quot;round&quot; stroke-linejoin=&quot;round&quot;/&gt;&lt;/svg&gt;&#39;); --handle-border-width:0.125rem; --slider-color:#ffffff; --slider-width:0.125rem;"><div class="svelte-compare-image-container svelte-1po6qlg" style="--slider-position: 50%;" data-testid="svelte-compare-image"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853752/blog/rwesmvkg6k7nptpoixc0.png" alt="prince adam without reg" class="left-img svelte-1po6qlg">
  <img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/e0layz06rtzl1mlsienh.png" alt="prince adam trained with regularization images." class="right-img svelte-1po6qlg">

  <label class="svelte-1po6qlg"><span class="visually-hidden svelte-1po6qlg">Set the visibility of one image over the other. 0 is full visibility of the second image and
			100 is full visibility of the first image. Any amount in-between is a left/right cutoff at the
			percentage of the slider.
		</span>
    <input type="range" min="0" max="100" value="50" class="svelte-1po6qlg"></label>
</div></div>
</div>
<h4 id="workflow-with-auto1111-webui"><a aria-hidden="true" tabindex="-1" href="#workflow-with-auto1111-webui"><span class="icon icon-link"></span></a>Workflow with Auto1111 WebUI</h4>
<p>We’re going to use <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" rel="nofollow">Stable Diffusion web UI</a> to interface to fine tune the training output LoRA.  There are other web UIs available to inference with Stable Diffusion.  Personally preference, I like this better because the application is laid out like a data science tool with many options at your fingertips.</p>
<p>We’re going to use the <code class="svelte-1ti8m27">X/Y/Z plot</code> script to compare different epochs.</p>
<ul><li>Select the text 2 image tab.  Enter a generic prompt princeadam, portrait, <princeadam0001:0.7></princeadam0001:0.7></li>
<li>In generation parameters and select the X/Y/Z plot script.</li>
<li>Select <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace.  We’re going to replace <code class="svelte-1ti8m27">&lt;princeadam0001:0.7&gt;</code> with different epoch: <code class="svelte-1ti8m27">&lt;princeadam0001:0.7&gt;, &lt;princeadam0003:0.7&gt;, &lt;princeadam0023:0.7&gt;</code></li>
<li>Select a fast sampler like <code class="svelte-1ti8m27">DPM2 KARRAS</code></li>
<li>CFG Scale set to <code class="svelte-1ti8m27">7</code> and Steps to <code class="svelte-1ti8m27">20</code></li></ul>
<p>After the inference finishes, a grid image will be generated.  Use those results to pick which epoch best represents the subject.  From there, we will fine tune more and view the strength of the LoRA.  Test an entire range to get an accutre view using plot grids to figure out a prefered range for your LoRA’s strength.  Recall setting <code class="svelte-1ti8m27">network_dim</code> and <code class="svelte-1ti8m27">network_alpha</code>?  Those are the settings that directly control the output strength mentioned earlier.
Use another </p>
<ul><li>Select <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace.  We’re going to replace the weights <code class="svelte-1ti8m27">&lt;princeadam12:0.4&gt;, &lt;princeadam12:0.5&gt;, &lt;princeadam12:0.6&gt;, &lt;princeadam12:0.7&gt;, &lt;princeadam12:0.8&gt;, &lt;princeadam12:0.9&gt;, &lt;princeadam12:1.0&gt;</code></li>
<li>Use Prompt SR to generate a variety of angles: Select <code class="svelte-1ti8m27">Prompt SR</code> for Prompt Replace.  Replace upper_body with different camera angles: from_below, from_above, close_up.</li>
<li>If you found results you liked, keep testing different situations to see if your Lora can be creative and do things not in the training data.</li>
<li>Use a Z axis and test different Checkpoint models with the LoRA model.  You will still see likeness when using different models due to the weights being the same in the LoRA model.</li></ul>
<h4 id="issues-to-look-for"><a aria-hidden="true" tabindex="-1" href="#issues-to-look-for"><span class="icon icon-link"></span></a>Issues to look for</h4>
<ul><li><strong>Undercooked:</strong> Lacks output, adjust unet learning rate or extend training duration.</li>
<li><strong>Overcooked:</strong> Distorted images persist and earlier epochs offer no improvement, adjust learning rate or repeats.</li>
<li><strong>Overfit:</strong> Overly restrictive, consider dataset size, tagging quality, or slight overcooking as possible issues.</li>
<li><strong>Mismatched:</strong> Doesn’t match expectations, it might be undercooked or have a low-quality dataset.</li></ul>
<p>If you’re experiencing these issues, it’s not uncommon to throw away the results and start again with a different set of parameters based on the previous setup.  Training a LoRA that consistantly gives great results with each inference requires patience and fine tuning.</p>
<p class="svelte-1ti8m27"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853753/blog/ewecjb3spk7k9i07somp.png" alt="image" class="svelte-1ti8m27"></p>
<h2 id="troubleshooting"><a aria-hidden="true" tabindex="-1" href="#troubleshooting"><span class="icon icon-link"></span></a>Troubleshooting</h2>
<p>If you find your results aren’t what you expected, make note of the results and compare to what you were expecting.  From there, figure out additional options to take when re-training:</p>
<ul><li>Lower input images, less regularization images needed.  Remember Dreambooth calls for about <code class="svelte-1ti8m27">200</code> regularization images per training image.</li>
<li>Repeats of regularization images, but may overfit more.  Increasing the <code class="svelte-1ti8m27">repetition_count</code> will cycle through the images more but the results may have results that overfit the model.</li>
<li>Create more regularization images without increasing repeats will help with the overfitting.</li></ul>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Issue</th>
<th class="svelte-1ti8m27">Situation</th>
<th class="svelte-1ti8m27">Recommendation</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Varying quality</td>
<td class="svelte-1ti8m27">Results differ from expectations</td>
<td class="svelte-1ti8m27">Evaluate the quality and quantity of reg images. Adjust number and selection - check for better results.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Inadequate regularization for input data</td>
<td class="svelte-1ti8m27">Lower input images, less regularization needed</td>
<td class="svelte-1ti8m27">Reduce the number of input images or increasing the quantity of reg images.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Overfitting due to repetition</td>
<td class="svelte-1ti8m27">Repeats of reg images, risk of overfitting</td>
<td class="svelte-1ti8m27">Adjust repetition_count to balance cycling through images without overfitting. Monitor results.</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Mitigate overfitting while increasing diversity</td>
<td class="svelte-1ti8m27">Create more reg images without repeats</td>
<td class="svelte-1ti8m27">Generate additional reg images without increasing repetitions. Enhance adaptability without overfitting.</td></tr></tbody></table>
<h4 id="more-solutions"><a aria-hidden="true" tabindex="-1" href="#more-solutions"><span class="icon icon-link"></span></a>More Solutions</h4>
<p>Need more help troubleshooting?  Here are additional solutions to problems that might turn up in during or after training.</p>
<table class="svelte-1ti8m27"><thead class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><th class="svelte-1ti8m27">Symptom</th>
<th class="svelte-1ti8m27">Likely Cause</th>
<th class="svelte-1ti8m27">Solution</th></tr></thead>
<tbody class="svelte-1ti8m27"><tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Plastic texture persists</td>
<td class="svelte-1ti8m27">Insufficient human reg images</td>
<td class="svelte-1ti8m27">Add real photos to reg set</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Loss plateaus early</td>
<td class="svelte-1ti8m27">Learning rate too low</td>
<td class="svelte-1ti8m27">Increase LR by 10x</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Features blurry</td>
<td class="svelte-1ti8m27">Network dimension too small</td>
<td class="svelte-1ti8m27">Increase network_dim to 64+</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Color distortion</td>
<td class="svelte-1ti8m27">Noise offset conflict</td>
<td class="svelte-1ti8m27">Try noise_offset 0.05-0.1</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Overly stylized outputs</td>
<td class="svelte-1ti8m27">Reg image style mismatch</td>
<td class="svelte-1ti8m27">Regenerate reg images with base model</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Training instability</td>
<td class="svelte-1ti8m27">Batch size too large</td>
<td class="svelte-1ti8m27">Reduce batch_size to 1-2</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Slow convergence</td>
<td class="svelte-1ti8m27">Network_alpha too high</td>
<td class="svelte-1ti8m27">Set alpha = dim/2 (e.g., 64/2 = 32)</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Loss divergence</td>
<td class="svelte-1ti8m27">Text encoder LR too high</td>
<td class="svelte-1ti8m27">Reduce text_encoder_lr by 10x</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Poor prompt adherence</td>
<td class="svelte-1ti8m27">Clip skip too high</td>
<td class="svelte-1ti8m27">Reduce clip_skip to 1-2</td></tr>
<tr class="svelte-1ti8m27"><td class="svelte-1ti8m27">Memory errors</td>
<td class="svelte-1ti8m27">Resolution too high</td>
<td class="svelte-1ti8m27">Reduce to 512-768px, enable gradient checkpointing</td></tr></tbody></table>
<h2 id="results"><a aria-hidden="true" tabindex="-1" href="#results"><span class="icon icon-link"></span></a>Results</h2>
<p>The delicate dance between overfitting and generalization has been choreographed with precision, allowing the model to navigate a nuanced artistic style in combining an action figure and regularization images.</p>
<p>Thoughtful application of regularization techniques and careful dataset curation are important while preparing to train a model. The results not only showcase the model’s ability to learn and adapt but also emphasize the importance of striking the right balance between simplicity and complexity for artistic performance.</p>
<p class="svelte-1ti8m27"><img src="https://res.cloudinary.com/dxgyuy0iu/image/upload/v1737853755/blog/ygl92e7oo9dghunhp0dg.png" alt="image" class="svelte-1ti8m27"></p>
<p>The journey doesn’t end here; it extends into the realm of fine-tuning and continuous exploration. Each epoch, each adjustment, contributes to the evolution of the LoRA model, uncovering new dimensions of creativity and paving the way for future experiments in the realm of stable diffusion and generative art.</p>
<h2 id="spacelab" class="svelte-1ti8m27"><a aria-hidden="true" tabindex="-1" href="#spacelab"><span class="icon icon-link"></span></a>spacelab</h2>
<hr>
	<div class="subscribe svelte-s12rf8"><h2 class="svelte-s12rf8">Training Dataset</h2>

		<p class="highlight large svelte-s12rf8"><ion-icon class="icon svelte-s12rf8" name="lock-closed"></ion-icon>SpaceLab Content</p>

		<p class="svelte-s12rf8">You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.</p>

		

		

		<button class="button subscribe svelte-s12rf8"><ion-icon class="icon svelte-s12rf8" name="planet"></ion-icon>
			<span>SpaceLab</span></button></div></div></article>
</section></main>

<footer class="svelte-1pv61cd"><div class="footer-container svelte-1pv61cd"><div class="footer-main svelte-1pv61cd"><div class="brand svelte-1pv61cd"><div class="footer-logo footer-logo-animation svelte-1pv61cd"><svg viewBox="0 0 30 17" class="svelte-1pv61cd"><g><g aria-label="3EE" font-size="16.383" stroke-width=".41"><path class="three-ee-text-logo svelte-1pv61cd" d="M7.077 3.584H3.649v1.132H.91V3.258q0-.583.063-1.08.078-.498.313-.84.235-.343.688-.532Q2.444.6 3.242.6h.063L7.42.566h.063q.36 0 .72.051.36.035.751.309.423.309.61.703.189.377.235.875.047.497.047.96 0 .223-.015.446v.411q-.016.223-.016.446v.463q0 .463-.11.789-.093.326-.36.617.267.274.36.617.11.326.11.79v2.417q0 .446-.156.823-.141.36-.407.652-.25.274-.61.428-.345.155-.736.155H2.788q-.391 0-.735-.155-.345-.154-.595-.428-.25-.292-.407-.652-.14-.377-.14-.823V8.402h2.738v1.132h3.428v-1.68H2.961V4.853h4.116zM19.205 9.568v3.001h-8.39V.566h8.39V3.55h-5.65v1.526h4.633v2.983h-4.633v1.51zM28.499 9.568v3.001h-8.39V.566h8.39V3.55h-5.65v1.526h4.632v2.983h-4.633v1.51z"></path></g><g aria-label="Third Eye Entertainment" font-size="2.117" stroke-width=".265"><path class="three-ee-unwrapped-text svelte-1pv61cd" d="M2.237 13.958v.368H1.82v1.113h-.37v-1.113h-.417v-.368zM3.555 13.954v1.481h-.368v-.556H2.72v.556h-.368v-1.481h.368v.556h.466v-.556zM4.068 13.958v1.481h-.37v-1.481zM5.35 14.356v.05l.002.05v.042l.002.038-.002.093-.006.093q-.009.061-.036.106-.025.042-.076.078-.034.023-.066.032-.03.006-.063.008l.273.49h-.422l-.27-.488h-.144v.487h-.37v-1.481h.91q.056 0 .105.02.049.02.085.058.036.036.057.087.021.048.021.105zm-.375.224v-.256h-.433v.256zM6.479 13.964q.07.021.108.053.038.03.055.068.017.038.021.082.004.045.004.093v.026q.002.01.002.023.003.03.003.07v.692q0 .06-.003.112-.002.053-.02.098-.02.044-.062.08-.04.036-.117.061-.019.005-.074.009l-.116.004h-.812v-1.481h.535q.046-.003.095-.003h.068q.055 0 .116.003.064 0 .119.004.057.002.076.006zM6.3 15.067v-.743h-.463v.743zM8.756 15.069v.37H7.62v-1.481h1.135v.368H7.99v.188h.627v.369h-.627v.186zM10.222 13.956l-.531.842v.64h-.369v-.64l-.533-.842h.436l.281.442.28-.442zM11.401 15.069v.37h-1.134v-1.481H11.4v.368h-.764v.188h.627v.369h-.627v.186zM13.477 15.069v.37h-1.135v-1.481h1.135v.368h-.764v.188h.626v.369h-.626v.186zM14.814 13.96v1.482h-.347l-.487-.762v.762h-.368V13.96h.347l.487.76v-.76zM16.136 13.958v.368h-.417v1.113h-.37v-1.113h-.417v-.368zM17.367 15.069v.37h-1.135v-1.481h1.135v.368h-.764v.188h.626v.369h-.626v.186zM18.67 14.356v.05l.002.05v.042l.002.038-.002.093-.006.093q-.008.061-.036.106-.025.042-.076.078-.034.023-.066.032-.03.006-.063.008l.273.49h-.421l-.271-.488h-.144v.487h-.37v-1.481h.91q.057 0 .105.02.049.02.085.058.036.036.057.087.021.048.021.105zm-.374.224v-.256h-.434v.256zM19.964 13.958v.368h-.417v1.113h-.37v-1.113h-.417v-.368zM20.903 13.954l.538 1.481h-.396l-.1-.277h-.45l-.1.277h-.394l.538-1.481zm-.093.834q-.013-.034-.021-.06l-.02-.053q-.008-.027-.02-.057l-.028-.076-.091.246zM21.87 13.958v1.481h-.37v-1.481zM23.186 13.96v1.482h-.348l-.486-.762v.762h-.369V13.96h.347l.487.76v-.76zM24.755 13.956v1.481h-.37v-.74l-.104.165-.097.158h-.271l-.201-.326v.743h-.37v-1.481h.35l.356.578.358-.578zM26.04 15.069v.37h-1.134v-1.481h1.134v.368h-.764v.188h.627v.369h-.627v.186zM27.377 13.96v1.482h-.347l-.486-.762v.762h-.369V13.96h.347l.487.76v-.76zM28.7 13.958v.368h-.417v1.113h-.37v-1.113h-.418v-.368z"></path></g></g></svg></div>
				<p class="legal svelte-1pv61cd">© Copyright 2025 3ee Games LLC. All rights reserved.</p>
				<p class="legal svelte-1pv61cd">Made with a giant barrel of <ion-icon class="heart-icon svelte-1pv61cd" name="heart-sharp"></ion-icon> by 3ee Games.
				</p>
				<p class="legal svelte-1pv61cd">In memory of Teela 🐱</p></div>
			<div class="footer-routes svelte-1pv61cd"><div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="planet-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">discover</h6></div>
					<a href="/about" aria-current="page" class="svelte-1pv61cd">about</a>
					<a href="/games" aria-current="page" class="svelte-1pv61cd">games</a>
					<a href="/blog" aria-current="page" class="svelte-1pv61cd">blog</a>
					<a href="https://discord.gg/3ee" target="_blank" class="svelte-1pv61cd">discord</a>
					<a href="/contact" aria-current="page" class="svelte-1pv61cd">contact</a></div>
				<div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="person-circle-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">account</h6></div>
					<a href="/account/login" aria-current="page" class="svelte-1pv61cd">login</a>
						<a href="/account/create" aria-current="page" class="svelte-1pv61cd">create an account</a>
						<a href="/account/accessibility" aria-current="page" class="svelte-1pv61cd">accessibility</a>
						<a href="/account/conduct" aria-current="page" class="svelte-1pv61cd">code of conduct</a>
						<a href="/account/privacy" aria-current="page" class="svelte-1pv61cd">privacy policy</a>
						<a href="/account/terms" aria-current="page" class="svelte-1pv61cd">terms of service</a></div>
				<div class="footer-category svelte-1pv61cd"><div class="footer-heading svelte-1pv61cd"><ion-icon class="footer-heading-icon svelte-1pv61cd" name="chatbubbles-sharp"></ion-icon>
						<h6 class="svelte-1pv61cd">social</h6></div>

					<a href="https://github.com/3ee-Games" target="_blank" class="svelte-1pv61cd">github</a>
					<a href="https://huggingface.co/3ee" target="_blank" class="svelte-1pv61cd">huggingface</a>
					<a href="https://www.youtube.com/@3eegames" target="_blank" class="svelte-1pv61cd">youtube</a>
					<a href="https://x.com/3ee_Games" target="_blank" class="svelte-1pv61cd">X</a>
					<a href="https://www.linkedin.com/company/3ee-games" target="_blank" class="svelte-1pv61cd">linkedin</a>
					<a href="https://www.facebook.com/3eecom" target="_blank" class="svelte-1pv61cd">facebook</a></div></div></div></div></footer>





	<script defer src="https://cloud.umami.is/script.js" data-website-id="ce2999d5-1ac8-4c93-b775-e76c96c916d1"></script>


		<script type="module" data-sveltekit-hydrate="1qj6ysk">
		import { start } from "/_app/immutable/start-6d8ebd8f.js";
		start({
			target: document.querySelector('[data-sveltekit-hydrate="1qj6ysk"]').parentNode,
			paths: {"base":"","assets":""},
			session: {},
			route: true,
			spa: false,
			trailing_slash: "always",
			hydrate: {
				status: 200,
				error: null,
				nodes: [0, 19],
				params: {},
				routeId: "blog/action-figure-art"
			}
		});
	</script><script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/posts.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Action Figure Art\",\"date\":\"2025-01-28 11:00:20\",\"modifiedDate\":\"2025-01-29 15:00:00\",\"categories\":[\"stable diffusion\",\"ai training\"],\"svg\":\"ActionFigure\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"Artwork created with action figure training sets.\",\"author\":\"Ryan Sadwick\",\"spacelab\":true,\"id\":1,\"spacelabDefaultTitle\":\"Training Dataset\",\"spacelabDefaultContent\":\"You can experiment with the dataset yourself and train your own LoRAs using your own action figures.  The training dataset is available to download if you have a Spacelab subscription.\",\"menu\":[{\"name\":\"Regularization?\",\"icon\":\"⚖️\",\"url\":\"/blog/action-figure-art/#what-are-regularization-images\"},{\"name\":\"Divergence\",\"icon\":\"💥\",\"url\":\"/blog/action-figure-art/#divergence\"},{\"name\":\"Overfitting\",\"icon\":\"🎭\",\"url\":\"/blog/action-figure-art/#overfitting\"},{\"name\":\"Generating\",\"icon\":\"✨\",\"url\":\"/blog/action-figure-art/#generating-regularization-images\"},{\"name\":\"Train LoRA\",\"icon\":\"🍳\",\"url\":\"/blog/action-figure-art/#training-a-lora\"},{\"name\":\"Troubleshooting\",\"icon\":\"🛠️\",\"url\":\"/blog/action-figure-art/#troubleshooting\"},{\"name\":\"Results\",\"icon\":\"📊\",\"url\":\"/blog/action-figure-art/#results\"},{\"name\":\"Spacelab Content\",\"icon\":\"🔒\",\"url\":\"/blog/action-figure-art/#spacelab\"}],\"keywords\":[\"stable diffusion\",\"generative ai\",\"lora\",\"machine learning\",\"action figures\",\"python\"]},\"path\":\"/blog/action-figure-art\"},{\"meta\":{\"title\":\"First-Party Experience\",\"date\":\"2025-01-08 11:00:20\",\"modifiedDate\":\"2025-01-15 11:00:20\",\"categories\":[\"cookies\",\"analytics\",\"containers\",\"docker\"],\"svg\":\"Cookie\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1736376433/blog/o5nsfwkgjhamizuegzzp.png\",\"shortDescription\":\"Discuss the insights of moving towards a first party experience.\",\"author\":\"Ryan Sadwick\",\"menu\":[{\"name\":\"First Party\",\"icon\":\"🥇\",\"url\":\"/blog/first-party-experience/#first-party-centric-built-in-privacy\"},{\"name\":\"cookies\",\"icon\":\"🍪\",\"url\":\"/blog/first-party-experience/#identify-all-cookies\"},{\"name\":\"google analytics\",\"icon\":\"⛅\",\"url\":\"/blog/first-party-experience/#example-replace-google-analytics\"},{\"name\":\"localstorage\",\"icon\":\"🛡️\",\"url\":\"/blog/first-party-experience/#from-cookies-to-localstorage\"},{\"name\":\"privacy policies\",\"icon\":\"🔒\",\"url\":\"/blog/first-party-experience/#updating-privacy-policies\"},{\"name\":\"Containerization\",\"icon\":\"📦\",\"url\":\"/blog/first-party-experience/#streamlining-with-containers\"}],\"keywords\":[\"analytics\",\"docker\",\"containers\",\"google\",\"youtube\",\"web development\"]},\"path\":\"/blog/first-party-experience\"},{\"meta\":{\"title\":\"Github Actions 101\",\"date\":\"2025-01-06 12:34:20\",\"modifiedDate\":\"2025-01-18 13:00:00\",\"categories\":[\"github\",\"automation\",\"web development\"],\"svg\":\"Api\",\"youtubeId\":\"wx6eOvvGEc8\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1736376656/blog/ydtnowkeirmxxcyjoyr5.png\",\"shortDescription\":\"Learn how 3ee Games uses Github Actions and GraphQL to automate issue tracking, enhancing transparency in game development.\",\"keywords\":[\"github\",\"issue tracker\",\"transparency\",\"web development\",\"actions\",\"automation\"],\"author\":\"Ryan Sadwick\"},\"path\":\"/blog/github-actions-101\"},{\"meta\":{\"title\":\"Ornamental Santa Diffusion\",\"date\":\"2022-12-08 19:30:10\",\"modifiedDate\":\"2023-01-08 19:30:10\",\"categories\":[\"stable diffusion\",\"ai training\"],\"svg\":\"Santa\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"Check out Ornamental Santa Diffusion, a model that uses stable diffusion to generate Santa Claus.\",\"keywords\":[\"stable diffusion\",\"generative art\",\"ai art\",\"santa claus\",\"ai training\"],\"author\":\"3ee Games\"},\"path\":\"/blog/ornamental-santa-diffusion\"},{\"meta\":{\"title\":\"Using Tiled as a level editor with Phaser\",\"date\":\"2021-02-07 20:55:50\",\"modifiedDate\":\"2023-04-25 20:55:50\",\"categories\":[\"tiled\",\"game development\",\"phaser\"],\"svg\":\"Scene\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703434770/img/tiled-poster.webp\",\"shortDescription\":\"When developing a game, look for ways to use tools that are proven to work and have solid integration with your game engine. This will allow you to focus on your game and not be distracted by creating custom tools to build your game's content.\",\"keywords\":[\"tiled\",\"game development\",\"phaser\",\"level design\",\"level editor\"],\"author\":\"Ryan Sadwick\",\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703434770/img/tiled-poster.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703434669/img/tiled-video.mp4\",\"type\":\"video/mp4\"}],\"tracks\":[{\"src\":\"/captions/tiled_phaser.vtt\",\"kind\":\"captions\",\"default\":true}]}]},\"path\":\"/blog/tiled-level-editor-phaser\"},{\"meta\":{\"title\":\"Flappy Jacob Prototype\",\"date\":\"2020-08-18\",\"modifiedDate\":\"2023-03-30 15:50:00\",\"categories\":[\"game development\",\"phaser\"],\"svg\":\"Balance\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703435222/img/flapper-poster.webp\",\"shortDescription\":\"Jamming on a flappy bird type game with my son called Flappy Jacob. We've implemented a heart point system, powerups based on a random number generator, bosses that have set patterns and attacks, and a scoring system.\",\"keywords\":[\"game jams\",\"game development\"],\"author\":\"Ryan Sadwick\",\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703435222/img/flapper-poster.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703435082/img/flapper-video.mp4\",\"type\":\"video/mp4\"}]}]},\"path\":\"/blog/flappy-jacob-prototype\"},{\"meta\":{\"title\":\"Phaser game with a React UI\",\"date\":\"2020-06-11 13:27:42\",\"modifiedDate\":\"2023-04-30 13:27:42\",\"youtubeId\":\"EDbW7lbtHOA\",\"categories\":[\"phaser\",\"react\",\"game development\"],\"svg\":\"Controller\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703433443/img/phaser-blog.webp\",\"shortDescription\":\"In this video, we show developing a game with Phaser and using React for the user interface. Using React to alleviate the burden of handling the UI in Canvas. RequestAnimationFrame can be expensive and should be used for the game only.\",\"keywords\":[\"phaser\",\"react\",\"game development\",\"javascript\",\"canvas\"],\"author\":\"Ryan Sadwick\",\"codePen\":{\"user\":\"halvves\",\"hash\":\"qQxPNo\"},\"videos\":[{\"width\":\"100%\",\"height\":600,\"controls\":true,\"poster\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703433443/img/phaser-blog.webp\",\"srcs\":[{\"src\":\"https://res.cloudinary.com/dxgyuy0iu/video/upload/v1703434143/img/phaser-video.mp4\",\"type\":\"video/mp4\"}]}]},\"path\":\"/blog/phaser-game-react-ui\"},{\"meta\":{\"title\":\"3ee Games YouTube Channel\",\"date\":\"2019-08-22 11:20:00\",\"modifiedDate\":\"2022-05-30 11:20:00\",\"categories\":[\"videos\",\"phaser\",\"game development\"],\"svg\":\"Youtube\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/editor_blender.jpg\",\"shortDescription\":\"We've created a mixture of game dev, playing games, and comedy Youtube channel for 3ee Games.  Our goal is to bring humorous and informative content to game developers, gamers, and folks that simply enjoy hearing a good story.\",\"keywords\":[\"youtube\",\"social media\",\"videos\",\"game development\"],\"author\":\"3ee Games\"},\"path\":\"/blog/3ee-games-youtube-channel\"},{\"meta\":{\"title\":\"Pong Kombat 2\",\"date\":\"2019-01-06 14:00:00\",\"modifiedDate\":\"2024-01-09 14:00:00 \",\"categories\":[\"pong kombat\",\"game development\"],\"svg\":\"Pong\",\"seoImage\":\"https://res.cloudinary.com/dxgyuy0iu/image/upload/v1703431871/img/pong-kombat-17.jpg\",\"shortDescription\":\"In the summer of 1996, Ryan Sadwick decided to make a sequel to Pong Kombat. While that was over 25 years ago, the experience provided an immense amount of insight into game design and development.\",\"keywords\":[\"ryan sadwick\",\"pong kombat\",\"game development\",\"klik and play\",\"clickteam\"],\"author\":\"Ryan Sadwick\"},\"path\":\"/blog/pong-kombat-2\"},{\"meta\":{\"title\":\"Shenanijam 2018\",\"date\":\"2018-06-01 16:45:00\",\"modifiedDate\":\"2022-05-30 16:45:00\",\"categories\":[\"game jams\"],\"svg\":\"Idea\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/shenanijam2.png\",\"shortDescription\":\"We are participating in The Shenanijam 2018.\",\"keywords\":[\"game jam\",\"game development\",\"shenanijam\"],\"author\":\"3ee Games\"},\"path\":\"/blog/shenanijam2018\"},{\"meta\":{\"title\":\"No Ads In Our Games\",\"date\":\"2018-05-26 15:00:20\",\"modifiedDate\":\"2023-04-20 15:00:20\",\"categories\":[\"games\",\"advertisements\"],\"svg\":\"Choice\",\"seoImage\":\"https://boatr.s3.amazonaws.com/static/media/uploads/blog/ads_suck.jpg\",\"shortDescription\":\"Read about why we do not have advertisements in our games.\",\"author\":\"3ee Games\"},\"path\":\"/blog/no-ads-in-our-games\"}]"}</script>
	<script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/games.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Divine Sun\",\"date\":\"2024-06-25\",\"categories\":[\"2d\",\"adventure\"],\"keywords\":[\"adventure\",\"games\",\"side scroll\",\"wizard\"],\"image\":\"ds_game.png\",\"description\":\"Step into the world of Kizomerre, a planet that once thrived under the harmonious yet discordant gaze of the Sun.\",\"content\":[{\"name\":\"Spells\",\"icon\":\"flask-sharp\",\"description\":\"Discover new spells to create all types of builds to devastate, support, and manipulate.\"},{\"name\":\"Questing\",\"icon\":\"receipt\",\"description\":\"Adventure through hundreds of different quests and explore the vast world.\"},{\"name\":\"Explore\",\"icon\":\"water\",\"description\":\"Explore the vast underwater caverns for difficult adventures with rare armor.\"}]},\"path\":\"/games/divine-sun\"},{\"meta\":{\"title\":\"Gorgons Legend\",\"date\":\"2022-06-25\",\"categories\":[\"2d\",\"arcade\",\"platformer\"],\"keywords\":[\"arcade\",\"platform\",\"2d game\",\"adventure\",\"games\"],\"image\":\"gorgons.png\",\"description\":\"The consequences of your choices shape the world around you. A journey that explores the dualities of good and evil, intricately woven into the tapestry of Greek Mythology.\",\"content\":[{\"name\":\"Adventures\",\"icon\":\"planet-sharp\",\"description\":\"As the game unfolders, you can play up to a total of 3 different characters, each with their own unique abilities and story.\"},{\"name\":\"Fast Paced\",\"icon\":\"trending-up-sharp\",\"description\":\"a mix of platformer with fast paced arcade action\"},{\"name\":\"Custom Builds\",\"icon\":\"git-branch-sharp\",\"description\":\"Customize and build each character with different attributes and abilities\"}]},\"path\":\"/games/cupids-balance\"},{\"meta\":{\"title\":\"Isle of Zultiki\",\"date\":\"2021-12-14\",\"categories\":[\"2d\",\"rpg\",\"action\"],\"keywords\":[\"role playing\",\"healing\",\"spells\",\"adventure\",\"games\"],\"image\":\"zultiki.png\",\"description\":\"Witness an enigmatic island, summoning souls from distant lands. These adventurers united by the island's allure, unfurl an epic saga of exploration and mystique.\",\"content\":[{\"name\":\"Professions\",\"icon\":\"bonfire-sharp\",\"description\":\"Enjoy up to 12 different professions to choose from that feature different spells and builds to customize.\"},{\"name\":\"Spells\",\"icon\":\"flask-sharp\",\"description\":\"Uncover new spells and abilities as you level up.  Use them strategically to your advantage.\"},{\"name\":\"Customize\",\"icon\":\"library-sharp\",\"description\":\"Build on your character's attributes and abilities to make them your own.\"}]},\"path\":\"/games/zultiki\"}]"}</script>
	<script type="application/json" sveltekit:data-type="data" sveltekit:data-url="/api/account.json">{"status":200,"statusText":"","headers":{"content-type":"application/json; charset=utf-8"},"body":"[{\"meta\":{\"title\":\"Accessibility\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-05-02\",\"shortDescription\":\"all of our games offer high levels of accessibility\",\"categories\":[\"accessibility\",\"control\",\"animation\",\"sound\",\"input\"],\"keywords\":[\"accessibility\",\"control\",\"animation\",\"sound\",\"input\"]},\"path\":\"/account/accessibility\"},{\"meta\":{\"title\":\"Code of Conduct\",\"shortDescription\":\"Code of conduct for playing games on 3ee platforms.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-14\",\"categories\":[\"behavior\",\"report\",\"ban\",\"cheat\",\"harass\"],\"keywords\":[\"behavior\",\"report\",\"ban\",\"cheat\",\"harass\"],\"svg\":\"Ocean\"},\"path\":\"/account/conduct\"},{\"meta\":{\"title\":\"Privacy Policy\",\"shortDescription\":\"Interactive privacy policy that contains data, protection, and privacy.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-30\",\"categories\":[\"privacy\",\"data\",\"protection\",\"collection\"],\"keywords\":[\"privacy\",\"data\",\"protection\",\"collection\"],\"menu\":[{\"name\":\"warm welcome\",\"icon\":\"☕\",\"url\":\"/account/privacy/#a-warm-welcome-from-3ee-games\"},{\"name\":\"info collected\",\"icon\":\"ℹ️\",\"url\":\"/account/privacy/#information-collection\"},{\"name\":\"shared info\",\"icon\":\"🫱🏾‍🫲🏼\",\"url\":\"/account/privacy/#using-your-information\"},{\"name\":\"Data & Protection\",\"icon\":\"🛡️\",\"url\":\"/account/privacy/#data-retention--protection\"},{\"name\":\"your privacy\",\"icon\":\"🔏\",\"url\":\"/account/privacy/#controlling-your-privacy\"},{\"name\":\"California Users\",\"icon\":\"🌅\",\"url\":\"/account/privacy/#california-user-information\"},{\"name\":\"Changes\",\"icon\":\"🧾\",\"url\":\"/account/privacy/#privacy-policy-updates\"}]},\"path\":\"/account/privacy\"},{\"meta\":{\"title\":\"Terms of Service\",\"shortDescription\":\"Check the terms of our service and what to expect when gaming on 3ee's platform.\",\"date\":\"2021-12-14\",\"modifiedDate\":\"2023-04-30\",\"categories\":[\"terms\",\"account\",\"copyright\",\"indemnity\"],\"keywords\":[\"terms\",\"account\",\"copyright\",\"indemnity\"],\"menu\":[{\"name\":\"who we are\",\"icon\":\"🌠\",\"url\":\"/account/terms/#who-we-are\"},{\"name\":\"age requirements\",\"icon\":\"ℹ️\",\"url\":\"/account/terms/#age-requirements\"},{\"name\":\"What you can expect\",\"icon\":\"🫱🏾‍🫲🏼\",\"url\":\"/account/terms/#what-you-can-expect\"},{\"name\":\"your account\",\"icon\":\"📒\",\"url\":\"/account/terms/#your-account\"},{\"name\":\"content\",\"icon\":\"✨\",\"url\":\"/account/terms/#content\"},{\"name\":\"software in services\",\"icon\":\"🔏\",\"url\":\"/account/terms/#software-in-3ee-games-services\"},{\"name\":\"copyright\",\"icon\":\"©️\",\"url\":\"/account/terms/#copyright\"},{\"name\":\"paid services\",\"icon\":\"🌅\",\"url\":\"/account/terms/#paid-services\"},{\"name\":\"Restrictions\",\"icon\":\"🚫\",\"url\":\"/account/terms/#usage-restrictions\"},{\"name\":\"termination\",\"icon\":\"💀\",\"url\":\"/account/terms/#termination\"},{\"name\":\"indemnity\",\"icon\":\"⚖️\",\"url\":\"/account/terms/#indemnity\"},{\"name\":\"as is\",\"icon\":\"🌅\",\"url\":\"/account/terms/#services-as-is\"},{\"name\":\"liability\",\"icon\":\"🧾\",\"url\":\"/account/terms/#limitation-of-liability\"},{\"name\":\"bonus level\",\"icon\":\"🏝️\",\"url\":\"/account/terms/#additional-important-information\"},{\"name\":\"contact us\",\"icon\":\"🛟\",\"url\":\"/account/terms/#contact-information\"}]},\"path\":\"/account/terms\"}]"}</script></div>
</body>

<script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
<script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</html>